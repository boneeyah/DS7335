{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/boneeyah/DS7335/blob/main/Case%20Study%207/CaseStudy7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "OZryWKHR3JAd"
      },
      "outputs": [],
      "source": [
        "#!pip install scikit-learn-intelex\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "tf.keras.utils.set_random_seed(807)\n",
        "tf.config.experimental.enable_op_determinism\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import tensorflow.keras.backend as K\n",
        "#from sklearnex import patch_sklearn\n",
        "#patch_sklearn()\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.model_selection import StratifiedKFold, GridSearchCV, cross_val_predict\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from numpy import random\n",
        "from itertools import product\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, classification_report, ConfusionMatrixDisplay\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "import xgboost as xgb\n",
        "from xgboost import DMatrix\n",
        "\n",
        "from numpy import random\n",
        "from itertools import product\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "import datetime\n",
        "import pydot\n",
        "import graphviz\n"
      ],
      "metadata": {
        "id": "HrVUsV_b8Ezp"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('drive')\n",
        "\n",
        "df = pd.read_csv(\"drive/My Drive/final_project(5).csv\")\n",
        "#df = pd.read_csv(\"/home/migue/Downloads/final_project(5).csv\")"
      ],
      "metadata": {
        "id": "hngzaeNL-EXs",
        "outputId": "613ad243-df5b-44d9-be80-8f4b05869b28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at drive; to attempt to forcibly remount, call drive.mount(\"drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()\n",
        "#there are NAs will need handling"
      ],
      "metadata": {
        "id": "kjzOue9y_SuK",
        "outputId": "2c900de1-90c1-47e9-a95c-aa04f43a666a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 160000 entries, 0 to 159999\n",
            "Data columns (total 51 columns):\n",
            " #   Column  Non-Null Count   Dtype  \n",
            "---  ------  --------------   -----  \n",
            " 0   x0      159974 non-null  float64\n",
            " 1   x1      159975 non-null  float64\n",
            " 2   x2      159962 non-null  float64\n",
            " 3   x3      159963 non-null  float64\n",
            " 4   x4      159974 non-null  float64\n",
            " 5   x5      159963 non-null  float64\n",
            " 6   x6      159974 non-null  float64\n",
            " 7   x7      159973 non-null  float64\n",
            " 8   x8      159979 non-null  float64\n",
            " 9   x9      159970 non-null  float64\n",
            " 10  x10     159957 non-null  float64\n",
            " 11  x11     159970 non-null  float64\n",
            " 12  x12     159964 non-null  float64\n",
            " 13  x13     159969 non-null  float64\n",
            " 14  x14     159966 non-null  float64\n",
            " 15  x15     159965 non-null  float64\n",
            " 16  x16     159974 non-null  float64\n",
            " 17  x17     159973 non-null  float64\n",
            " 18  x18     159960 non-null  float64\n",
            " 19  x19     159965 non-null  float64\n",
            " 20  x20     159962 non-null  float64\n",
            " 21  x21     159971 non-null  float64\n",
            " 22  x22     159973 non-null  float64\n",
            " 23  x23     159953 non-null  float64\n",
            " 24  x24     159972 non-null  object \n",
            " 25  x25     159978 non-null  float64\n",
            " 26  x26     159964 non-null  float64\n",
            " 27  x27     159970 non-null  float64\n",
            " 28  x28     159965 non-null  float64\n",
            " 29  x29     159970 non-null  object \n",
            " 30  x30     159970 non-null  object \n",
            " 31  x31     159961 non-null  float64\n",
            " 32  x32     159969 non-null  object \n",
            " 33  x33     159959 non-null  float64\n",
            " 34  x34     159959 non-null  float64\n",
            " 35  x35     159970 non-null  float64\n",
            " 36  x36     159973 non-null  float64\n",
            " 37  x37     159977 non-null  object \n",
            " 38  x38     159969 non-null  float64\n",
            " 39  x39     159977 non-null  float64\n",
            " 40  x40     159964 non-null  float64\n",
            " 41  x41     159960 non-null  float64\n",
            " 42  x42     159974 non-null  float64\n",
            " 43  x43     159963 non-null  float64\n",
            " 44  x44     159960 non-null  float64\n",
            " 45  x45     159971 non-null  float64\n",
            " 46  x46     159969 non-null  float64\n",
            " 47  x47     159963 non-null  float64\n",
            " 48  x48     159968 non-null  float64\n",
            " 49  x49     159968 non-null  float64\n",
            " 50  y       160000 non-null  int64  \n",
            "dtypes: float64(45), int64(1), object(5)\n",
            "memory usage: 62.3+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in df.columns:\n",
        "    if df[i].isna().sum() > 0:\n",
        "        print('{} has {}% NAs'.format(i,(df[i].isna().sum() / len(df))*100))"
      ],
      "metadata": {
        "id": "CC3yFJ6BzzOw",
        "outputId": "c1f4964a-ce6f-48a8-d48c-b8331608a53e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x0 has 0.01625% NAs\n",
            "x1 has 0.015625% NAs\n",
            "x2 has 0.02375% NAs\n",
            "x3 has 0.023125% NAs\n",
            "x4 has 0.01625% NAs\n",
            "x5 has 0.023125% NAs\n",
            "x6 has 0.01625% NAs\n",
            "x7 has 0.016875% NAs\n",
            "x8 has 0.013125% NAs\n",
            "x9 has 0.01875% NAs\n",
            "x10 has 0.026875% NAs\n",
            "x11 has 0.01875% NAs\n",
            "x12 has 0.0225% NAs\n",
            "x13 has 0.019375% NAs\n",
            "x14 has 0.021249999999999998% NAs\n",
            "x15 has 0.021875000000000002% NAs\n",
            "x16 has 0.01625% NAs\n",
            "x17 has 0.016875% NAs\n",
            "x18 has 0.025% NAs\n",
            "x19 has 0.021875000000000002% NAs\n",
            "x20 has 0.02375% NAs\n",
            "x21 has 0.018125% NAs\n",
            "x22 has 0.016875% NAs\n",
            "x23 has 0.029375000000000002% NAs\n",
            "x24 has 0.017499999999999998% NAs\n",
            "x25 has 0.01375% NAs\n",
            "x26 has 0.0225% NAs\n",
            "x27 has 0.01875% NAs\n",
            "x28 has 0.021875000000000002% NAs\n",
            "x29 has 0.01875% NAs\n",
            "x30 has 0.01875% NAs\n",
            "x31 has 0.024374999999999997% NAs\n",
            "x32 has 0.019375% NAs\n",
            "x33 has 0.025625000000000002% NAs\n",
            "x34 has 0.025625000000000002% NAs\n",
            "x35 has 0.01875% NAs\n",
            "x36 has 0.016875% NAs\n",
            "x37 has 0.014374999999999999% NAs\n",
            "x38 has 0.019375% NAs\n",
            "x39 has 0.014374999999999999% NAs\n",
            "x40 has 0.0225% NAs\n",
            "x41 has 0.025% NAs\n",
            "x42 has 0.01625% NAs\n",
            "x43 has 0.023125% NAs\n",
            "x44 has 0.025% NAs\n",
            "x45 has 0.018125% NAs\n",
            "x46 has 0.019375% NAs\n",
            "x47 has 0.023125% NAs\n",
            "x48 has 0.02% NAs\n",
            "x49 has 0.02% NAs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['x24'].value_counts()"
      ],
      "metadata": {
        "id": "TybuIbMLz6Ng",
        "outputId": "71b9e5c9-0144-40f3-ae88-9c6651623e89",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "asia       138965\n",
              "euorpe      16538\n",
              "america      4469\n",
              "Name: x24, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.bar(x=df['x24'].value_counts().index,height=df['x24'].value_counts().values)"
      ],
      "metadata": {
        "id": "ME56MKaIz7sN",
        "outputId": "d0254f8b-1e3e-4575-bd37-d4a826d110c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 3 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 94
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 550x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['x29'].value_counts()"
      ],
      "metadata": {
        "id": "P7rMlCalz9WH",
        "outputId": "298be3a3-4c81-4c76-b6ed-c5ce4638087a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "July       45569\n",
              "Jun        41329\n",
              "Aug        29406\n",
              "May        21939\n",
              "sept.      10819\n",
              "Apr         6761\n",
              "Oct         2407\n",
              "Mar         1231\n",
              "Nov          337\n",
              "Feb          140\n",
              "Dev           23\n",
              "January        9\n",
              "Name: x29, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#clean up month formatting to standard 3 letters\n",
        "df['x29'].replace(to_replace=['July','sept.','Dev','January'],value=['Jul','Sep','Dec','Jan'],inplace=True)"
      ],
      "metadata": {
        "id": "gB-gkjC2z_fK"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mo = ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
        "heights = []\n",
        "for i in mo:\n",
        "    x = df['x29'].to_list().count(i)\n",
        "    heights.append(x)\n",
        "plt.bar(x=mo,height=heights)"
      ],
      "metadata": {
        "id": "eZTNOL9P0CM3",
        "outputId": "7819c56e-5ab5-4c73-f47e-1df04e809657",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 12 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 97
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 550x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(1,3, figsize = (25, 5))\n",
        "plt.subplots_adjust(wspace=.18,hspace=1)\n",
        "fig.subplots_adjust(top = .96)\n",
        "sns.set(rc={'figure.figsize':(5.5,6)})\n",
        "sns.countplot(x = 'x29', data = df, hue = 'y', ax = axes[0]);\n",
        "sns.countplot(x = 'x30', data = df, hue = 'y', ax = axes[1]);\n",
        "sns.countplot(x = 'x24', data = df, hue = 'y', ax = axes[2]);\n",
        "\n",
        "fig.suptitle('Count plots for categorical features')"
      ],
      "metadata": {
        "id": "lCaK4Zy0zbuh",
        "outputId": "6e3d25c0-0666-4459-e0c3-93201c0a83d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        }
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0.98, 'Count plots for categorical features')"
            ]
          },
          "metadata": {},
          "execution_count": 98
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2500x500 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['x30'].value_counts()"
      ],
      "metadata": {
        "id": "_1LSKgy80ENF",
        "outputId": "c7bad62c-1d17-44fa-d60d-7b0ecda49761",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "wednesday    101535\n",
              "thurday       29429\n",
              "tuesday       27954\n",
              "friday          564\n",
              "monday          488\n",
              "Name: x30, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# thursday is incorrect\n",
        "df['x30'].replace(to_replace = 'thurday',value='thursday')\n",
        "days = ['monday','tuesday','wednesday','thursday','friday']\n",
        "d_heights = []\n",
        "for i in days:\n",
        "    x = df['x30'].to_list().count(i)\n",
        "    d_heights.append(x)\n",
        "plt.bar(x=days,height = d_heights)"
      ],
      "metadata": {
        "id": "3hFwgArL0GAB",
        "outputId": "6af4d0a5-b475-4b7b-cf50-b763c808481e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 5 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 100
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 550x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['x32'].value_counts()"
      ],
      "metadata": {
        "id": "WErTHaJ70Ia2",
        "outputId": "c16cbad9-ba67-4a17-e8de-461132aa9be3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.01%     40767\n",
              "-0.01%    34094\n",
              "0.0%      33923\n",
              "-0.0%     30492\n",
              "-0.02%     9924\n",
              "0.02%      7987\n",
              "-0.03%     1727\n",
              "0.03%       855\n",
              "-0.04%      138\n",
              "0.04%        55\n",
              "-0.05%        6\n",
              "0.05%         1\n",
              "Name: x32, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['x37'].value_counts()\n"
      ],
      "metadata": {
        "id": "r98Zehw50LS1",
        "outputId": "3dc8e210-c4d5-4d8a-efef-759a55992706",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "$-311.26     6\n",
              "$-336.77     6\n",
              "$237.4       6\n",
              "$72.42       6\n",
              "$341.26      6\n",
              "            ..\n",
              "$-505.21     1\n",
              "$770.07      1\n",
              "$74.62       1\n",
              "$-1082.96    1\n",
              "$-1229.34    1\n",
              "Name: x37, Length: 129198, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### x32 and x37 are actually numeric with string format (even though x32 has few \"levels\" or possible values)\n",
        "### x32 is in percentage, but don't think it needs to be transformed to proportion since data will be scaled later (will double check, but should make no difference)\n",
        "\n",
        "df['x32'] = df['x32'].transform(lambda x: float(str(x).replace('%','')))\n",
        "df['x37'] = df['x37'].transform(lambda x: float(str(x).replace('$','')))"
      ],
      "metadata": {
        "id": "-8HSIli70VDX"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#all significanlty less than 5%, should be no issue imputing,\n",
        "#imputing categorical features with modes\n",
        "# imputing continent with mode, then dates by mode grouped by continent\n",
        "\n",
        "print('imputing continent with mode: {}'.format(df['x24'].aggregate(pd.Series.mode)))\n",
        "df['x24'] = df['x24'].transform(lambda x: x.fillna(pd.Series.mode(x)[0]))\n",
        "\n",
        "print('imputing month with mode by cont: {}'.format(df[['x24','x29']].groupby(by='x24').aggregate(pd.Series.mode)))\n",
        "idx_29 = df.loc[df['x29'].isna(),:].index #saving NAs indices to quick check what they've been imputed with\n",
        "df['x29'] = df[['x24','x29']].groupby(by='x24').transform(lambda grp: grp.fillna(pd.Series.mode(grp)[0]))\n",
        "\n",
        "# will fix index showing on print later\n"
      ],
      "metadata": {
        "id": "qyAc5R1u209T",
        "outputId": "a013137f-0ac1-4a10-e7da-f0ac7001be15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "imputing continent with mode: 0    asia\n",
            "Name: x24, dtype: object\n",
            "imputing month with mode by cont:          x29\n",
            "x24         \n",
            "america  Jul\n",
            "asia     Jul\n",
            "euorpe   Jul\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[['x24','x29','x30']].groupby(by=['x24','x29']).aggregate(pd.Series.mode)\n",
        "# could just impute with wednesday since Wed is mode per month, but adding continent gives more context and different days for some months"
      ],
      "metadata": {
        "id": "2iV02zDI3Emu",
        "outputId": "d06329a5-5c65-4853-924f-734045d99b8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   x30\n",
              "x24     x29           \n",
              "america Apr  wednesday\n",
              "        Aug  wednesday\n",
              "        Feb    tuesday\n",
              "        Jul  wednesday\n",
              "        Jun  wednesday\n",
              "        Mar  wednesday\n",
              "        May  wednesday\n",
              "        Nov  wednesday\n",
              "        Oct  wednesday\n",
              "        Sep  wednesday\n",
              "asia    Apr  wednesday\n",
              "        Aug  wednesday\n",
              "        Dec  wednesday\n",
              "        Feb  wednesday\n",
              "        Jan  wednesday\n",
              "        Jul  wednesday\n",
              "        Jun  wednesday\n",
              "        Mar  wednesday\n",
              "        May  wednesday\n",
              "        Nov  wednesday\n",
              "        Oct  wednesday\n",
              "        Sep  wednesday\n",
              "euorpe  Apr  wednesday\n",
              "        Aug  wednesday\n",
              "        Dec  wednesday\n",
              "        Feb    tuesday\n",
              "        Jul  wednesday\n",
              "        Jun  wednesday\n",
              "        Mar  wednesday\n",
              "        May  wednesday\n",
              "        Nov  wednesday\n",
              "        Oct  wednesday\n",
              "        Sep  wednesday"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-86abbd1d-4b68-4ce2-a165-c8267c3b47ca\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>x30</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>x24</th>\n",
              "      <th>x29</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"10\" valign=\"top\">america</th>\n",
              "      <th>Apr</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Aug</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feb</th>\n",
              "      <td>tuesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Jul</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Jun</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mar</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>May</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Nov</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Oct</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sep</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"12\" valign=\"top\">asia</th>\n",
              "      <th>Apr</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Aug</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Dec</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feb</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Jan</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Jul</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Jun</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mar</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>May</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Nov</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Oct</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sep</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"11\" valign=\"top\">euorpe</th>\n",
              "      <th>Apr</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Aug</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Dec</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feb</th>\n",
              "      <td>tuesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Jul</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Jun</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mar</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>May</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Nov</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Oct</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sep</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-86abbd1d-4b68-4ce2-a165-c8267c3b47ca')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-f3cd4aaf-1b65-40a4-9a31-cef343795ed0\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f3cd4aaf-1b65-40a4-9a31-cef343795ed0')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-f3cd4aaf-1b65-40a4-9a31-cef343795ed0 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-86abbd1d-4b68-4ce2-a165-c8267c3b47ca button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-86abbd1d-4b68-4ce2-a165-c8267c3b47ca');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# impute day\n",
        "df['x30'] = df[['x24','x29','x30']].groupby(by=['x24','x29']).transform(lambda grp: grp.fillna(pd.Series.mode(grp)[0]))"
      ],
      "metadata": {
        "id": "HVQavir8IV9m"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[df['x24'] == 'america','x29'].value_counts()"
      ],
      "metadata": {
        "id": "MkQymqCW-cfl",
        "outputId": "4c075e86-b755-4d3f-9002-6d50b60e3a44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Jul    1279\n",
              "Jun    1183\n",
              "Aug     815\n",
              "May     595\n",
              "Sep     301\n",
              "Apr     179\n",
              "Oct      66\n",
              "Mar      37\n",
              "Nov      10\n",
              "Feb       4\n",
              "Name: x29, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mo = ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
        "heights = []\n",
        "for i in mo:\n",
        "    x = df['x29'].to_list().count(i)\n",
        "    heights.append(x)\n",
        "plt.bar(x=mo,height=heights)"
      ],
      "metadata": {
        "id": "CssNU827A5hU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mo = ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
        "heights = []\n",
        "for i in mo:\n",
        "    x = df.loc[df['x24'] == 'america','x29'].to_list().count(i)\n",
        "    heights.append(x)\n",
        "plt.bar(x=mo,height=heights)"
      ],
      "metadata": {
        "id": "lid34mckAT_T",
        "outputId": "f5c9a290-381f-4042-df75-e3d5406cde0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 12 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 139
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 550x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mo = ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
        "heights = []\n",
        "for i in mo:\n",
        "    x = df.loc[df['x24'] == 'euorpe','x29'].to_list().count(i)\n",
        "    heights.append(x)\n",
        "plt.bar(x=mo,height=heights)"
      ],
      "metadata": {
        "id": "6KEUzsjECLXg",
        "outputId": "9f4def9a-c7e7-4e7b-8811-da5c945e9c42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 12 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 144
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 550x600 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfIAAAH+CAYAAABnU4yrAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA1/ElEQVR4nO3de1iUdf7/8dcMB0VlAF0jC0swJTUPaCsSSBmVgqdOpB08pKtuZqbp/jzkqSyl0iyFPC1mZW2l67WtwNrBdWVzrbay7bhpQi1aUnkAFJTDzO8PL+bbOKQMp+GDz8d1eeHc87nvz/ueuWdec3/ue+6xOBwOhwAAgJGs3i4AAADUHEEOAIDBCHIAAAxGkAMAYDCCHAAAgxHkAAAYjCAHAMBgBDkAAAYjyAEAMJivtwvwFofDIbvdexe1s1otXu2fGqihsdXg7f6pgRoaUw1Wq0UWi6VabS/YILfbHTp69KRX+vb1tSokpKUKC4tVXm6nBmq44Gvwdv/UQA2NrYbWrVvKx6d6Qc7QOgAABiPIAQAwGEEOAIDBCHIAAAxGkAMAYDCCHAAAgxHkAAAYjCAHAMBgBDkAAAYjyAEAMBhBDgCAwQhyAAAMRpADAGAwghwAAIMR5AAAGIwgBwDAYAQ5AAAGI8gBADAYQQ4AgMF8vV0AgKbHarXIarVUu72Pj9Xlb3XZ7Q7Z7Q6P5gGaGoIcQJ2yWi0KDm7hcShLks0W4FH7igq7jh8vJsxxQSPIAdQpq9UiHx+rlr38kQ7mF9VbP2GhgZp5dx9ZrRaCHBc0ghxAvTiYX6QDhwq8XQbQ5HGyGwAABiPIAQAwGEEOAIDBCHIAAAxGkAMAYDCCHAAAgxHkAAAYjCAHAMBgBDkAAAYjyAEAMBhBDgCAwQhyAAAMRpADAGAwghwAAIMR5AAAGIwgBwDAYAQ5AAAGI8gBADAYQQ4AgMEIcgAADEaQAwBgMIIcAACDEeQAABiMIAcAwGAEOQAABiPIAQAwGEEOAIDBCHIAAAxGkAMAYDCCHAAAgxHkAAAYjCAHAMBgBDkAAAYjyAEAMBhBDgCAwQhyAAAMRpADAGAwX28XAKBuWa0WWa0Wj+bx8bG6/K0uu90hu93h0TwA6hZBDjQhVqtFwcEtPA7kSjZbgEftKyrsOn68mDAHvIggB5oQq9UiHx+rlr38kQ7mF9VrX2GhgZp5dx9ZrRaCHPAighxogg7mF+nAoQJvlwGgAXCyGwAABiPIAQAwGEEOAIDBCHIAAAxGkAMAYDCCHAAAgxHkAAAYjCAHAMBgBDkAAAYjyAEAMBhBDgCAwQhyAAAMRpADAGAwghwAAIMR5AAAGIwgBwDAYLUK8pMnTyo+Pl6RkZH67LPPXO7bvHmzBg4cqO7du2vYsGHauXOn2/xFRUWaO3eu+vbtq6ioKE2dOlU//vijW7uPP/5YI0aMUI8ePTRgwACtW7dODoejNqUDANAk1CrIn3vuOVVUVLhNz8zM1Pz585WYmKj169erV69emjJlij755BOXdtOmTdPu3bu1aNEiLVu2TLm5uZowYYLKy8udbb777juNHz9ebdu21dq1azVmzBitXLlSGzZsqE3pAAA0Cb41nfHAgQN65ZVXNGvWLC1cuNDlvpUrV2rw4MGaNm2aJKlfv37at2+f0tLStH79eknS3r179e677yo9PV1xcXGSpPDwcCUlJemtt95SUlKSJCk9PV0hISF6+umn5e/vr5iYGB09elRr1qzRqFGj5O/vX9NVAADAeDXeI3/sscc0cuRIhYeHu0zPy8vTt99+q8TERJfpSUlJ2rNnj0pLSyVJ2dnZstlsio2NdbaJiIhQly5dlJ2d7ZyWnZ2thIQEl8BOSkpSYWGh9u7dW9PyAQBoEmoU5Nu3b9e+fft0//33u92Xk5MjSW4B37FjR5WVlSkvL8/ZLjw8XBaLxaVdRESEcxnFxcX64YcfFBER4dbGYrE42wEAcKHyeGi9pKREKSkpmj59ulq1auV2f0FBgSTJZrO5TK+8XXl/YWGhAgMD3eYPCgrS559/LunMyXBVLcvf318BAQHOZdWUr693Ttr38bG6/KUGaqirGryxHmf32dA11FV/TW1boAbza6guj4N89erVatOmjW677bb6qKfBWK0WhYS09GoNNluAV/unBmqoC96uu6779/b6UAM1eMqjID906JA2bNigtLQ0595ycXGx8+/JkycVFBQk6czedNu2bZ3zFhYWSpLzfpvNpsOHD7v1UVBQ4GxTucde2Vel0tJSlZSUONvVhN3uUGFhcY3nrw0fH6tstgAVFpaoosJODdRQZzVULqshnV13Q9dQV89dU9sWqMHsGmy2gGqPBngU5AcPHlRZWZkmTpzodt/o0aPVs2dPLV++XNKZY+C/PLadk5MjPz8/tW/fXtKZ49x79uyRw+FwOU6em5urzp07S5JatGihdu3auR0Lz83NlcPhcDt27qnycu9sIJUqKuzUQA2Nqoaa8Hbddd2/t9eHGqjBUx4N/nfp0kUvvviiy785c+ZIkh555BEtXLhQ7du3V4cOHbR9+3aXebOyshQTE+M8+zw+Pl4FBQXas2ePs01ubq6+/PJLxcfHO6fFx8drx44dKisrc1mWzWZTVFSU52sMAEAT4tEeuc1mU3R0dJX3devWTd26dZMkPfDAA5o5c6Yuu+wyRUdHKysrS59++qk2bdrkbB8VFaW4uDjNnTtXs2bNUrNmzbRixQpFRkbqpptucrYbP368tm3bphkzZujOO+/Uvn37lJ6erunTp/MdcgDABa/GF4Q5lyFDhqikpETr16/XunXrFB4ertTUVLc96GeeeUZLly7VggULVF5erri4OM2bN0++vv9X1uWXX6709HSlpKRo4sSJat26taZOnapx48bVR+kAABil1kEeHR2tr7/+2m16cnKykpOTzzlvYGCglixZoiVLlpyzXe/evfX666/Xqk4AAJqixv8FOQAA8KsIcgAADEaQAwBgMIIcAACDEeQAABiMIAcAwGAEOQAABiPIAQAwGEEOAIDBCHIAAAxGkAMAYDCCHAAAgxHkAAAYjCAHAMBgBDkAAAYjyAEAMBhBDgCAwQhyAAAMRpADAGAwghwAAIMR5AAAGIwgBwDAYAQ5AAAGI8gBADAYQQ4AgMEIcgAADEaQAwBgMIIcAACDEeQAABiMIAcAwGAEOQAABiPIAQAwGEEOAIDBCHIAAAxGkAMAYDCCHAAAgxHkAAAYjCAHAMBgBDkAAAYjyAEAMBhBDgCAwQhyAAAMRpADAGAwghwAAIMR5AAAGIwgBwDAYAQ5AAAGI8gBADAYQQ4AgMEIcgAADEaQAwBgMIIcAACDEeQAABiMIAcAwGAEOQAABiPIAQAwGEEOAIDBCHIAAAxGkAMAYDCCHAAAgxHkAAAYjCAHAMBgBDkAAAYjyAEAMBhBDgCAwQhyAAAMRpADAGAwghwAAIMR5AAAGIwgBwDAYAQ5AAAGI8gBADAYQQ4AgMEIcgAADEaQAwBgMIIcAACDEeQAABiMIAcAwGAEOQAABiPIAQAwGEEOAIDBPAryXbt26Z577lG/fv101VVXKSEhQUuXLlVRUZFLu7///e8aNmyYunfvroEDB+rPf/6z27JKS0v1xBNPKDY2Vr169dK9996rnJwct3YHDhzQvffeq169eik2NlZPPvmkSktLPVxNAACaJl9PGh8/flw9evTQqFGjFBwcrP3792vVqlXav3+/NmzYIEn68MMPNWXKFN1+++2aO3eu3nvvPT388MNq2bKlBg0a5FzWY489pqysLM2ePVuhoaFas2aNxo4dq8zMTAUGBkqSCgoKNGbMGHXo0EGrVq1Sfn6+UlJSdOrUKS1YsKAOHwYAAMzkUZAPHz7c5XZ0dLT8/f01f/585efnKzQ0VKtXr1aPHj306KOPSpL69eunvLw8rVy50hnkhw8f1pYtW7Rw4ULdfvvtkqTu3btrwIABevXVVzVhwgRJ0quvvqqTJ08qNTVVwcHBkqSKigo98sgjmjRpkkJDQ2u18gAAmK7Wx8grA7asrEylpaV6//33Xfa8JSkpKUkHDhzQwYMHJUnvvvuu7Ha7S7vg4GDFxsYqOzvbOS07O1sxMTHOPiQpMTFRdrtdu3fvrm3pAAAYz6M98koVFRUqLy/XN998o7S0NF1//fUKCwvTN998o7KyMkVERLi079ixoyQpJydHYWFhysnJUZs2bRQUFOTWbsuWLc7bOTk5uu2221za2Gw2tW3btsrj6Z7y9fXOuX4+PlaXv9RADXVVgzfW4+w+G7qGX+vPYrHIarVUezmVbf38fDxaB7vdIYfDUe3259LUtkdqaBg1CvIBAwYoPz9fktS/f38tX75c0plj2tKZsP2lytuV9xcWFjqPg5/drrJNZbuzlyVJQUFBLu1qwmq1KCSkZa2WUVs2W4BX+6cGaqgL3q771/q32x0eBXmlVq2ae9S+pv2ci7cfU2poXDWcT42CfN26dSopKdE333yj1atX6/e//72ef/75uq6tXtntDhUWFnulbx8fq2y2ABUWlqiiwk4N1FBnNVQuqyGdXXdD11DV41ZZw7KXP9LB/KJfmbP2wkIDNfPuPnW2/TS17ZEaas5mC6j2aECNgvzKK6+UJEVFRal79+4aPny43n77bV1xxRWS5PZ1tMLCQklyDqXbbDadOHHCbbmFhYUuw+02m81tWdKZPfuzh+VrorzcOxtIpYoKOzVQQ6OqoSa8Xfe5+j+YX6QDh2o3elfbGhrD8qjB7BrOp9aD/5GRkfLz89P//vc/XXbZZfLz83M7fl15u/LYeUREhH7++We34fGcnByX4+sRERFuyyoqKtJPP/3kdhweAIALUa2D/D//+Y/KysoUFhYmf39/RUdH680333Rpk5WVpY4dOyosLEySFBcXJ6vVqrfeesvZpqCgQO+++67i4+Od0+Lj4/Wvf/3LuUcvSdu3b5fValVsbGxtSwcAwHgeDa1PmTJFV111lSIjI9W8eXP997//VXp6uiIjI3XDDTdIku677z6NHj1aixYtUmJiot5//31lZGRoxYoVzuVcfPHFuv322/Xkk0/KarUqNDRUa9euVWBgoEaOHOlsN3LkSL300ku6//77NWnSJOXn5+vJJ5/UyJEj+Q45AADyMMh79OihrKwsrVu3Tg6HQ5deeqmSk5M1fvx4+fv7S5KuvvpqrVq1Ss8884y2bNmiSy65RI899pgSExNdljVv3jy1bNlSy5cv18mTJ9W7d289//zzLmezBwUF6YUXXtDixYt1//33q2XLlrr99ts1ffr0Olh1AADM51GQT5w4URMnTjxvu4SEBCUkJJyzjb+/v2bNmqVZs2ads13Hjh21ceNGT8oEAOCC0fi/6Q4AAH4VQQ4AgMEIcgAADEaQAwBgMIIcAACDEeQAABiMIAcAwGAEOQAABiPIAQAwGEEOAIDBCHIAAAxGkAMAYDCCHAAAgxHkAAAYjCAHAMBgBDkAAAYjyAEAMBhBDgCAwQhyAAAMRpADAGAwghwAAIMR5AAAGIwgBwDAYAQ5AAAGI8gBADAYQQ4AgMEIcgAADEaQAwBgMIIcAACDEeQAABiMIAcAwGAEOQAABiPIAQAwGEEOAIDBCHIAAAxGkAMAYDCCHAAAgxHkAAAYjCAHAMBgBDkAAAYjyAEAMBhBDgCAwQhyAAAMRpADAGAwghwAAIMR5AAAGIwgBwDAYAQ5AAAGI8gBADAYQQ4AgMEIcgAADEaQAwBgMIIcAACDEeQAABiMIAcAwGAEOQAABiPIAQAwGEEOAIDBCHIAAAxGkAMAYDCCHAAAgxHkAAAYjCAHAMBgBDkAAAbz9XYBQFNjtVpktVqq3d7Hx+ryt7rsdofsdodH8wBoeghyoA5ZrRYFB7fwOJQlyWYL8Kh9RYVdx48XE+bABY4gB+qQ1WqRj49Vy17+SAfzi+qtn7DQQM28u4+sVgtBDlzgCHKgHhzML9KBQwXeLgPABYCT3QAAMBhBDgCAwQhyAAAMRpADAGAwghwAAIMR5AAAGIwgBwDAYAQ5AAAGI8gBADAYQQ4AgMEIcgAADEaQAwBgMI+C/G9/+5vuu+8+xcfHq1evXho+fLi2bNkih8P115c2b96sgQMHqnv37ho2bJh27tzptqyioiLNnTtXffv2VVRUlKZOnaoff/zRrd3HH3+sESNGqEePHhowYIDWrVvn1h8AABcqj4J848aNCggI0OzZs7V69WrFx8dr/vz5SktLc7bJzMzU/PnzlZiYqPXr16tXr16aMmWKPvnkE5dlTZs2Tbt379aiRYu0bNky5ebmasKECSovL3e2+e677zR+/Hi1bdtWa9eu1ZgxY7Ry5Upt2LChdmsNAEAT4dHPmK5evVqtW7d23o6JidHx48f1/PPPa/LkybJarVq5cqUGDx6sadOmSZL69eunffv2KS0tTevXr5ck7d27V++++67S09MVFxcnSQoPD1dSUpLeeustJSUlSZLS09MVEhKip59+Wv7+/oqJidHRo0e1Zs0ajRo1Sv7+/nXxGAAAYCyP9sh/GeKVunTpohMnTqi4uFh5eXn69ttvlZiY6NImKSlJe/bsUWlpqSQpOztbNptNsbGxzjYRERHq0qWLsrOzndOys7OVkJDgEthJSUkqLCzU3r17PSkdAIAmqdYnu3300UcKDQ1Vq1atlJOTI+nM3vUvdezYUWVlZcrLy5Mk5eTkKDw8XBaLxaVdRESEcxnFxcX64YcfFBER4dbGYrE42wEAcCHzaGj9bB9++KGysrI0a9YsSVJBQYEkyWazubSrvF15f2FhoQIDA92WFxQUpM8//1zSmZPhqlqWv7+/AgICnMuqDV9f75y07+NjdflLDU2nhoZel7P788Zj6e0aquqvMdRQm+U0pdcENdS/Ggf54cOHNX36dEVHR2v06NF1WVODsFotCglp6dUabLYAr/ZPDY2rhppoDHV7uwZv918fNTTFdaKG+lOjIC8sLNSECRMUHBysVatWyWo984klKChI0pm96bZt27q0/+X9NptNhw8fdltuQUGBs03lHnvlnnml0tJSlZSUONvVlN3uUGFhca2WUVM+PlbZbAEqLCxRRYWdGppQDZXLayhn193Q/TeGGqp67hpDDTXRFF8T1FAzNltAtUcDPA7yU6dOadKkSSoqKtJrr73mMkReeTw7JyfH5dh2Tk6O/Pz81L59e2e7PXv2yOFwuBwnz83NVefOnSVJLVq0ULt27dyOhefm5srhcLgdO6+J8nLvbCCVKirs1EANtdIY6vZ2Dd7uvz5qaIrrRA31x6PB//Lyck2bNk05OTn64x//qNDQUJf727dvrw4dOmj79u0u07OyshQTE+M8+zw+Pl4FBQXas2ePs01ubq6+/PJLxcfHO6fFx8drx44dKisrc1mWzWZTVFSUJ6UDANAkebRH/sgjj2jnzp2aPXu2Tpw44XKRl65du8rf318PPPCAZs6cqcsuu0zR0dHKysrSp59+qk2bNjnbRkVFKS4uTnPnztWsWbPUrFkzrVixQpGRkbrpppuc7caPH69t27ZpxowZuvPOO7Vv3z6lp6dr+vTpfIccAAB5GOS7d++WJKWkpLjdt2PHDoWFhWnIkCEqKSnR+vXrtW7dOoWHhys1NdVtD/qZZ57R0qVLtWDBApWXlysuLk7z5s2Tr+//lXT55ZcrPT1dKSkpmjhxolq3bq2pU6dq3LhxNVlXAACaHI+C/O9//3u12iUnJys5OfmcbQIDA7VkyRItWbLknO169+6t119/vdo1AgBwIWn8X5ADAAC/iiAHAMBgBDkAAAYjyAEAMBhBDgCAwQhyAAAMRpADAGAwghwAAIMR5AAAGIwgBwDAYAQ5AAAGI8gBADAYQQ4AgMEIcgAADEaQAwBgMIIcAACDEeQAABiMIAcAwGAEOQAABiPIAQAwGEEOAIDBCHIAAAxGkAMAYDCCHAAAgxHkAAAYjCAHAMBgBDkAAAYjyAEAMBhBDgCAwQhyAAAMRpADAGAwghwAAIMR5AAAGIwgBwDAYAQ5AAAGI8gBADAYQQ4AgMEIcgAADEaQAwBgMIIcAACDEeQAABiMIAcAwGAEOQAABiPIAQAwGEEOAIDBCHIAAAxGkAMAYDCCHAAAgxHkAAAYjCAHAMBgBDkAAAYjyAEAMBhBDgCAwQhyAAAMRpADAGAwghwAAIMR5AAAGIwgBwDAYAQ5AAAGI8gBADAYQQ4AgMEIcgAADEaQAwBgMIIcAACDEeQAABiMIAcAwGAEOQAABiPIAQAwGEEOAIDBCHIAAAzm6+0CAKCpslotslot1W7v42N1+VtddrtDdrvDo3nQdBDkAFAPrFaLgoNbeBzKkmSzBXjUvqLCruPHiwnzCxRBDgD1wGq1yMfHqmUvf6SD+UX11k9YaKBm3t1HVquFIL9AEeQAUI8O5hfpwKECb5eBJoyT3QAAMBhBDgCAwQhyAAAMRpADAGAwghwAAIMR5AAAGIwgBwDAYB4H+XfffacFCxZo+PDh6tq1q4YMGVJlu82bN2vgwIHq3r27hg0bpp07d7q1KSoq0ty5c9W3b19FRUVp6tSp+vHHH93affzxxxoxYoR69OihAQMGaN26dXI4uPABAAAeB/n+/fu1a9cuXX755erYsWOVbTIzMzV//nwlJiZq/fr16tWrl6ZMmaJPPvnEpd20adO0e/duLVq0SMuWLVNubq4mTJig8vJyZ5vvvvtO48ePV9u2bbV27VqNGTNGK1eu1IYNGzwtHQCAJsfjK7tdf/31uuGGGyRJs2fP1ueff+7WZuXKlRo8eLCmTZsmSerXr5/27duntLQ0rV+/XpK0d+9evfvuu0pPT1dcXJwkKTw8XElJSXrrrbeUlJQkSUpPT1dISIiefvpp+fv7KyYmRkePHtWaNWs0atQo+fv712jFAQBoCjzeI7dazz1LXl6evv32WyUmJrpMT0pK0p49e1RaWipJys7Ols1mU2xsrLNNRESEunTpouzsbOe07OxsJSQkuAR2UlKSCgsLtXfvXk/LBwCgSanza63n5ORIOrN3/UsdO3ZUWVmZ8vLy1LFjR+Xk5Cg8PFwWi+tP/EVERDiXUVxcrB9++EERERFubSwWi3JychQdHV3jWn19vXOuX01/qpAaGn8NDb0uZ/fnjcfS2zVU1R811H45Tel1aWoN1VXnQV5QcObHAWw2m8v0ytuV9xcWFiowMNBt/qCgIOdwfVFRUZXL8vf3V0BAgHNZNWG1WhQS0rLG89cFT3+qkBqadg010Rjq9nYN3u6/qdbQFNfJ1BrO54L99TO73aHCwmKv9O3jY5XNFqDCwhJVVNipoQnVULm8hnJ23Q3df2Oooarnjhpqrim+Lk2swWYLqPZoQJ0HeVBQkKQze9Nt27Z1Ti8sLHS532az6fDhw27zFxQUONtU7rFX7plXKi0tVUlJibNdTZWXe2cDqVRRYacGaqiVxlC3t2vwdv9NtYamuE6m1nA+dT74X3k8u/I4d6WcnBz5+fmpffv2zna5ublu3wfPzc11LqNFixZq166d27Iq5zv72DkAABeaOg/y9u3bq0OHDtq+fbvL9KysLMXExDjPPo+Pj1dBQYH27NnjbJObm6svv/xS8fHxzmnx8fHasWOHysrKXJZls9kUFRVV1+UDAGAUj4fWS0pKtGvXLknSoUOHdOLECWdo9+3bV61bt9YDDzygmTNn6rLLLlN0dLSysrL06aefatOmTc7lREVFKS4uTnPnztWsWbPUrFkzrVixQpGRkbrpppuc7caPH69t27ZpxowZuvPOO7Vv3z6lp6dr+vTpfIccAHDB8zjIjxw5ogcffNBlWuXtF198UdHR0RoyZIhKSkq0fv16rVu3TuHh4UpNTXXbg37mmWe0dOlSLViwQOXl5YqLi9O8efPk6/t/ZV1++eVKT09XSkqKJk6cqNatW2vq1KkaN25cTdYXAIAmxeMgDwsL09dff33edsnJyUpOTj5nm8DAQC1ZskRLliw5Z7vevXvr9ddf96hOAAAuBI3/m+4AAOBXEeQAABiMIAcAwGAEOQAABiPIAQAwGEEOAIDBCHIAAAxGkAMAYDCCHAAAgxHkAAAYjCAHAMBgBDkAAAYjyAEAMBhBDgCAwQhyAAAM5vHvkQONmdVqkdVqqXZ7Hx+ry9/qstsdstsdHs0DAPWBIEeTYbVaFBzcwuNQliSbLcCj9hUVdh0/XkyYA/A6ghxNhtVqkY+PVcte/kgH84vqrZ+w0EDNvLuPrFYLQQ7A6whyNDkH84t04FCBt8sAgAbByW4AABiMIAcAwGAEOQAABiPIAQAwGEEOAIDBCHIAAAxGkAMAYDCCHAAAgxHkAAAYjCAHAMBgBDkAAAYjyAEAMBhBDgCAwQhyAAAMRpADAGAwghwAAIMR5AAAGIwgBwDAYAQ5AAAGI8gBADAYQQ4AgMEIcgAADEaQAwBgMIIcAACDEeQAABiMIAcAwGAEOQAABiPIAQAwGEEOAIDBCHIAAAxGkAMAYDCCHAAAgxHkAAAYjCAHAMBgBDkAAAYjyAEAMBhBDgCAwQhyAAAMRpADAGAwghwAAIMR5AAAGIwgBwDAYAQ5AAAG8/V2AQCA+mO1WmS1Wqrd3sfH6vK3uux2h+x2h0fzoG4Q5ADQRFmtFgUHt/A4lCXJZgvwqH1FhV3HjxcT5l5AkANAE2W1WuTjY9Wylz/SwfyieusnLDRQM+/uI6vVQpB7AUEOAE3cwfwiHThU4O0yUE842Q0AAIMR5AAAGIwgBwDAYAQ5AAAGI8gBADAYQQ4AgMEIcgAADMb3yFFnuBQkADQ8ghx1gktBAoB3EOSoE1wKEgC8gyBHneJSkADQsDjZDQAAgxHkAAAYjCAHAMBgRgT5gQMHdO+996pXr16KjY3Vk08+qdLSUm+XBQCA1zX6k90KCgo0ZswYdejQQatWrVJ+fr5SUlJ06tQpLViwwNvlAQDOg2tM1K9GH+SvvvqqTp48qdTUVAUHB0uSKioq9Mgjj2jSpEkKDQ31boEAgF/FNSbqX6MP8uzsbMXExDhDXJISExO1cOFC7d69W7feeqv3igMAnBPXmKh/jT7Ic3JydNttt7lMs9lsatu2rXJycrxUVePD0BWAxoxrTNQfi8PhaNTvyt26ddODDz6oiRMnukwfMmSIoqKitHjx4hot1+Go20CyVD9DJUlWq1V2u92jec71TFmtFlk8LaIGfu1xs1jOrNPxotMqr/BsvTzh62NVcGAz2e12t8eDGhqu/8ZQQ2N+HqihcdVQWYen6vp92rO+q/+e3uj3yOuLxWKRj0/9B9+5WK1GfGnAxfket+DAZg1Sx7keO2pouP4bQw2N+XmghsZVQ2NYXn1o9BXabDYVFbkfVykoKFBQUJAXKgIAoPFo9EEeERHhdiy8qKhIP/30kyIiIrxUFQAAjUOjD/L4+Hj961//UmFhoXPa9u3bZbVaFRsb68XKAADwvkZ/sltBQYEGDx6s8PBwTZo0yXlBmKFDh3JBGADABa/RB7l05hKtixcv1t69e9WyZUsNHz5c06dPl7+/v7dLAwDAq4wIcgAAULVGf4wcAAD8OoIcAACDEeQAABiMIAcAwGAEOQAABiPIAQAwGEFex1atWqWoqCiv9R0ZGen2b8iQIdWa//3331dkZKQ+++yzWvXfv3//Kn8xaOTIkYqMjNTs2bNrtPyaGDZsmCIjI/Xhhx/We1+Ncf29uT2erSa11EX9DbkNVOWvf/2rbr/9dvXp00e9e/dWYmKiHn74YR05csRr9YwcOVJRUVGKiorSiBEj9Je//MWjZRQWFmrVqlX65ptvztu28nVx9913u933+OOP6/rrr/eo75r45XvjlVdeqT59+mjo0KF69NFHdeDAgXrvv75dsL9+1lQ1b95cL7zwgtu0huLn56djx47p3//+t6Kjo53TDx06pE8++UQtWrRosFr279+vr7/+WpK0bds2XX311fXeZ2Naf3hnG/il9evXa/ny5Ro7dqymTp0qh8Oh/fv3a9u2bfrxxx/Vpk2bBq1n8eLFevnll3Xbbbdp8uTJslgsevPNNzV79mx99tlnmj9/frWWU1hYqNTUVHXq1ElXXHFFteb58MMP9f7777u8LhrSL98bT548qX379um1117T66+/rscff1zDhw/3Sl11gSBvYqxWq3r16uW1/v38/BQTE6PMzEyXF2xmZqY6depUJz8JeOrUqWp9ONm2bZusVqt++9vfavv27Zo3b578/Pzqtf+GWH9UX31tA9X10ksv6ZZbbnEZhbn22mv1u9/9zuPfua6tHTt2aNOmTZoyZYoeeOAB5/T+/fvroosuUlpammJjY+tlD7lFixa64oor9Nxzz3ktyM9+b4yNjdVdd92liRMn6uGHH1bv3r3Vvn17r9RWW7yr1LNly5Zp6NChioqKUv/+/fXQQw/pxx9/dGkzatQoTZo0Sdu3b9fAgQMVFRWl0aNH63//+1+d1vKPf/xDycnJ6tGjh/r166eFCxequLjYrd3Ro0c1ZcoU9erVS3FxcVqzZo1H/QwZMkRvvvmmysrKnNMyMjLchvgPHDig6dOn69prr1XPnj2VlJSkDRs2uLzBHTx4UJGRkdq6davmzZun6OhoJScnn7cGh8OhjIwM9evXT/fee6+OHz+uf/7zn877Kw8j7Nq165zrWjm0++mnn2rEiBHq3r27Xn755QZb/1tvvVUzZsxw6+Opp55SXFycKioqzvtYnL3OZx86mTx5skaNGuW2zl9//bXuvPNO9ezZU0OGDHF5/GqrurXUxvm2ga1btyoyMlJHjx51mW/48OFuhz9effVVDRgwQD179tS9996rL7/80rldnkthYaEuuuiiKu87+0Pd1q1bNXToUHXv3l39+/fXihUrXJ7fyno/+eQTjR49Wj179tT111+vLVu2VOvxeOGFFxQUFKRx48a53Td+/HgFBQW5jObt3btX48aNU+/evRUVFaXk5GTt3r1bBw8eVEJCgiTpwQcfdA5ZHzx48Jz9T548We+9954+/vjjX21z6NAhTZ06VX369FGvXr00fvx454iKJM2ePbvKQ4U7d+5UZGSk2y9lnk+zZs00f/58lZWVafPmzc7p53suJCk/P1//7//9P11zzTXq0aOHBg0a5DYa2lAI8np25MgRTZo0SWvXrtXDDz+sQ4cOadSoUSovL3dp99VXXyk9PV0zZ87U0qVL9b///U9/+MMfatRneXm5yz+Hw6Ht27frvvvuU+fOnZWamqo//OEPevvtt/Xwww+7zT9//ny1b99eq1at0tChQ7VixQr96U9/qnb/AwYMUGlpqXbv3i1J+uabb/T1118rKSnJpd2PP/6o8PBwLVy4UOvWrdMdd9yhtLQ0Pffcc27LfPrpp+VwOLR8+fJqPS4ff/yxDh06pCFDhiguLk7BwcHKyMio0bqWlZVpxowZGjZsmNavX3/eX92ry/VPTk7WO++8o6KiIue0iooKvfHGG7rlllvk4+Nz3seiJsrKyjRz5kzdeuutSk1NVevWrTV16lQdO3asXvqrD9XdBs5nx44dWrhwoWJjY5WamqqYmBhNmzatWvN269ZNr776qjZv3qyffvrpV9s9//zzmjdvnvPD5IQJE/Tiiy9qxYoVbm0feughZy3R0dF6+OGHlZ2dfc46ysvLtXfvXkVHR6tly5Zu97ds2VLR0dHau3evysvL9dFHH2nUqFEqLS3VY489plWrVikhIUHff/+9LrroIqWmpjpree211/Taa6/96geWSgMGDFDXrl2VlpZW5f0nTpzQqFGj9OWXX+qRRx7RU089pWPHjumee+7RDz/8IEkaPHiw9u/fr3379rnMm5GRoW7dutXop62vuOIKhYaGau/evZKq91wcO3ZMI0aM0AcffKDp06dr7dq1Gjt2rPLz8z3uvy4wtF7Pli5d6vx/RUWFoqKiFB8fr/fee09xcXHO+4qKivSXv/xFrVu3liQVFxdrzpw5Onz4sC6++OJq91dcXKxu3bq5THviiSe0cuVKJSUl6fHHH3dOb9u2rSZOnKjJkyerU6dOzun9+vXTrFmzJJ0Zdjty5IhWr16tESNGVGtoOCAgQNdff70yMzN13XXXKSMjQ1FRUW7DVjExMYqJiZF0Zu+pT58+OnXqlHP475euvPJKl9rPJyMjQ82aNdNNN90kPz8/DRw4UH/961918uRJlzey6qxrWVmZpk+f7hbEDbH+Q4cO1RNPPKFt27bprrvukiTt2rVLP/30k2677bZqPx6eqgzya6+9VpIUHh6uhIQEZWdnG3MssbrbwPmsXr1a/fr102OPPSbpzHZSXl6uZ5999rzzLly4UFOmTNG8efMkSWFhYRowYIDGjh2rsLAwSWcCbOXKlfrd736nhx56SNKZYV8/Pz+lpKRo/PjxCgkJcS5z+PDhmjRpkrOWvLw8paWlKT4+/lfrOHbsmEpLS9WuXbtfbdOuXTudPn1ax48f11NPPaXLL79cL7zwgvPD4i/fr7p06SJJuvzyyz06lHfffffpgQce0KeffqoePXq43Ld161Z9//33yszMVMeOHSVJv/3tbzVgwAC98MILmj17tmJiYtS6dWtlZmaqc+fOkqSSkhL9/e9/d3vP8ES7du30888/V/u52Lhxo44cOaK//e1vzuex8rXsDeyR17Ndu3Zp5MiR6tOnj7p27ep8sX377bcu7a688kpniEtynkBy+PBhj/pr3ry5tmzZ4vIvPDxchw4dUmJiosueet++fWW1WvX555+7LOPGG290uT1w4EDl5+d7VMuQIUO0Y8cOnTp1SllZWRo8eLBbm9OnT2vlypW68cYb1b17d3Xr1k0rVqzQTz/9pJMnT7q0ve6666rdd3l5ubZv365rr71WgYGBks4EYklJid5++22XttVd18pAq666Wv9WrVopMTFRf/7zn53zbd26VVdffbU6dOjgUU2esFqtLm9MYWFhat68udf2ODzlyTZwLhUVFfrqq6/cjhtXDi2fT+fOnZWRkaF169Zp9OjRCgwM1EsvvaRhw4bpq6++knRmCLu4uFiDBg1yeX1ec801OnXqlPbv3++yzLO32ZtuuklffPGFR4dZzuX06dP6z3/+o5tvvrnOR3xuvPFGde7cucq98g8//FCdOnVyhrgkBQcH65prrtFHH30kSfL19dWgQYOUlZXlbLNz506VlJRU+RqrLofDIYvFUu3nYs+ePerXr58zxL2NPfJ69Omnn2ry5MlKSEjQhAkT1KZNG1ksFt1xxx06ffq0S1ubzeZyu/KEnLPbnY/ValX37t1dplW+CO6///4q56kctqr0yw8UkvSb3/xGkvTTTz/pkksuqVYdcXFx8vPz07PPPquDBw8qMTHRrc1TTz2lzZs36/7779dVV12lwMBA7dixQ6tXr9bp06dd9po8Obt39+7dOnr0qAYMGKDCwkJJZ95Q27Ztq4yMDN18880erWtAQIBHe3BS3a7/HXfcoZEjR+q///2vLrroIv3jH//Qo48+6lE9nmrevLnbzwT7+fl5vD16iyfbwLkcPXpU5eXlbtuJJ9ujv7+/rr32WueHwX/+85+aNGmS0tLSlJqa6jxcccstt1Q5/9mvz7P7/s1vfqOysjIdO3bMuf2eLSQkRP7+/m7LOrufZs2aSZLsdvt5h8prwmKx6Pe//70eeughffHFFy73FRYWVll/mzZtXD7MDB48WK+88opzrz4zM1NXX321RyOXZzt8+LA6dOhQ7efi+PHjLqOY3kaQ16N33nlHrVq10jPPPOMcpj106FCD1xEcHCxJWrBggdtwliS3F+zZJ//8/PPPks4MxVeXn5+fbrrpJm3cuFExMTFVvkC3b9+uESNGaOLEic5pu3btqnJ5Foul2n1v27ZNkjRnzhzNmTPH5b5jx465fH+3OuvqSd+V6nL9o6Ki1KlTJ/35z3/WJZdcIn9/fw0aNMjjmirfpH95Ep505g20JutYG/VdS3W2gXPVUKl169by9fV1205q8x3w/v3768orr3R+fzkoKEiSlJqaWmUYnb3Xd+TIEYWGhjpv//zzz/Lz83MZfj+br6+voqKi9MEHH6i4uNjta5DFxcX64IMPFBUVpZCQEFmtVreTcutKYmKiVq1apeeee85lxyAoKEi5ublu7Y8cOeJ8jCSpT58+ateunTIzMxUeHq7s7GzNnTu3xvXs379f+fn5uuWWW6r9XAQHB9fb41MTBHk9OnXqlPz8/FzemCrfYBpSRESELr74YuXl5VV5UYazvf322y7Dd2+++aYuuugijz/xJicn68iRI7rjjjuqvP/06dMuXwWqqKhQZmamR32craSkRDt27NANN9yg0aNHu9z3888/66GHHlJWVpbz+FpdrWtV6nL9k5OTtXr1arVp00ZJSUk1+j565TodOHBAvXv3lnTmg8wXX3yhq666yuPl1UZ91lLdbaDyOG9OTo4zGA8cOOCy1+rj46MuXbpox44dGjNmjHP6O++8U61afv75Z7cPcadOndIPP/zgPHwWFRWlgIAAHT582G3YvCpvv/22unbt6rz91ltvqVu3bucdBh8zZowmT56sDRs2uB1P3rBhg44fP64xY8aoRYsW6tWrl9544w2NGzeuyuXWdMRQOjNq+Pvf/16zZ89W3759ndP79OmjN998Uzk5Oc6T1goKCvSvf/1LI0aMcLazWCxKSkpSRkaGOnXqJLvdroEDB3pcR2X9ixcvlr+/v5KTk2Wz2ar1XMTExGjDhg36/vvvqz1KWZ8I8noUGxurF154QYsXL9aNN96ovXv36o033mjwOiwWi2bPnq2ZM2equLhY1113nQICAvT9999r165dmj59usLDw53t33vvPT3xxBOKjY3V7t279cYbb2jBggUefwe6R48eVZ6BXumaa67R5s2bdcUVVygkJESvvPKKSktLa7ye0pkzjIuLizVq1Kgqv6/6xz/+URkZGc4TWepqXatSl+s/fPhwLVu2TMeOHfPopL9fuvjii9WzZ0+lpaUpMDBQvr6+Wr9+vfMYckOqz1qquw2MHDlS7dq105IlSzRjxgydOHFC69atc45gVbrvvvs0efJkzZs3T4MGDdKXX37pvBLa+baToUOHasCAAYqLi9NFF12k/Px8bdq0SceOHXN+MLDZbJo6daqeeuopHT58WH379pWPj4/y8vK0Y8cOrVq1SgEBAc5lvvHGG2revLm6du2qrKws/fvf/9a6devO+7gkJCTonnvuUWpqqg4fPuwc1Xnrrbf0+uuv65577nGeCzBjxgyNHTtWY8eO1V133aWgoCB98cUXCgkJ0e233662bdvKZrMpMzNTYWFh8vf3V2RkpNvhmHM9LmlpaXr//fd16aWXSjrzVcuNGzdq0qRJmjZtmpo1a6bVq1fL19fX5UOUdOYclPT0dD377LOKjY11O/RRFbvdrk8++UTSmRGIygvC5OXlKSUlxbm3XZ3nYuzYsXrjjTd0zz336L777lP79u2Vl5enb7/9tsbfNqoNgryOnTp1yrkxX3vttZo5c6Y2bdqkrVu3qnfv3lq7dm2NPz3WRmJiomw2m9asWeMcFbj00kvVv39/tz2GRx99VK+99pr+9Kc/qWXLlnrwwQertSfvqfnz52vhwoVavHixAgICdMstt+jGG290nuFbExkZGbrkkkt+9aITN998s5YsWeL8jn5DrWtVPFn/4OBg9e3bV4cPH/boLOFfbo/SmesazJs3T3PmzNFvfvMbTZs2TZmZmS5fb6svDVVLdbeBH374QampqVq0aJEefPBBXXbZZZo7d65SUlJc2ickJGjRokVau3at/vrXv6pnz55atGiRxo0bp1atWp2zlilTpmjnzp1KSUnR0aNHFRISosjISG3cuFH9+vVzths3bpxCQ0P1/PPPa9OmTfL19dVll12m6667zu0CNsuXL9fTTz+ttLQ0tWnTRosXL672yZjz589Xz5499corrzgvCtO5c2elpKS4nDdw9dVX68UXX9QzzzyjOXPmyGq1qlOnTs6v3VmtVi1dulRPP/20xo4dq9LSUu3YsaPaJ3/5+Pho4sSJLtt6q1at9NJLLyklJUXz58+X3W5X7969tWnTJrez7bt27arw8HDl5uZq5syZ1erz1KlTzj37Fi1aKCwsTDExMUpNTXU5wa46z0VISIj+9Kc/afny5Vq2bJlKSkp06aWXOr9Z0tAsDofD4ZWem6gpU6bo+++/P++FIuBd77//vkaPHq0tW7a4nRzYGJ04cUL9+/fXAw88UOUFPX5NY9oeG1MttbV582bNmzfPo/Cqra1bt2rOnDnas2dPtfZAceFgj7yOfPXVV/rggw/0j3/8w+Xyh0BtnDhxQgcOHNArr7wii8WiW2+9tVrzNabtsTHVUhPHjx9Xamqq+vXrp5YtW+qzzz7TmjVrlJCQ0Gi+foQLG0FeR+bOnauCggLde++9Gj9+vLfLQRPxxRdfaPTo0WrXrp2eeOIJt+O3v6YxbY+NqZaa8PX1VV5enjIyMlRUVKSQkBANHz682kO6QH1jaB0AAINxZTcAAAxGkAMAYDCCHAAAgxHkAAAYjCAHAMBgBDkAAAYjyAEAMBhBDgCAwQhyAAAM9v8BesPj5I5vii4AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['x24']"
      ],
      "metadata": {
        "id": "OU1gFJ_9CcDf",
        "outputId": "7fe2cdc0-e50e-4368-e902-b4a2cb5ce811",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         euorpe\n",
              "1           asia\n",
              "2           asia\n",
              "3           asia\n",
              "4           asia\n",
              "           ...  \n",
              "159995      asia\n",
              "159996      asia\n",
              "159997      asia\n",
              "159998      asia\n",
              "159999      asia\n",
              "Name: x24, Length: 160000, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mo = ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
        "heights = []\n",
        "for i in mo:\n",
        "    x = df.loc[df['x24'] == 'asia','x29'].to_list().count(i)\n",
        "    heights.append(x)\n",
        "plt.bar(x=mo,height=heights)"
      ],
      "metadata": {
        "id": "HhMvMtZjCPiv",
        "outputId": "ccba96a0-b155-48fb-ef7c-6b20e8c533f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 12 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 141
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 550x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nlpV3OtGBoUY",
        "outputId": "4a82efd8-e556-4a90-b9f6-3f5901eb80b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[df['x24'] == 'america','x29'].to_list().count('Jul')"
      ],
      "metadata": {
        "id": "iXrcPQPiBG6E",
        "outputId": "462f9f26-117b-4c1e-a283-8f28c27af90b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1279"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.loc[:,df.columns != 'y']\n",
        "y = df['y'].values.flatten()\n",
        "\n",
        "df_num = X.select_dtypes(exclude='object')\n",
        "num_cols = df_num.columns\n",
        "\n",
        "# impute numeric with median\n",
        "for i in num_cols:\n",
        "    df_num[i] = df_num[i].transform(lambda x: x.fillna(pd.Series.mode(x)[0]))\n",
        "df_num.info()\n",
        "\n",
        "df_cat = X.select_dtypes(include='object')\n",
        "cat_cols = df_cat.columns\n",
        "\n",
        "# scale numerical data\n",
        "scaler = StandardScaler()\n",
        "df_num = scaler.fit_transform(df_num)\n",
        "\n",
        "#one hot encode cat data\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "df_cat = encoder.fit_transform(df_cat)"
      ],
      "metadata": {
        "id": "w8Uy9xG3Iern",
        "outputId": "3aed46a3-8379-47d4-cd0c-82f38e3e182f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 160000 entries, 0 to 159999\n",
            "Data columns (total 47 columns):\n",
            " #   Column  Non-Null Count   Dtype  \n",
            "---  ------  --------------   -----  \n",
            " 0   x0      160000 non-null  float64\n",
            " 1   x1      160000 non-null  float64\n",
            " 2   x2      160000 non-null  float64\n",
            " 3   x3      160000 non-null  float64\n",
            " 4   x4      160000 non-null  float64\n",
            " 5   x5      160000 non-null  float64\n",
            " 6   x6      160000 non-null  float64\n",
            " 7   x7      160000 non-null  float64\n",
            " 8   x8      160000 non-null  float64\n",
            " 9   x9      160000 non-null  float64\n",
            " 10  x10     160000 non-null  float64\n",
            " 11  x11     160000 non-null  float64\n",
            " 12  x12     160000 non-null  float64\n",
            " 13  x13     160000 non-null  float64\n",
            " 14  x14     160000 non-null  float64\n",
            " 15  x15     160000 non-null  float64\n",
            " 16  x16     160000 non-null  float64\n",
            " 17  x17     160000 non-null  float64\n",
            " 18  x18     160000 non-null  float64\n",
            " 19  x19     160000 non-null  float64\n",
            " 20  x20     160000 non-null  float64\n",
            " 21  x21     160000 non-null  float64\n",
            " 22  x22     160000 non-null  float64\n",
            " 23  x23     160000 non-null  float64\n",
            " 24  x25     160000 non-null  float64\n",
            " 25  x26     160000 non-null  float64\n",
            " 26  x27     160000 non-null  float64\n",
            " 27  x28     160000 non-null  float64\n",
            " 28  x31     160000 non-null  float64\n",
            " 29  x32     160000 non-null  float64\n",
            " 30  x33     160000 non-null  float64\n",
            " 31  x34     160000 non-null  float64\n",
            " 32  x35     160000 non-null  float64\n",
            " 33  x36     160000 non-null  float64\n",
            " 34  x37     160000 non-null  float64\n",
            " 35  x38     160000 non-null  float64\n",
            " 36  x39     160000 non-null  float64\n",
            " 37  x40     160000 non-null  float64\n",
            " 38  x41     160000 non-null  float64\n",
            " 39  x42     160000 non-null  float64\n",
            " 40  x43     160000 non-null  float64\n",
            " 41  x44     160000 non-null  float64\n",
            " 42  x45     160000 non-null  float64\n",
            " 43  x46     160000 non-null  float64\n",
            " 44  x47     160000 non-null  float64\n",
            " 45  x48     160000 non-null  float64\n",
            " 46  x49     160000 non-null  float64\n",
            "dtypes: float64(47)\n",
            "memory usage: 57.4 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.hstack([df_num,df_cat])"
      ],
      "metadata": {
        "id": "R4oaw8CgIkXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1zPG-Q7z7U3",
        "outputId": "640c15d2-1dff-487b-c225-3db1d9f3bfca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(160000, 67)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['y'].value_counts() # not balanced"
      ],
      "metadata": {
        "id": "xbzdACUdImVy",
        "outputId": "77c2f5dc-a171-40e4-ba49-433965287e64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "y\n",
              "0    95803\n",
              "1    64197\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## define cost function\n",
        "def cost_func(y_pred,y_true):\n",
        "    diff = y_pred - y_true\n",
        "    x = 0\n",
        "    for i in diff:\n",
        "        #false pos (y_pred -y_true == 1)\n",
        "        if i == 1:\n",
        "            x += 100\n",
        "        #false neg (y_pred -y_true ==-1)\n",
        "        elif i == -1:\n",
        "            x += 150\n",
        "    return(x)"
      ],
      "metadata": {
        "id": "HRJz__nu_bxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skf = StratifiedKFold(n_splits=10,random_state=807,shuffle=True)\n",
        "skf.get_n_splits(X,y)"
      ],
      "metadata": {
        "id": "qIgBnSnHIqjU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2881078-9712-44df-ceae-cc62b50f7192"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression"
      ],
      "metadata": {
        "id": "gpPJ9Gb95HXb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#logR = LogisticRegression(random_state=807,penalty='elasticnet',class_weight='balanced',solver='saga')\n",
        "#params = {'C':[0.00001,0.0001,0.001,0.01,0.1,1,2,5,10],'l1_ratio':[0,0.001,0.01,0.1,0.25,0.5,0.75,0.9,0.99,1],'max_iter':[25,50,75]}\n",
        "\n",
        "#lr_clf = GridSearchCV(estimator=logR,param_grid=params,n_jobs=-1,cv=skf)\n",
        "#lr_clf.fit(X,y)"
      ],
      "metadata": {
        "id": "AcpquSzJO6SF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#lr_params = lr_clf.best_params_\n",
        "lr_params ={'C': 0.001, 'l1_ratio': 0.5, 'max_iter': 50}"
      ],
      "metadata": {
        "id": "Eb5e2xOvO8pr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "{'C': 0.001, 'l1_ratio': 0.5, 'max_iter': 50}"
      ],
      "metadata": {
        "id": "gfllGKF4pUMP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = LogisticRegression(random_state=807,penalty='elasticnet',class_weight='balanced',solver='saga')\n",
        "model1.set_params(**lr_params)\n",
        "model1.fit(X,y)\n",
        "\n",
        "preds_m1 = cross_val_predict(model1,X,y,cv=skf)"
      ],
      "metadata": {
        "id": "RHUkzlw2PATu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cr_m1 = classification_report(y,preds_m1,output_dict=True)\n",
        "cr_m1"
      ],
      "metadata": {
        "id": "3katCHeBPQB-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebf8318a-733e-4dfe-a99c-c387e0f38fef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'0': {'precision': 0.7707924178564336,\n",
              "  'recall': 0.7292047221903281,\n",
              "  'f1-score': 0.7494220567805746,\n",
              "  'support': 95803},\n",
              " '1': {'precision': 0.6259983277109823,\n",
              "  'recall': 0.6764023240961415,\n",
              "  'f1-score': 0.6502249874591017,\n",
              "  'support': 64197},\n",
              " 'accuracy': 0.70801875,\n",
              " 'macro avg': {'precision': 0.698395372783708,\n",
              "  'recall': 0.7028035231432348,\n",
              "  'f1-score': 0.6998235221198381,\n",
              "  'support': 160000},\n",
              " 'weighted avg': {'precision': 0.7126965040747615,\n",
              "  'recall': 0.70801875,\n",
              "  'f1-score': 0.7096210926603833,\n",
              "  'support': 160000}}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ConfusionMatrixDisplay.from_predictions(y,preds_m1)"
      ],
      "metadata": {
        "id": "ent8XHdUPayB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "outputId": "7b29cb60-2c16-4502-cf3c-5c991f3e8001"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7cd8252c5e70>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 550x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cost_m1 = cost_func(preds_m1,y)\n",
        "cost_m1"
      ],
      "metadata": {
        "id": "zawbBlwk_fbc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41eb76c9-4ac5-47ed-e1c2-0ebc467e257a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5710400"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest"
      ],
      "metadata": {
        "id": "gWPF0EgN5Mw7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier(random_state=807,criterion='gini',class_weight='balanced')\n",
        "params = {'n_estimators':[100, 200],'max_features':['sqrt','log2',20]}\n",
        "rf_clf = GridSearchCV(rf,param_grid=params,cv=skf,n_jobs = -1)"
      ],
      "metadata": {
        "id": "4HWotr_VPhhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_clf.fit(X,y)"
      ],
      "metadata": {
        "id": "soQp5nQ8PkUl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "12f4caae-9c96-47f7-87f9-ac547e74cf61"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=807, shuffle=True),\n",
              "             estimator=RandomForestClassifier(class_weight=&#x27;balanced&#x27;,\n",
              "                                              random_state=807),\n",
              "             n_jobs=-1,\n",
              "             param_grid={&#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;, 20],\n",
              "                         &#x27;n_estimators&#x27;: [100, 200]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=807, shuffle=True),\n",
              "             estimator=RandomForestClassifier(class_weight=&#x27;balanced&#x27;,\n",
              "                                              random_state=807),\n",
              "             n_jobs=-1,\n",
              "             param_grid={&#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;, 20],\n",
              "                         &#x27;n_estimators&#x27;: [100, 200]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, random_state=807)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, random_state=807)</pre></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=807, shuffle=True),\n",
              "             estimator=RandomForestClassifier(class_weight='balanced',\n",
              "                                              random_state=807),\n",
              "             n_jobs=-1,\n",
              "             param_grid={'max_features': ['sqrt', 'log2', 20],\n",
              "                         'n_estimators': [100, 200]})"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rf_clf.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3jhHtsE6rFk",
        "outputId": "268d129a-e1f6-430c-d247-a7a524d48ea1"
      },
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'max_features': 20, 'n_estimators': 200}"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rf_params = rf_clf.best_params_\n",
        "rf_params"
      ],
      "metadata": {
        "id": "Hz6owkMTPlOF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "207a18c1-62ab-4f41-8327-6158aafca873"
      },
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'max_features': 20, 'n_estimators': 200}"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = RandomForestClassifier(random_state=807,criterion='gini',class_weight='balanced')\n",
        "model2.set_params(**rf_params)\n",
        "preds_m2 = cross_val_predict(model2,X,y,cv=skf)"
      ],
      "metadata": {
        "id": "hvIbks5bPnfm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "cd42f3e3-d5ad-4807-da28-b61400c7725f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-331-c2093db50b55>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m807\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gini'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mrf_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpreds_m2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_predict\u001b[0;34m(estimator, X, y, groups, cv, n_jobs, verbose, fit_params, pre_dispatch, method)\u001b[0m\n\u001b[1;32m    984\u001b[0m     \u001b[0;31m# independent, and that it is pickle-able.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m     \u001b[0mparallel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m     predictions = parallel(\n\u001b[0m\u001b[1;32m    987\u001b[0m         delayed(_fit_and_predict)(\n\u001b[1;32m    988\u001b[0m             \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1853\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1854\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1855\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1856\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1857\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1784\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_predict\u001b[0;34m(estimator, X, y, train, test, verbose, fit_params, method)\u001b[0m\n\u001b[1;32m   1066\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1068\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1069\u001b[0m     \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    471\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             trees = Parallel(\n\u001b[0m\u001b[1;32m    474\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1853\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1854\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1855\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1856\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1857\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1784\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"balanced\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    887\u001b[0m         \"\"\"\n\u001b[1;32m    888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m    890\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    377\u001b[0m             )\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cr_m2 = classification_report(y,preds_m2,output_dict=True)\n",
        "cr_m2"
      ],
      "metadata": {
        "id": "Aaw8aFI7PpCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ConfusionMatrixDisplay.from_predictions(y,preds_m2 ,cmap='Blues', colorbar=False)"
      ],
      "metadata": {
        "id": "BK6zSOo4Pq_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cost_m2 = cost_func(preds_m2,y)\n",
        "cost_m2"
      ],
      "metadata": {
        "id": "XqmhfmAx9Ge2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Neural Network"
      ],
      "metadata": {
        "id": "qA5qTJxP5amW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### define a cost function used in validation with keras and backend\n",
        "### returns the average cost (total cost divided by array tensor size)\n",
        "def cost(y_true,y_pred):\n",
        "  bin_p = tf.where(tf.greater_equal(y_pred,0.5),tf.constant(1,dtype='float32'),tf.constant(0,dtype='float32'))\n",
        "\n",
        "  diff = bin_p - y_true\n",
        "\n",
        "  error = tf.where(\n",
        "      tf.equal(diff,1),100,\n",
        "      tf.where(\n",
        "          tf.equal(diff,-1),150,\n",
        "          0\n",
        "      )\n",
        "  )\n",
        "  return(K.sum(error)/tf.size(bin_p))"
      ],
      "metadata": {
        "id": "EV-gIgK12n02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "now = datetime.datetime.now"
      ],
      "metadata": {
        "id": "b04x7Mf5dBDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "es = EarlyStopping(monitor='val_cost', mode='min',patience=50,restore_best_weights=True,start_from_epoch=100)\n",
        "fold_results = {}\n",
        "t_tot = now()\n",
        "for i, (train_index, test_index) in enumerate(skf.split(X,y)):\n",
        "  # building model within loop to reset weights each time\n",
        "  tf.keras.backend.clear_session()\n",
        "  tf.keras.utils.set_random_seed(807)\n",
        "  model4 = tf.keras.Sequential()\n",
        "  model4.add(tf.keras.Input(shape=(X.shape[1],)))\n",
        "  model4.add(tf.keras.layers.Dense(64, activation='relu',name=\"Relu1\"))\n",
        "  model4.add(tf.keras.layers.Dense(64, activation='relu', name=\"Relu2\"))\n",
        "  model4.add(tf.keras.layers.Dropout(0.2))\n",
        "  model4.add(tf.keras.layers.Dense(1, activation='sigmoid', name=\"Activation\"))\n",
        "  model4.compile(optimizer='adam',\n",
        "                loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
        "                metrics = [tf.keras.metrics.AUC(from_logits=False), 'accuracy',cost])\n",
        "  t_fold = now()\n",
        "  print('x_train shape:', X[train_index].shape)\n",
        "  model4.fit(X[train_index],y[train_index],epochs=1000,batch_size=1080,validation_split=0.10,callbacks=[es])\n",
        "  score = model4.evaluate(X[test_index],y[test_index])\n",
        "  fold_results.update({i:{'predictions':model4.predict(X[test_index]).flatten(),'index':test_index,'y_true':y[test_index]}})\n",
        "  print('fold train/predict time: %s' % (now()-t_fold))\n",
        "  print('fold accuracy: {} - fold cost: {}'.format(score[2],score[3]))\n",
        "print('total train/predict time: %s' % (now()-t_tot))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEjPIqNtVPF1",
        "outputId": "7d37b9cc-a1d3-40ee-cc5f-cc89d7a27717"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-08-05 18:24:48.463919: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-08-05 18:24:48.471943: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-08-05 18:24:48.472365: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-08-05 18:24:48.473798: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-08-05 18:24:48.474263: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-08-05 18:24:48.474553: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-08-05 18:24:49.066887: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-08-05 18:24:49.067197: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-08-05 18:24:49.067442: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-08-05 18:24:49.067652: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3326 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1050 Ti with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (144000, 67)\n",
            "Epoch 1/1000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-08-05 18:24:50.181745: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f878367c6c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2023-08-05 18:24:50.181766: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce GTX 1050 Ti with Max-Q Design, Compute Capability 6.1\n",
            "2023-08-05 18:24:50.185418: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "2023-08-05 18:24:50.333423: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
            "2023-08-05 18:24:50.455142: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "120/120 [==============================] - 2s 5ms/step - loss: 0.5321 - auc: 0.7954 - accuracy: 0.7260 - cost: 36.5748 - val_loss: 0.4003 - val_auc: 0.8976 - val_accuracy: 0.8232 - val_cost: 22.5231\n",
            "Epoch 2/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.3524 - auc: 0.9212 - accuracy: 0.8483 - cost: 19.3557 - val_loss: 0.3178 - val_auc: 0.9358 - val_accuracy: 0.8656 - val_cost: 16.9940\n",
            "Epoch 3/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.3031 - auc: 0.9418 - accuracy: 0.8744 - cost: 15.9012 - val_loss: 0.2909 - val_auc: 0.9469 - val_accuracy: 0.8783 - val_cost: 15.7507\n",
            "Epoch 4/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.2755 - auc: 0.9521 - accuracy: 0.8883 - cost: 14.1628 - val_loss: 0.2647 - val_auc: 0.9560 - val_accuracy: 0.8920 - val_cost: 13.2771\n",
            "Epoch 5/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.2531 - auc: 0.9596 - accuracy: 0.8980 - cost: 12.9136 - val_loss: 0.2447 - val_auc: 0.9622 - val_accuracy: 0.9024 - val_cost: 12.2189\n",
            "Epoch 6/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.2345 - auc: 0.9652 - accuracy: 0.9081 - cost: 11.6169 - val_loss: 0.2292 - val_auc: 0.9673 - val_accuracy: 0.9099 - val_cost: 10.9061\n",
            "Epoch 7/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.2183 - auc: 0.9698 - accuracy: 0.9160 - cost: 10.6292 - val_loss: 0.2129 - val_auc: 0.9713 - val_accuracy: 0.9213 - val_cost: 9.7950\n",
            "Epoch 8/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.2035 - auc: 0.9737 - accuracy: 0.9224 - cost: 9.8287 - val_loss: 0.2006 - val_auc: 0.9742 - val_accuracy: 0.9279 - val_cost: 9.0807\n",
            "Epoch 9/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1929 - auc: 0.9763 - accuracy: 0.9264 - cost: 9.2975 - val_loss: 0.1913 - val_auc: 0.9763 - val_accuracy: 0.9300 - val_cost: 8.8492\n",
            "Epoch 10/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1832 - auc: 0.9784 - accuracy: 0.9312 - cost: 8.6956 - val_loss: 0.1829 - val_auc: 0.9782 - val_accuracy: 0.9347 - val_cost: 8.1250\n",
            "Epoch 11/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1755 - auc: 0.9800 - accuracy: 0.9348 - cost: 8.2531 - val_loss: 0.1771 - val_auc: 0.9796 - val_accuracy: 0.9387 - val_cost: 7.5066\n",
            "Epoch 12/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1688 - auc: 0.9813 - accuracy: 0.9379 - cost: 7.8542 - val_loss: 0.1713 - val_auc: 0.9806 - val_accuracy: 0.9407 - val_cost: 7.3743\n",
            "Epoch 13/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1622 - auc: 0.9827 - accuracy: 0.9410 - cost: 7.4672 - val_loss: 0.1647 - val_auc: 0.9819 - val_accuracy: 0.9436 - val_cost: 7.0370\n",
            "Epoch 14/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1575 - auc: 0.9836 - accuracy: 0.9429 - cost: 7.2245 - val_loss: 0.1626 - val_auc: 0.9823 - val_accuracy: 0.9433 - val_cost: 7.0635\n",
            "Epoch 15/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1534 - auc: 0.9844 - accuracy: 0.9446 - cost: 7.0046 - val_loss: 0.1567 - val_auc: 0.9834 - val_accuracy: 0.9465 - val_cost: 6.7725\n",
            "Epoch 16/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1486 - auc: 0.9853 - accuracy: 0.9476 - cost: 6.6397 - val_loss: 0.1543 - val_auc: 0.9838 - val_accuracy: 0.9472 - val_cost: 6.5278\n",
            "Epoch 17/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.1458 - auc: 0.9857 - accuracy: 0.9483 - cost: 6.5463 - val_loss: 0.1524 - val_auc: 0.9841 - val_accuracy: 0.9477 - val_cost: 6.4120\n",
            "Epoch 18/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1430 - auc: 0.9862 - accuracy: 0.9500 - cost: 6.3329 - val_loss: 0.1493 - val_auc: 0.9846 - val_accuracy: 0.9481 - val_cost: 6.6534\n",
            "Epoch 19/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1407 - auc: 0.9866 - accuracy: 0.9508 - cost: 6.2149 - val_loss: 0.1477 - val_auc: 0.9850 - val_accuracy: 0.9498 - val_cost: 6.3062\n",
            "Epoch 20/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.1362 - auc: 0.9873 - accuracy: 0.9523 - cost: 6.0482 - val_loss: 0.1461 - val_auc: 0.9851 - val_accuracy: 0.9500 - val_cost: 6.1971\n",
            "Epoch 21/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1338 - auc: 0.9876 - accuracy: 0.9534 - cost: 5.8904 - val_loss: 0.1444 - val_auc: 0.9854 - val_accuracy: 0.9513 - val_cost: 6.2070\n",
            "Epoch 22/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1319 - auc: 0.9879 - accuracy: 0.9551 - cost: 5.6925 - val_loss: 0.1428 - val_auc: 0.9856 - val_accuracy: 0.9515 - val_cost: 6.1640\n",
            "Epoch 23/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1301 - auc: 0.9882 - accuracy: 0.9551 - cost: 5.6941 - val_loss: 0.1413 - val_auc: 0.9858 - val_accuracy: 0.9523 - val_cost: 5.9358\n",
            "Epoch 24/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1282 - auc: 0.9886 - accuracy: 0.9553 - cost: 5.6632 - val_loss: 0.1395 - val_auc: 0.9860 - val_accuracy: 0.9538 - val_cost: 5.6944\n",
            "Epoch 25/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1257 - auc: 0.9888 - accuracy: 0.9571 - cost: 5.4309 - val_loss: 0.1394 - val_auc: 0.9861 - val_accuracy: 0.9543 - val_cost: 5.6911\n",
            "Epoch 26/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1245 - auc: 0.9891 - accuracy: 0.9572 - cost: 5.4329 - val_loss: 0.1375 - val_auc: 0.9865 - val_accuracy: 0.9552 - val_cost: 5.5423\n",
            "Epoch 27/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1226 - auc: 0.9892 - accuracy: 0.9584 - cost: 5.2747 - val_loss: 0.1371 - val_auc: 0.9865 - val_accuracy: 0.9550 - val_cost: 5.5423\n",
            "Epoch 28/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1202 - auc: 0.9896 - accuracy: 0.9592 - cost: 5.1821 - val_loss: 0.1350 - val_auc: 0.9868 - val_accuracy: 0.9566 - val_cost: 5.3902\n",
            "Epoch 29/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1193 - auc: 0.9897 - accuracy: 0.9601 - cost: 5.0575 - val_loss: 0.1347 - val_auc: 0.9869 - val_accuracy: 0.9566 - val_cost: 5.3737\n",
            "Epoch 30/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1171 - auc: 0.9901 - accuracy: 0.9613 - cost: 4.9097 - val_loss: 0.1321 - val_auc: 0.9871 - val_accuracy: 0.9572 - val_cost: 5.3604\n",
            "Epoch 31/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1166 - auc: 0.9900 - accuracy: 0.9615 - cost: 4.8943 - val_loss: 0.1318 - val_auc: 0.9871 - val_accuracy: 0.9572 - val_cost: 5.3704\n",
            "Epoch 32/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1142 - auc: 0.9905 - accuracy: 0.9624 - cost: 4.7785 - val_loss: 0.1304 - val_auc: 0.9874 - val_accuracy: 0.9585 - val_cost: 5.2447\n",
            "Epoch 33/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1126 - auc: 0.9906 - accuracy: 0.9631 - cost: 4.6779 - val_loss: 0.1295 - val_auc: 0.9873 - val_accuracy: 0.9590 - val_cost: 5.1521\n",
            "Epoch 34/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1118 - auc: 0.9907 - accuracy: 0.9633 - cost: 4.6551 - val_loss: 0.1294 - val_auc: 0.9873 - val_accuracy: 0.9595 - val_cost: 5.0595\n",
            "Epoch 35/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1107 - auc: 0.9909 - accuracy: 0.9638 - cost: 4.5907 - val_loss: 0.1282 - val_auc: 0.9875 - val_accuracy: 0.9596 - val_cost: 5.1091\n",
            "Epoch 36/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1084 - auc: 0.9911 - accuracy: 0.9649 - cost: 4.4506 - val_loss: 0.1271 - val_auc: 0.9878 - val_accuracy: 0.9592 - val_cost: 5.1389\n",
            "Epoch 37/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1082 - auc: 0.9912 - accuracy: 0.9646 - cost: 4.4780 - val_loss: 0.1272 - val_auc: 0.9877 - val_accuracy: 0.9600 - val_cost: 5.0661\n",
            "Epoch 38/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1064 - auc: 0.9914 - accuracy: 0.9657 - cost: 4.3480 - val_loss: 0.1274 - val_auc: 0.9877 - val_accuracy: 0.9601 - val_cost: 5.0099\n",
            "Epoch 39/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1057 - auc: 0.9914 - accuracy: 0.9655 - cost: 4.3611 - val_loss: 0.1249 - val_auc: 0.9879 - val_accuracy: 0.9604 - val_cost: 5.0099\n",
            "Epoch 40/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1036 - auc: 0.9917 - accuracy: 0.9667 - cost: 4.2238 - val_loss: 0.1244 - val_auc: 0.9881 - val_accuracy: 0.9622 - val_cost: 4.7255\n",
            "Epoch 41/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1030 - auc: 0.9918 - accuracy: 0.9670 - cost: 4.1829 - val_loss: 0.1247 - val_auc: 0.9880 - val_accuracy: 0.9618 - val_cost: 4.6892\n",
            "Epoch 42/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1024 - auc: 0.9919 - accuracy: 0.9671 - cost: 4.1852 - val_loss: 0.1225 - val_auc: 0.9884 - val_accuracy: 0.9623 - val_cost: 4.6825\n",
            "Epoch 43/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1014 - auc: 0.9920 - accuracy: 0.9677 - cost: 4.1019 - val_loss: 0.1226 - val_auc: 0.9882 - val_accuracy: 0.9626 - val_cost: 4.7024\n",
            "Epoch 44/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1007 - auc: 0.9920 - accuracy: 0.9673 - cost: 4.1582 - val_loss: 0.1223 - val_auc: 0.9885 - val_accuracy: 0.9619 - val_cost: 4.7421\n",
            "Epoch 45/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1001 - auc: 0.9921 - accuracy: 0.9681 - cost: 4.0529 - val_loss: 0.1201 - val_auc: 0.9885 - val_accuracy: 0.9632 - val_cost: 4.6131\n",
            "Epoch 46/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0980 - auc: 0.9923 - accuracy: 0.9684 - cost: 4.0131 - val_loss: 0.1194 - val_auc: 0.9888 - val_accuracy: 0.9627 - val_cost: 4.6958\n",
            "Epoch 47/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0975 - auc: 0.9924 - accuracy: 0.9689 - cost: 3.9568 - val_loss: 0.1207 - val_auc: 0.9887 - val_accuracy: 0.9637 - val_cost: 4.4511\n",
            "Epoch 48/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0973 - auc: 0.9924 - accuracy: 0.9693 - cost: 3.8974 - val_loss: 0.1199 - val_auc: 0.9886 - val_accuracy: 0.9634 - val_cost: 4.6164\n",
            "Epoch 49/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0963 - auc: 0.9924 - accuracy: 0.9694 - cost: 3.8954 - val_loss: 0.1182 - val_auc: 0.9889 - val_accuracy: 0.9639 - val_cost: 4.5172\n",
            "Epoch 50/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0959 - auc: 0.9925 - accuracy: 0.9701 - cost: 3.8067 - val_loss: 0.1184 - val_auc: 0.9887 - val_accuracy: 0.9637 - val_cost: 4.5899\n",
            "Epoch 51/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0949 - auc: 0.9926 - accuracy: 0.9705 - cost: 3.7569 - val_loss: 0.1190 - val_auc: 0.9887 - val_accuracy: 0.9642 - val_cost: 4.3882\n",
            "Epoch 52/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0943 - auc: 0.9927 - accuracy: 0.9703 - cost: 3.7820 - val_loss: 0.1172 - val_auc: 0.9889 - val_accuracy: 0.9646 - val_cost: 4.4643\n",
            "Epoch 53/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0930 - auc: 0.9928 - accuracy: 0.9711 - cost: 3.6736 - val_loss: 0.1165 - val_auc: 0.9890 - val_accuracy: 0.9655 - val_cost: 4.3353\n",
            "Epoch 54/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0928 - auc: 0.9929 - accuracy: 0.9708 - cost: 3.7187 - val_loss: 0.1171 - val_auc: 0.9887 - val_accuracy: 0.9651 - val_cost: 4.3519\n",
            "Epoch 55/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0922 - auc: 0.9929 - accuracy: 0.9712 - cost: 3.6759 - val_loss: 0.1166 - val_auc: 0.9889 - val_accuracy: 0.9649 - val_cost: 4.3948\n",
            "Epoch 56/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0915 - auc: 0.9929 - accuracy: 0.9718 - cost: 3.6030 - val_loss: 0.1154 - val_auc: 0.9891 - val_accuracy: 0.9655 - val_cost: 4.3353\n",
            "Epoch 57/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0900 - auc: 0.9931 - accuracy: 0.9722 - cost: 3.5374 - val_loss: 0.1149 - val_auc: 0.9892 - val_accuracy: 0.9653 - val_cost: 4.2725\n",
            "Epoch 58/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0912 - auc: 0.9930 - accuracy: 0.9718 - cost: 3.5810 - val_loss: 0.1171 - val_auc: 0.9889 - val_accuracy: 0.9651 - val_cost: 4.2295\n",
            "Epoch 59/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0894 - auc: 0.9932 - accuracy: 0.9722 - cost: 3.5305 - val_loss: 0.1151 - val_auc: 0.9892 - val_accuracy: 0.9660 - val_cost: 4.2791\n",
            "Epoch 60/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0903 - auc: 0.9931 - accuracy: 0.9716 - cost: 3.6142 - val_loss: 0.1164 - val_auc: 0.9890 - val_accuracy: 0.9644 - val_cost: 4.3452\n",
            "Epoch 61/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0888 - auc: 0.9933 - accuracy: 0.9720 - cost: 3.5575 - val_loss: 0.1147 - val_auc: 0.9892 - val_accuracy: 0.9664 - val_cost: 4.1369\n",
            "Epoch 62/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0890 - auc: 0.9932 - accuracy: 0.9721 - cost: 3.5529 - val_loss: 0.1152 - val_auc: 0.9893 - val_accuracy: 0.9658 - val_cost: 4.2063\n",
            "Epoch 63/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0871 - auc: 0.9934 - accuracy: 0.9730 - cost: 3.4340 - val_loss: 0.1136 - val_auc: 0.9893 - val_accuracy: 0.9664 - val_cost: 4.1997\n",
            "Epoch 64/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0873 - auc: 0.9934 - accuracy: 0.9732 - cost: 3.4217 - val_loss: 0.1150 - val_auc: 0.9891 - val_accuracy: 0.9665 - val_cost: 4.1071\n",
            "Epoch 65/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0864 - auc: 0.9936 - accuracy: 0.9733 - cost: 3.3981 - val_loss: 0.1135 - val_auc: 0.9895 - val_accuracy: 0.9669 - val_cost: 4.1865\n",
            "Epoch 66/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0861 - auc: 0.9936 - accuracy: 0.9730 - cost: 3.4421 - val_loss: 0.1124 - val_auc: 0.9893 - val_accuracy: 0.9663 - val_cost: 4.1898\n",
            "Epoch 67/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0856 - auc: 0.9936 - accuracy: 0.9737 - cost: 3.3600 - val_loss: 0.1142 - val_auc: 0.9894 - val_accuracy: 0.9677 - val_cost: 3.9187\n",
            "Epoch 68/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0864 - auc: 0.9934 - accuracy: 0.9734 - cost: 3.3873 - val_loss: 0.1144 - val_auc: 0.9893 - val_accuracy: 0.9667 - val_cost: 4.1303\n",
            "Epoch 69/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0853 - auc: 0.9936 - accuracy: 0.9739 - cost: 3.3368 - val_loss: 0.1132 - val_auc: 0.9894 - val_accuracy: 0.9674 - val_cost: 4.0013\n",
            "Epoch 70/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0848 - auc: 0.9937 - accuracy: 0.9740 - cost: 3.3183 - val_loss: 0.1116 - val_auc: 0.9896 - val_accuracy: 0.9674 - val_cost: 4.0939\n",
            "Epoch 71/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0834 - auc: 0.9937 - accuracy: 0.9745 - cost: 3.2546 - val_loss: 0.1116 - val_auc: 0.9897 - val_accuracy: 0.9681 - val_cost: 3.9881\n",
            "Epoch 72/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0828 - auc: 0.9938 - accuracy: 0.9746 - cost: 3.2438 - val_loss: 0.1121 - val_auc: 0.9896 - val_accuracy: 0.9674 - val_cost: 4.1766\n",
            "Epoch 73/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0828 - auc: 0.9939 - accuracy: 0.9745 - cost: 3.2508 - val_loss: 0.1120 - val_auc: 0.9895 - val_accuracy: 0.9674 - val_cost: 4.0774\n",
            "Epoch 74/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0826 - auc: 0.9939 - accuracy: 0.9747 - cost: 3.2269 - val_loss: 0.1111 - val_auc: 0.9897 - val_accuracy: 0.9685 - val_cost: 3.8724\n",
            "Epoch 75/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0815 - auc: 0.9941 - accuracy: 0.9747 - cost: 3.2234 - val_loss: 0.1119 - val_auc: 0.9896 - val_accuracy: 0.9678 - val_cost: 4.0840\n",
            "Epoch 76/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0818 - auc: 0.9940 - accuracy: 0.9748 - cost: 3.2133 - val_loss: 0.1118 - val_auc: 0.9895 - val_accuracy: 0.9676 - val_cost: 4.0046\n",
            "Epoch 77/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0815 - auc: 0.9939 - accuracy: 0.9750 - cost: 3.1925 - val_loss: 0.1131 - val_auc: 0.9895 - val_accuracy: 0.9673 - val_cost: 4.0939\n",
            "Epoch 78/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0809 - auc: 0.9941 - accuracy: 0.9755 - cost: 3.1389 - val_loss: 0.1104 - val_auc: 0.9897 - val_accuracy: 0.9691 - val_cost: 3.9087\n",
            "Epoch 79/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0809 - auc: 0.9941 - accuracy: 0.9752 - cost: 3.1624 - val_loss: 0.1108 - val_auc: 0.9895 - val_accuracy: 0.9688 - val_cost: 3.8790\n",
            "Epoch 80/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0806 - auc: 0.9940 - accuracy: 0.9754 - cost: 3.1316 - val_loss: 0.1114 - val_auc: 0.9898 - val_accuracy: 0.9685 - val_cost: 3.8856\n",
            "Epoch 81/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0794 - auc: 0.9942 - accuracy: 0.9759 - cost: 3.0698 - val_loss: 0.1098 - val_auc: 0.9896 - val_accuracy: 0.9690 - val_cost: 3.8558\n",
            "Epoch 82/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0794 - auc: 0.9941 - accuracy: 0.9762 - cost: 3.0285 - val_loss: 0.1099 - val_auc: 0.9894 - val_accuracy: 0.9688 - val_cost: 3.9054\n",
            "Epoch 83/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0789 - auc: 0.9943 - accuracy: 0.9756 - cost: 3.1142 - val_loss: 0.1113 - val_auc: 0.9894 - val_accuracy: 0.9689 - val_cost: 3.8955\n",
            "Epoch 84/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0782 - auc: 0.9943 - accuracy: 0.9765 - cost: 2.9958 - val_loss: 0.1092 - val_auc: 0.9899 - val_accuracy: 0.9691 - val_cost: 3.8724\n",
            "Epoch 85/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0784 - auc: 0.9944 - accuracy: 0.9761 - cost: 3.0478 - val_loss: 0.1100 - val_auc: 0.9895 - val_accuracy: 0.9694 - val_cost: 3.8856\n",
            "Epoch 86/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0789 - auc: 0.9941 - accuracy: 0.9761 - cost: 3.0451 - val_loss: 0.1089 - val_auc: 0.9898 - val_accuracy: 0.9692 - val_cost: 3.8955\n",
            "Epoch 87/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0770 - auc: 0.9944 - accuracy: 0.9770 - cost: 2.9387 - val_loss: 0.1113 - val_auc: 0.9896 - val_accuracy: 0.9685 - val_cost: 3.8261\n",
            "Epoch 88/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0776 - auc: 0.9944 - accuracy: 0.9766 - cost: 2.9826 - val_loss: 0.1098 - val_auc: 0.9896 - val_accuracy: 0.9699 - val_cost: 3.7566\n",
            "Epoch 89/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0767 - auc: 0.9945 - accuracy: 0.9770 - cost: 2.9321 - val_loss: 0.1101 - val_auc: 0.9897 - val_accuracy: 0.9703 - val_cost: 3.7632\n",
            "Epoch 90/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0771 - auc: 0.9942 - accuracy: 0.9772 - cost: 2.9124 - val_loss: 0.1117 - val_auc: 0.9896 - val_accuracy: 0.9690 - val_cost: 3.9319\n",
            "Epoch 91/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0771 - auc: 0.9945 - accuracy: 0.9767 - cost: 2.9568 - val_loss: 0.1091 - val_auc: 0.9897 - val_accuracy: 0.9698 - val_cost: 3.8062\n",
            "Epoch 92/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0773 - auc: 0.9943 - accuracy: 0.9765 - cost: 2.9981 - val_loss: 0.1104 - val_auc: 0.9895 - val_accuracy: 0.9697 - val_cost: 3.8360\n",
            "Epoch 93/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0756 - auc: 0.9946 - accuracy: 0.9770 - cost: 2.9302 - val_loss: 0.1087 - val_auc: 0.9898 - val_accuracy: 0.9697 - val_cost: 3.8558\n",
            "Epoch 94/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0752 - auc: 0.9946 - accuracy: 0.9772 - cost: 2.9124 - val_loss: 0.1113 - val_auc: 0.9896 - val_accuracy: 0.9700 - val_cost: 3.8194\n",
            "Epoch 95/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0754 - auc: 0.9945 - accuracy: 0.9774 - cost: 2.8785 - val_loss: 0.1104 - val_auc: 0.9899 - val_accuracy: 0.9709 - val_cost: 3.5681\n",
            "Epoch 96/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0748 - auc: 0.9946 - accuracy: 0.9774 - cost: 2.8862 - val_loss: 0.1097 - val_auc: 0.9898 - val_accuracy: 0.9704 - val_cost: 3.6971\n",
            "Epoch 97/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0749 - auc: 0.9947 - accuracy: 0.9771 - cost: 2.9105 - val_loss: 0.1098 - val_auc: 0.9897 - val_accuracy: 0.9695 - val_cost: 3.8327\n",
            "Epoch 98/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0748 - auc: 0.9946 - accuracy: 0.9775 - cost: 2.8735 - val_loss: 0.1087 - val_auc: 0.9896 - val_accuracy: 0.9701 - val_cost: 3.6971\n",
            "Epoch 99/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0745 - auc: 0.9946 - accuracy: 0.9774 - cost: 2.8924 - val_loss: 0.1102 - val_auc: 0.9899 - val_accuracy: 0.9690 - val_cost: 3.8261\n",
            "Epoch 100/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0749 - auc: 0.9947 - accuracy: 0.9776 - cost: 2.8484 - val_loss: 0.1091 - val_auc: 0.9898 - val_accuracy: 0.9701 - val_cost: 3.8525\n",
            "Epoch 101/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0734 - auc: 0.9948 - accuracy: 0.9779 - cost: 2.8314 - val_loss: 0.1079 - val_auc: 0.9899 - val_accuracy: 0.9708 - val_cost: 3.7070\n",
            "Epoch 102/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0743 - auc: 0.9947 - accuracy: 0.9776 - cost: 2.8569 - val_loss: 0.1093 - val_auc: 0.9897 - val_accuracy: 0.9701 - val_cost: 3.7798\n",
            "Epoch 103/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0732 - auc: 0.9948 - accuracy: 0.9785 - cost: 2.7380 - val_loss: 0.1097 - val_auc: 0.9896 - val_accuracy: 0.9699 - val_cost: 3.7302\n",
            "Epoch 104/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0730 - auc: 0.9949 - accuracy: 0.9783 - cost: 2.7712 - val_loss: 0.1080 - val_auc: 0.9900 - val_accuracy: 0.9712 - val_cost: 3.5946\n",
            "Epoch 105/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0734 - auc: 0.9947 - accuracy: 0.9781 - cost: 2.7905 - val_loss: 0.1092 - val_auc: 0.9894 - val_accuracy: 0.9705 - val_cost: 3.7037\n",
            "Epoch 106/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0730 - auc: 0.9948 - accuracy: 0.9781 - cost: 2.7975 - val_loss: 0.1090 - val_auc: 0.9896 - val_accuracy: 0.9703 - val_cost: 3.7831\n",
            "Epoch 107/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0730 - auc: 0.9948 - accuracy: 0.9784 - cost: 2.7616 - val_loss: 0.1062 - val_auc: 0.9900 - val_accuracy: 0.9706 - val_cost: 3.7831\n",
            "Epoch 108/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0726 - auc: 0.9949 - accuracy: 0.9783 - cost: 2.7739 - val_loss: 0.1087 - val_auc: 0.9898 - val_accuracy: 0.9705 - val_cost: 3.7599\n",
            "Epoch 109/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0716 - auc: 0.9949 - accuracy: 0.9786 - cost: 2.7407 - val_loss: 0.1081 - val_auc: 0.9897 - val_accuracy: 0.9710 - val_cost: 3.6276\n",
            "Epoch 110/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0726 - auc: 0.9949 - accuracy: 0.9784 - cost: 2.7569 - val_loss: 0.1073 - val_auc: 0.9902 - val_accuracy: 0.9710 - val_cost: 3.6772\n",
            "Epoch 111/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0719 - auc: 0.9950 - accuracy: 0.9786 - cost: 2.7249 - val_loss: 0.1085 - val_auc: 0.9899 - val_accuracy: 0.9713 - val_cost: 3.6475\n",
            "Epoch 112/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0717 - auc: 0.9950 - accuracy: 0.9784 - cost: 2.7604 - val_loss: 0.1085 - val_auc: 0.9900 - val_accuracy: 0.9706 - val_cost: 3.7202\n",
            "Epoch 113/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0714 - auc: 0.9949 - accuracy: 0.9789 - cost: 2.6844 - val_loss: 0.1071 - val_auc: 0.9900 - val_accuracy: 0.9712 - val_cost: 3.5615\n",
            "Epoch 114/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0714 - auc: 0.9950 - accuracy: 0.9788 - cost: 2.7164 - val_loss: 0.1083 - val_auc: 0.9898 - val_accuracy: 0.9703 - val_cost: 3.7269\n",
            "Epoch 115/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0711 - auc: 0.9950 - accuracy: 0.9786 - cost: 2.7450 - val_loss: 0.1083 - val_auc: 0.9896 - val_accuracy: 0.9714 - val_cost: 3.6111\n",
            "Epoch 116/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0702 - auc: 0.9951 - accuracy: 0.9794 - cost: 2.6427 - val_loss: 0.1098 - val_auc: 0.9900 - val_accuracy: 0.9703 - val_cost: 3.6706\n",
            "Epoch 117/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0709 - auc: 0.9950 - accuracy: 0.9791 - cost: 2.6609 - val_loss: 0.1098 - val_auc: 0.9899 - val_accuracy: 0.9703 - val_cost: 3.6376\n",
            "Epoch 118/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0703 - auc: 0.9949 - accuracy: 0.9792 - cost: 2.6597 - val_loss: 0.1071 - val_auc: 0.9900 - val_accuracy: 0.9714 - val_cost: 3.4987\n",
            "Epoch 119/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0708 - auc: 0.9949 - accuracy: 0.9792 - cost: 2.6578 - val_loss: 0.1074 - val_auc: 0.9900 - val_accuracy: 0.9712 - val_cost: 3.6607\n",
            "Epoch 120/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0708 - auc: 0.9949 - accuracy: 0.9789 - cost: 2.6964 - val_loss: 0.1075 - val_auc: 0.9901 - val_accuracy: 0.9717 - val_cost: 3.6045\n",
            "Epoch 121/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0691 - auc: 0.9952 - accuracy: 0.9796 - cost: 2.6007 - val_loss: 0.1091 - val_auc: 0.9898 - val_accuracy: 0.9707 - val_cost: 3.6574\n",
            "Epoch 122/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0698 - auc: 0.9951 - accuracy: 0.9791 - cost: 2.6601 - val_loss: 0.1081 - val_auc: 0.9899 - val_accuracy: 0.9710 - val_cost: 3.6541\n",
            "Epoch 123/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0707 - auc: 0.9951 - accuracy: 0.9788 - cost: 2.7133 - val_loss: 0.1076 - val_auc: 0.9900 - val_accuracy: 0.9712 - val_cost: 3.5681\n",
            "Epoch 124/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0697 - auc: 0.9951 - accuracy: 0.9792 - cost: 2.6566 - val_loss: 0.1088 - val_auc: 0.9900 - val_accuracy: 0.9705 - val_cost: 3.7831\n",
            "Epoch 125/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0691 - auc: 0.9951 - accuracy: 0.9797 - cost: 2.5995 - val_loss: 0.1088 - val_auc: 0.9897 - val_accuracy: 0.9713 - val_cost: 3.5780\n",
            "Epoch 126/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0692 - auc: 0.9952 - accuracy: 0.9798 - cost: 2.5810 - val_loss: 0.1090 - val_auc: 0.9899 - val_accuracy: 0.9715 - val_cost: 3.6310\n",
            "Epoch 127/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0692 - auc: 0.9952 - accuracy: 0.9793 - cost: 2.6539 - val_loss: 0.1087 - val_auc: 0.9899 - val_accuracy: 0.9717 - val_cost: 3.5384\n",
            "Epoch 128/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0696 - auc: 0.9951 - accuracy: 0.9790 - cost: 2.6860 - val_loss: 0.1084 - val_auc: 0.9898 - val_accuracy: 0.9710 - val_cost: 3.6310\n",
            "Epoch 129/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0690 - auc: 0.9951 - accuracy: 0.9797 - cost: 2.6111 - val_loss: 0.1086 - val_auc: 0.9899 - val_accuracy: 0.9711 - val_cost: 3.6508\n",
            "Epoch 130/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0684 - auc: 0.9953 - accuracy: 0.9794 - cost: 2.6393 - val_loss: 0.1094 - val_auc: 0.9897 - val_accuracy: 0.9708 - val_cost: 3.5780\n",
            "Epoch 131/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0688 - auc: 0.9951 - accuracy: 0.9799 - cost: 2.5710 - val_loss: 0.1083 - val_auc: 0.9898 - val_accuracy: 0.9712 - val_cost: 3.6177\n",
            "Epoch 132/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0691 - auc: 0.9953 - accuracy: 0.9791 - cost: 2.6817 - val_loss: 0.1067 - val_auc: 0.9897 - val_accuracy: 0.9715 - val_cost: 3.6177\n",
            "Epoch 133/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0676 - auc: 0.9954 - accuracy: 0.9799 - cost: 2.5733 - val_loss: 0.1080 - val_auc: 0.9899 - val_accuracy: 0.9708 - val_cost: 3.7467\n",
            "Epoch 134/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0678 - auc: 0.9954 - accuracy: 0.9797 - cost: 2.6042 - val_loss: 0.1076 - val_auc: 0.9898 - val_accuracy: 0.9710 - val_cost: 3.6409\n",
            "Epoch 135/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0675 - auc: 0.9953 - accuracy: 0.9800 - cost: 2.5579 - val_loss: 0.1099 - val_auc: 0.9896 - val_accuracy: 0.9706 - val_cost: 3.7533\n",
            "Epoch 136/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0682 - auc: 0.9953 - accuracy: 0.9800 - cost: 2.5633 - val_loss: 0.1075 - val_auc: 0.9902 - val_accuracy: 0.9714 - val_cost: 3.5813\n",
            "Epoch 137/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0679 - auc: 0.9953 - accuracy: 0.9800 - cost: 2.5590 - val_loss: 0.1104 - val_auc: 0.9898 - val_accuracy: 0.9705 - val_cost: 3.6177\n",
            "Epoch 138/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0677 - auc: 0.9953 - accuracy: 0.9798 - cost: 2.5810 - val_loss: 0.1087 - val_auc: 0.9896 - val_accuracy: 0.9719 - val_cost: 3.4557\n",
            "Epoch 139/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0678 - auc: 0.9953 - accuracy: 0.9799 - cost: 2.5675 - val_loss: 0.1075 - val_auc: 0.9898 - val_accuracy: 0.9717 - val_cost: 3.5218\n",
            "Epoch 140/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0672 - auc: 0.9954 - accuracy: 0.9801 - cost: 2.5482 - val_loss: 0.1096 - val_auc: 0.9898 - val_accuracy: 0.9711 - val_cost: 3.5979\n",
            "Epoch 141/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0662 - auc: 0.9955 - accuracy: 0.9803 - cost: 2.5285 - val_loss: 0.1087 - val_auc: 0.9895 - val_accuracy: 0.9710 - val_cost: 3.6706\n",
            "Epoch 142/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0673 - auc: 0.9954 - accuracy: 0.9799 - cost: 2.5856 - val_loss: 0.1092 - val_auc: 0.9900 - val_accuracy: 0.9717 - val_cost: 3.5747\n",
            "Epoch 143/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0671 - auc: 0.9953 - accuracy: 0.9804 - cost: 2.5039 - val_loss: 0.1110 - val_auc: 0.9893 - val_accuracy: 0.9710 - val_cost: 3.7235\n",
            "Epoch 144/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0666 - auc: 0.9954 - accuracy: 0.9804 - cost: 2.5243 - val_loss: 0.1102 - val_auc: 0.9894 - val_accuracy: 0.9715 - val_cost: 3.4855\n",
            "Epoch 145/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0671 - auc: 0.9953 - accuracy: 0.9805 - cost: 2.5031 - val_loss: 0.1089 - val_auc: 0.9893 - val_accuracy: 0.9718 - val_cost: 3.5582\n",
            "Epoch 146/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0664 - auc: 0.9954 - accuracy: 0.9803 - cost: 2.5174 - val_loss: 0.1091 - val_auc: 0.9897 - val_accuracy: 0.9712 - val_cost: 3.5351\n",
            "Epoch 147/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0653 - auc: 0.9956 - accuracy: 0.9804 - cost: 2.5131 - val_loss: 0.1082 - val_auc: 0.9897 - val_accuracy: 0.9715 - val_cost: 3.5813\n",
            "Epoch 148/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0663 - auc: 0.9955 - accuracy: 0.9806 - cost: 2.4846 - val_loss: 0.1100 - val_auc: 0.9899 - val_accuracy: 0.9703 - val_cost: 3.6739\n",
            "Epoch 149/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0659 - auc: 0.9955 - accuracy: 0.9802 - cost: 2.5278 - val_loss: 0.1105 - val_auc: 0.9893 - val_accuracy: 0.9706 - val_cost: 3.6739\n",
            "Epoch 150/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0663 - auc: 0.9954 - accuracy: 0.9802 - cost: 2.5421 - val_loss: 0.1103 - val_auc: 0.9896 - val_accuracy: 0.9715 - val_cost: 3.5284\n",
            "Epoch 151/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0660 - auc: 0.9954 - accuracy: 0.9804 - cost: 2.5197 - val_loss: 0.1094 - val_auc: 0.9892 - val_accuracy: 0.9711 - val_cost: 3.5979\n",
            "Epoch 152/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0658 - auc: 0.9954 - accuracy: 0.9803 - cost: 2.5258 - val_loss: 0.1108 - val_auc: 0.9896 - val_accuracy: 0.9713 - val_cost: 3.5780\n",
            "Epoch 153/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0658 - auc: 0.9955 - accuracy: 0.9804 - cost: 2.5039 - val_loss: 0.1110 - val_auc: 0.9892 - val_accuracy: 0.9705 - val_cost: 3.7269\n",
            "Epoch 154/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0656 - auc: 0.9956 - accuracy: 0.9804 - cost: 2.5077 - val_loss: 0.1107 - val_auc: 0.9894 - val_accuracy: 0.9707 - val_cost: 3.6012\n",
            "Epoch 155/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0655 - auc: 0.9954 - accuracy: 0.9809 - cost: 2.4414 - val_loss: 0.1122 - val_auc: 0.9896 - val_accuracy: 0.9701 - val_cost: 3.8228\n",
            "Epoch 156/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0640 - auc: 0.9956 - accuracy: 0.9815 - cost: 2.3723 - val_loss: 0.1099 - val_auc: 0.9895 - val_accuracy: 0.9715 - val_cost: 3.5483\n",
            "Epoch 157/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0653 - auc: 0.9956 - accuracy: 0.9808 - cost: 2.4579 - val_loss: 0.1114 - val_auc: 0.9893 - val_accuracy: 0.9706 - val_cost: 3.6905\n",
            "Epoch 158/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0652 - auc: 0.9956 - accuracy: 0.9807 - cost: 2.4549 - val_loss: 0.1104 - val_auc: 0.9896 - val_accuracy: 0.9702 - val_cost: 3.7632\n",
            "Epoch 159/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0647 - auc: 0.9956 - accuracy: 0.9806 - cost: 2.4865 - val_loss: 0.1104 - val_auc: 0.9897 - val_accuracy: 0.9706 - val_cost: 3.6243\n",
            "Epoch 160/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0645 - auc: 0.9957 - accuracy: 0.9809 - cost: 2.4464 - val_loss: 0.1112 - val_auc: 0.9895 - val_accuracy: 0.9717 - val_cost: 3.5615\n",
            "Epoch 161/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0652 - auc: 0.9955 - accuracy: 0.9810 - cost: 2.4275 - val_loss: 0.1101 - val_auc: 0.9897 - val_accuracy: 0.9715 - val_cost: 3.5747\n",
            "Epoch 162/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0646 - auc: 0.9957 - accuracy: 0.9809 - cost: 2.4340 - val_loss: 0.1110 - val_auc: 0.9895 - val_accuracy: 0.9706 - val_cost: 3.6971\n",
            "Epoch 163/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0645 - auc: 0.9956 - accuracy: 0.9810 - cost: 2.4309 - val_loss: 0.1087 - val_auc: 0.9897 - val_accuracy: 0.9707 - val_cost: 3.7665\n",
            "Epoch 164/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0639 - auc: 0.9957 - accuracy: 0.9810 - cost: 2.4371 - val_loss: 0.1102 - val_auc: 0.9896 - val_accuracy: 0.9706 - val_cost: 3.7004\n",
            "Epoch 165/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0643 - auc: 0.9957 - accuracy: 0.9811 - cost: 2.4124 - val_loss: 0.1104 - val_auc: 0.9895 - val_accuracy: 0.9708 - val_cost: 3.6673\n",
            "Epoch 166/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0641 - auc: 0.9957 - accuracy: 0.9810 - cost: 2.4282 - val_loss: 0.1118 - val_auc: 0.9891 - val_accuracy: 0.9701 - val_cost: 3.7335\n",
            "Epoch 167/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0640 - auc: 0.9957 - accuracy: 0.9810 - cost: 2.4371 - val_loss: 0.1113 - val_auc: 0.9897 - val_accuracy: 0.9713 - val_cost: 3.6111\n",
            "Epoch 168/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0633 - auc: 0.9958 - accuracy: 0.9811 - cost: 2.4225 - val_loss: 0.1108 - val_auc: 0.9896 - val_accuracy: 0.9719 - val_cost: 3.5615\n",
            "Epoch 169/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0631 - auc: 0.9958 - accuracy: 0.9810 - cost: 2.4240 - val_loss: 0.1098 - val_auc: 0.9897 - val_accuracy: 0.9713 - val_cost: 3.7368\n",
            "Epoch 170/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0635 - auc: 0.9957 - accuracy: 0.9812 - cost: 2.4144 - val_loss: 0.1117 - val_auc: 0.9894 - val_accuracy: 0.9710 - val_cost: 3.6012\n",
            "Epoch 171/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0634 - auc: 0.9959 - accuracy: 0.9809 - cost: 2.4437 - val_loss: 0.1134 - val_auc: 0.9896 - val_accuracy: 0.9701 - val_cost: 3.7434\n",
            "Epoch 172/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0633 - auc: 0.9957 - accuracy: 0.9814 - cost: 2.3808 - val_loss: 0.1123 - val_auc: 0.9893 - val_accuracy: 0.9707 - val_cost: 3.7070\n",
            "Epoch 173/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0622 - auc: 0.9960 - accuracy: 0.9813 - cost: 2.3927 - val_loss: 0.1108 - val_auc: 0.9896 - val_accuracy: 0.9708 - val_cost: 3.7235\n",
            "Epoch 174/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0626 - auc: 0.9958 - accuracy: 0.9817 - cost: 2.3329 - val_loss: 0.1117 - val_auc: 0.9892 - val_accuracy: 0.9710 - val_cost: 3.7070\n",
            "Epoch 175/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0636 - auc: 0.9958 - accuracy: 0.9813 - cost: 2.3916 - val_loss: 0.1101 - val_auc: 0.9898 - val_accuracy: 0.9717 - val_cost: 3.6210\n",
            "Epoch 176/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0634 - auc: 0.9957 - accuracy: 0.9809 - cost: 2.4525 - val_loss: 0.1117 - val_auc: 0.9895 - val_accuracy: 0.9706 - val_cost: 3.6938\n",
            "Epoch 177/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0634 - auc: 0.9958 - accuracy: 0.9815 - cost: 2.3650 - val_loss: 0.1117 - val_auc: 0.9894 - val_accuracy: 0.9706 - val_cost: 3.6706\n",
            "Epoch 178/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0639 - auc: 0.9958 - accuracy: 0.9805 - cost: 2.4977 - val_loss: 0.1114 - val_auc: 0.9899 - val_accuracy: 0.9719 - val_cost: 3.5450\n",
            "Epoch 179/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0619 - auc: 0.9959 - accuracy: 0.9817 - cost: 2.3553 - val_loss: 0.1131 - val_auc: 0.9897 - val_accuracy: 0.9711 - val_cost: 3.6177\n",
            "Epoch 180/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0621 - auc: 0.9958 - accuracy: 0.9820 - cost: 2.2994 - val_loss: 0.1121 - val_auc: 0.9896 - val_accuracy: 0.9701 - val_cost: 3.7169\n",
            "Epoch 181/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0623 - auc: 0.9959 - accuracy: 0.9815 - cost: 2.3661 - val_loss: 0.1113 - val_auc: 0.9893 - val_accuracy: 0.9710 - val_cost: 3.7897\n",
            "Epoch 182/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0621 - auc: 0.9959 - accuracy: 0.9820 - cost: 2.3113 - val_loss: 0.1133 - val_auc: 0.9894 - val_accuracy: 0.9708 - val_cost: 3.7202\n",
            "Epoch 183/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0630 - auc: 0.9958 - accuracy: 0.9814 - cost: 2.3804 - val_loss: 0.1138 - val_auc: 0.9894 - val_accuracy: 0.9710 - val_cost: 3.7467\n",
            "Epoch 184/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0613 - auc: 0.9960 - accuracy: 0.9820 - cost: 2.3056 - val_loss: 0.1136 - val_auc: 0.9894 - val_accuracy: 0.9706 - val_cost: 3.8327\n",
            "Epoch 185/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0617 - auc: 0.9959 - accuracy: 0.9817 - cost: 2.3499 - val_loss: 0.1139 - val_auc: 0.9894 - val_accuracy: 0.9708 - val_cost: 3.7765\n",
            "Epoch 186/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0627 - auc: 0.9959 - accuracy: 0.9815 - cost: 2.3719 - val_loss: 0.1133 - val_auc: 0.9892 - val_accuracy: 0.9724 - val_cost: 3.5615\n",
            "Epoch 187/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0613 - auc: 0.9959 - accuracy: 0.9818 - cost: 2.3233 - val_loss: 0.1136 - val_auc: 0.9893 - val_accuracy: 0.9707 - val_cost: 3.7698\n",
            "Epoch 188/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0618 - auc: 0.9960 - accuracy: 0.9814 - cost: 2.3831 - val_loss: 0.1135 - val_auc: 0.9893 - val_accuracy: 0.9697 - val_cost: 3.8856\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.1074 - auc: 0.9908 - accuracy: 0.9709 - cost: 3.5906\n",
            "500/500 [==============================] - 1s 994us/step\n",
            "fold train/predict time: 0:01:17.749013\n",
            "fold accuracy: 0.9709374904632568 - fold cost: 3.590625047683716\n",
            "x_train shape: (144000, 67)\n",
            "Epoch 1/1000\n",
            "120/120 [==============================] - 2s 5ms/step - loss: 0.5333 - auc: 0.7947 - accuracy: 0.7271 - cost: 36.3997 - val_loss: 0.4027 - val_auc: 0.8969 - val_accuracy: 0.8235 - val_cost: 23.0423\n",
            "Epoch 2/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.3527 - auc: 0.9209 - accuracy: 0.8479 - cost: 19.4020 - val_loss: 0.3177 - val_auc: 0.9359 - val_accuracy: 0.8650 - val_cost: 16.9213\n",
            "Epoch 3/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.3028 - auc: 0.9419 - accuracy: 0.8752 - cost: 15.7909 - val_loss: 0.2890 - val_auc: 0.9475 - val_accuracy: 0.8792 - val_cost: 15.4729\n",
            "Epoch 4/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.2740 - auc: 0.9525 - accuracy: 0.8884 - cost: 14.1358 - val_loss: 0.2635 - val_auc: 0.9561 - val_accuracy: 0.8938 - val_cost: 13.3796\n",
            "Epoch 5/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.2506 - auc: 0.9604 - accuracy: 0.8993 - cost: 12.7488 - val_loss: 0.2435 - val_auc: 0.9626 - val_accuracy: 0.9040 - val_cost: 11.9676\n",
            "Epoch 6/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.2320 - auc: 0.9659 - accuracy: 0.9086 - cost: 11.5648 - val_loss: 0.2277 - val_auc: 0.9673 - val_accuracy: 0.9121 - val_cost: 11.2731\n",
            "Epoch 7/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.2168 - auc: 0.9701 - accuracy: 0.9166 - cost: 10.5451 - val_loss: 0.2139 - val_auc: 0.9710 - val_accuracy: 0.9191 - val_cost: 10.1323\n",
            "Epoch 8/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.2030 - auc: 0.9737 - accuracy: 0.9224 - cost: 9.8021 - val_loss: 0.2010 - val_auc: 0.9743 - val_accuracy: 0.9260 - val_cost: 9.3585\n",
            "Epoch 9/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1919 - auc: 0.9765 - accuracy: 0.9271 - cost: 9.2215 - val_loss: 0.1915 - val_auc: 0.9765 - val_accuracy: 0.9309 - val_cost: 8.7930\n",
            "Epoch 10/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1826 - auc: 0.9785 - accuracy: 0.9319 - cost: 8.6215 - val_loss: 0.1851 - val_auc: 0.9779 - val_accuracy: 0.9330 - val_cost: 8.3697\n",
            "Epoch 11/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1756 - auc: 0.9800 - accuracy: 0.9350 - cost: 8.2392 - val_loss: 0.1771 - val_auc: 0.9796 - val_accuracy: 0.9372 - val_cost: 7.8274\n",
            "Epoch 12/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1680 - auc: 0.9816 - accuracy: 0.9382 - cost: 7.8345 - val_loss: 0.1716 - val_auc: 0.9806 - val_accuracy: 0.9392 - val_cost: 7.7116\n",
            "Epoch 13/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1631 - auc: 0.9825 - accuracy: 0.9407 - cost: 7.5166 - val_loss: 0.1664 - val_auc: 0.9818 - val_accuracy: 0.9407 - val_cost: 7.4372\n",
            "Epoch 14/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1572 - auc: 0.9836 - accuracy: 0.9434 - cost: 7.1628 - val_loss: 0.1611 - val_auc: 0.9828 - val_accuracy: 0.9433 - val_cost: 7.1792\n",
            "Epoch 15/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1526 - auc: 0.9845 - accuracy: 0.9453 - cost: 6.9174 - val_loss: 0.1576 - val_auc: 0.9835 - val_accuracy: 0.9458 - val_cost: 6.8915\n",
            "Epoch 16/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1495 - auc: 0.9849 - accuracy: 0.9467 - cost: 6.7481 - val_loss: 0.1552 - val_auc: 0.9838 - val_accuracy: 0.9458 - val_cost: 6.6634\n",
            "Epoch 17/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1450 - auc: 0.9859 - accuracy: 0.9490 - cost: 6.4695 - val_loss: 0.1526 - val_auc: 0.9842 - val_accuracy: 0.9472 - val_cost: 6.6667\n",
            "Epoch 18/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1412 - auc: 0.9864 - accuracy: 0.9499 - cost: 6.3445 - val_loss: 0.1497 - val_auc: 0.9849 - val_accuracy: 0.9474 - val_cost: 6.4649\n",
            "Epoch 19/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1388 - auc: 0.9868 - accuracy: 0.9517 - cost: 6.1285 - val_loss: 0.1490 - val_auc: 0.9849 - val_accuracy: 0.9481 - val_cost: 6.6700\n",
            "Epoch 20/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1364 - auc: 0.9872 - accuracy: 0.9525 - cost: 6.0293 - val_loss: 0.1455 - val_auc: 0.9856 - val_accuracy: 0.9504 - val_cost: 6.1475\n",
            "Epoch 21/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1324 - auc: 0.9879 - accuracy: 0.9541 - cost: 5.8171 - val_loss: 0.1447 - val_auc: 0.9856 - val_accuracy: 0.9506 - val_cost: 6.2533\n",
            "Epoch 22/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1296 - auc: 0.9882 - accuracy: 0.9557 - cost: 5.6146 - val_loss: 0.1416 - val_auc: 0.9861 - val_accuracy: 0.9517 - val_cost: 5.9755\n",
            "Epoch 23/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1279 - auc: 0.9884 - accuracy: 0.9564 - cost: 5.5062 - val_loss: 0.1406 - val_auc: 0.9862 - val_accuracy: 0.9530 - val_cost: 5.9888\n",
            "Epoch 24/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1262 - auc: 0.9887 - accuracy: 0.9570 - cost: 5.4444 - val_loss: 0.1387 - val_auc: 0.9864 - val_accuracy: 0.9547 - val_cost: 5.5423\n",
            "Epoch 25/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1230 - auc: 0.9892 - accuracy: 0.9583 - cost: 5.3036 - val_loss: 0.1356 - val_auc: 0.9867 - val_accuracy: 0.9557 - val_cost: 5.6283\n",
            "Epoch 26/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1211 - auc: 0.9895 - accuracy: 0.9587 - cost: 5.2373 - val_loss: 0.1350 - val_auc: 0.9869 - val_accuracy: 0.9561 - val_cost: 5.5026\n",
            "Epoch 27/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1193 - auc: 0.9897 - accuracy: 0.9598 - cost: 5.1046 - val_loss: 0.1340 - val_auc: 0.9870 - val_accuracy: 0.9561 - val_cost: 5.4696\n",
            "Epoch 28/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1171 - auc: 0.9900 - accuracy: 0.9607 - cost: 4.9776 - val_loss: 0.1335 - val_auc: 0.9871 - val_accuracy: 0.9568 - val_cost: 5.4101\n",
            "Epoch 29/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1152 - auc: 0.9902 - accuracy: 0.9617 - cost: 4.8603 - val_loss: 0.1311 - val_auc: 0.9874 - val_accuracy: 0.9576 - val_cost: 5.4332\n",
            "Epoch 30/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1144 - auc: 0.9903 - accuracy: 0.9619 - cost: 4.8434 - val_loss: 0.1290 - val_auc: 0.9876 - val_accuracy: 0.9592 - val_cost: 5.1124\n",
            "Epoch 31/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1128 - auc: 0.9905 - accuracy: 0.9626 - cost: 4.7423 - val_loss: 0.1290 - val_auc: 0.9876 - val_accuracy: 0.9592 - val_cost: 5.3208\n",
            "Epoch 32/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1107 - auc: 0.9908 - accuracy: 0.9635 - cost: 4.6431 - val_loss: 0.1287 - val_auc: 0.9877 - val_accuracy: 0.9585 - val_cost: 5.1257\n",
            "Epoch 33/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1093 - auc: 0.9910 - accuracy: 0.9638 - cost: 4.6030 - val_loss: 0.1265 - val_auc: 0.9879 - val_accuracy: 0.9594 - val_cost: 5.1753\n",
            "Epoch 34/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1076 - auc: 0.9912 - accuracy: 0.9646 - cost: 4.5012 - val_loss: 0.1259 - val_auc: 0.9880 - val_accuracy: 0.9595 - val_cost: 5.0198\n",
            "Epoch 35/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1063 - auc: 0.9913 - accuracy: 0.9653 - cost: 4.4201 - val_loss: 0.1253 - val_auc: 0.9883 - val_accuracy: 0.9608 - val_cost: 4.8776\n",
            "Epoch 36/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1041 - auc: 0.9915 - accuracy: 0.9662 - cost: 4.2785 - val_loss: 0.1241 - val_auc: 0.9883 - val_accuracy: 0.9599 - val_cost: 5.1521\n",
            "Epoch 37/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1040 - auc: 0.9916 - accuracy: 0.9660 - cost: 4.3345 - val_loss: 0.1235 - val_auc: 0.9884 - val_accuracy: 0.9606 - val_cost: 4.8743\n",
            "Epoch 38/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1026 - auc: 0.9917 - accuracy: 0.9672 - cost: 4.1551 - val_loss: 0.1232 - val_auc: 0.9884 - val_accuracy: 0.9607 - val_cost: 4.8545\n",
            "Epoch 39/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1018 - auc: 0.9918 - accuracy: 0.9669 - cost: 4.1948 - val_loss: 0.1226 - val_auc: 0.9886 - val_accuracy: 0.9619 - val_cost: 4.8347\n",
            "Epoch 40/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1007 - auc: 0.9919 - accuracy: 0.9681 - cost: 4.0513 - val_loss: 0.1207 - val_auc: 0.9888 - val_accuracy: 0.9619 - val_cost: 4.8810\n",
            "Epoch 41/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0992 - auc: 0.9922 - accuracy: 0.9679 - cost: 4.0779 - val_loss: 0.1219 - val_auc: 0.9887 - val_accuracy: 0.9626 - val_cost: 4.5899\n",
            "Epoch 42/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0989 - auc: 0.9921 - accuracy: 0.9686 - cost: 3.9838 - val_loss: 0.1210 - val_auc: 0.9885 - val_accuracy: 0.9615 - val_cost: 4.7817\n",
            "Epoch 43/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0973 - auc: 0.9924 - accuracy: 0.9689 - cost: 3.9522 - val_loss: 0.1197 - val_auc: 0.9888 - val_accuracy: 0.9625 - val_cost: 4.7652\n",
            "Epoch 44/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0967 - auc: 0.9924 - accuracy: 0.9692 - cost: 3.9240 - val_loss: 0.1217 - val_auc: 0.9887 - val_accuracy: 0.9632 - val_cost: 4.4577\n",
            "Epoch 45/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0956 - auc: 0.9926 - accuracy: 0.9693 - cost: 3.9086 - val_loss: 0.1195 - val_auc: 0.9892 - val_accuracy: 0.9629 - val_cost: 4.5470\n",
            "Epoch 46/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0955 - auc: 0.9926 - accuracy: 0.9693 - cost: 3.9074 - val_loss: 0.1177 - val_auc: 0.9893 - val_accuracy: 0.9642 - val_cost: 4.4544\n",
            "Epoch 47/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0941 - auc: 0.9928 - accuracy: 0.9702 - cost: 3.7955 - val_loss: 0.1168 - val_auc: 0.9890 - val_accuracy: 0.9648 - val_cost: 4.4048\n",
            "Epoch 48/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0929 - auc: 0.9928 - accuracy: 0.9709 - cost: 3.6987 - val_loss: 0.1184 - val_auc: 0.9891 - val_accuracy: 0.9647 - val_cost: 4.3221\n",
            "Epoch 49/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0927 - auc: 0.9929 - accuracy: 0.9707 - cost: 3.7307 - val_loss: 0.1196 - val_auc: 0.9890 - val_accuracy: 0.9635 - val_cost: 4.4213\n",
            "Epoch 50/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0916 - auc: 0.9930 - accuracy: 0.9709 - cost: 3.6898 - val_loss: 0.1177 - val_auc: 0.9893 - val_accuracy: 0.9648 - val_cost: 4.5073\n",
            "Epoch 51/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0912 - auc: 0.9930 - accuracy: 0.9715 - cost: 3.6238 - val_loss: 0.1180 - val_auc: 0.9891 - val_accuracy: 0.9641 - val_cost: 4.5205\n",
            "Epoch 52/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0900 - auc: 0.9932 - accuracy: 0.9716 - cost: 3.6103 - val_loss: 0.1169 - val_auc: 0.9893 - val_accuracy: 0.9648 - val_cost: 4.4345\n",
            "Epoch 53/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0899 - auc: 0.9932 - accuracy: 0.9723 - cost: 3.5324 - val_loss: 0.1154 - val_auc: 0.9894 - val_accuracy: 0.9649 - val_cost: 4.3585\n",
            "Epoch 54/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0886 - auc: 0.9932 - accuracy: 0.9725 - cost: 3.4954 - val_loss: 0.1147 - val_auc: 0.9896 - val_accuracy: 0.9658 - val_cost: 4.3221\n",
            "Epoch 55/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0885 - auc: 0.9932 - accuracy: 0.9724 - cost: 3.5015 - val_loss: 0.1140 - val_auc: 0.9897 - val_accuracy: 0.9656 - val_cost: 4.4676\n",
            "Epoch 56/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0874 - auc: 0.9934 - accuracy: 0.9730 - cost: 3.4344 - val_loss: 0.1149 - val_auc: 0.9897 - val_accuracy: 0.9655 - val_cost: 4.4246\n",
            "Epoch 57/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0870 - auc: 0.9934 - accuracy: 0.9730 - cost: 3.4514 - val_loss: 0.1157 - val_auc: 0.9894 - val_accuracy: 0.9658 - val_cost: 4.2229\n",
            "Epoch 58/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0866 - auc: 0.9934 - accuracy: 0.9727 - cost: 3.4645 - val_loss: 0.1136 - val_auc: 0.9898 - val_accuracy: 0.9658 - val_cost: 4.2890\n",
            "Epoch 59/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0866 - auc: 0.9934 - accuracy: 0.9726 - cost: 3.4846 - val_loss: 0.1146 - val_auc: 0.9895 - val_accuracy: 0.9652 - val_cost: 4.4147\n",
            "Epoch 60/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0857 - auc: 0.9936 - accuracy: 0.9737 - cost: 3.3549 - val_loss: 0.1147 - val_auc: 0.9896 - val_accuracy: 0.9666 - val_cost: 4.0807\n",
            "Epoch 61/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0855 - auc: 0.9937 - accuracy: 0.9734 - cost: 3.3916 - val_loss: 0.1145 - val_auc: 0.9898 - val_accuracy: 0.9660 - val_cost: 4.1931\n",
            "Epoch 62/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0852 - auc: 0.9937 - accuracy: 0.9735 - cost: 3.3746 - val_loss: 0.1141 - val_auc: 0.9897 - val_accuracy: 0.9658 - val_cost: 4.2725\n",
            "Epoch 63/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0841 - auc: 0.9937 - accuracy: 0.9737 - cost: 3.3511 - val_loss: 0.1135 - val_auc: 0.9896 - val_accuracy: 0.9660 - val_cost: 4.1766\n",
            "Epoch 64/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0837 - auc: 0.9938 - accuracy: 0.9744 - cost: 3.2662 - val_loss: 0.1146 - val_auc: 0.9898 - val_accuracy: 0.9662 - val_cost: 4.1402\n",
            "Epoch 65/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0833 - auc: 0.9938 - accuracy: 0.9742 - cost: 3.3029 - val_loss: 0.1116 - val_auc: 0.9902 - val_accuracy: 0.9667 - val_cost: 4.1997\n",
            "Epoch 66/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0832 - auc: 0.9938 - accuracy: 0.9744 - cost: 3.2627 - val_loss: 0.1132 - val_auc: 0.9899 - val_accuracy: 0.9659 - val_cost: 4.4015\n",
            "Epoch 67/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0822 - auc: 0.9939 - accuracy: 0.9743 - cost: 3.2704 - val_loss: 0.1143 - val_auc: 0.9898 - val_accuracy: 0.9663 - val_cost: 4.1071\n",
            "Epoch 68/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0817 - auc: 0.9940 - accuracy: 0.9749 - cost: 3.1952 - val_loss: 0.1119 - val_auc: 0.9897 - val_accuracy: 0.9671 - val_cost: 4.0840\n",
            "Epoch 69/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0815 - auc: 0.9939 - accuracy: 0.9752 - cost: 3.1532 - val_loss: 0.1117 - val_auc: 0.9899 - val_accuracy: 0.9672 - val_cost: 4.1832\n",
            "Epoch 70/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0816 - auc: 0.9940 - accuracy: 0.9748 - cost: 3.2245 - val_loss: 0.1134 - val_auc: 0.9897 - val_accuracy: 0.9667 - val_cost: 4.1369\n",
            "Epoch 71/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0820 - auc: 0.9940 - accuracy: 0.9746 - cost: 3.2473 - val_loss: 0.1110 - val_auc: 0.9901 - val_accuracy: 0.9674 - val_cost: 4.1667\n",
            "Epoch 72/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0804 - auc: 0.9940 - accuracy: 0.9752 - cost: 3.1601 - val_loss: 0.1103 - val_auc: 0.9900 - val_accuracy: 0.9679 - val_cost: 4.0708\n",
            "Epoch 73/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0801 - auc: 0.9940 - accuracy: 0.9753 - cost: 3.1551 - val_loss: 0.1102 - val_auc: 0.9900 - val_accuracy: 0.9675 - val_cost: 4.1567\n",
            "Epoch 74/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0792 - auc: 0.9942 - accuracy: 0.9757 - cost: 3.0907 - val_loss: 0.1105 - val_auc: 0.9900 - val_accuracy: 0.9685 - val_cost: 3.8922\n",
            "Epoch 75/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0794 - auc: 0.9941 - accuracy: 0.9760 - cost: 3.0671 - val_loss: 0.1102 - val_auc: 0.9902 - val_accuracy: 0.9680 - val_cost: 4.0046\n",
            "Epoch 76/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0794 - auc: 0.9942 - accuracy: 0.9759 - cost: 3.0806 - val_loss: 0.1110 - val_auc: 0.9900 - val_accuracy: 0.9686 - val_cost: 3.8591\n",
            "Epoch 77/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0793 - auc: 0.9942 - accuracy: 0.9758 - cost: 3.0783 - val_loss: 0.1111 - val_auc: 0.9900 - val_accuracy: 0.9682 - val_cost: 3.9683\n",
            "Epoch 78/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0785 - auc: 0.9943 - accuracy: 0.9762 - cost: 3.0343 - val_loss: 0.1102 - val_auc: 0.9901 - val_accuracy: 0.9683 - val_cost: 3.9120\n",
            "Epoch 79/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0779 - auc: 0.9943 - accuracy: 0.9764 - cost: 3.0054 - val_loss: 0.1111 - val_auc: 0.9900 - val_accuracy: 0.9692 - val_cost: 3.8062\n",
            "Epoch 80/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0783 - auc: 0.9943 - accuracy: 0.9766 - cost: 2.9969 - val_loss: 0.1092 - val_auc: 0.9902 - val_accuracy: 0.9688 - val_cost: 3.9153\n",
            "Epoch 81/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0764 - auc: 0.9945 - accuracy: 0.9767 - cost: 2.9672 - val_loss: 0.1096 - val_auc: 0.9902 - val_accuracy: 0.9678 - val_cost: 4.0311\n",
            "Epoch 82/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0776 - auc: 0.9944 - accuracy: 0.9768 - cost: 2.9618 - val_loss: 0.1092 - val_auc: 0.9899 - val_accuracy: 0.9698 - val_cost: 3.8856\n",
            "Epoch 83/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0763 - auc: 0.9945 - accuracy: 0.9768 - cost: 2.9657 - val_loss: 0.1105 - val_auc: 0.9901 - val_accuracy: 0.9676 - val_cost: 3.9385\n",
            "Epoch 84/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0763 - auc: 0.9945 - accuracy: 0.9769 - cost: 2.9576 - val_loss: 0.1108 - val_auc: 0.9902 - val_accuracy: 0.9694 - val_cost: 3.7831\n",
            "Epoch 85/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0768 - auc: 0.9944 - accuracy: 0.9770 - cost: 2.9441 - val_loss: 0.1096 - val_auc: 0.9903 - val_accuracy: 0.9693 - val_cost: 3.7368\n",
            "Epoch 86/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0758 - auc: 0.9945 - accuracy: 0.9774 - cost: 2.8800 - val_loss: 0.1086 - val_auc: 0.9903 - val_accuracy: 0.9697 - val_cost: 3.8591\n",
            "Epoch 87/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0759 - auc: 0.9945 - accuracy: 0.9773 - cost: 2.8943 - val_loss: 0.1100 - val_auc: 0.9900 - val_accuracy: 0.9686 - val_cost: 3.9220\n",
            "Epoch 88/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0755 - auc: 0.9946 - accuracy: 0.9772 - cost: 2.9190 - val_loss: 0.1113 - val_auc: 0.9899 - val_accuracy: 0.9697 - val_cost: 3.7665\n",
            "Epoch 89/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0757 - auc: 0.9945 - accuracy: 0.9771 - cost: 2.9225 - val_loss: 0.1096 - val_auc: 0.9904 - val_accuracy: 0.9688 - val_cost: 3.9484\n",
            "Epoch 90/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0745 - auc: 0.9946 - accuracy: 0.9778 - cost: 2.8322 - val_loss: 0.1107 - val_auc: 0.9902 - val_accuracy: 0.9690 - val_cost: 3.8492\n",
            "Epoch 91/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0745 - auc: 0.9946 - accuracy: 0.9775 - cost: 2.8796 - val_loss: 0.1101 - val_auc: 0.9898 - val_accuracy: 0.9693 - val_cost: 3.7765\n",
            "Epoch 92/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0745 - auc: 0.9947 - accuracy: 0.9775 - cost: 2.8812 - val_loss: 0.1086 - val_auc: 0.9903 - val_accuracy: 0.9699 - val_cost: 3.7202\n",
            "Epoch 93/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0744 - auc: 0.9947 - accuracy: 0.9774 - cost: 2.8885 - val_loss: 0.1082 - val_auc: 0.9903 - val_accuracy: 0.9692 - val_cost: 3.8558\n",
            "Epoch 94/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0743 - auc: 0.9947 - accuracy: 0.9781 - cost: 2.8098 - val_loss: 0.1099 - val_auc: 0.9901 - val_accuracy: 0.9688 - val_cost: 3.9517\n",
            "Epoch 95/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0739 - auc: 0.9947 - accuracy: 0.9777 - cost: 2.8569 - val_loss: 0.1095 - val_auc: 0.9905 - val_accuracy: 0.9692 - val_cost: 3.7963\n",
            "Epoch 96/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0732 - auc: 0.9948 - accuracy: 0.9780 - cost: 2.8140 - val_loss: 0.1087 - val_auc: 0.9902 - val_accuracy: 0.9686 - val_cost: 3.9848\n",
            "Epoch 97/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0739 - auc: 0.9947 - accuracy: 0.9778 - cost: 2.8353 - val_loss: 0.1094 - val_auc: 0.9902 - val_accuracy: 0.9701 - val_cost: 3.7169\n",
            "Epoch 98/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0736 - auc: 0.9948 - accuracy: 0.9779 - cost: 2.8318 - val_loss: 0.1083 - val_auc: 0.9904 - val_accuracy: 0.9692 - val_cost: 3.8591\n",
            "Epoch 99/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0730 - auc: 0.9948 - accuracy: 0.9782 - cost: 2.7867 - val_loss: 0.1118 - val_auc: 0.9902 - val_accuracy: 0.9684 - val_cost: 3.8459\n",
            "Epoch 100/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0727 - auc: 0.9949 - accuracy: 0.9781 - cost: 2.7975 - val_loss: 0.1095 - val_auc: 0.9901 - val_accuracy: 0.9694 - val_cost: 3.8690\n",
            "Epoch 101/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0733 - auc: 0.9947 - accuracy: 0.9781 - cost: 2.7905 - val_loss: 0.1070 - val_auc: 0.9904 - val_accuracy: 0.9703 - val_cost: 3.7004\n",
            "Epoch 102/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0719 - auc: 0.9948 - accuracy: 0.9786 - cost: 2.7357 - val_loss: 0.1079 - val_auc: 0.9904 - val_accuracy: 0.9707 - val_cost: 3.6806\n",
            "Epoch 103/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0719 - auc: 0.9949 - accuracy: 0.9785 - cost: 2.7515 - val_loss: 0.1089 - val_auc: 0.9902 - val_accuracy: 0.9707 - val_cost: 3.6078\n",
            "Epoch 104/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0718 - auc: 0.9950 - accuracy: 0.9782 - cost: 2.7801 - val_loss: 0.1104 - val_auc: 0.9902 - val_accuracy: 0.9699 - val_cost: 3.7004\n",
            "Epoch 105/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0716 - auc: 0.9949 - accuracy: 0.9788 - cost: 2.7103 - val_loss: 0.1087 - val_auc: 0.9904 - val_accuracy: 0.9708 - val_cost: 3.6276\n",
            "Epoch 106/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0712 - auc: 0.9949 - accuracy: 0.9792 - cost: 2.6721 - val_loss: 0.1082 - val_auc: 0.9903 - val_accuracy: 0.9706 - val_cost: 3.6177\n",
            "Epoch 107/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0706 - auc: 0.9951 - accuracy: 0.9790 - cost: 2.6821 - val_loss: 0.1098 - val_auc: 0.9906 - val_accuracy: 0.9702 - val_cost: 3.6541\n",
            "Epoch 108/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0719 - auc: 0.9949 - accuracy: 0.9787 - cost: 2.7222 - val_loss: 0.1093 - val_auc: 0.9902 - val_accuracy: 0.9701 - val_cost: 3.7698\n",
            "Epoch 109/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0706 - auc: 0.9950 - accuracy: 0.9789 - cost: 2.6998 - val_loss: 0.1078 - val_auc: 0.9900 - val_accuracy: 0.9707 - val_cost: 3.6739\n",
            "Epoch 110/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0711 - auc: 0.9949 - accuracy: 0.9790 - cost: 2.6944 - val_loss: 0.1088 - val_auc: 0.9902 - val_accuracy: 0.9710 - val_cost: 3.5747\n",
            "Epoch 111/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0706 - auc: 0.9950 - accuracy: 0.9788 - cost: 2.7106 - val_loss: 0.1099 - val_auc: 0.9903 - val_accuracy: 0.9697 - val_cost: 3.7533\n",
            "Epoch 112/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0705 - auc: 0.9950 - accuracy: 0.9789 - cost: 2.7022 - val_loss: 0.1086 - val_auc: 0.9904 - val_accuracy: 0.9706 - val_cost: 3.6508\n",
            "Epoch 113/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0705 - auc: 0.9951 - accuracy: 0.9792 - cost: 2.6617 - val_loss: 0.1094 - val_auc: 0.9903 - val_accuracy: 0.9704 - val_cost: 3.5913\n",
            "Epoch 114/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0696 - auc: 0.9952 - accuracy: 0.9791 - cost: 2.6752 - val_loss: 0.1093 - val_auc: 0.9904 - val_accuracy: 0.9700 - val_cost: 3.8360\n",
            "Epoch 115/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0692 - auc: 0.9952 - accuracy: 0.9797 - cost: 2.6026 - val_loss: 0.1092 - val_auc: 0.9903 - val_accuracy: 0.9697 - val_cost: 3.8327\n",
            "Epoch 116/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0695 - auc: 0.9951 - accuracy: 0.9796 - cost: 2.6204 - val_loss: 0.1088 - val_auc: 0.9904 - val_accuracy: 0.9694 - val_cost: 3.8790\n",
            "Epoch 117/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0698 - auc: 0.9951 - accuracy: 0.9795 - cost: 2.6254 - val_loss: 0.1104 - val_auc: 0.9898 - val_accuracy: 0.9696 - val_cost: 3.8856\n",
            "Epoch 118/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0695 - auc: 0.9951 - accuracy: 0.9792 - cost: 2.6609 - val_loss: 0.1100 - val_auc: 0.9901 - val_accuracy: 0.9703 - val_cost: 3.7037\n",
            "Epoch 119/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0694 - auc: 0.9951 - accuracy: 0.9792 - cost: 2.6705 - val_loss: 0.1101 - val_auc: 0.9902 - val_accuracy: 0.9708 - val_cost: 3.6607\n",
            "Epoch 120/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0688 - auc: 0.9952 - accuracy: 0.9798 - cost: 2.5872 - val_loss: 0.1092 - val_auc: 0.9903 - val_accuracy: 0.9714 - val_cost: 3.6045\n",
            "Epoch 121/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0689 - auc: 0.9953 - accuracy: 0.9796 - cost: 2.6157 - val_loss: 0.1115 - val_auc: 0.9901 - val_accuracy: 0.9701 - val_cost: 3.7169\n",
            "Epoch 122/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0691 - auc: 0.9953 - accuracy: 0.9791 - cost: 2.6790 - val_loss: 0.1074 - val_auc: 0.9903 - val_accuracy: 0.9714 - val_cost: 3.5516\n",
            "Epoch 123/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0678 - auc: 0.9954 - accuracy: 0.9797 - cost: 2.5953 - val_loss: 0.1092 - val_auc: 0.9905 - val_accuracy: 0.9694 - val_cost: 3.8128\n",
            "Epoch 124/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0677 - auc: 0.9953 - accuracy: 0.9799 - cost: 2.5640 - val_loss: 0.1075 - val_auc: 0.9905 - val_accuracy: 0.9703 - val_cost: 3.7434\n",
            "Epoch 125/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0681 - auc: 0.9953 - accuracy: 0.9799 - cost: 2.5718 - val_loss: 0.1076 - val_auc: 0.9905 - val_accuracy: 0.9707 - val_cost: 3.6144\n",
            "Epoch 126/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0683 - auc: 0.9953 - accuracy: 0.9799 - cost: 2.5718 - val_loss: 0.1080 - val_auc: 0.9902 - val_accuracy: 0.9706 - val_cost: 3.6508\n",
            "Epoch 127/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0689 - auc: 0.9952 - accuracy: 0.9797 - cost: 2.6034 - val_loss: 0.1089 - val_auc: 0.9905 - val_accuracy: 0.9707 - val_cost: 3.6376\n",
            "Epoch 128/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0673 - auc: 0.9954 - accuracy: 0.9799 - cost: 2.5760 - val_loss: 0.1086 - val_auc: 0.9902 - val_accuracy: 0.9707 - val_cost: 3.6640\n",
            "Epoch 129/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0686 - auc: 0.9951 - accuracy: 0.9801 - cost: 2.5525 - val_loss: 0.1104 - val_auc: 0.9902 - val_accuracy: 0.9701 - val_cost: 3.7335\n",
            "Epoch 130/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0674 - auc: 0.9954 - accuracy: 0.9800 - cost: 2.5617 - val_loss: 0.1088 - val_auc: 0.9904 - val_accuracy: 0.9706 - val_cost: 3.6475\n",
            "Epoch 131/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0677 - auc: 0.9953 - accuracy: 0.9799 - cost: 2.5787 - val_loss: 0.1086 - val_auc: 0.9905 - val_accuracy: 0.9701 - val_cost: 3.8062\n",
            "Epoch 132/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0661 - auc: 0.9955 - accuracy: 0.9804 - cost: 2.5035 - val_loss: 0.1100 - val_auc: 0.9899 - val_accuracy: 0.9709 - val_cost: 3.6640\n",
            "Epoch 133/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0656 - auc: 0.9955 - accuracy: 0.9807 - cost: 2.4672 - val_loss: 0.1098 - val_auc: 0.9903 - val_accuracy: 0.9700 - val_cost: 3.7368\n",
            "Epoch 134/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0669 - auc: 0.9954 - accuracy: 0.9797 - cost: 2.5887 - val_loss: 0.1082 - val_auc: 0.9906 - val_accuracy: 0.9715 - val_cost: 3.5549\n",
            "Epoch 135/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0673 - auc: 0.9953 - accuracy: 0.9801 - cost: 2.5602 - val_loss: 0.1105 - val_auc: 0.9903 - val_accuracy: 0.9702 - val_cost: 3.6409\n",
            "Epoch 136/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0665 - auc: 0.9954 - accuracy: 0.9800 - cost: 2.5498 - val_loss: 0.1073 - val_auc: 0.9908 - val_accuracy: 0.9713 - val_cost: 3.4888\n",
            "Epoch 137/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0669 - auc: 0.9954 - accuracy: 0.9806 - cost: 2.4765 - val_loss: 0.1092 - val_auc: 0.9908 - val_accuracy: 0.9697 - val_cost: 3.8393\n",
            "Epoch 138/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0668 - auc: 0.9955 - accuracy: 0.9800 - cost: 2.5617 - val_loss: 0.1102 - val_auc: 0.9906 - val_accuracy: 0.9705 - val_cost: 3.6607\n",
            "Epoch 139/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0662 - auc: 0.9953 - accuracy: 0.9806 - cost: 2.4830 - val_loss: 0.1087 - val_auc: 0.9902 - val_accuracy: 0.9712 - val_cost: 3.6276\n",
            "Epoch 140/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0655 - auc: 0.9955 - accuracy: 0.9806 - cost: 2.4745 - val_loss: 0.1110 - val_auc: 0.9903 - val_accuracy: 0.9709 - val_cost: 3.6376\n",
            "Epoch 141/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0654 - auc: 0.9956 - accuracy: 0.9806 - cost: 2.4830 - val_loss: 0.1109 - val_auc: 0.9901 - val_accuracy: 0.9700 - val_cost: 3.7533\n",
            "Epoch 142/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0659 - auc: 0.9955 - accuracy: 0.9811 - cost: 2.4217 - val_loss: 0.1107 - val_auc: 0.9904 - val_accuracy: 0.9705 - val_cost: 3.7434\n",
            "Epoch 143/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0650 - auc: 0.9956 - accuracy: 0.9810 - cost: 2.4452 - val_loss: 0.1090 - val_auc: 0.9906 - val_accuracy: 0.9708 - val_cost: 3.6276\n",
            "Epoch 144/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0649 - auc: 0.9956 - accuracy: 0.9812 - cost: 2.4016 - val_loss: 0.1077 - val_auc: 0.9907 - val_accuracy: 0.9701 - val_cost: 3.7434\n",
            "Epoch 145/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0658 - auc: 0.9956 - accuracy: 0.9802 - cost: 2.5316 - val_loss: 0.1098 - val_auc: 0.9903 - val_accuracy: 0.9710 - val_cost: 3.5913\n",
            "Epoch 146/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0657 - auc: 0.9954 - accuracy: 0.9807 - cost: 2.4603 - val_loss: 0.1109 - val_auc: 0.9904 - val_accuracy: 0.9695 - val_cost: 3.8062\n",
            "Epoch 147/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0650 - auc: 0.9955 - accuracy: 0.9809 - cost: 2.4410 - val_loss: 0.1096 - val_auc: 0.9906 - val_accuracy: 0.9702 - val_cost: 3.7070\n",
            "Epoch 148/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0643 - auc: 0.9956 - accuracy: 0.9806 - cost: 2.4842 - val_loss: 0.1112 - val_auc: 0.9904 - val_accuracy: 0.9706 - val_cost: 3.6409\n",
            "Epoch 149/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0654 - auc: 0.9955 - accuracy: 0.9808 - cost: 2.4579 - val_loss: 0.1095 - val_auc: 0.9906 - val_accuracy: 0.9717 - val_cost: 3.5020\n",
            "Epoch 150/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0649 - auc: 0.9956 - accuracy: 0.9808 - cost: 2.4529 - val_loss: 0.1088 - val_auc: 0.9909 - val_accuracy: 0.9701 - val_cost: 3.7765\n",
            "Epoch 151/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0647 - auc: 0.9956 - accuracy: 0.9812 - cost: 2.4124 - val_loss: 0.1072 - val_auc: 0.9910 - val_accuracy: 0.9714 - val_cost: 3.6310\n",
            "Epoch 152/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0641 - auc: 0.9956 - accuracy: 0.9815 - cost: 2.3708 - val_loss: 0.1109 - val_auc: 0.9904 - val_accuracy: 0.9697 - val_cost: 3.8095\n",
            "Epoch 153/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0652 - auc: 0.9956 - accuracy: 0.9807 - cost: 2.4680 - val_loss: 0.1127 - val_auc: 0.9902 - val_accuracy: 0.9710 - val_cost: 3.5714\n",
            "Epoch 154/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0644 - auc: 0.9956 - accuracy: 0.9810 - cost: 2.4294 - val_loss: 0.1105 - val_auc: 0.9902 - val_accuracy: 0.9703 - val_cost: 3.7235\n",
            "Epoch 155/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0643 - auc: 0.9955 - accuracy: 0.9809 - cost: 2.4483 - val_loss: 0.1113 - val_auc: 0.9903 - val_accuracy: 0.9707 - val_cost: 3.6310\n",
            "Epoch 156/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0645 - auc: 0.9956 - accuracy: 0.9809 - cost: 2.4387 - val_loss: 0.1142 - val_auc: 0.9900 - val_accuracy: 0.9695 - val_cost: 3.7533\n",
            "Epoch 157/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0647 - auc: 0.9955 - accuracy: 0.9812 - cost: 2.4128 - val_loss: 0.1106 - val_auc: 0.9903 - val_accuracy: 0.9709 - val_cost: 3.5979\n",
            "Epoch 158/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0641 - auc: 0.9957 - accuracy: 0.9811 - cost: 2.4194 - val_loss: 0.1125 - val_auc: 0.9903 - val_accuracy: 0.9702 - val_cost: 3.6574\n",
            "Epoch 159/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0641 - auc: 0.9958 - accuracy: 0.9814 - cost: 2.3854 - val_loss: 0.1097 - val_auc: 0.9905 - val_accuracy: 0.9706 - val_cost: 3.6442\n",
            "Epoch 160/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0637 - auc: 0.9956 - accuracy: 0.9818 - cost: 2.3353 - val_loss: 0.1111 - val_auc: 0.9904 - val_accuracy: 0.9703 - val_cost: 3.7004\n",
            "Epoch 161/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0638 - auc: 0.9957 - accuracy: 0.9812 - cost: 2.4205 - val_loss: 0.1101 - val_auc: 0.9904 - val_accuracy: 0.9703 - val_cost: 3.6310\n",
            "Epoch 162/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0640 - auc: 0.9957 - accuracy: 0.9813 - cost: 2.3904 - val_loss: 0.1100 - val_auc: 0.9902 - val_accuracy: 0.9712 - val_cost: 3.5648\n",
            "Epoch 163/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0633 - auc: 0.9957 - accuracy: 0.9815 - cost: 2.3696 - val_loss: 0.1112 - val_auc: 0.9904 - val_accuracy: 0.9710 - val_cost: 3.6607\n",
            "Epoch 164/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0631 - auc: 0.9957 - accuracy: 0.9814 - cost: 2.3866 - val_loss: 0.1085 - val_auc: 0.9905 - val_accuracy: 0.9712 - val_cost: 3.5946\n",
            "Epoch 165/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0626 - auc: 0.9958 - accuracy: 0.9814 - cost: 2.3812 - val_loss: 0.1110 - val_auc: 0.9903 - val_accuracy: 0.9706 - val_cost: 3.7169\n",
            "Epoch 166/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0636 - auc: 0.9957 - accuracy: 0.9812 - cost: 2.4078 - val_loss: 0.1115 - val_auc: 0.9902 - val_accuracy: 0.9709 - val_cost: 3.6640\n",
            "Epoch 167/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0630 - auc: 0.9957 - accuracy: 0.9817 - cost: 2.3430 - val_loss: 0.1140 - val_auc: 0.9900 - val_accuracy: 0.9712 - val_cost: 3.5384\n",
            "Epoch 168/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0632 - auc: 0.9957 - accuracy: 0.9814 - cost: 2.3897 - val_loss: 0.1116 - val_auc: 0.9903 - val_accuracy: 0.9712 - val_cost: 3.5516\n",
            "Epoch 169/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0628 - auc: 0.9958 - accuracy: 0.9818 - cost: 2.3395 - val_loss: 0.1118 - val_auc: 0.9901 - val_accuracy: 0.9717 - val_cost: 3.4689\n",
            "Epoch 170/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0628 - auc: 0.9958 - accuracy: 0.9818 - cost: 2.3326 - val_loss: 0.1115 - val_auc: 0.9904 - val_accuracy: 0.9712 - val_cost: 3.4888\n",
            "Epoch 171/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0630 - auc: 0.9957 - accuracy: 0.9815 - cost: 2.3615 - val_loss: 0.1106 - val_auc: 0.9904 - val_accuracy: 0.9715 - val_cost: 3.6078\n",
            "Epoch 172/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0618 - auc: 0.9959 - accuracy: 0.9816 - cost: 2.3692 - val_loss: 0.1110 - val_auc: 0.9902 - val_accuracy: 0.9717 - val_cost: 3.4755\n",
            "Epoch 173/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0621 - auc: 0.9958 - accuracy: 0.9817 - cost: 2.3488 - val_loss: 0.1152 - val_auc: 0.9900 - val_accuracy: 0.9710 - val_cost: 3.4921\n",
            "Epoch 174/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0627 - auc: 0.9958 - accuracy: 0.9816 - cost: 2.3515 - val_loss: 0.1111 - val_auc: 0.9903 - val_accuracy: 0.9705 - val_cost: 3.7070\n",
            "Epoch 175/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0629 - auc: 0.9958 - accuracy: 0.9817 - cost: 2.3422 - val_loss: 0.1145 - val_auc: 0.9900 - val_accuracy: 0.9714 - val_cost: 3.4656\n",
            "Epoch 176/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0628 - auc: 0.9958 - accuracy: 0.9814 - cost: 2.3885 - val_loss: 0.1105 - val_auc: 0.9905 - val_accuracy: 0.9713 - val_cost: 3.5020\n",
            "Epoch 177/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0623 - auc: 0.9959 - accuracy: 0.9820 - cost: 2.3083 - val_loss: 0.1112 - val_auc: 0.9901 - val_accuracy: 0.9708 - val_cost: 3.6243\n",
            "Epoch 178/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0632 - auc: 0.9957 - accuracy: 0.9814 - cost: 2.3781 - val_loss: 0.1111 - val_auc: 0.9904 - val_accuracy: 0.9711 - val_cost: 3.6210\n",
            "Epoch 179/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0619 - auc: 0.9959 - accuracy: 0.9818 - cost: 2.3391 - val_loss: 0.1104 - val_auc: 0.9901 - val_accuracy: 0.9718 - val_cost: 3.5251\n",
            "Epoch 180/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0611 - auc: 0.9959 - accuracy: 0.9824 - cost: 2.2581 - val_loss: 0.1122 - val_auc: 0.9900 - val_accuracy: 0.9708 - val_cost: 3.6409\n",
            "Epoch 181/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0615 - auc: 0.9960 - accuracy: 0.9818 - cost: 2.3372 - val_loss: 0.1132 - val_auc: 0.9901 - val_accuracy: 0.9709 - val_cost: 3.5747\n",
            "Epoch 182/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0619 - auc: 0.9958 - accuracy: 0.9820 - cost: 2.3175 - val_loss: 0.1121 - val_auc: 0.9898 - val_accuracy: 0.9710 - val_cost: 3.6673\n",
            "Epoch 183/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0611 - auc: 0.9959 - accuracy: 0.9824 - cost: 2.2654 - val_loss: 0.1115 - val_auc: 0.9902 - val_accuracy: 0.9715 - val_cost: 3.5648\n",
            "Epoch 184/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0614 - auc: 0.9960 - accuracy: 0.9819 - cost: 2.3252 - val_loss: 0.1160 - val_auc: 0.9896 - val_accuracy: 0.9710 - val_cost: 3.6442\n",
            "Epoch 185/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0614 - auc: 0.9959 - accuracy: 0.9816 - cost: 2.3557 - val_loss: 0.1124 - val_auc: 0.9904 - val_accuracy: 0.9710 - val_cost: 3.6243\n",
            "Epoch 186/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0620 - auc: 0.9959 - accuracy: 0.9818 - cost: 2.3295 - val_loss: 0.1144 - val_auc: 0.9896 - val_accuracy: 0.9699 - val_cost: 3.7798\n",
            "Epoch 187/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0614 - auc: 0.9959 - accuracy: 0.9816 - cost: 2.3499 - val_loss: 0.1134 - val_auc: 0.9899 - val_accuracy: 0.9706 - val_cost: 3.6905\n",
            "Epoch 188/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0609 - auc: 0.9960 - accuracy: 0.9824 - cost: 2.2562 - val_loss: 0.1136 - val_auc: 0.9897 - val_accuracy: 0.9723 - val_cost: 3.5747\n",
            "Epoch 189/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0608 - auc: 0.9960 - accuracy: 0.9820 - cost: 2.3090 - val_loss: 0.1122 - val_auc: 0.9904 - val_accuracy: 0.9725 - val_cost: 3.4425\n",
            "Epoch 190/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0613 - auc: 0.9960 - accuracy: 0.9824 - cost: 2.2681 - val_loss: 0.1147 - val_auc: 0.9902 - val_accuracy: 0.9709 - val_cost: 3.5549\n",
            "Epoch 191/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0618 - auc: 0.9958 - accuracy: 0.9816 - cost: 2.3549 - val_loss: 0.1130 - val_auc: 0.9896 - val_accuracy: 0.9717 - val_cost: 3.5747\n",
            "Epoch 192/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0612 - auc: 0.9960 - accuracy: 0.9822 - cost: 2.2762 - val_loss: 0.1136 - val_auc: 0.9901 - val_accuracy: 0.9718 - val_cost: 3.4854\n",
            "Epoch 193/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0606 - auc: 0.9960 - accuracy: 0.9825 - cost: 2.2388 - val_loss: 0.1142 - val_auc: 0.9901 - val_accuracy: 0.9702 - val_cost: 3.7500\n",
            "Epoch 194/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0606 - auc: 0.9960 - accuracy: 0.9823 - cost: 2.2685 - val_loss: 0.1161 - val_auc: 0.9898 - val_accuracy: 0.9697 - val_cost: 3.7665\n",
            "Epoch 195/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0606 - auc: 0.9961 - accuracy: 0.9821 - cost: 2.3009 - val_loss: 0.1150 - val_auc: 0.9900 - val_accuracy: 0.9715 - val_cost: 3.5119\n",
            "Epoch 196/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0609 - auc: 0.9960 - accuracy: 0.9820 - cost: 2.3160 - val_loss: 0.1136 - val_auc: 0.9899 - val_accuracy: 0.9713 - val_cost: 3.6012\n",
            "Epoch 197/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0612 - auc: 0.9960 - accuracy: 0.9819 - cost: 2.3183 - val_loss: 0.1144 - val_auc: 0.9898 - val_accuracy: 0.9710 - val_cost: 3.5516\n",
            "Epoch 198/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0599 - auc: 0.9962 - accuracy: 0.9822 - cost: 2.2812 - val_loss: 0.1136 - val_auc: 0.9898 - val_accuracy: 0.9722 - val_cost: 3.4491\n",
            "Epoch 199/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0611 - auc: 0.9960 - accuracy: 0.9820 - cost: 2.3221 - val_loss: 0.1160 - val_auc: 0.9901 - val_accuracy: 0.9712 - val_cost: 3.5615\n",
            "Epoch 200/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0603 - auc: 0.9960 - accuracy: 0.9821 - cost: 2.2990 - val_loss: 0.1125 - val_auc: 0.9900 - val_accuracy: 0.9721 - val_cost: 3.4788\n",
            "Epoch 201/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0602 - auc: 0.9961 - accuracy: 0.9823 - cost: 2.2720 - val_loss: 0.1135 - val_auc: 0.9900 - val_accuracy: 0.9715 - val_cost: 3.6012\n",
            "Epoch 202/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0600 - auc: 0.9961 - accuracy: 0.9827 - cost: 2.2253 - val_loss: 0.1129 - val_auc: 0.9901 - val_accuracy: 0.9723 - val_cost: 3.4392\n",
            "Epoch 203/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0601 - auc: 0.9960 - accuracy: 0.9821 - cost: 2.2959 - val_loss: 0.1125 - val_auc: 0.9903 - val_accuracy: 0.9713 - val_cost: 3.5317\n",
            "Epoch 204/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0603 - auc: 0.9960 - accuracy: 0.9821 - cost: 2.2959 - val_loss: 0.1127 - val_auc: 0.9903 - val_accuracy: 0.9717 - val_cost: 3.4921\n",
            "Epoch 205/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0595 - auc: 0.9961 - accuracy: 0.9825 - cost: 2.2469 - val_loss: 0.1159 - val_auc: 0.9897 - val_accuracy: 0.9715 - val_cost: 3.5780\n",
            "Epoch 206/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0606 - auc: 0.9960 - accuracy: 0.9820 - cost: 2.3040 - val_loss: 0.1142 - val_auc: 0.9901 - val_accuracy: 0.9716 - val_cost: 3.4921\n",
            "Epoch 207/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0602 - auc: 0.9961 - accuracy: 0.9823 - cost: 2.2666 - val_loss: 0.1144 - val_auc: 0.9900 - val_accuracy: 0.9717 - val_cost: 3.4722\n",
            "Epoch 208/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0602 - auc: 0.9961 - accuracy: 0.9821 - cost: 2.2905 - val_loss: 0.1158 - val_auc: 0.9895 - val_accuracy: 0.9714 - val_cost: 3.5714\n",
            "Epoch 209/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0600 - auc: 0.9961 - accuracy: 0.9822 - cost: 2.2735 - val_loss: 0.1147 - val_auc: 0.9900 - val_accuracy: 0.9715 - val_cost: 3.5152\n",
            "Epoch 210/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0601 - auc: 0.9962 - accuracy: 0.9822 - cost: 2.2948 - val_loss: 0.1148 - val_auc: 0.9897 - val_accuracy: 0.9715 - val_cost: 3.5417\n",
            "Epoch 211/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0595 - auc: 0.9963 - accuracy: 0.9825 - cost: 2.2377 - val_loss: 0.1160 - val_auc: 0.9896 - val_accuracy: 0.9718 - val_cost: 3.5714\n",
            "Epoch 212/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0598 - auc: 0.9962 - accuracy: 0.9824 - cost: 2.2589 - val_loss: 0.1147 - val_auc: 0.9899 - val_accuracy: 0.9722 - val_cost: 3.4292\n",
            "Epoch 213/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0596 - auc: 0.9962 - accuracy: 0.9824 - cost: 2.2689 - val_loss: 0.1154 - val_auc: 0.9899 - val_accuracy: 0.9704 - val_cost: 3.7599\n",
            "Epoch 214/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0593 - auc: 0.9962 - accuracy: 0.9825 - cost: 2.2539 - val_loss: 0.1135 - val_auc: 0.9900 - val_accuracy: 0.9712 - val_cost: 3.5119\n",
            "Epoch 215/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0588 - auc: 0.9962 - accuracy: 0.9827 - cost: 2.2234 - val_loss: 0.1160 - val_auc: 0.9895 - val_accuracy: 0.9708 - val_cost: 3.6243\n",
            "Epoch 216/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0595 - auc: 0.9962 - accuracy: 0.9822 - cost: 2.2824 - val_loss: 0.1162 - val_auc: 0.9898 - val_accuracy: 0.9714 - val_cost: 3.5780\n",
            "Epoch 217/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0598 - auc: 0.9961 - accuracy: 0.9825 - cost: 2.2485 - val_loss: 0.1171 - val_auc: 0.9899 - val_accuracy: 0.9712 - val_cost: 3.5351\n",
            "Epoch 218/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0596 - auc: 0.9962 - accuracy: 0.9823 - cost: 2.2697 - val_loss: 0.1155 - val_auc: 0.9896 - val_accuracy: 0.9709 - val_cost: 3.6078\n",
            "Epoch 219/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0590 - auc: 0.9962 - accuracy: 0.9827 - cost: 2.2226 - val_loss: 0.1170 - val_auc: 0.9899 - val_accuracy: 0.9699 - val_cost: 3.6839\n",
            "Epoch 220/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0592 - auc: 0.9962 - accuracy: 0.9823 - cost: 2.2681 - val_loss: 0.1177 - val_auc: 0.9900 - val_accuracy: 0.9708 - val_cost: 3.5979\n",
            "Epoch 221/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0592 - auc: 0.9962 - accuracy: 0.9825 - cost: 2.2369 - val_loss: 0.1155 - val_auc: 0.9896 - val_accuracy: 0.9722 - val_cost: 3.5020\n",
            "Epoch 222/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0596 - auc: 0.9961 - accuracy: 0.9825 - cost: 2.2515 - val_loss: 0.1187 - val_auc: 0.9891 - val_accuracy: 0.9723 - val_cost: 3.4590\n",
            "Epoch 223/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0595 - auc: 0.9961 - accuracy: 0.9825 - cost: 2.2407 - val_loss: 0.1195 - val_auc: 0.9897 - val_accuracy: 0.9710 - val_cost: 3.4921\n",
            "Epoch 224/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0588 - auc: 0.9962 - accuracy: 0.9825 - cost: 2.2481 - val_loss: 0.1149 - val_auc: 0.9895 - val_accuracy: 0.9725 - val_cost: 3.4921\n",
            "Epoch 225/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0585 - auc: 0.9963 - accuracy: 0.9824 - cost: 2.2593 - val_loss: 0.1173 - val_auc: 0.9896 - val_accuracy: 0.9708 - val_cost: 3.5979\n",
            "Epoch 226/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0600 - auc: 0.9961 - accuracy: 0.9825 - cost: 2.2454 - val_loss: 0.1191 - val_auc: 0.9891 - val_accuracy: 0.9715 - val_cost: 3.4987\n",
            "Epoch 227/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0590 - auc: 0.9961 - accuracy: 0.9825 - cost: 2.2469 - val_loss: 0.1185 - val_auc: 0.9896 - val_accuracy: 0.9701 - val_cost: 3.6872\n",
            "Epoch 228/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0591 - auc: 0.9963 - accuracy: 0.9823 - cost: 2.2820 - val_loss: 0.1158 - val_auc: 0.9896 - val_accuracy: 0.9720 - val_cost: 3.4524\n",
            "Epoch 229/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0585 - auc: 0.9962 - accuracy: 0.9828 - cost: 2.1979 - val_loss: 0.1169 - val_auc: 0.9896 - val_accuracy: 0.9718 - val_cost: 3.5946\n",
            "Epoch 230/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0593 - auc: 0.9962 - accuracy: 0.9825 - cost: 2.2539 - val_loss: 0.1190 - val_auc: 0.9895 - val_accuracy: 0.9710 - val_cost: 3.4954\n",
            "Epoch 231/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0591 - auc: 0.9962 - accuracy: 0.9825 - cost: 2.2473 - val_loss: 0.1171 - val_auc: 0.9898 - val_accuracy: 0.9715 - val_cost: 3.5648\n",
            "Epoch 232/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0584 - auc: 0.9962 - accuracy: 0.9828 - cost: 2.2079 - val_loss: 0.1164 - val_auc: 0.9892 - val_accuracy: 0.9708 - val_cost: 3.6442\n",
            "Epoch 233/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0590 - auc: 0.9963 - accuracy: 0.9827 - cost: 2.2311 - val_loss: 0.1159 - val_auc: 0.9898 - val_accuracy: 0.9713 - val_cost: 3.5714\n",
            "Epoch 234/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0582 - auc: 0.9964 - accuracy: 0.9828 - cost: 2.2095 - val_loss: 0.1161 - val_auc: 0.9898 - val_accuracy: 0.9712 - val_cost: 3.5847\n",
            "Epoch 235/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0587 - auc: 0.9963 - accuracy: 0.9828 - cost: 2.2168 - val_loss: 0.1169 - val_auc: 0.9895 - val_accuracy: 0.9706 - val_cost: 3.6607\n",
            "Epoch 236/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0581 - auc: 0.9963 - accuracy: 0.9829 - cost: 2.1998 - val_loss: 0.1189 - val_auc: 0.9895 - val_accuracy: 0.9699 - val_cost: 3.7235\n",
            "Epoch 237/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0591 - auc: 0.9962 - accuracy: 0.9823 - cost: 2.2650 - val_loss: 0.1170 - val_auc: 0.9894 - val_accuracy: 0.9707 - val_cost: 3.6574\n",
            "Epoch 238/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0579 - auc: 0.9963 - accuracy: 0.9829 - cost: 2.1825 - val_loss: 0.1179 - val_auc: 0.9894 - val_accuracy: 0.9708 - val_cost: 3.6276\n",
            "Epoch 239/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0575 - auc: 0.9963 - accuracy: 0.9829 - cost: 2.1914 - val_loss: 0.1175 - val_auc: 0.9895 - val_accuracy: 0.9714 - val_cost: 3.5847\n",
            "Epoch 240/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0580 - auc: 0.9963 - accuracy: 0.9828 - cost: 2.2099 - val_loss: 0.1184 - val_auc: 0.9897 - val_accuracy: 0.9714 - val_cost: 3.5185\n",
            "Epoch 241/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0573 - auc: 0.9964 - accuracy: 0.9829 - cost: 2.1863 - val_loss: 0.1156 - val_auc: 0.9896 - val_accuracy: 0.9709 - val_cost: 3.5549\n",
            "Epoch 242/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0578 - auc: 0.9963 - accuracy: 0.9828 - cost: 2.2137 - val_loss: 0.1176 - val_auc: 0.9897 - val_accuracy: 0.9708 - val_cost: 3.5946\n",
            "Epoch 243/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0582 - auc: 0.9963 - accuracy: 0.9828 - cost: 2.1968 - val_loss: 0.1160 - val_auc: 0.9896 - val_accuracy: 0.9705 - val_cost: 3.7037\n",
            "Epoch 244/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0582 - auc: 0.9962 - accuracy: 0.9828 - cost: 2.2133 - val_loss: 0.1164 - val_auc: 0.9897 - val_accuracy: 0.9717 - val_cost: 3.6343\n",
            "Epoch 245/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0579 - auc: 0.9962 - accuracy: 0.9829 - cost: 2.1840 - val_loss: 0.1160 - val_auc: 0.9893 - val_accuracy: 0.9722 - val_cost: 3.4755\n",
            "Epoch 246/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0587 - auc: 0.9963 - accuracy: 0.9828 - cost: 2.2103 - val_loss: 0.1176 - val_auc: 0.9896 - val_accuracy: 0.9711 - val_cost: 3.5714\n",
            "Epoch 247/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0572 - auc: 0.9965 - accuracy: 0.9829 - cost: 2.1871 - val_loss: 0.1155 - val_auc: 0.9897 - val_accuracy: 0.9708 - val_cost: 3.6574\n",
            "Epoch 248/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0571 - auc: 0.9965 - accuracy: 0.9832 - cost: 2.1624 - val_loss: 0.1188 - val_auc: 0.9895 - val_accuracy: 0.9703 - val_cost: 3.5681\n",
            "Epoch 249/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0575 - auc: 0.9963 - accuracy: 0.9831 - cost: 2.1682 - val_loss: 0.1184 - val_auc: 0.9895 - val_accuracy: 0.9706 - val_cost: 3.6739\n",
            "Epoch 250/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0572 - auc: 0.9964 - accuracy: 0.9830 - cost: 2.1933 - val_loss: 0.1167 - val_auc: 0.9895 - val_accuracy: 0.9712 - val_cost: 3.5681\n",
            "Epoch 251/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0579 - auc: 0.9964 - accuracy: 0.9825 - cost: 2.2469 - val_loss: 0.1183 - val_auc: 0.9894 - val_accuracy: 0.9715 - val_cost: 3.4954\n",
            "Epoch 252/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0580 - auc: 0.9963 - accuracy: 0.9831 - cost: 2.1779 - val_loss: 0.1201 - val_auc: 0.9890 - val_accuracy: 0.9712 - val_cost: 3.5317\n",
            "Epoch 253/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0579 - auc: 0.9964 - accuracy: 0.9827 - cost: 2.2133 - val_loss: 0.1169 - val_auc: 0.9894 - val_accuracy: 0.9717 - val_cost: 3.4788\n",
            "Epoch 254/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0575 - auc: 0.9963 - accuracy: 0.9834 - cost: 2.1277 - val_loss: 0.1186 - val_auc: 0.9895 - val_accuracy: 0.9703 - val_cost: 3.6905\n",
            "Epoch 255/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0574 - auc: 0.9964 - accuracy: 0.9832 - cost: 2.1574 - val_loss: 0.1208 - val_auc: 0.9893 - val_accuracy: 0.9711 - val_cost: 3.5417\n",
            "Epoch 256/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0570 - auc: 0.9964 - accuracy: 0.9832 - cost: 2.1578 - val_loss: 0.1189 - val_auc: 0.9895 - val_accuracy: 0.9722 - val_cost: 3.4226\n",
            "Epoch 257/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0572 - auc: 0.9964 - accuracy: 0.9830 - cost: 2.1809 - val_loss: 0.1201 - val_auc: 0.9894 - val_accuracy: 0.9712 - val_cost: 3.5119\n",
            "Epoch 258/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0573 - auc: 0.9964 - accuracy: 0.9830 - cost: 2.1875 - val_loss: 0.1171 - val_auc: 0.9894 - val_accuracy: 0.9712 - val_cost: 3.5417\n",
            "Epoch 259/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0568 - auc: 0.9964 - accuracy: 0.9831 - cost: 2.1586 - val_loss: 0.1164 - val_auc: 0.9898 - val_accuracy: 0.9720 - val_cost: 3.5185\n",
            "Epoch 260/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0581 - auc: 0.9963 - accuracy: 0.9829 - cost: 2.1898 - val_loss: 0.1190 - val_auc: 0.9894 - val_accuracy: 0.9717 - val_cost: 3.5185\n",
            "Epoch 261/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0573 - auc: 0.9964 - accuracy: 0.9832 - cost: 2.1617 - val_loss: 0.1214 - val_auc: 0.9890 - val_accuracy: 0.9715 - val_cost: 3.5417\n",
            "Epoch 262/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0575 - auc: 0.9963 - accuracy: 0.9828 - cost: 2.2052 - val_loss: 0.1190 - val_auc: 0.9895 - val_accuracy: 0.9708 - val_cost: 3.6376\n",
            "Epoch 263/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0571 - auc: 0.9965 - accuracy: 0.9829 - cost: 2.1894 - val_loss: 0.1172 - val_auc: 0.9897 - val_accuracy: 0.9706 - val_cost: 3.6541\n",
            "Epoch 264/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0569 - auc: 0.9964 - accuracy: 0.9830 - cost: 2.1817 - val_loss: 0.1186 - val_auc: 0.9898 - val_accuracy: 0.9712 - val_cost: 3.5880\n",
            "Epoch 265/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0568 - auc: 0.9964 - accuracy: 0.9830 - cost: 2.1852 - val_loss: 0.1194 - val_auc: 0.9895 - val_accuracy: 0.9711 - val_cost: 3.6243\n",
            "Epoch 266/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0565 - auc: 0.9965 - accuracy: 0.9831 - cost: 2.1728 - val_loss: 0.1176 - val_auc: 0.9898 - val_accuracy: 0.9720 - val_cost: 3.4854\n",
            "Epoch 267/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0578 - auc: 0.9963 - accuracy: 0.9829 - cost: 2.1948 - val_loss: 0.1176 - val_auc: 0.9892 - val_accuracy: 0.9713 - val_cost: 3.6409\n",
            "Epoch 268/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0574 - auc: 0.9963 - accuracy: 0.9830 - cost: 2.1775 - val_loss: 0.1185 - val_auc: 0.9894 - val_accuracy: 0.9713 - val_cost: 3.6376\n",
            "Epoch 269/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0578 - auc: 0.9962 - accuracy: 0.9829 - cost: 2.1929 - val_loss: 0.1187 - val_auc: 0.9896 - val_accuracy: 0.9724 - val_cost: 3.5053\n",
            "Epoch 270/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0563 - auc: 0.9964 - accuracy: 0.9836 - cost: 2.1130 - val_loss: 0.1181 - val_auc: 0.9896 - val_accuracy: 0.9706 - val_cost: 3.6541\n",
            "Epoch 271/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0566 - auc: 0.9964 - accuracy: 0.9830 - cost: 2.1852 - val_loss: 0.1194 - val_auc: 0.9894 - val_accuracy: 0.9711 - val_cost: 3.6111\n",
            "Epoch 272/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0569 - auc: 0.9964 - accuracy: 0.9832 - cost: 2.1539 - val_loss: 0.1188 - val_auc: 0.9891 - val_accuracy: 0.9708 - val_cost: 3.6673\n",
            "Epoch 273/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0574 - auc: 0.9964 - accuracy: 0.9831 - cost: 2.1632 - val_loss: 0.1192 - val_auc: 0.9894 - val_accuracy: 0.9710 - val_cost: 3.5582\n",
            "Epoch 274/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0571 - auc: 0.9964 - accuracy: 0.9831 - cost: 2.1717 - val_loss: 0.1188 - val_auc: 0.9892 - val_accuracy: 0.9710 - val_cost: 3.6144\n",
            "Epoch 275/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0568 - auc: 0.9965 - accuracy: 0.9828 - cost: 2.2103 - val_loss: 0.1185 - val_auc: 0.9894 - val_accuracy: 0.9703 - val_cost: 3.6045\n",
            "Epoch 276/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0559 - auc: 0.9965 - accuracy: 0.9834 - cost: 2.1265 - val_loss: 0.1221 - val_auc: 0.9893 - val_accuracy: 0.9703 - val_cost: 3.5979\n",
            "Epoch 277/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0564 - auc: 0.9964 - accuracy: 0.9832 - cost: 2.1590 - val_loss: 0.1182 - val_auc: 0.9897 - val_accuracy: 0.9708 - val_cost: 3.6276\n",
            "Epoch 278/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0560 - auc: 0.9966 - accuracy: 0.9832 - cost: 2.1408 - val_loss: 0.1192 - val_auc: 0.9895 - val_accuracy: 0.9708 - val_cost: 3.6045\n",
            "Epoch 279/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0568 - auc: 0.9965 - accuracy: 0.9827 - cost: 2.2238 - val_loss: 0.1193 - val_auc: 0.9898 - val_accuracy: 0.9706 - val_cost: 3.5714\n",
            "Epoch 280/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0568 - auc: 0.9965 - accuracy: 0.9826 - cost: 2.2346 - val_loss: 0.1211 - val_auc: 0.9893 - val_accuracy: 0.9715 - val_cost: 3.4392\n",
            "Epoch 281/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0567 - auc: 0.9964 - accuracy: 0.9830 - cost: 2.1829 - val_loss: 0.1169 - val_auc: 0.9898 - val_accuracy: 0.9710 - val_cost: 3.5847\n",
            "Epoch 282/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0565 - auc: 0.9965 - accuracy: 0.9833 - cost: 2.1408 - val_loss: 0.1193 - val_auc: 0.9894 - val_accuracy: 0.9715 - val_cost: 3.5813\n",
            "Epoch 283/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0570 - auc: 0.9963 - accuracy: 0.9832 - cost: 2.1609 - val_loss: 0.1195 - val_auc: 0.9895 - val_accuracy: 0.9710 - val_cost: 3.5813\n",
            "Epoch 284/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0567 - auc: 0.9964 - accuracy: 0.9833 - cost: 2.1431 - val_loss: 0.1195 - val_auc: 0.9891 - val_accuracy: 0.9716 - val_cost: 3.5615\n",
            "Epoch 285/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0555 - auc: 0.9965 - accuracy: 0.9836 - cost: 2.1065 - val_loss: 0.1199 - val_auc: 0.9893 - val_accuracy: 0.9707 - val_cost: 3.6607\n",
            "Epoch 286/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0561 - auc: 0.9965 - accuracy: 0.9831 - cost: 2.1786 - val_loss: 0.1213 - val_auc: 0.9896 - val_accuracy: 0.9707 - val_cost: 3.5780\n",
            "Epoch 287/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0566 - auc: 0.9964 - accuracy: 0.9834 - cost: 2.1265 - val_loss: 0.1193 - val_auc: 0.9897 - val_accuracy: 0.9712 - val_cost: 3.5847\n",
            "Epoch 288/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0562 - auc: 0.9965 - accuracy: 0.9833 - cost: 2.1416 - val_loss: 0.1202 - val_auc: 0.9895 - val_accuracy: 0.9708 - val_cost: 3.5847\n",
            "Epoch 289/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0558 - auc: 0.9966 - accuracy: 0.9835 - cost: 2.1204 - val_loss: 0.1213 - val_auc: 0.9896 - val_accuracy: 0.9710 - val_cost: 3.5582\n",
            "Epoch 290/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0564 - auc: 0.9965 - accuracy: 0.9833 - cost: 2.1478 - val_loss: 0.1205 - val_auc: 0.9890 - val_accuracy: 0.9710 - val_cost: 3.6409\n",
            "Epoch 291/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0560 - auc: 0.9965 - accuracy: 0.9832 - cost: 2.1593 - val_loss: 0.1205 - val_auc: 0.9895 - val_accuracy: 0.9715 - val_cost: 3.5119\n",
            "Epoch 292/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0558 - auc: 0.9965 - accuracy: 0.9835 - cost: 2.1262 - val_loss: 0.1213 - val_auc: 0.9894 - val_accuracy: 0.9712 - val_cost: 3.5615\n",
            "Epoch 293/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0558 - auc: 0.9967 - accuracy: 0.9833 - cost: 2.1416 - val_loss: 0.1218 - val_auc: 0.9893 - val_accuracy: 0.9709 - val_cost: 3.6045\n",
            "Epoch 294/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0561 - auc: 0.9964 - accuracy: 0.9834 - cost: 2.1312 - val_loss: 0.1214 - val_auc: 0.9892 - val_accuracy: 0.9710 - val_cost: 3.5582\n",
            "Epoch 295/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0561 - auc: 0.9964 - accuracy: 0.9832 - cost: 2.1524 - val_loss: 0.1194 - val_auc: 0.9897 - val_accuracy: 0.9701 - val_cost: 3.7302\n",
            "Epoch 296/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0550 - auc: 0.9966 - accuracy: 0.9832 - cost: 2.1570 - val_loss: 0.1249 - val_auc: 0.9891 - val_accuracy: 0.9703 - val_cost: 3.7235\n",
            "Epoch 297/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0556 - auc: 0.9965 - accuracy: 0.9834 - cost: 2.1300 - val_loss: 0.1205 - val_auc: 0.9892 - val_accuracy: 0.9710 - val_cost: 3.6210\n",
            "Epoch 298/1000\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 0.0550 - auc: 0.9966 - accuracy: 0.9835 - cost: 2.1154 - val_loss: 0.1191 - val_auc: 0.9894 - val_accuracy: 0.9704 - val_cost: 3.6343\n",
            "Epoch 299/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0557 - auc: 0.9966 - accuracy: 0.9831 - cost: 2.1667 - val_loss: 0.1194 - val_auc: 0.9897 - val_accuracy: 0.9722 - val_cost: 3.5384\n",
            "Epoch 300/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0552 - auc: 0.9966 - accuracy: 0.9838 - cost: 2.0756 - val_loss: 0.1201 - val_auc: 0.9894 - val_accuracy: 0.9702 - val_cost: 3.7169\n",
            "Epoch 301/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0556 - auc: 0.9966 - accuracy: 0.9835 - cost: 2.1219 - val_loss: 0.1206 - val_auc: 0.9896 - val_accuracy: 0.9715 - val_cost: 3.6045\n",
            "Epoch 302/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0557 - auc: 0.9966 - accuracy: 0.9834 - cost: 2.1285 - val_loss: 0.1224 - val_auc: 0.9892 - val_accuracy: 0.9716 - val_cost: 3.6045\n",
            "Epoch 303/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0561 - auc: 0.9966 - accuracy: 0.9835 - cost: 2.1335 - val_loss: 0.1200 - val_auc: 0.9894 - val_accuracy: 0.9717 - val_cost: 3.4788\n",
            "Epoch 304/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0555 - auc: 0.9965 - accuracy: 0.9836 - cost: 2.0980 - val_loss: 0.1228 - val_auc: 0.9894 - val_accuracy: 0.9716 - val_cost: 3.4788\n",
            "Epoch 305/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0553 - auc: 0.9965 - accuracy: 0.9832 - cost: 2.1570 - val_loss: 0.1220 - val_auc: 0.9891 - val_accuracy: 0.9712 - val_cost: 3.5582\n",
            "Epoch 306/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0547 - auc: 0.9966 - accuracy: 0.9837 - cost: 2.1042 - val_loss: 0.1235 - val_auc: 0.9890 - val_accuracy: 0.9704 - val_cost: 3.6508\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.1192 - auc: 0.9899 - accuracy: 0.9712 - cost: 3.6031\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:02:07.215817\n",
            "fold accuracy: 0.9711874723434448 - fold cost: 3.6031250953674316\n",
            "x_train shape: (144000, 67)\n",
            "Epoch 1/1000\n",
            "120/120 [==============================] - 2s 6ms/step - loss: 0.5321 - auc: 0.7960 - accuracy: 0.7264 - cost: 36.4738 - val_loss: 0.3994 - val_auc: 0.8983 - val_accuracy: 0.8247 - val_cost: 22.2685\n",
            "Epoch 2/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.3521 - auc: 0.9212 - accuracy: 0.8492 - cost: 19.2191 - val_loss: 0.3194 - val_auc: 0.9348 - val_accuracy: 0.8668 - val_cost: 16.8684\n",
            "Epoch 3/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.3032 - auc: 0.9417 - accuracy: 0.8738 - cost: 15.9911 - val_loss: 0.2892 - val_auc: 0.9470 - val_accuracy: 0.8812 - val_cost: 14.7421\n",
            "Epoch 4/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2749 - auc: 0.9522 - accuracy: 0.8886 - cost: 14.0945 - val_loss: 0.2649 - val_auc: 0.9559 - val_accuracy: 0.8943 - val_cost: 13.5251\n",
            "Epoch 5/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2525 - auc: 0.9597 - accuracy: 0.8986 - cost: 12.8434 - val_loss: 0.2442 - val_auc: 0.9625 - val_accuracy: 0.9053 - val_cost: 11.9147\n",
            "Epoch 6/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.2327 - auc: 0.9659 - accuracy: 0.9080 - cost: 11.6227 - val_loss: 0.2272 - val_auc: 0.9672 - val_accuracy: 0.9132 - val_cost: 10.9325\n",
            "Epoch 7/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2167 - auc: 0.9702 - accuracy: 0.9163 - cost: 10.5914 - val_loss: 0.2140 - val_auc: 0.9709 - val_accuracy: 0.9195 - val_cost: 10.0529\n",
            "Epoch 8/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2026 - auc: 0.9739 - accuracy: 0.9221 - cost: 9.8414 - val_loss: 0.2022 - val_auc: 0.9737 - val_accuracy: 0.9244 - val_cost: 9.5701\n",
            "Epoch 9/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1918 - auc: 0.9765 - accuracy: 0.9274 - cost: 9.1821 - val_loss: 0.1916 - val_auc: 0.9763 - val_accuracy: 0.9302 - val_cost: 8.7434\n",
            "Epoch 10/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1818 - auc: 0.9787 - accuracy: 0.9325 - cost: 8.5255 - val_loss: 0.1874 - val_auc: 0.9774 - val_accuracy: 0.9315 - val_cost: 8.8624\n",
            "Epoch 11/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1749 - auc: 0.9801 - accuracy: 0.9352 - cost: 8.2002 - val_loss: 0.1783 - val_auc: 0.9791 - val_accuracy: 0.9356 - val_cost: 8.1647\n",
            "Epoch 12/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1680 - auc: 0.9815 - accuracy: 0.9383 - cost: 7.8144 - val_loss: 0.1733 - val_auc: 0.9802 - val_accuracy: 0.9370 - val_cost: 7.8968\n",
            "Epoch 13/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1624 - auc: 0.9825 - accuracy: 0.9408 - cost: 7.4830 - val_loss: 0.1691 - val_auc: 0.9809 - val_accuracy: 0.9395 - val_cost: 7.6422\n",
            "Epoch 14/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1580 - auc: 0.9835 - accuracy: 0.9425 - cost: 7.2874 - val_loss: 0.1657 - val_auc: 0.9816 - val_accuracy: 0.9407 - val_cost: 7.3545\n",
            "Epoch 15/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1537 - auc: 0.9842 - accuracy: 0.9449 - cost: 6.9788 - val_loss: 0.1611 - val_auc: 0.9827 - val_accuracy: 0.9431 - val_cost: 7.1660\n",
            "Epoch 16/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1499 - auc: 0.9849 - accuracy: 0.9464 - cost: 6.7890 - val_loss: 0.1589 - val_auc: 0.9831 - val_accuracy: 0.9434 - val_cost: 7.1925\n",
            "Epoch 17/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.1462 - auc: 0.9855 - accuracy: 0.9482 - cost: 6.5613 - val_loss: 0.1591 - val_auc: 0.9832 - val_accuracy: 0.9443 - val_cost: 6.8056\n",
            "Epoch 18/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1434 - auc: 0.9860 - accuracy: 0.9491 - cost: 6.4529 - val_loss: 0.1542 - val_auc: 0.9839 - val_accuracy: 0.9467 - val_cost: 6.6501\n",
            "Epoch 19/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.1410 - auc: 0.9865 - accuracy: 0.9502 - cost: 6.3086 - val_loss: 0.1532 - val_auc: 0.9842 - val_accuracy: 0.9465 - val_cost: 6.6733\n",
            "Epoch 20/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1380 - auc: 0.9869 - accuracy: 0.9516 - cost: 6.1254 - val_loss: 0.1509 - val_auc: 0.9845 - val_accuracy: 0.9469 - val_cost: 6.7394\n",
            "Epoch 21/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1361 - auc: 0.9873 - accuracy: 0.9525 - cost: 6.0208 - val_loss: 0.1500 - val_auc: 0.9848 - val_accuracy: 0.9484 - val_cost: 6.3757\n",
            "Epoch 22/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1333 - auc: 0.9877 - accuracy: 0.9537 - cost: 5.8688 - val_loss: 0.1488 - val_auc: 0.9850 - val_accuracy: 0.9474 - val_cost: 6.4418\n",
            "Epoch 23/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1312 - auc: 0.9881 - accuracy: 0.9542 - cost: 5.7990 - val_loss: 0.1451 - val_auc: 0.9855 - val_accuracy: 0.9498 - val_cost: 6.2136\n",
            "Epoch 24/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1292 - auc: 0.9883 - accuracy: 0.9555 - cost: 5.6254 - val_loss: 0.1448 - val_auc: 0.9856 - val_accuracy: 0.9498 - val_cost: 6.2996\n",
            "Epoch 25/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1274 - auc: 0.9885 - accuracy: 0.9565 - cost: 5.5212 - val_loss: 0.1437 - val_auc: 0.9857 - val_accuracy: 0.9500 - val_cost: 6.2070\n",
            "Epoch 26/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1253 - auc: 0.9888 - accuracy: 0.9572 - cost: 5.4105 - val_loss: 0.1428 - val_auc: 0.9860 - val_accuracy: 0.9519 - val_cost: 5.9292\n",
            "Epoch 27/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1235 - auc: 0.9891 - accuracy: 0.9580 - cost: 5.3106 - val_loss: 0.1433 - val_auc: 0.9860 - val_accuracy: 0.9513 - val_cost: 6.3294\n",
            "Epoch 28/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.1222 - auc: 0.9893 - accuracy: 0.9587 - cost: 5.2272 - val_loss: 0.1401 - val_auc: 0.9862 - val_accuracy: 0.9525 - val_cost: 6.0119\n",
            "Epoch 29/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.1209 - auc: 0.9895 - accuracy: 0.9590 - cost: 5.1991 - val_loss: 0.1394 - val_auc: 0.9864 - val_accuracy: 0.9528 - val_cost: 6.0483\n",
            "Epoch 30/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1189 - auc: 0.9897 - accuracy: 0.9600 - cost: 5.0671 - val_loss: 0.1390 - val_auc: 0.9866 - val_accuracy: 0.9533 - val_cost: 5.9127\n",
            "Epoch 31/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1176 - auc: 0.9899 - accuracy: 0.9608 - cost: 4.9726 - val_loss: 0.1372 - val_auc: 0.9868 - val_accuracy: 0.9542 - val_cost: 5.7275\n",
            "Epoch 32/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1169 - auc: 0.9900 - accuracy: 0.9608 - cost: 4.9495 - val_loss: 0.1374 - val_auc: 0.9867 - val_accuracy: 0.9541 - val_cost: 5.8399\n",
            "Epoch 33/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1149 - auc: 0.9902 - accuracy: 0.9623 - cost: 4.7805 - val_loss: 0.1366 - val_auc: 0.9869 - val_accuracy: 0.9562 - val_cost: 5.4663\n",
            "Epoch 34/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1138 - auc: 0.9904 - accuracy: 0.9620 - cost: 4.8125 - val_loss: 0.1351 - val_auc: 0.9872 - val_accuracy: 0.9563 - val_cost: 5.4729\n",
            "Epoch 35/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1127 - auc: 0.9906 - accuracy: 0.9630 - cost: 4.6848 - val_loss: 0.1336 - val_auc: 0.9871 - val_accuracy: 0.9574 - val_cost: 5.3968\n",
            "Epoch 36/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1108 - auc: 0.9908 - accuracy: 0.9633 - cost: 4.6620 - val_loss: 0.1343 - val_auc: 0.9872 - val_accuracy: 0.9573 - val_cost: 5.4101\n",
            "Epoch 37/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1107 - auc: 0.9908 - accuracy: 0.9635 - cost: 4.6335 - val_loss: 0.1336 - val_auc: 0.9872 - val_accuracy: 0.9577 - val_cost: 5.2017\n",
            "Epoch 38/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1101 - auc: 0.9909 - accuracy: 0.9638 - cost: 4.5922 - val_loss: 0.1328 - val_auc: 0.9873 - val_accuracy: 0.9574 - val_cost: 5.2778\n",
            "Epoch 39/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1072 - auc: 0.9913 - accuracy: 0.9648 - cost: 4.4568 - val_loss: 0.1319 - val_auc: 0.9873 - val_accuracy: 0.9571 - val_cost: 5.4828\n",
            "Epoch 40/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1072 - auc: 0.9911 - accuracy: 0.9651 - cost: 4.4344 - val_loss: 0.1319 - val_auc: 0.9872 - val_accuracy: 0.9580 - val_cost: 5.2679\n",
            "Epoch 41/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1069 - auc: 0.9912 - accuracy: 0.9654 - cost: 4.3900 - val_loss: 0.1307 - val_auc: 0.9874 - val_accuracy: 0.9587 - val_cost: 5.1852\n",
            "Epoch 42/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1046 - auc: 0.9915 - accuracy: 0.9668 - cost: 4.2133 - val_loss: 0.1311 - val_auc: 0.9875 - val_accuracy: 0.9577 - val_cost: 5.2083\n",
            "Epoch 43/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1029 - auc: 0.9918 - accuracy: 0.9664 - cost: 4.2654 - val_loss: 0.1292 - val_auc: 0.9877 - val_accuracy: 0.9590 - val_cost: 5.0893\n",
            "Epoch 44/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1029 - auc: 0.9917 - accuracy: 0.9668 - cost: 4.2242 - val_loss: 0.1287 - val_auc: 0.9876 - val_accuracy: 0.9591 - val_cost: 5.1422\n",
            "Epoch 45/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1016 - auc: 0.9919 - accuracy: 0.9670 - cost: 4.1887 - val_loss: 0.1286 - val_auc: 0.9876 - val_accuracy: 0.9607 - val_cost: 4.9603\n",
            "Epoch 46/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1017 - auc: 0.9919 - accuracy: 0.9673 - cost: 4.1566 - val_loss: 0.1283 - val_auc: 0.9877 - val_accuracy: 0.9603 - val_cost: 4.8776\n",
            "Epoch 47/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0999 - auc: 0.9920 - accuracy: 0.9682 - cost: 4.0293 - val_loss: 0.1266 - val_auc: 0.9877 - val_accuracy: 0.9591 - val_cost: 5.1323\n",
            "Epoch 48/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1002 - auc: 0.9919 - accuracy: 0.9681 - cost: 4.0502 - val_loss: 0.1243 - val_auc: 0.9881 - val_accuracy: 0.9618 - val_cost: 4.8512\n",
            "Epoch 49/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0978 - auc: 0.9923 - accuracy: 0.9692 - cost: 3.9178 - val_loss: 0.1249 - val_auc: 0.9882 - val_accuracy: 0.9601 - val_cost: 5.1455\n",
            "Epoch 50/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0970 - auc: 0.9924 - accuracy: 0.9692 - cost: 3.9198 - val_loss: 0.1246 - val_auc: 0.9885 - val_accuracy: 0.9618 - val_cost: 4.7553\n",
            "Epoch 51/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0970 - auc: 0.9924 - accuracy: 0.9691 - cost: 3.9333 - val_loss: 0.1238 - val_auc: 0.9883 - val_accuracy: 0.9617 - val_cost: 4.9339\n",
            "Epoch 52/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0959 - auc: 0.9925 - accuracy: 0.9701 - cost: 3.8171 - val_loss: 0.1245 - val_auc: 0.9882 - val_accuracy: 0.9621 - val_cost: 4.6329\n",
            "Epoch 53/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0952 - auc: 0.9925 - accuracy: 0.9703 - cost: 3.7731 - val_loss: 0.1237 - val_auc: 0.9882 - val_accuracy: 0.9617 - val_cost: 4.8710\n",
            "Epoch 54/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0945 - auc: 0.9926 - accuracy: 0.9706 - cost: 3.7299 - val_loss: 0.1237 - val_auc: 0.9884 - val_accuracy: 0.9633 - val_cost: 4.4808\n",
            "Epoch 55/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0931 - auc: 0.9928 - accuracy: 0.9709 - cost: 3.6991 - val_loss: 0.1217 - val_auc: 0.9885 - val_accuracy: 0.9636 - val_cost: 4.6329\n",
            "Epoch 56/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0927 - auc: 0.9928 - accuracy: 0.9708 - cost: 3.7010 - val_loss: 0.1207 - val_auc: 0.9886 - val_accuracy: 0.9628 - val_cost: 4.6693\n",
            "Epoch 57/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0926 - auc: 0.9927 - accuracy: 0.9709 - cost: 3.6894 - val_loss: 0.1207 - val_auc: 0.9886 - val_accuracy: 0.9632 - val_cost: 4.6263\n",
            "Epoch 58/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0908 - auc: 0.9931 - accuracy: 0.9714 - cost: 3.6308 - val_loss: 0.1226 - val_auc: 0.9887 - val_accuracy: 0.9638 - val_cost: 4.5007\n",
            "Epoch 59/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0911 - auc: 0.9930 - accuracy: 0.9714 - cost: 3.6196 - val_loss: 0.1185 - val_auc: 0.9889 - val_accuracy: 0.9631 - val_cost: 4.6627\n",
            "Epoch 60/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0896 - auc: 0.9932 - accuracy: 0.9727 - cost: 3.4726 - val_loss: 0.1177 - val_auc: 0.9890 - val_accuracy: 0.9645 - val_cost: 4.4874\n",
            "Epoch 61/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0890 - auc: 0.9931 - accuracy: 0.9726 - cost: 3.4792 - val_loss: 0.1178 - val_auc: 0.9890 - val_accuracy: 0.9640 - val_cost: 4.5205\n",
            "Epoch 62/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0890 - auc: 0.9931 - accuracy: 0.9725 - cost: 3.5120 - val_loss: 0.1183 - val_auc: 0.9888 - val_accuracy: 0.9641 - val_cost: 4.4312\n",
            "Epoch 63/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0877 - auc: 0.9933 - accuracy: 0.9730 - cost: 3.4333 - val_loss: 0.1171 - val_auc: 0.9889 - val_accuracy: 0.9648 - val_cost: 4.4081\n",
            "Epoch 64/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0878 - auc: 0.9932 - accuracy: 0.9734 - cost: 3.3758 - val_loss: 0.1167 - val_auc: 0.9893 - val_accuracy: 0.9649 - val_cost: 4.5139\n",
            "Epoch 65/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0863 - auc: 0.9934 - accuracy: 0.9734 - cost: 3.3754 - val_loss: 0.1154 - val_auc: 0.9894 - val_accuracy: 0.9641 - val_cost: 4.5767\n",
            "Epoch 66/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0866 - auc: 0.9934 - accuracy: 0.9734 - cost: 3.3785 - val_loss: 0.1159 - val_auc: 0.9889 - val_accuracy: 0.9635 - val_cost: 4.5635\n",
            "Epoch 67/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0855 - auc: 0.9935 - accuracy: 0.9740 - cost: 3.3029 - val_loss: 0.1165 - val_auc: 0.9891 - val_accuracy: 0.9643 - val_cost: 4.5470\n",
            "Epoch 68/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0850 - auc: 0.9936 - accuracy: 0.9738 - cost: 3.3314 - val_loss: 0.1148 - val_auc: 0.9891 - val_accuracy: 0.9663 - val_cost: 4.1799\n",
            "Epoch 69/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0854 - auc: 0.9936 - accuracy: 0.9739 - cost: 3.3164 - val_loss: 0.1151 - val_auc: 0.9893 - val_accuracy: 0.9656 - val_cost: 4.3485\n",
            "Epoch 70/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0840 - auc: 0.9937 - accuracy: 0.9745 - cost: 3.2604 - val_loss: 0.1151 - val_auc: 0.9894 - val_accuracy: 0.9648 - val_cost: 4.3783\n",
            "Epoch 71/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0827 - auc: 0.9938 - accuracy: 0.9747 - cost: 3.2110 - val_loss: 0.1148 - val_auc: 0.9893 - val_accuracy: 0.9654 - val_cost: 4.2725\n",
            "Epoch 72/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0836 - auc: 0.9937 - accuracy: 0.9747 - cost: 3.2133 - val_loss: 0.1145 - val_auc: 0.9892 - val_accuracy: 0.9653 - val_cost: 4.3783\n",
            "Epoch 73/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0841 - auc: 0.9937 - accuracy: 0.9743 - cost: 3.2654 - val_loss: 0.1157 - val_auc: 0.9894 - val_accuracy: 0.9654 - val_cost: 4.1799\n",
            "Epoch 74/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0817 - auc: 0.9939 - accuracy: 0.9753 - cost: 3.1412 - val_loss: 0.1133 - val_auc: 0.9896 - val_accuracy: 0.9672 - val_cost: 4.0675\n",
            "Epoch 75/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0819 - auc: 0.9939 - accuracy: 0.9748 - cost: 3.2091 - val_loss: 0.1144 - val_auc: 0.9896 - val_accuracy: 0.9654 - val_cost: 4.2857\n",
            "Epoch 76/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0812 - auc: 0.9939 - accuracy: 0.9754 - cost: 3.1316 - val_loss: 0.1132 - val_auc: 0.9896 - val_accuracy: 0.9667 - val_cost: 4.2593\n",
            "Epoch 77/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0806 - auc: 0.9941 - accuracy: 0.9754 - cost: 3.1346 - val_loss: 0.1131 - val_auc: 0.9893 - val_accuracy: 0.9660 - val_cost: 4.3022\n",
            "Epoch 78/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0811 - auc: 0.9939 - accuracy: 0.9754 - cost: 3.1350 - val_loss: 0.1132 - val_auc: 0.9894 - val_accuracy: 0.9655 - val_cost: 4.3816\n",
            "Epoch 79/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0808 - auc: 0.9939 - accuracy: 0.9756 - cost: 3.1046 - val_loss: 0.1129 - val_auc: 0.9895 - val_accuracy: 0.9667 - val_cost: 4.2196\n",
            "Epoch 80/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0800 - auc: 0.9941 - accuracy: 0.9762 - cost: 3.0274 - val_loss: 0.1142 - val_auc: 0.9895 - val_accuracy: 0.9666 - val_cost: 4.1138\n",
            "Epoch 81/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0796 - auc: 0.9941 - accuracy: 0.9760 - cost: 3.0502 - val_loss: 0.1133 - val_auc: 0.9895 - val_accuracy: 0.9676 - val_cost: 4.0410\n",
            "Epoch 82/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0801 - auc: 0.9940 - accuracy: 0.9756 - cost: 3.1030 - val_loss: 0.1127 - val_auc: 0.9895 - val_accuracy: 0.9669 - val_cost: 4.2063\n",
            "Epoch 83/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0784 - auc: 0.9942 - accuracy: 0.9768 - cost: 2.9498 - val_loss: 0.1120 - val_auc: 0.9893 - val_accuracy: 0.9668 - val_cost: 4.2163\n",
            "Epoch 84/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0779 - auc: 0.9943 - accuracy: 0.9764 - cost: 3.0050 - val_loss: 0.1113 - val_auc: 0.9896 - val_accuracy: 0.9660 - val_cost: 4.2361\n",
            "Epoch 85/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0787 - auc: 0.9942 - accuracy: 0.9765 - cost: 2.9942 - val_loss: 0.1111 - val_auc: 0.9895 - val_accuracy: 0.9661 - val_cost: 4.2857\n",
            "Epoch 86/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0775 - auc: 0.9943 - accuracy: 0.9763 - cost: 3.0181 - val_loss: 0.1112 - val_auc: 0.9896 - val_accuracy: 0.9676 - val_cost: 3.9021\n",
            "Epoch 87/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0782 - auc: 0.9943 - accuracy: 0.9760 - cost: 3.0571 - val_loss: 0.1114 - val_auc: 0.9896 - val_accuracy: 0.9672 - val_cost: 4.1038\n",
            "Epoch 88/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0769 - auc: 0.9944 - accuracy: 0.9772 - cost: 2.9062 - val_loss: 0.1112 - val_auc: 0.9896 - val_accuracy: 0.9686 - val_cost: 3.8724\n",
            "Epoch 89/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0764 - auc: 0.9943 - accuracy: 0.9774 - cost: 2.8812 - val_loss: 0.1142 - val_auc: 0.9893 - val_accuracy: 0.9667 - val_cost: 4.0675\n",
            "Epoch 90/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0769 - auc: 0.9943 - accuracy: 0.9772 - cost: 2.9066 - val_loss: 0.1126 - val_auc: 0.9894 - val_accuracy: 0.9667 - val_cost: 4.1634\n",
            "Epoch 91/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0758 - auc: 0.9944 - accuracy: 0.9773 - cost: 2.8873 - val_loss: 0.1124 - val_auc: 0.9896 - val_accuracy: 0.9669 - val_cost: 4.1270\n",
            "Epoch 92/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0754 - auc: 0.9945 - accuracy: 0.9772 - cost: 2.9051 - val_loss: 0.1102 - val_auc: 0.9896 - val_accuracy: 0.9679 - val_cost: 4.0377\n",
            "Epoch 93/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0762 - auc: 0.9944 - accuracy: 0.9772 - cost: 2.8893 - val_loss: 0.1104 - val_auc: 0.9896 - val_accuracy: 0.9683 - val_cost: 4.0046\n",
            "Epoch 94/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0752 - auc: 0.9945 - accuracy: 0.9780 - cost: 2.8059 - val_loss: 0.1101 - val_auc: 0.9897 - val_accuracy: 0.9674 - val_cost: 4.1369\n",
            "Epoch 95/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0738 - auc: 0.9946 - accuracy: 0.9780 - cost: 2.8036 - val_loss: 0.1117 - val_auc: 0.9895 - val_accuracy: 0.9679 - val_cost: 4.0575\n",
            "Epoch 96/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0749 - auc: 0.9946 - accuracy: 0.9776 - cost: 2.8480 - val_loss: 0.1116 - val_auc: 0.9893 - val_accuracy: 0.9686 - val_cost: 3.9385\n",
            "Epoch 97/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0740 - auc: 0.9947 - accuracy: 0.9780 - cost: 2.7936 - val_loss: 0.1101 - val_auc: 0.9897 - val_accuracy: 0.9685 - val_cost: 3.9187\n",
            "Epoch 98/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0742 - auc: 0.9946 - accuracy: 0.9781 - cost: 2.7886 - val_loss: 0.1107 - val_auc: 0.9895 - val_accuracy: 0.9680 - val_cost: 4.0146\n",
            "Epoch 99/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0731 - auc: 0.9948 - accuracy: 0.9781 - cost: 2.7870 - val_loss: 0.1115 - val_auc: 0.9897 - val_accuracy: 0.9678 - val_cost: 4.0046\n",
            "Epoch 100/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0732 - auc: 0.9946 - accuracy: 0.9786 - cost: 2.7307 - val_loss: 0.1091 - val_auc: 0.9896 - val_accuracy: 0.9691 - val_cost: 3.9550\n",
            "Epoch 101/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0742 - auc: 0.9946 - accuracy: 0.9781 - cost: 2.7948 - val_loss: 0.1105 - val_auc: 0.9897 - val_accuracy: 0.9674 - val_cost: 3.9947\n",
            "Epoch 102/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0737 - auc: 0.9946 - accuracy: 0.9782 - cost: 2.7890 - val_loss: 0.1097 - val_auc: 0.9898 - val_accuracy: 0.9690 - val_cost: 3.8823\n",
            "Epoch 103/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0726 - auc: 0.9947 - accuracy: 0.9782 - cost: 2.7751 - val_loss: 0.1113 - val_auc: 0.9897 - val_accuracy: 0.9674 - val_cost: 4.1567\n",
            "Epoch 104/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0724 - auc: 0.9947 - accuracy: 0.9790 - cost: 2.6836 - val_loss: 0.1103 - val_auc: 0.9898 - val_accuracy: 0.9687 - val_cost: 3.9616\n",
            "Epoch 105/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0720 - auc: 0.9948 - accuracy: 0.9790 - cost: 2.6690 - val_loss: 0.1096 - val_auc: 0.9896 - val_accuracy: 0.9690 - val_cost: 3.9683\n",
            "Epoch 106/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0730 - auc: 0.9947 - accuracy: 0.9786 - cost: 2.7380 - val_loss: 0.1120 - val_auc: 0.9897 - val_accuracy: 0.9682 - val_cost: 4.0079\n",
            "Epoch 107/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0723 - auc: 0.9949 - accuracy: 0.9790 - cost: 2.6782 - val_loss: 0.1101 - val_auc: 0.9896 - val_accuracy: 0.9683 - val_cost: 3.9220\n",
            "Epoch 108/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0717 - auc: 0.9949 - accuracy: 0.9789 - cost: 2.6991 - val_loss: 0.1113 - val_auc: 0.9895 - val_accuracy: 0.9690 - val_cost: 3.9418\n",
            "Epoch 109/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0713 - auc: 0.9949 - accuracy: 0.9794 - cost: 2.6385 - val_loss: 0.1108 - val_auc: 0.9896 - val_accuracy: 0.9690 - val_cost: 3.8558\n",
            "Epoch 110/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0711 - auc: 0.9950 - accuracy: 0.9794 - cost: 2.6443 - val_loss: 0.1105 - val_auc: 0.9900 - val_accuracy: 0.9688 - val_cost: 3.9220\n",
            "Epoch 111/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0711 - auc: 0.9949 - accuracy: 0.9791 - cost: 2.6694 - val_loss: 0.1109 - val_auc: 0.9899 - val_accuracy: 0.9694 - val_cost: 3.8624\n",
            "Epoch 112/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0713 - auc: 0.9949 - accuracy: 0.9790 - cost: 2.6852 - val_loss: 0.1092 - val_auc: 0.9899 - val_accuracy: 0.9691 - val_cost: 4.0079\n",
            "Epoch 113/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0717 - auc: 0.9949 - accuracy: 0.9788 - cost: 2.6995 - val_loss: 0.1094 - val_auc: 0.9895 - val_accuracy: 0.9701 - val_cost: 3.7401\n",
            "Epoch 114/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0708 - auc: 0.9950 - accuracy: 0.9792 - cost: 2.6644 - val_loss: 0.1102 - val_auc: 0.9897 - val_accuracy: 0.9697 - val_cost: 3.8525\n",
            "Epoch 115/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0696 - auc: 0.9950 - accuracy: 0.9792 - cost: 2.6701 - val_loss: 0.1100 - val_auc: 0.9897 - val_accuracy: 0.9701 - val_cost: 3.7665\n",
            "Epoch 116/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0703 - auc: 0.9950 - accuracy: 0.9794 - cost: 2.6281 - val_loss: 0.1088 - val_auc: 0.9898 - val_accuracy: 0.9696 - val_cost: 3.8988\n",
            "Epoch 117/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0702 - auc: 0.9950 - accuracy: 0.9791 - cost: 2.6617 - val_loss: 0.1098 - val_auc: 0.9897 - val_accuracy: 0.9697 - val_cost: 3.7599\n",
            "Epoch 118/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0707 - auc: 0.9950 - accuracy: 0.9792 - cost: 2.6574 - val_loss: 0.1096 - val_auc: 0.9897 - val_accuracy: 0.9696 - val_cost: 3.7831\n",
            "Epoch 119/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0704 - auc: 0.9950 - accuracy: 0.9793 - cost: 2.6481 - val_loss: 0.1099 - val_auc: 0.9897 - val_accuracy: 0.9697 - val_cost: 3.7070\n",
            "Epoch 120/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0707 - auc: 0.9949 - accuracy: 0.9795 - cost: 2.6231 - val_loss: 0.1093 - val_auc: 0.9896 - val_accuracy: 0.9699 - val_cost: 3.7632\n",
            "Epoch 121/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0688 - auc: 0.9950 - accuracy: 0.9797 - cost: 2.5945 - val_loss: 0.1095 - val_auc: 0.9893 - val_accuracy: 0.9698 - val_cost: 3.8327\n",
            "Epoch 122/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0688 - auc: 0.9952 - accuracy: 0.9797 - cost: 2.5880 - val_loss: 0.1092 - val_auc: 0.9895 - val_accuracy: 0.9696 - val_cost: 3.8095\n",
            "Epoch 123/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0690 - auc: 0.9951 - accuracy: 0.9801 - cost: 2.5421 - val_loss: 0.1104 - val_auc: 0.9895 - val_accuracy: 0.9699 - val_cost: 3.7765\n",
            "Epoch 124/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0686 - auc: 0.9952 - accuracy: 0.9798 - cost: 2.5891 - val_loss: 0.1107 - val_auc: 0.9897 - val_accuracy: 0.9687 - val_cost: 3.9187\n",
            "Epoch 125/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0693 - auc: 0.9951 - accuracy: 0.9797 - cost: 2.6073 - val_loss: 0.1100 - val_auc: 0.9898 - val_accuracy: 0.9694 - val_cost: 3.8657\n",
            "Epoch 126/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0679 - auc: 0.9952 - accuracy: 0.9800 - cost: 2.5718 - val_loss: 0.1099 - val_auc: 0.9894 - val_accuracy: 0.9700 - val_cost: 3.6839\n",
            "Epoch 127/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0684 - auc: 0.9952 - accuracy: 0.9799 - cost: 2.5613 - val_loss: 0.1090 - val_auc: 0.9897 - val_accuracy: 0.9701 - val_cost: 3.7269\n",
            "Epoch 128/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0684 - auc: 0.9953 - accuracy: 0.9797 - cost: 2.5910 - val_loss: 0.1103 - val_auc: 0.9898 - val_accuracy: 0.9686 - val_cost: 3.9517\n",
            "Epoch 129/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0679 - auc: 0.9953 - accuracy: 0.9800 - cost: 2.5640 - val_loss: 0.1096 - val_auc: 0.9894 - val_accuracy: 0.9701 - val_cost: 3.6839\n",
            "Epoch 130/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0671 - auc: 0.9953 - accuracy: 0.9806 - cost: 2.4788 - val_loss: 0.1098 - val_auc: 0.9899 - val_accuracy: 0.9698 - val_cost: 3.7996\n",
            "Epoch 131/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0679 - auc: 0.9953 - accuracy: 0.9802 - cost: 2.5316 - val_loss: 0.1077 - val_auc: 0.9899 - val_accuracy: 0.9694 - val_cost: 3.7698\n",
            "Epoch 132/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0677 - auc: 0.9952 - accuracy: 0.9802 - cost: 2.5328 - val_loss: 0.1092 - val_auc: 0.9895 - val_accuracy: 0.9710 - val_cost: 3.6607\n",
            "Epoch 133/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0673 - auc: 0.9953 - accuracy: 0.9807 - cost: 2.4688 - val_loss: 0.1077 - val_auc: 0.9899 - val_accuracy: 0.9699 - val_cost: 3.8161\n",
            "Epoch 134/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0675 - auc: 0.9952 - accuracy: 0.9803 - cost: 2.5112 - val_loss: 0.1091 - val_auc: 0.9898 - val_accuracy: 0.9698 - val_cost: 3.7765\n",
            "Epoch 135/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0674 - auc: 0.9953 - accuracy: 0.9803 - cost: 2.5131 - val_loss: 0.1093 - val_auc: 0.9900 - val_accuracy: 0.9710 - val_cost: 3.8062\n",
            "Epoch 136/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0671 - auc: 0.9954 - accuracy: 0.9804 - cost: 2.4985 - val_loss: 0.1091 - val_auc: 0.9897 - val_accuracy: 0.9710 - val_cost: 3.6541\n",
            "Epoch 137/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0671 - auc: 0.9952 - accuracy: 0.9804 - cost: 2.5039 - val_loss: 0.1113 - val_auc: 0.9899 - val_accuracy: 0.9695 - val_cost: 3.7368\n",
            "Epoch 138/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0669 - auc: 0.9953 - accuracy: 0.9805 - cost: 2.4938 - val_loss: 0.1095 - val_auc: 0.9900 - val_accuracy: 0.9708 - val_cost: 3.7004\n",
            "Epoch 139/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0664 - auc: 0.9955 - accuracy: 0.9805 - cost: 2.4826 - val_loss: 0.1117 - val_auc: 0.9897 - val_accuracy: 0.9691 - val_cost: 3.8161\n",
            "Epoch 140/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0666 - auc: 0.9954 - accuracy: 0.9808 - cost: 2.4564 - val_loss: 0.1096 - val_auc: 0.9895 - val_accuracy: 0.9706 - val_cost: 3.7136\n",
            "Epoch 141/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0661 - auc: 0.9956 - accuracy: 0.9806 - cost: 2.4784 - val_loss: 0.1112 - val_auc: 0.9895 - val_accuracy: 0.9697 - val_cost: 3.8624\n",
            "Epoch 142/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0660 - auc: 0.9955 - accuracy: 0.9808 - cost: 2.4533 - val_loss: 0.1087 - val_auc: 0.9897 - val_accuracy: 0.9699 - val_cost: 3.8029\n",
            "Epoch 143/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0665 - auc: 0.9953 - accuracy: 0.9810 - cost: 2.4367 - val_loss: 0.1102 - val_auc: 0.9896 - val_accuracy: 0.9695 - val_cost: 3.8228\n",
            "Epoch 144/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0651 - auc: 0.9956 - accuracy: 0.9810 - cost: 2.4294 - val_loss: 0.1097 - val_auc: 0.9894 - val_accuracy: 0.9699 - val_cost: 3.8261\n",
            "Epoch 145/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0659 - auc: 0.9955 - accuracy: 0.9807 - cost: 2.4722 - val_loss: 0.1101 - val_auc: 0.9894 - val_accuracy: 0.9708 - val_cost: 3.5747\n",
            "Epoch 146/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0656 - auc: 0.9955 - accuracy: 0.9811 - cost: 2.4201 - val_loss: 0.1117 - val_auc: 0.9899 - val_accuracy: 0.9699 - val_cost: 3.6772\n",
            "Epoch 147/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0660 - auc: 0.9955 - accuracy: 0.9807 - cost: 2.4699 - val_loss: 0.1093 - val_auc: 0.9894 - val_accuracy: 0.9703 - val_cost: 3.7004\n",
            "Epoch 148/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0653 - auc: 0.9956 - accuracy: 0.9809 - cost: 2.4491 - val_loss: 0.1105 - val_auc: 0.9894 - val_accuracy: 0.9710 - val_cost: 3.6409\n",
            "Epoch 149/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0649 - auc: 0.9956 - accuracy: 0.9809 - cost: 2.4371 - val_loss: 0.1085 - val_auc: 0.9898 - val_accuracy: 0.9714 - val_cost: 3.5218\n",
            "Epoch 150/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0647 - auc: 0.9957 - accuracy: 0.9809 - cost: 2.4417 - val_loss: 0.1115 - val_auc: 0.9895 - val_accuracy: 0.9703 - val_cost: 3.7269\n",
            "Epoch 151/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0649 - auc: 0.9955 - accuracy: 0.9814 - cost: 2.3715 - val_loss: 0.1097 - val_auc: 0.9898 - val_accuracy: 0.9715 - val_cost: 3.6012\n",
            "Epoch 152/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0643 - auc: 0.9956 - accuracy: 0.9814 - cost: 2.3785 - val_loss: 0.1102 - val_auc: 0.9898 - val_accuracy: 0.9706 - val_cost: 3.7434\n",
            "Epoch 153/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0636 - auc: 0.9957 - accuracy: 0.9816 - cost: 2.3542 - val_loss: 0.1080 - val_auc: 0.9897 - val_accuracy: 0.9710 - val_cost: 3.6839\n",
            "Epoch 154/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0641 - auc: 0.9956 - accuracy: 0.9814 - cost: 2.3862 - val_loss: 0.1096 - val_auc: 0.9897 - val_accuracy: 0.9705 - val_cost: 3.7235\n",
            "Epoch 155/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0643 - auc: 0.9956 - accuracy: 0.9813 - cost: 2.3870 - val_loss: 0.1094 - val_auc: 0.9897 - val_accuracy: 0.9711 - val_cost: 3.6078\n",
            "Epoch 156/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0639 - auc: 0.9956 - accuracy: 0.9810 - cost: 2.4117 - val_loss: 0.1103 - val_auc: 0.9897 - val_accuracy: 0.9710 - val_cost: 3.8062\n",
            "Epoch 157/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0639 - auc: 0.9956 - accuracy: 0.9813 - cost: 2.3862 - val_loss: 0.1096 - val_auc: 0.9895 - val_accuracy: 0.9712 - val_cost: 3.6177\n",
            "Epoch 158/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0639 - auc: 0.9957 - accuracy: 0.9815 - cost: 2.3681 - val_loss: 0.1105 - val_auc: 0.9896 - val_accuracy: 0.9703 - val_cost: 3.7269\n",
            "Epoch 159/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0640 - auc: 0.9956 - accuracy: 0.9815 - cost: 2.3669 - val_loss: 0.1101 - val_auc: 0.9897 - val_accuracy: 0.9701 - val_cost: 3.6706\n",
            "Epoch 160/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0637 - auc: 0.9957 - accuracy: 0.9816 - cost: 2.3588 - val_loss: 0.1085 - val_auc: 0.9897 - val_accuracy: 0.9699 - val_cost: 3.8029\n",
            "Epoch 161/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0639 - auc: 0.9957 - accuracy: 0.9815 - cost: 2.3742 - val_loss: 0.1098 - val_auc: 0.9896 - val_accuracy: 0.9703 - val_cost: 3.7037\n",
            "Epoch 162/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0631 - auc: 0.9958 - accuracy: 0.9816 - cost: 2.3549 - val_loss: 0.1105 - val_auc: 0.9899 - val_accuracy: 0.9715 - val_cost: 3.5351\n",
            "Epoch 163/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0634 - auc: 0.9957 - accuracy: 0.9817 - cost: 2.3407 - val_loss: 0.1105 - val_auc: 0.9896 - val_accuracy: 0.9704 - val_cost: 3.7930\n",
            "Epoch 164/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0630 - auc: 0.9957 - accuracy: 0.9815 - cost: 2.3738 - val_loss: 0.1093 - val_auc: 0.9898 - val_accuracy: 0.9708 - val_cost: 3.7202\n",
            "Epoch 165/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0635 - auc: 0.9957 - accuracy: 0.9813 - cost: 2.3947 - val_loss: 0.1095 - val_auc: 0.9894 - val_accuracy: 0.9719 - val_cost: 3.4921\n",
            "Epoch 166/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0634 - auc: 0.9958 - accuracy: 0.9815 - cost: 2.3692 - val_loss: 0.1112 - val_auc: 0.9897 - val_accuracy: 0.9706 - val_cost: 3.7533\n",
            "Epoch 167/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0633 - auc: 0.9957 - accuracy: 0.9816 - cost: 2.3453 - val_loss: 0.1136 - val_auc: 0.9892 - val_accuracy: 0.9699 - val_cost: 3.9253\n",
            "Epoch 168/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0636 - auc: 0.9957 - accuracy: 0.9814 - cost: 2.3762 - val_loss: 0.1099 - val_auc: 0.9896 - val_accuracy: 0.9712 - val_cost: 3.5351\n",
            "Epoch 169/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0630 - auc: 0.9957 - accuracy: 0.9819 - cost: 2.3079 - val_loss: 0.1096 - val_auc: 0.9897 - val_accuracy: 0.9711 - val_cost: 3.5582\n",
            "Epoch 170/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0622 - auc: 0.9958 - accuracy: 0.9820 - cost: 2.3063 - val_loss: 0.1116 - val_auc: 0.9893 - val_accuracy: 0.9701 - val_cost: 3.7235\n",
            "Epoch 171/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0628 - auc: 0.9959 - accuracy: 0.9820 - cost: 2.2940 - val_loss: 0.1097 - val_auc: 0.9896 - val_accuracy: 0.9712 - val_cost: 3.6144\n",
            "Epoch 172/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0635 - auc: 0.9957 - accuracy: 0.9816 - cost: 2.3603 - val_loss: 0.1093 - val_auc: 0.9896 - val_accuracy: 0.9706 - val_cost: 3.6409\n",
            "Epoch 173/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0621 - auc: 0.9959 - accuracy: 0.9818 - cost: 2.3268 - val_loss: 0.1084 - val_auc: 0.9900 - val_accuracy: 0.9711 - val_cost: 3.7500\n",
            "Epoch 174/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0628 - auc: 0.9958 - accuracy: 0.9815 - cost: 2.3592 - val_loss: 0.1084 - val_auc: 0.9898 - val_accuracy: 0.9708 - val_cost: 3.6607\n",
            "Epoch 175/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0622 - auc: 0.9959 - accuracy: 0.9816 - cost: 2.3565 - val_loss: 0.1087 - val_auc: 0.9898 - val_accuracy: 0.9712 - val_cost: 3.6310\n",
            "Epoch 176/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0621 - auc: 0.9959 - accuracy: 0.9823 - cost: 2.2693 - val_loss: 0.1094 - val_auc: 0.9898 - val_accuracy: 0.9713 - val_cost: 3.6409\n",
            "Epoch 177/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0621 - auc: 0.9959 - accuracy: 0.9819 - cost: 2.3164 - val_loss: 0.1109 - val_auc: 0.9898 - val_accuracy: 0.9708 - val_cost: 3.5979\n",
            "Epoch 178/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0623 - auc: 0.9958 - accuracy: 0.9817 - cost: 2.3407 - val_loss: 0.1109 - val_auc: 0.9894 - val_accuracy: 0.9715 - val_cost: 3.5813\n",
            "Epoch 179/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0622 - auc: 0.9959 - accuracy: 0.9815 - cost: 2.3592 - val_loss: 0.1135 - val_auc: 0.9892 - val_accuracy: 0.9703 - val_cost: 3.6276\n",
            "Epoch 180/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0613 - auc: 0.9959 - accuracy: 0.9822 - cost: 2.2843 - val_loss: 0.1104 - val_auc: 0.9895 - val_accuracy: 0.9709 - val_cost: 3.8261\n",
            "Epoch 181/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0622 - auc: 0.9960 - accuracy: 0.9822 - cost: 2.2762 - val_loss: 0.1115 - val_auc: 0.9895 - val_accuracy: 0.9697 - val_cost: 3.7401\n",
            "Epoch 182/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0607 - auc: 0.9960 - accuracy: 0.9825 - cost: 2.2427 - val_loss: 0.1094 - val_auc: 0.9895 - val_accuracy: 0.9712 - val_cost: 3.6210\n",
            "Epoch 183/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0616 - auc: 0.9959 - accuracy: 0.9820 - cost: 2.3005 - val_loss: 0.1101 - val_auc: 0.9895 - val_accuracy: 0.9712 - val_cost: 3.6376\n",
            "Epoch 184/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0610 - auc: 0.9959 - accuracy: 0.9825 - cost: 2.2334 - val_loss: 0.1112 - val_auc: 0.9897 - val_accuracy: 0.9715 - val_cost: 3.6177\n",
            "Epoch 185/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0611 - auc: 0.9959 - accuracy: 0.9822 - cost: 2.2681 - val_loss: 0.1120 - val_auc: 0.9896 - val_accuracy: 0.9714 - val_cost: 3.5317\n",
            "Epoch 186/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0621 - auc: 0.9959 - accuracy: 0.9819 - cost: 2.3160 - val_loss: 0.1099 - val_auc: 0.9896 - val_accuracy: 0.9714 - val_cost: 3.5284\n",
            "Epoch 187/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0614 - auc: 0.9958 - accuracy: 0.9822 - cost: 2.2758 - val_loss: 0.1108 - val_auc: 0.9896 - val_accuracy: 0.9722 - val_cost: 3.5880\n",
            "Epoch 188/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0618 - auc: 0.9958 - accuracy: 0.9822 - cost: 2.2693 - val_loss: 0.1105 - val_auc: 0.9896 - val_accuracy: 0.9713 - val_cost: 3.5847\n",
            "Epoch 189/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0603 - auc: 0.9960 - accuracy: 0.9824 - cost: 2.2461 - val_loss: 0.1098 - val_auc: 0.9897 - val_accuracy: 0.9714 - val_cost: 3.5714\n",
            "Epoch 190/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0606 - auc: 0.9960 - accuracy: 0.9828 - cost: 2.2076 - val_loss: 0.1122 - val_auc: 0.9894 - val_accuracy: 0.9718 - val_cost: 3.5218\n",
            "Epoch 191/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0610 - auc: 0.9960 - accuracy: 0.9819 - cost: 2.3113 - val_loss: 0.1127 - val_auc: 0.9893 - val_accuracy: 0.9714 - val_cost: 3.6177\n",
            "Epoch 192/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0610 - auc: 0.9960 - accuracy: 0.9824 - cost: 2.2608 - val_loss: 0.1104 - val_auc: 0.9897 - val_accuracy: 0.9714 - val_cost: 3.5351\n",
            "Epoch 193/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0609 - auc: 0.9959 - accuracy: 0.9820 - cost: 2.3083 - val_loss: 0.1105 - val_auc: 0.9895 - val_accuracy: 0.9724 - val_cost: 3.4888\n",
            "Epoch 194/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0608 - auc: 0.9960 - accuracy: 0.9823 - cost: 2.2512 - val_loss: 0.1112 - val_auc: 0.9894 - val_accuracy: 0.9722 - val_cost: 3.6210\n",
            "Epoch 195/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0610 - auc: 0.9960 - accuracy: 0.9820 - cost: 2.2982 - val_loss: 0.1123 - val_auc: 0.9896 - val_accuracy: 0.9722 - val_cost: 3.4755\n",
            "Epoch 196/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0615 - auc: 0.9959 - accuracy: 0.9820 - cost: 2.3032 - val_loss: 0.1101 - val_auc: 0.9899 - val_accuracy: 0.9722 - val_cost: 3.5020\n",
            "Epoch 197/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0599 - auc: 0.9961 - accuracy: 0.9827 - cost: 2.2149 - val_loss: 0.1093 - val_auc: 0.9895 - val_accuracy: 0.9716 - val_cost: 3.5351\n",
            "Epoch 198/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0607 - auc: 0.9961 - accuracy: 0.9824 - cost: 2.2531 - val_loss: 0.1107 - val_auc: 0.9896 - val_accuracy: 0.9719 - val_cost: 3.4987\n",
            "Epoch 199/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0600 - auc: 0.9961 - accuracy: 0.9826 - cost: 2.2276 - val_loss: 0.1104 - val_auc: 0.9895 - val_accuracy: 0.9713 - val_cost: 3.6971\n",
            "Epoch 200/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0600 - auc: 0.9960 - accuracy: 0.9825 - cost: 2.2369 - val_loss: 0.1104 - val_auc: 0.9895 - val_accuracy: 0.9722 - val_cost: 3.5847\n",
            "Epoch 201/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0607 - auc: 0.9961 - accuracy: 0.9823 - cost: 2.2654 - val_loss: 0.1141 - val_auc: 0.9893 - val_accuracy: 0.9706 - val_cost: 3.6243\n",
            "Epoch 202/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0604 - auc: 0.9959 - accuracy: 0.9824 - cost: 2.2461 - val_loss: 0.1105 - val_auc: 0.9896 - val_accuracy: 0.9713 - val_cost: 3.6541\n",
            "Epoch 203/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0600 - auc: 0.9960 - accuracy: 0.9826 - cost: 2.2276 - val_loss: 0.1141 - val_auc: 0.9892 - val_accuracy: 0.9711 - val_cost: 3.6739\n",
            "Epoch 204/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0607 - auc: 0.9960 - accuracy: 0.9819 - cost: 2.3156 - val_loss: 0.1122 - val_auc: 0.9898 - val_accuracy: 0.9718 - val_cost: 3.5152\n",
            "Epoch 205/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0600 - auc: 0.9960 - accuracy: 0.9825 - cost: 2.2461 - val_loss: 0.1108 - val_auc: 0.9895 - val_accuracy: 0.9721 - val_cost: 3.5516\n",
            "Epoch 206/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0600 - auc: 0.9962 - accuracy: 0.9821 - cost: 2.2967 - val_loss: 0.1122 - val_auc: 0.9894 - val_accuracy: 0.9707 - val_cost: 3.7930\n",
            "Epoch 207/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0595 - auc: 0.9960 - accuracy: 0.9830 - cost: 2.1821 - val_loss: 0.1150 - val_auc: 0.9892 - val_accuracy: 0.9706 - val_cost: 3.6012\n",
            "Epoch 208/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0600 - auc: 0.9960 - accuracy: 0.9827 - cost: 2.2091 - val_loss: 0.1124 - val_auc: 0.9894 - val_accuracy: 0.9712 - val_cost: 3.7599\n",
            "Epoch 209/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0597 - auc: 0.9960 - accuracy: 0.9826 - cost: 2.2326 - val_loss: 0.1134 - val_auc: 0.9895 - val_accuracy: 0.9712 - val_cost: 3.6078\n",
            "Epoch 210/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0592 - auc: 0.9963 - accuracy: 0.9828 - cost: 2.2049 - val_loss: 0.1140 - val_auc: 0.9895 - val_accuracy: 0.9715 - val_cost: 3.7004\n",
            "Epoch 211/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0597 - auc: 0.9959 - accuracy: 0.9826 - cost: 2.2346 - val_loss: 0.1136 - val_auc: 0.9894 - val_accuracy: 0.9714 - val_cost: 3.5549\n",
            "Epoch 212/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0591 - auc: 0.9961 - accuracy: 0.9830 - cost: 2.1651 - val_loss: 0.1142 - val_auc: 0.9891 - val_accuracy: 0.9712 - val_cost: 3.7235\n",
            "Epoch 213/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0594 - auc: 0.9962 - accuracy: 0.9826 - cost: 2.2292 - val_loss: 0.1130 - val_auc: 0.9894 - val_accuracy: 0.9718 - val_cost: 3.5847\n",
            "Epoch 214/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0606 - auc: 0.9960 - accuracy: 0.9824 - cost: 2.2473 - val_loss: 0.1132 - val_auc: 0.9894 - val_accuracy: 0.9716 - val_cost: 3.5714\n",
            "Epoch 215/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0597 - auc: 0.9961 - accuracy: 0.9829 - cost: 2.1802 - val_loss: 0.1120 - val_auc: 0.9895 - val_accuracy: 0.9717 - val_cost: 3.5681\n",
            "Epoch 216/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0592 - auc: 0.9962 - accuracy: 0.9824 - cost: 2.2519 - val_loss: 0.1157 - val_auc: 0.9894 - val_accuracy: 0.9710 - val_cost: 3.7831\n",
            "Epoch 217/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0594 - auc: 0.9961 - accuracy: 0.9824 - cost: 2.2589 - val_loss: 0.1136 - val_auc: 0.9894 - val_accuracy: 0.9715 - val_cost: 3.5317\n",
            "Epoch 218/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0591 - auc: 0.9961 - accuracy: 0.9829 - cost: 2.1906 - val_loss: 0.1151 - val_auc: 0.9891 - val_accuracy: 0.9716 - val_cost: 3.6706\n",
            "Epoch 219/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0592 - auc: 0.9961 - accuracy: 0.9829 - cost: 2.1744 - val_loss: 0.1121 - val_auc: 0.9896 - val_accuracy: 0.9719 - val_cost: 3.5020\n",
            "Epoch 220/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0583 - auc: 0.9962 - accuracy: 0.9829 - cost: 2.1802 - val_loss: 0.1153 - val_auc: 0.9894 - val_accuracy: 0.9713 - val_cost: 3.6144\n",
            "Epoch 221/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0586 - auc: 0.9962 - accuracy: 0.9828 - cost: 2.2025 - val_loss: 0.1133 - val_auc: 0.9892 - val_accuracy: 0.9703 - val_cost: 3.7897\n",
            "Epoch 222/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0583 - auc: 0.9963 - accuracy: 0.9829 - cost: 2.1879 - val_loss: 0.1147 - val_auc: 0.9894 - val_accuracy: 0.9720 - val_cost: 3.5714\n",
            "Epoch 223/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0582 - auc: 0.9962 - accuracy: 0.9832 - cost: 2.1524 - val_loss: 0.1158 - val_auc: 0.9892 - val_accuracy: 0.9708 - val_cost: 3.5946\n",
            "Epoch 224/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0588 - auc: 0.9962 - accuracy: 0.9831 - cost: 2.1559 - val_loss: 0.1156 - val_auc: 0.9893 - val_accuracy: 0.9708 - val_cost: 3.6111\n",
            "Epoch 225/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0590 - auc: 0.9962 - accuracy: 0.9830 - cost: 2.1840 - val_loss: 0.1142 - val_auc: 0.9896 - val_accuracy: 0.9718 - val_cost: 3.6310\n",
            "Epoch 226/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0591 - auc: 0.9961 - accuracy: 0.9828 - cost: 2.2064 - val_loss: 0.1149 - val_auc: 0.9893 - val_accuracy: 0.9715 - val_cost: 3.5747\n",
            "Epoch 227/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0602 - auc: 0.9961 - accuracy: 0.9825 - cost: 2.2303 - val_loss: 0.1131 - val_auc: 0.9895 - val_accuracy: 0.9710 - val_cost: 3.7269\n",
            "Epoch 228/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0589 - auc: 0.9962 - accuracy: 0.9833 - cost: 2.1439 - val_loss: 0.1155 - val_auc: 0.9893 - val_accuracy: 0.9705 - val_cost: 3.7599\n",
            "Epoch 229/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0593 - auc: 0.9961 - accuracy: 0.9830 - cost: 2.1833 - val_loss: 0.1151 - val_auc: 0.9892 - val_accuracy: 0.9708 - val_cost: 3.7103\n",
            "Epoch 230/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0587 - auc: 0.9963 - accuracy: 0.9828 - cost: 2.2049 - val_loss: 0.1145 - val_auc: 0.9895 - val_accuracy: 0.9713 - val_cost: 3.6012\n",
            "Epoch 231/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0586 - auc: 0.9962 - accuracy: 0.9829 - cost: 2.1941 - val_loss: 0.1134 - val_auc: 0.9893 - val_accuracy: 0.9715 - val_cost: 3.6541\n",
            "Epoch 232/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0582 - auc: 0.9962 - accuracy: 0.9833 - cost: 2.1377 - val_loss: 0.1121 - val_auc: 0.9890 - val_accuracy: 0.9703 - val_cost: 3.7930\n",
            "Epoch 233/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0585 - auc: 0.9962 - accuracy: 0.9830 - cost: 2.1709 - val_loss: 0.1150 - val_auc: 0.9890 - val_accuracy: 0.9705 - val_cost: 3.7731\n",
            "Epoch 234/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0581 - auc: 0.9963 - accuracy: 0.9828 - cost: 2.2002 - val_loss: 0.1131 - val_auc: 0.9894 - val_accuracy: 0.9715 - val_cost: 3.6276\n",
            "Epoch 235/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0586 - auc: 0.9962 - accuracy: 0.9827 - cost: 2.2103 - val_loss: 0.1159 - val_auc: 0.9892 - val_accuracy: 0.9703 - val_cost: 3.6673\n",
            "Epoch 236/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0574 - auc: 0.9964 - accuracy: 0.9829 - cost: 2.1782 - val_loss: 0.1142 - val_auc: 0.9895 - val_accuracy: 0.9710 - val_cost: 3.6508\n",
            "Epoch 237/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0584 - auc: 0.9963 - accuracy: 0.9828 - cost: 2.2137 - val_loss: 0.1146 - val_auc: 0.9895 - val_accuracy: 0.9717 - val_cost: 3.6078\n",
            "Epoch 238/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0575 - auc: 0.9963 - accuracy: 0.9829 - cost: 2.1848 - val_loss: 0.1153 - val_auc: 0.9893 - val_accuracy: 0.9708 - val_cost: 3.6806\n",
            "Epoch 239/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0580 - auc: 0.9963 - accuracy: 0.9835 - cost: 2.1080 - val_loss: 0.1145 - val_auc: 0.9895 - val_accuracy: 0.9707 - val_cost: 3.6673\n",
            "Epoch 240/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0577 - auc: 0.9963 - accuracy: 0.9831 - cost: 2.1698 - val_loss: 0.1156 - val_auc: 0.9894 - val_accuracy: 0.9708 - val_cost: 3.7599\n",
            "Epoch 241/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0579 - auc: 0.9963 - accuracy: 0.9830 - cost: 2.1690 - val_loss: 0.1158 - val_auc: 0.9894 - val_accuracy: 0.9714 - val_cost: 3.5384\n",
            "Epoch 242/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0581 - auc: 0.9962 - accuracy: 0.9832 - cost: 2.1501 - val_loss: 0.1142 - val_auc: 0.9896 - val_accuracy: 0.9713 - val_cost: 3.6442\n",
            "Epoch 243/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0576 - auc: 0.9963 - accuracy: 0.9835 - cost: 2.1080 - val_loss: 0.1165 - val_auc: 0.9895 - val_accuracy: 0.9710 - val_cost: 3.6640\n",
            "Epoch 244/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0579 - auc: 0.9963 - accuracy: 0.9830 - cost: 2.1725 - val_loss: 0.1152 - val_auc: 0.9898 - val_accuracy: 0.9709 - val_cost: 3.6938\n",
            "Epoch 245/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0577 - auc: 0.9962 - accuracy: 0.9833 - cost: 2.1346 - val_loss: 0.1143 - val_auc: 0.9897 - val_accuracy: 0.9709 - val_cost: 3.7401\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0938 - auc: 0.9922 - accuracy: 0.9743 - cost: 3.2750\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:01:55.079632\n",
            "fold accuracy: 0.9742500185966492 - fold cost: 3.2750000953674316\n",
            "x_train shape: (144000, 67)\n",
            "Epoch 1/1000\n",
            "120/120 [==============================] - 2s 5ms/step - loss: 0.5308 - auc: 0.7975 - accuracy: 0.7283 - cost: 36.1543 - val_loss: 0.3956 - val_auc: 0.9004 - val_accuracy: 0.8267 - val_cost: 22.2090\n",
            "Epoch 2/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.3517 - auc: 0.9214 - accuracy: 0.8492 - cost: 19.2052 - val_loss: 0.3157 - val_auc: 0.9366 - val_accuracy: 0.8684 - val_cost: 16.4120\n",
            "Epoch 3/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.3027 - auc: 0.9420 - accuracy: 0.8741 - cost: 15.9352 - val_loss: 0.2841 - val_auc: 0.9489 - val_accuracy: 0.8836 - val_cost: 14.5966\n",
            "Epoch 4/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2736 - auc: 0.9528 - accuracy: 0.8880 - cost: 14.1478 - val_loss: 0.2600 - val_auc: 0.9571 - val_accuracy: 0.8933 - val_cost: 13.4425\n",
            "Epoch 5/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2503 - auc: 0.9605 - accuracy: 0.8998 - cost: 12.6995 - val_loss: 0.2396 - val_auc: 0.9639 - val_accuracy: 0.9062 - val_cost: 11.5542\n",
            "Epoch 6/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.2301 - auc: 0.9666 - accuracy: 0.9096 - cost: 11.4348 - val_loss: 0.2223 - val_auc: 0.9686 - val_accuracy: 0.9144 - val_cost: 10.7044\n",
            "Epoch 7/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2138 - auc: 0.9710 - accuracy: 0.9176 - cost: 10.4113 - val_loss: 0.2091 - val_auc: 0.9726 - val_accuracy: 0.9219 - val_cost: 9.5040\n",
            "Epoch 8/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2008 - auc: 0.9744 - accuracy: 0.9239 - cost: 9.6281 - val_loss: 0.1959 - val_auc: 0.9755 - val_accuracy: 0.9286 - val_cost: 8.8393\n",
            "Epoch 9/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1892 - auc: 0.9771 - accuracy: 0.9284 - cost: 9.0440 - val_loss: 0.1879 - val_auc: 0.9775 - val_accuracy: 0.9312 - val_cost: 8.4325\n",
            "Epoch 10/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1804 - auc: 0.9790 - accuracy: 0.9329 - cost: 8.4653 - val_loss: 0.1811 - val_auc: 0.9788 - val_accuracy: 0.9356 - val_cost: 8.2606\n",
            "Epoch 11/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1723 - auc: 0.9808 - accuracy: 0.9361 - cost: 8.0976 - val_loss: 0.1730 - val_auc: 0.9803 - val_accuracy: 0.9390 - val_cost: 7.6422\n",
            "Epoch 12/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1664 - auc: 0.9819 - accuracy: 0.9397 - cost: 7.6385 - val_loss: 0.1683 - val_auc: 0.9813 - val_accuracy: 0.9412 - val_cost: 7.4603\n",
            "Epoch 13/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1612 - auc: 0.9829 - accuracy: 0.9422 - cost: 7.3468 - val_loss: 0.1636 - val_auc: 0.9821 - val_accuracy: 0.9423 - val_cost: 7.2751\n",
            "Epoch 14/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1561 - auc: 0.9839 - accuracy: 0.9439 - cost: 7.1103 - val_loss: 0.1602 - val_auc: 0.9829 - val_accuracy: 0.9440 - val_cost: 6.9378\n",
            "Epoch 15/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1519 - auc: 0.9847 - accuracy: 0.9458 - cost: 6.8754 - val_loss: 0.1585 - val_auc: 0.9832 - val_accuracy: 0.9444 - val_cost: 6.7890\n",
            "Epoch 16/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1478 - auc: 0.9853 - accuracy: 0.9479 - cost: 6.6169 - val_loss: 0.1540 - val_auc: 0.9839 - val_accuracy: 0.9466 - val_cost: 6.6303\n",
            "Epoch 17/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1450 - auc: 0.9858 - accuracy: 0.9491 - cost: 6.4452 - val_loss: 0.1524 - val_auc: 0.9841 - val_accuracy: 0.9486 - val_cost: 6.3988\n",
            "Epoch 18/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1425 - auc: 0.9862 - accuracy: 0.9506 - cost: 6.2774 - val_loss: 0.1498 - val_auc: 0.9846 - val_accuracy: 0.9494 - val_cost: 6.3823\n",
            "Epoch 19/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1382 - auc: 0.9869 - accuracy: 0.9520 - cost: 6.0856 - val_loss: 0.1466 - val_auc: 0.9851 - val_accuracy: 0.9513 - val_cost: 6.0747\n",
            "Epoch 20/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1365 - auc: 0.9871 - accuracy: 0.9528 - cost: 5.9877 - val_loss: 0.1459 - val_auc: 0.9851 - val_accuracy: 0.9512 - val_cost: 6.2070\n",
            "Epoch 21/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1336 - auc: 0.9877 - accuracy: 0.9545 - cost: 5.7712 - val_loss: 0.1434 - val_auc: 0.9857 - val_accuracy: 0.9522 - val_cost: 6.0880\n",
            "Epoch 22/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1309 - auc: 0.9880 - accuracy: 0.9547 - cost: 5.7620 - val_loss: 0.1424 - val_auc: 0.9859 - val_accuracy: 0.9523 - val_cost: 5.8366\n",
            "Epoch 23/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1287 - auc: 0.9884 - accuracy: 0.9559 - cost: 5.5937 - val_loss: 0.1400 - val_auc: 0.9861 - val_accuracy: 0.9542 - val_cost: 5.6779\n",
            "Epoch 24/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1270 - auc: 0.9886 - accuracy: 0.9568 - cost: 5.5069 - val_loss: 0.1386 - val_auc: 0.9864 - val_accuracy: 0.9548 - val_cost: 5.6911\n",
            "Epoch 25/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1241 - auc: 0.9890 - accuracy: 0.9581 - cost: 5.3302 - val_loss: 0.1382 - val_auc: 0.9864 - val_accuracy: 0.9563 - val_cost: 5.4630\n",
            "Epoch 26/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1228 - auc: 0.9892 - accuracy: 0.9584 - cost: 5.2944 - val_loss: 0.1368 - val_auc: 0.9865 - val_accuracy: 0.9565 - val_cost: 5.5357\n",
            "Epoch 27/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1214 - auc: 0.9893 - accuracy: 0.9594 - cost: 5.1439 - val_loss: 0.1352 - val_auc: 0.9867 - val_accuracy: 0.9567 - val_cost: 5.6019\n",
            "Epoch 28/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1189 - auc: 0.9897 - accuracy: 0.9603 - cost: 5.0409 - val_loss: 0.1351 - val_auc: 0.9867 - val_accuracy: 0.9576 - val_cost: 5.2712\n",
            "Epoch 29/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1178 - auc: 0.9899 - accuracy: 0.9607 - cost: 4.9900 - val_loss: 0.1339 - val_auc: 0.9869 - val_accuracy: 0.9565 - val_cost: 5.3737\n",
            "Epoch 30/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1161 - auc: 0.9900 - accuracy: 0.9615 - cost: 4.8877 - val_loss: 0.1327 - val_auc: 0.9871 - val_accuracy: 0.9583 - val_cost: 5.1819\n",
            "Epoch 31/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1147 - auc: 0.9903 - accuracy: 0.9624 - cost: 4.7782 - val_loss: 0.1323 - val_auc: 0.9871 - val_accuracy: 0.9584 - val_cost: 5.2976\n",
            "Epoch 32/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1135 - auc: 0.9904 - accuracy: 0.9621 - cost: 4.8098 - val_loss: 0.1305 - val_auc: 0.9874 - val_accuracy: 0.9604 - val_cost: 5.0496\n",
            "Epoch 33/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1114 - auc: 0.9907 - accuracy: 0.9632 - cost: 4.6782 - val_loss: 0.1300 - val_auc: 0.9875 - val_accuracy: 0.9589 - val_cost: 5.0562\n",
            "Epoch 34/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.1103 - auc: 0.9908 - accuracy: 0.9635 - cost: 4.6323 - val_loss: 0.1290 - val_auc: 0.9875 - val_accuracy: 0.9603 - val_cost: 4.9008\n",
            "Epoch 35/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.1098 - auc: 0.9910 - accuracy: 0.9639 - cost: 4.5787 - val_loss: 0.1273 - val_auc: 0.9876 - val_accuracy: 0.9608 - val_cost: 4.9008\n",
            "Epoch 36/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1075 - auc: 0.9912 - accuracy: 0.9644 - cost: 4.5390 - val_loss: 0.1276 - val_auc: 0.9878 - val_accuracy: 0.9612 - val_cost: 4.9140\n",
            "Epoch 37/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1076 - auc: 0.9912 - accuracy: 0.9648 - cost: 4.4695 - val_loss: 0.1266 - val_auc: 0.9879 - val_accuracy: 0.9615 - val_cost: 4.9173\n",
            "Epoch 38/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1061 - auc: 0.9913 - accuracy: 0.9650 - cost: 4.4394 - val_loss: 0.1246 - val_auc: 0.9881 - val_accuracy: 0.9608 - val_cost: 4.9934\n",
            "Epoch 39/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1050 - auc: 0.9915 - accuracy: 0.9657 - cost: 4.3557 - val_loss: 0.1253 - val_auc: 0.9879 - val_accuracy: 0.9619 - val_cost: 4.8677\n",
            "Epoch 40/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1031 - auc: 0.9917 - accuracy: 0.9668 - cost: 4.2218 - val_loss: 0.1234 - val_auc: 0.9884 - val_accuracy: 0.9622 - val_cost: 4.6726\n",
            "Epoch 41/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.1031 - auc: 0.9917 - accuracy: 0.9665 - cost: 4.2728 - val_loss: 0.1238 - val_auc: 0.9881 - val_accuracy: 0.9624 - val_cost: 4.6792\n",
            "Epoch 42/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.1020 - auc: 0.9918 - accuracy: 0.9670 - cost: 4.2010 - val_loss: 0.1219 - val_auc: 0.9886 - val_accuracy: 0.9630 - val_cost: 4.6131\n",
            "Epoch 43/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1013 - auc: 0.9919 - accuracy: 0.9673 - cost: 4.1528 - val_loss: 0.1225 - val_auc: 0.9884 - val_accuracy: 0.9631 - val_cost: 4.6825\n",
            "Epoch 44/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0999 - auc: 0.9921 - accuracy: 0.9679 - cost: 4.0891 - val_loss: 0.1215 - val_auc: 0.9886 - val_accuracy: 0.9631 - val_cost: 4.5701\n",
            "Epoch 45/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0991 - auc: 0.9922 - accuracy: 0.9679 - cost: 4.0810 - val_loss: 0.1210 - val_auc: 0.9886 - val_accuracy: 0.9649 - val_cost: 4.2758\n",
            "Epoch 46/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0981 - auc: 0.9922 - accuracy: 0.9684 - cost: 4.0162 - val_loss: 0.1196 - val_auc: 0.9887 - val_accuracy: 0.9642 - val_cost: 4.4940\n",
            "Epoch 47/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0964 - auc: 0.9925 - accuracy: 0.9687 - cost: 3.9865 - val_loss: 0.1193 - val_auc: 0.9888 - val_accuracy: 0.9642 - val_cost: 4.5337\n",
            "Epoch 48/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0964 - auc: 0.9925 - accuracy: 0.9690 - cost: 3.9433 - val_loss: 0.1191 - val_auc: 0.9887 - val_accuracy: 0.9642 - val_cost: 4.5767\n",
            "Epoch 49/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0957 - auc: 0.9925 - accuracy: 0.9693 - cost: 3.8985 - val_loss: 0.1200 - val_auc: 0.9886 - val_accuracy: 0.9638 - val_cost: 4.4180\n",
            "Epoch 50/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0953 - auc: 0.9926 - accuracy: 0.9695 - cost: 3.8835 - val_loss: 0.1164 - val_auc: 0.9890 - val_accuracy: 0.9655 - val_cost: 4.3155\n",
            "Epoch 51/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0941 - auc: 0.9927 - accuracy: 0.9703 - cost: 3.7855 - val_loss: 0.1166 - val_auc: 0.9892 - val_accuracy: 0.9664 - val_cost: 4.2163\n",
            "Epoch 52/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0932 - auc: 0.9928 - accuracy: 0.9706 - cost: 3.7373 - val_loss: 0.1174 - val_auc: 0.9892 - val_accuracy: 0.9647 - val_cost: 4.3684\n",
            "Epoch 53/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0926 - auc: 0.9929 - accuracy: 0.9706 - cost: 3.7431 - val_loss: 0.1160 - val_auc: 0.9890 - val_accuracy: 0.9660 - val_cost: 4.3585\n",
            "Epoch 54/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0914 - auc: 0.9929 - accuracy: 0.9711 - cost: 3.6755 - val_loss: 0.1158 - val_auc: 0.9892 - val_accuracy: 0.9660 - val_cost: 4.1766\n",
            "Epoch 55/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0919 - auc: 0.9929 - accuracy: 0.9710 - cost: 3.6840 - val_loss: 0.1174 - val_auc: 0.9892 - val_accuracy: 0.9653 - val_cost: 4.2229\n",
            "Epoch 56/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0907 - auc: 0.9931 - accuracy: 0.9716 - cost: 3.6123 - val_loss: 0.1142 - val_auc: 0.9894 - val_accuracy: 0.9660 - val_cost: 4.2262\n",
            "Epoch 57/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0903 - auc: 0.9931 - accuracy: 0.9713 - cost: 3.6520 - val_loss: 0.1140 - val_auc: 0.9895 - val_accuracy: 0.9669 - val_cost: 4.1601\n",
            "Epoch 58/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0892 - auc: 0.9932 - accuracy: 0.9721 - cost: 3.5324 - val_loss: 0.1145 - val_auc: 0.9893 - val_accuracy: 0.9664 - val_cost: 4.3585\n",
            "Epoch 59/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0899 - auc: 0.9931 - accuracy: 0.9717 - cost: 3.6042 - val_loss: 0.1138 - val_auc: 0.9895 - val_accuracy: 0.9675 - val_cost: 4.0013\n",
            "Epoch 60/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0886 - auc: 0.9932 - accuracy: 0.9720 - cost: 3.5583 - val_loss: 0.1140 - val_auc: 0.9892 - val_accuracy: 0.9658 - val_cost: 4.3022\n",
            "Epoch 61/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0878 - auc: 0.9934 - accuracy: 0.9726 - cost: 3.4950 - val_loss: 0.1139 - val_auc: 0.9894 - val_accuracy: 0.9665 - val_cost: 4.0906\n",
            "Epoch 62/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0885 - auc: 0.9933 - accuracy: 0.9725 - cost: 3.4969 - val_loss: 0.1148 - val_auc: 0.9894 - val_accuracy: 0.9670 - val_cost: 4.0179\n",
            "Epoch 63/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0871 - auc: 0.9934 - accuracy: 0.9729 - cost: 3.4537 - val_loss: 0.1121 - val_auc: 0.9897 - val_accuracy: 0.9673 - val_cost: 4.2626\n",
            "Epoch 64/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0872 - auc: 0.9935 - accuracy: 0.9731 - cost: 3.4263 - val_loss: 0.1119 - val_auc: 0.9895 - val_accuracy: 0.9679 - val_cost: 3.9418\n",
            "Epoch 65/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0866 - auc: 0.9934 - accuracy: 0.9732 - cost: 3.4205 - val_loss: 0.1105 - val_auc: 0.9896 - val_accuracy: 0.9684 - val_cost: 3.9550\n",
            "Epoch 66/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0856 - auc: 0.9935 - accuracy: 0.9733 - cost: 3.3951 - val_loss: 0.1124 - val_auc: 0.9894 - val_accuracy: 0.9671 - val_cost: 4.0311\n",
            "Epoch 67/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0844 - auc: 0.9938 - accuracy: 0.9737 - cost: 3.3511 - val_loss: 0.1119 - val_auc: 0.9894 - val_accuracy: 0.9681 - val_cost: 4.0145\n",
            "Epoch 68/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0848 - auc: 0.9936 - accuracy: 0.9738 - cost: 3.3225 - val_loss: 0.1124 - val_auc: 0.9895 - val_accuracy: 0.9681 - val_cost: 4.0212\n",
            "Epoch 69/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0838 - auc: 0.9938 - accuracy: 0.9741 - cost: 3.2982 - val_loss: 0.1104 - val_auc: 0.9896 - val_accuracy: 0.9695 - val_cost: 3.8161\n",
            "Epoch 70/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0838 - auc: 0.9938 - accuracy: 0.9743 - cost: 3.2751 - val_loss: 0.1116 - val_auc: 0.9894 - val_accuracy: 0.9691 - val_cost: 3.8988\n",
            "Epoch 71/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0828 - auc: 0.9939 - accuracy: 0.9743 - cost: 3.2674 - val_loss: 0.1117 - val_auc: 0.9896 - val_accuracy: 0.9688 - val_cost: 3.8228\n",
            "Epoch 72/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0829 - auc: 0.9939 - accuracy: 0.9741 - cost: 3.2948 - val_loss: 0.1114 - val_auc: 0.9895 - val_accuracy: 0.9681 - val_cost: 3.9649\n",
            "Epoch 73/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0823 - auc: 0.9940 - accuracy: 0.9748 - cost: 3.2076 - val_loss: 0.1125 - val_auc: 0.9894 - val_accuracy: 0.9673 - val_cost: 4.0939\n",
            "Epoch 74/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0822 - auc: 0.9939 - accuracy: 0.9748 - cost: 3.2068 - val_loss: 0.1107 - val_auc: 0.9896 - val_accuracy: 0.9687 - val_cost: 3.9087\n",
            "Epoch 75/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0817 - auc: 0.9941 - accuracy: 0.9747 - cost: 3.2253 - val_loss: 0.1117 - val_auc: 0.9895 - val_accuracy: 0.9682 - val_cost: 3.9352\n",
            "Epoch 76/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0821 - auc: 0.9940 - accuracy: 0.9747 - cost: 3.2149 - val_loss: 0.1119 - val_auc: 0.9894 - val_accuracy: 0.9690 - val_cost: 3.8823\n",
            "Epoch 77/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0810 - auc: 0.9941 - accuracy: 0.9747 - cost: 3.2249 - val_loss: 0.1130 - val_auc: 0.9897 - val_accuracy: 0.9691 - val_cost: 3.7996\n",
            "Epoch 78/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0800 - auc: 0.9942 - accuracy: 0.9755 - cost: 3.1254 - val_loss: 0.1116 - val_auc: 0.9897 - val_accuracy: 0.9689 - val_cost: 3.9484\n",
            "Epoch 79/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0800 - auc: 0.9941 - accuracy: 0.9757 - cost: 3.1007 - val_loss: 0.1096 - val_auc: 0.9899 - val_accuracy: 0.9687 - val_cost: 3.8955\n",
            "Epoch 80/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0798 - auc: 0.9942 - accuracy: 0.9759 - cost: 3.0721 - val_loss: 0.1120 - val_auc: 0.9897 - val_accuracy: 0.9680 - val_cost: 4.0013\n",
            "Epoch 81/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0795 - auc: 0.9943 - accuracy: 0.9752 - cost: 3.1566 - val_loss: 0.1103 - val_auc: 0.9897 - val_accuracy: 0.9688 - val_cost: 3.8657\n",
            "Epoch 82/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0789 - auc: 0.9944 - accuracy: 0.9757 - cost: 3.0887 - val_loss: 0.1117 - val_auc: 0.9897 - val_accuracy: 0.9680 - val_cost: 3.9484\n",
            "Epoch 83/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0797 - auc: 0.9942 - accuracy: 0.9755 - cost: 3.1142 - val_loss: 0.1099 - val_auc: 0.9898 - val_accuracy: 0.9688 - val_cost: 3.9583\n",
            "Epoch 84/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0790 - auc: 0.9943 - accuracy: 0.9757 - cost: 3.0999 - val_loss: 0.1106 - val_auc: 0.9897 - val_accuracy: 0.9690 - val_cost: 3.8393\n",
            "Epoch 85/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0785 - auc: 0.9943 - accuracy: 0.9759 - cost: 3.0849 - val_loss: 0.1087 - val_auc: 0.9899 - val_accuracy: 0.9690 - val_cost: 4.0377\n",
            "Epoch 86/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0780 - auc: 0.9943 - accuracy: 0.9759 - cost: 3.0814 - val_loss: 0.1093 - val_auc: 0.9900 - val_accuracy: 0.9693 - val_cost: 3.8261\n",
            "Epoch 87/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0774 - auc: 0.9944 - accuracy: 0.9763 - cost: 3.0405 - val_loss: 0.1098 - val_auc: 0.9896 - val_accuracy: 0.9694 - val_cost: 3.7930\n",
            "Epoch 88/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0770 - auc: 0.9944 - accuracy: 0.9765 - cost: 2.9988 - val_loss: 0.1108 - val_auc: 0.9897 - val_accuracy: 0.9697 - val_cost: 3.7665\n",
            "Epoch 89/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0768 - auc: 0.9945 - accuracy: 0.9770 - cost: 2.9298 - val_loss: 0.1101 - val_auc: 0.9897 - val_accuracy: 0.9699 - val_cost: 3.7731\n",
            "Epoch 90/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0760 - auc: 0.9945 - accuracy: 0.9767 - cost: 2.9668 - val_loss: 0.1103 - val_auc: 0.9897 - val_accuracy: 0.9691 - val_cost: 3.9484\n",
            "Epoch 91/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0759 - auc: 0.9947 - accuracy: 0.9763 - cost: 3.0154 - val_loss: 0.1090 - val_auc: 0.9900 - val_accuracy: 0.9689 - val_cost: 3.9319\n",
            "Epoch 92/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0764 - auc: 0.9945 - accuracy: 0.9763 - cost: 3.0239 - val_loss: 0.1119 - val_auc: 0.9894 - val_accuracy: 0.9694 - val_cost: 3.7136\n",
            "Epoch 93/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0757 - auc: 0.9946 - accuracy: 0.9765 - cost: 2.9981 - val_loss: 0.1109 - val_auc: 0.9899 - val_accuracy: 0.9705 - val_cost: 3.6872\n",
            "Epoch 94/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0755 - auc: 0.9946 - accuracy: 0.9770 - cost: 2.9329 - val_loss: 0.1100 - val_auc: 0.9900 - val_accuracy: 0.9705 - val_cost: 3.6772\n",
            "Epoch 95/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0751 - auc: 0.9946 - accuracy: 0.9775 - cost: 2.8819 - val_loss: 0.1094 - val_auc: 0.9897 - val_accuracy: 0.9700 - val_cost: 3.6872\n",
            "Epoch 96/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0754 - auc: 0.9946 - accuracy: 0.9769 - cost: 2.9460 - val_loss: 0.1073 - val_auc: 0.9900 - val_accuracy: 0.9709 - val_cost: 3.6971\n",
            "Epoch 97/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0747 - auc: 0.9946 - accuracy: 0.9777 - cost: 2.8588 - val_loss: 0.1114 - val_auc: 0.9898 - val_accuracy: 0.9694 - val_cost: 3.7235\n",
            "Epoch 98/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0751 - auc: 0.9946 - accuracy: 0.9774 - cost: 2.8769 - val_loss: 0.1101 - val_auc: 0.9897 - val_accuracy: 0.9697 - val_cost: 3.7765\n",
            "Epoch 99/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0745 - auc: 0.9946 - accuracy: 0.9776 - cost: 2.8580 - val_loss: 0.1105 - val_auc: 0.9899 - val_accuracy: 0.9699 - val_cost: 3.8492\n",
            "Epoch 100/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0740 - auc: 0.9948 - accuracy: 0.9772 - cost: 2.9086 - val_loss: 0.1109 - val_auc: 0.9899 - val_accuracy: 0.9697 - val_cost: 3.7698\n",
            "Epoch 101/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0736 - auc: 0.9947 - accuracy: 0.9777 - cost: 2.8461 - val_loss: 0.1098 - val_auc: 0.9900 - val_accuracy: 0.9688 - val_cost: 3.9484\n",
            "Epoch 102/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0737 - auc: 0.9949 - accuracy: 0.9774 - cost: 2.8931 - val_loss: 0.1103 - val_auc: 0.9898 - val_accuracy: 0.9701 - val_cost: 3.8591\n",
            "Epoch 103/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0740 - auc: 0.9947 - accuracy: 0.9776 - cost: 2.8650 - val_loss: 0.1111 - val_auc: 0.9899 - val_accuracy: 0.9703 - val_cost: 3.6376\n",
            "Epoch 104/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0735 - auc: 0.9949 - accuracy: 0.9775 - cost: 2.8796 - val_loss: 0.1114 - val_auc: 0.9901 - val_accuracy: 0.9709 - val_cost: 3.5317\n",
            "Epoch 105/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0729 - auc: 0.9948 - accuracy: 0.9782 - cost: 2.7782 - val_loss: 0.1113 - val_auc: 0.9897 - val_accuracy: 0.9710 - val_cost: 3.5185\n",
            "Epoch 106/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0726 - auc: 0.9949 - accuracy: 0.9783 - cost: 2.7755 - val_loss: 0.1111 - val_auc: 0.9899 - val_accuracy: 0.9712 - val_cost: 3.6276\n",
            "Epoch 107/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0735 - auc: 0.9948 - accuracy: 0.9778 - cost: 2.8245 - val_loss: 0.1122 - val_auc: 0.9897 - val_accuracy: 0.9700 - val_cost: 3.8228\n",
            "Epoch 108/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0723 - auc: 0.9949 - accuracy: 0.9782 - cost: 2.7828 - val_loss: 0.1109 - val_auc: 0.9899 - val_accuracy: 0.9702 - val_cost: 3.7368\n",
            "Epoch 109/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0714 - auc: 0.9950 - accuracy: 0.9784 - cost: 2.7608 - val_loss: 0.1102 - val_auc: 0.9900 - val_accuracy: 0.9706 - val_cost: 3.6144\n",
            "Epoch 110/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0720 - auc: 0.9950 - accuracy: 0.9782 - cost: 2.7840 - val_loss: 0.1101 - val_auc: 0.9901 - val_accuracy: 0.9706 - val_cost: 3.6772\n",
            "Epoch 111/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0727 - auc: 0.9949 - accuracy: 0.9779 - cost: 2.8256 - val_loss: 0.1117 - val_auc: 0.9897 - val_accuracy: 0.9710 - val_cost: 3.5714\n",
            "Epoch 112/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0717 - auc: 0.9950 - accuracy: 0.9785 - cost: 2.7276 - val_loss: 0.1107 - val_auc: 0.9899 - val_accuracy: 0.9709 - val_cost: 3.7004\n",
            "Epoch 113/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0712 - auc: 0.9951 - accuracy: 0.9787 - cost: 2.7222 - val_loss: 0.1125 - val_auc: 0.9898 - val_accuracy: 0.9701 - val_cost: 3.6343\n",
            "Epoch 114/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0714 - auc: 0.9949 - accuracy: 0.9786 - cost: 2.7338 - val_loss: 0.1104 - val_auc: 0.9899 - val_accuracy: 0.9708 - val_cost: 3.6243\n",
            "Epoch 115/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0711 - auc: 0.9951 - accuracy: 0.9785 - cost: 2.7465 - val_loss: 0.1104 - val_auc: 0.9898 - val_accuracy: 0.9710 - val_cost: 3.6177\n",
            "Epoch 116/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0713 - auc: 0.9950 - accuracy: 0.9785 - cost: 2.7461 - val_loss: 0.1110 - val_auc: 0.9897 - val_accuracy: 0.9704 - val_cost: 3.7269\n",
            "Epoch 117/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0702 - auc: 0.9951 - accuracy: 0.9794 - cost: 2.6304 - val_loss: 0.1126 - val_auc: 0.9897 - val_accuracy: 0.9713 - val_cost: 3.4491\n",
            "Epoch 118/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0707 - auc: 0.9950 - accuracy: 0.9792 - cost: 2.6539 - val_loss: 0.1109 - val_auc: 0.9898 - val_accuracy: 0.9703 - val_cost: 3.6343\n",
            "Epoch 119/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0702 - auc: 0.9951 - accuracy: 0.9785 - cost: 2.7431 - val_loss: 0.1100 - val_auc: 0.9899 - val_accuracy: 0.9712 - val_cost: 3.6409\n",
            "Epoch 120/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0705 - auc: 0.9951 - accuracy: 0.9791 - cost: 2.6705 - val_loss: 0.1113 - val_auc: 0.9900 - val_accuracy: 0.9701 - val_cost: 3.6640\n",
            "Epoch 121/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0703 - auc: 0.9951 - accuracy: 0.9789 - cost: 2.6902 - val_loss: 0.1103 - val_auc: 0.9899 - val_accuracy: 0.9707 - val_cost: 3.6276\n",
            "Epoch 122/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0700 - auc: 0.9951 - accuracy: 0.9789 - cost: 2.6941 - val_loss: 0.1114 - val_auc: 0.9897 - val_accuracy: 0.9700 - val_cost: 3.7202\n",
            "Epoch 123/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0703 - auc: 0.9952 - accuracy: 0.9789 - cost: 2.7018 - val_loss: 0.1114 - val_auc: 0.9896 - val_accuracy: 0.9699 - val_cost: 3.7235\n",
            "Epoch 124/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0703 - auc: 0.9950 - accuracy: 0.9788 - cost: 2.7018 - val_loss: 0.1112 - val_auc: 0.9896 - val_accuracy: 0.9704 - val_cost: 3.6376\n",
            "Epoch 125/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0693 - auc: 0.9951 - accuracy: 0.9796 - cost: 2.6046 - val_loss: 0.1114 - val_auc: 0.9901 - val_accuracy: 0.9705 - val_cost: 3.6376\n",
            "Epoch 126/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0696 - auc: 0.9951 - accuracy: 0.9793 - cost: 2.6400 - val_loss: 0.1123 - val_auc: 0.9898 - val_accuracy: 0.9697 - val_cost: 3.6673\n",
            "Epoch 127/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0701 - auc: 0.9952 - accuracy: 0.9788 - cost: 2.7145 - val_loss: 0.1127 - val_auc: 0.9900 - val_accuracy: 0.9697 - val_cost: 3.8690\n",
            "Epoch 128/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0701 - auc: 0.9950 - accuracy: 0.9791 - cost: 2.6717 - val_loss: 0.1095 - val_auc: 0.9899 - val_accuracy: 0.9710 - val_cost: 3.5747\n",
            "Epoch 129/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0692 - auc: 0.9952 - accuracy: 0.9792 - cost: 2.6644 - val_loss: 0.1097 - val_auc: 0.9900 - val_accuracy: 0.9711 - val_cost: 3.5714\n",
            "Epoch 130/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0697 - auc: 0.9952 - accuracy: 0.9788 - cost: 2.7133 - val_loss: 0.1126 - val_auc: 0.9901 - val_accuracy: 0.9705 - val_cost: 3.6144\n",
            "Epoch 131/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0694 - auc: 0.9952 - accuracy: 0.9790 - cost: 2.6794 - val_loss: 0.1110 - val_auc: 0.9898 - val_accuracy: 0.9710 - val_cost: 3.6276\n",
            "Epoch 132/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0679 - auc: 0.9954 - accuracy: 0.9795 - cost: 2.6200 - val_loss: 0.1120 - val_auc: 0.9900 - val_accuracy: 0.9703 - val_cost: 3.7930\n",
            "Epoch 133/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0677 - auc: 0.9954 - accuracy: 0.9798 - cost: 2.5837 - val_loss: 0.1110 - val_auc: 0.9898 - val_accuracy: 0.9711 - val_cost: 3.5880\n",
            "Epoch 134/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0683 - auc: 0.9953 - accuracy: 0.9795 - cost: 2.6181 - val_loss: 0.1092 - val_auc: 0.9900 - val_accuracy: 0.9714 - val_cost: 3.5979\n",
            "Epoch 135/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0690 - auc: 0.9953 - accuracy: 0.9793 - cost: 2.6489 - val_loss: 0.1119 - val_auc: 0.9901 - val_accuracy: 0.9711 - val_cost: 3.5251\n",
            "Epoch 136/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0682 - auc: 0.9954 - accuracy: 0.9795 - cost: 2.6146 - val_loss: 0.1118 - val_auc: 0.9900 - val_accuracy: 0.9706 - val_cost: 3.5913\n",
            "Epoch 137/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0672 - auc: 0.9954 - accuracy: 0.9801 - cost: 2.5540 - val_loss: 0.1119 - val_auc: 0.9899 - val_accuracy: 0.9703 - val_cost: 3.6310\n",
            "Epoch 138/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0677 - auc: 0.9953 - accuracy: 0.9798 - cost: 2.5787 - val_loss: 0.1118 - val_auc: 0.9900 - val_accuracy: 0.9705 - val_cost: 3.7335\n",
            "Epoch 139/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0674 - auc: 0.9955 - accuracy: 0.9797 - cost: 2.6049 - val_loss: 0.1117 - val_auc: 0.9898 - val_accuracy: 0.9703 - val_cost: 3.6376\n",
            "Epoch 140/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0667 - auc: 0.9955 - accuracy: 0.9802 - cost: 2.5301 - val_loss: 0.1131 - val_auc: 0.9897 - val_accuracy: 0.9706 - val_cost: 3.6442\n",
            "Epoch 141/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0666 - auc: 0.9956 - accuracy: 0.9800 - cost: 2.5540 - val_loss: 0.1131 - val_auc: 0.9896 - val_accuracy: 0.9707 - val_cost: 3.5813\n",
            "Epoch 142/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0668 - auc: 0.9955 - accuracy: 0.9802 - cost: 2.5231 - val_loss: 0.1133 - val_auc: 0.9896 - val_accuracy: 0.9708 - val_cost: 3.6508\n",
            "Epoch 143/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0673 - auc: 0.9954 - accuracy: 0.9800 - cost: 2.5563 - val_loss: 0.1144 - val_auc: 0.9897 - val_accuracy: 0.9717 - val_cost: 3.5317\n",
            "Epoch 144/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0668 - auc: 0.9955 - accuracy: 0.9801 - cost: 2.5409 - val_loss: 0.1130 - val_auc: 0.9896 - val_accuracy: 0.9705 - val_cost: 3.6276\n",
            "Epoch 145/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0670 - auc: 0.9954 - accuracy: 0.9800 - cost: 2.5532 - val_loss: 0.1132 - val_auc: 0.9899 - val_accuracy: 0.9706 - val_cost: 3.7037\n",
            "Epoch 146/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0664 - auc: 0.9955 - accuracy: 0.9803 - cost: 2.5104 - val_loss: 0.1115 - val_auc: 0.9899 - val_accuracy: 0.9716 - val_cost: 3.5351\n",
            "Epoch 147/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0662 - auc: 0.9956 - accuracy: 0.9803 - cost: 2.5081 - val_loss: 0.1132 - val_auc: 0.9896 - val_accuracy: 0.9703 - val_cost: 3.7136\n",
            "Epoch 148/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0666 - auc: 0.9955 - accuracy: 0.9804 - cost: 2.5189 - val_loss: 0.1145 - val_auc: 0.9896 - val_accuracy: 0.9710 - val_cost: 3.5218\n",
            "Epoch 149/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0662 - auc: 0.9955 - accuracy: 0.9804 - cost: 2.5093 - val_loss: 0.1125 - val_auc: 0.9899 - val_accuracy: 0.9715 - val_cost: 3.5417\n",
            "Epoch 150/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0668 - auc: 0.9956 - accuracy: 0.9796 - cost: 2.6184 - val_loss: 0.1152 - val_auc: 0.9893 - val_accuracy: 0.9705 - val_cost: 3.6012\n",
            "Epoch 151/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0653 - auc: 0.9956 - accuracy: 0.9806 - cost: 2.4834 - val_loss: 0.1137 - val_auc: 0.9899 - val_accuracy: 0.9708 - val_cost: 3.5582\n",
            "Epoch 152/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0665 - auc: 0.9956 - accuracy: 0.9799 - cost: 2.5610 - val_loss: 0.1133 - val_auc: 0.9895 - val_accuracy: 0.9706 - val_cost: 3.6210\n",
            "Epoch 153/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0653 - auc: 0.9957 - accuracy: 0.9811 - cost: 2.4213 - val_loss: 0.1135 - val_auc: 0.9896 - val_accuracy: 0.9715 - val_cost: 3.5284\n",
            "Epoch 154/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0654 - auc: 0.9956 - accuracy: 0.9807 - cost: 2.4583 - val_loss: 0.1131 - val_auc: 0.9898 - val_accuracy: 0.9716 - val_cost: 3.5384\n",
            "Epoch 155/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0654 - auc: 0.9956 - accuracy: 0.9807 - cost: 2.4695 - val_loss: 0.1142 - val_auc: 0.9899 - val_accuracy: 0.9710 - val_cost: 3.5946\n",
            "Epoch 156/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0654 - auc: 0.9955 - accuracy: 0.9805 - cost: 2.4857 - val_loss: 0.1177 - val_auc: 0.9893 - val_accuracy: 0.9702 - val_cost: 3.6607\n",
            "Epoch 157/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0656 - auc: 0.9956 - accuracy: 0.9805 - cost: 2.4973 - val_loss: 0.1157 - val_auc: 0.9892 - val_accuracy: 0.9702 - val_cost: 3.6475\n",
            "Epoch 158/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0650 - auc: 0.9956 - accuracy: 0.9809 - cost: 2.4414 - val_loss: 0.1146 - val_auc: 0.9895 - val_accuracy: 0.9713 - val_cost: 3.5516\n",
            "Epoch 159/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0654 - auc: 0.9956 - accuracy: 0.9808 - cost: 2.4576 - val_loss: 0.1168 - val_auc: 0.9892 - val_accuracy: 0.9701 - val_cost: 3.7401\n",
            "Epoch 160/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0652 - auc: 0.9957 - accuracy: 0.9804 - cost: 2.5004 - val_loss: 0.1152 - val_auc: 0.9892 - val_accuracy: 0.9709 - val_cost: 3.6905\n",
            "Epoch 161/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0645 - auc: 0.9957 - accuracy: 0.9808 - cost: 2.4633 - val_loss: 0.1132 - val_auc: 0.9893 - val_accuracy: 0.9709 - val_cost: 3.6078\n",
            "Epoch 162/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0648 - auc: 0.9957 - accuracy: 0.9807 - cost: 2.4653 - val_loss: 0.1153 - val_auc: 0.9895 - val_accuracy: 0.9706 - val_cost: 3.7632\n",
            "Epoch 163/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0648 - auc: 0.9957 - accuracy: 0.9808 - cost: 2.4560 - val_loss: 0.1184 - val_auc: 0.9895 - val_accuracy: 0.9701 - val_cost: 3.6872\n",
            "Epoch 164/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0651 - auc: 0.9956 - accuracy: 0.9809 - cost: 2.4525 - val_loss: 0.1153 - val_auc: 0.9894 - val_accuracy: 0.9715 - val_cost: 3.5714\n",
            "Epoch 165/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0651 - auc: 0.9956 - accuracy: 0.9805 - cost: 2.4807 - val_loss: 0.1143 - val_auc: 0.9896 - val_accuracy: 0.9714 - val_cost: 3.6310\n",
            "Epoch 166/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0647 - auc: 0.9956 - accuracy: 0.9812 - cost: 2.4020 - val_loss: 0.1146 - val_auc: 0.9894 - val_accuracy: 0.9712 - val_cost: 3.5185\n",
            "Epoch 167/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0645 - auc: 0.9958 - accuracy: 0.9811 - cost: 2.4151 - val_loss: 0.1159 - val_auc: 0.9893 - val_accuracy: 0.9712 - val_cost: 3.5946\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0999 - auc: 0.9909 - accuracy: 0.9708 - cost: 3.6500\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:01:25.251856\n",
            "fold accuracy: 0.9708124995231628 - fold cost: 3.6500000953674316\n",
            "x_train shape: (144000, 67)\n",
            "Epoch 1/1000\n",
            "120/120 [==============================] - 2s 5ms/step - loss: 0.5332 - auc: 0.7947 - accuracy: 0.7271 - cost: 36.4279 - val_loss: 0.4019 - val_auc: 0.8971 - val_accuracy: 0.8231 - val_cost: 22.8373\n",
            "Epoch 2/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.3547 - auc: 0.9200 - accuracy: 0.8476 - cost: 19.4402 - val_loss: 0.3194 - val_auc: 0.9350 - val_accuracy: 0.8638 - val_cost: 17.2950\n",
            "Epoch 3/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.3044 - auc: 0.9413 - accuracy: 0.8734 - cost: 16.0525 - val_loss: 0.2890 - val_auc: 0.9472 - val_accuracy: 0.8808 - val_cost: 14.7156\n",
            "Epoch 4/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.2759 - auc: 0.9519 - accuracy: 0.8872 - cost: 14.3056 - val_loss: 0.2641 - val_auc: 0.9557 - val_accuracy: 0.8903 - val_cost: 13.8459\n",
            "Epoch 5/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.2527 - auc: 0.9597 - accuracy: 0.8990 - cost: 12.7832 - val_loss: 0.2442 - val_auc: 0.9625 - val_accuracy: 0.9034 - val_cost: 12.0800\n",
            "Epoch 6/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.2328 - auc: 0.9658 - accuracy: 0.9090 - cost: 11.4954 - val_loss: 0.2261 - val_auc: 0.9678 - val_accuracy: 0.9131 - val_cost: 10.9491\n",
            "Epoch 7/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.2177 - auc: 0.9701 - accuracy: 0.9152 - cost: 10.7257 - val_loss: 0.2126 - val_auc: 0.9715 - val_accuracy: 0.9197 - val_cost: 10.1190\n",
            "Epoch 8/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.2044 - auc: 0.9735 - accuracy: 0.9219 - cost: 9.8750 - val_loss: 0.2013 - val_auc: 0.9743 - val_accuracy: 0.9242 - val_cost: 9.4411\n",
            "Epoch 9/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1931 - auc: 0.9761 - accuracy: 0.9270 - cost: 9.2311 - val_loss: 0.1917 - val_auc: 0.9766 - val_accuracy: 0.9289 - val_cost: 8.9616\n",
            "Epoch 10/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1834 - auc: 0.9783 - accuracy: 0.9312 - cost: 8.7122 - val_loss: 0.1848 - val_auc: 0.9780 - val_accuracy: 0.9324 - val_cost: 8.6243\n",
            "Epoch 11/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1765 - auc: 0.9798 - accuracy: 0.9351 - cost: 8.2326 - val_loss: 0.1777 - val_auc: 0.9798 - val_accuracy: 0.9358 - val_cost: 7.9563\n",
            "Epoch 12/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1695 - auc: 0.9814 - accuracy: 0.9380 - cost: 7.8542 - val_loss: 0.1729 - val_auc: 0.9805 - val_accuracy: 0.9388 - val_cost: 7.6488\n",
            "Epoch 13/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1641 - auc: 0.9824 - accuracy: 0.9400 - cost: 7.6165 - val_loss: 0.1683 - val_auc: 0.9815 - val_accuracy: 0.9418 - val_cost: 7.3876\n",
            "Epoch 14/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1585 - auc: 0.9834 - accuracy: 0.9432 - cost: 7.2199 - val_loss: 0.1634 - val_auc: 0.9825 - val_accuracy: 0.9423 - val_cost: 7.2685\n",
            "Epoch 15/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1544 - auc: 0.9841 - accuracy: 0.9449 - cost: 6.9896 - val_loss: 0.1610 - val_auc: 0.9828 - val_accuracy: 0.9435 - val_cost: 7.1032\n",
            "Epoch 16/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1487 - auc: 0.9853 - accuracy: 0.9474 - cost: 6.6806 - val_loss: 0.1564 - val_auc: 0.9837 - val_accuracy: 0.9446 - val_cost: 6.9180\n",
            "Epoch 17/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1460 - auc: 0.9856 - accuracy: 0.9483 - cost: 6.5563 - val_loss: 0.1525 - val_auc: 0.9845 - val_accuracy: 0.9465 - val_cost: 6.8684\n",
            "Epoch 18/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1436 - auc: 0.9860 - accuracy: 0.9499 - cost: 6.3507 - val_loss: 0.1502 - val_auc: 0.9848 - val_accuracy: 0.9472 - val_cost: 6.7295\n",
            "Epoch 19/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.1406 - auc: 0.9865 - accuracy: 0.9506 - cost: 6.2820 - val_loss: 0.1491 - val_auc: 0.9850 - val_accuracy: 0.9478 - val_cost: 6.4947\n",
            "Epoch 20/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.1386 - auc: 0.9869 - accuracy: 0.9516 - cost: 6.1389 - val_loss: 0.1460 - val_auc: 0.9855 - val_accuracy: 0.9501 - val_cost: 6.2136\n",
            "Epoch 21/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1343 - auc: 0.9876 - accuracy: 0.9537 - cost: 5.8785 - val_loss: 0.1447 - val_auc: 0.9857 - val_accuracy: 0.9504 - val_cost: 6.2798\n",
            "Epoch 22/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1328 - auc: 0.9878 - accuracy: 0.9537 - cost: 5.8754 - val_loss: 0.1439 - val_auc: 0.9857 - val_accuracy: 0.9514 - val_cost: 6.1409\n",
            "Epoch 23/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.1318 - auc: 0.9879 - accuracy: 0.9550 - cost: 5.7145 - val_loss: 0.1413 - val_auc: 0.9861 - val_accuracy: 0.9511 - val_cost: 6.2335\n",
            "Epoch 24/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1288 - auc: 0.9884 - accuracy: 0.9563 - cost: 5.5467 - val_loss: 0.1397 - val_auc: 0.9864 - val_accuracy: 0.9519 - val_cost: 6.0351\n",
            "Epoch 25/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1271 - auc: 0.9886 - accuracy: 0.9567 - cost: 5.4961 - val_loss: 0.1398 - val_auc: 0.9863 - val_accuracy: 0.9526 - val_cost: 5.8862\n",
            "Epoch 26/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1244 - auc: 0.9889 - accuracy: 0.9584 - cost: 5.2731 - val_loss: 0.1388 - val_auc: 0.9864 - val_accuracy: 0.9532 - val_cost: 5.8399\n",
            "Epoch 27/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.1223 - auc: 0.9893 - accuracy: 0.9589 - cost: 5.2323 - val_loss: 0.1373 - val_auc: 0.9867 - val_accuracy: 0.9539 - val_cost: 5.8730\n",
            "Epoch 28/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1212 - auc: 0.9895 - accuracy: 0.9594 - cost: 5.1535 - val_loss: 0.1369 - val_auc: 0.9868 - val_accuracy: 0.9537 - val_cost: 5.8598\n",
            "Epoch 29/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1201 - auc: 0.9896 - accuracy: 0.9596 - cost: 5.1300 - val_loss: 0.1377 - val_auc: 0.9868 - val_accuracy: 0.9548 - val_cost: 5.5456\n",
            "Epoch 30/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.1189 - auc: 0.9897 - accuracy: 0.9603 - cost: 5.0436 - val_loss: 0.1351 - val_auc: 0.9870 - val_accuracy: 0.9565 - val_cost: 5.4861\n",
            "Epoch 31/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1161 - auc: 0.9901 - accuracy: 0.9614 - cost: 4.9059 - val_loss: 0.1348 - val_auc: 0.9871 - val_accuracy: 0.9558 - val_cost: 5.6878\n",
            "Epoch 32/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1156 - auc: 0.9902 - accuracy: 0.9616 - cost: 4.8696 - val_loss: 0.1327 - val_auc: 0.9872 - val_accuracy: 0.9561 - val_cost: 5.5390\n",
            "Epoch 33/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1137 - auc: 0.9904 - accuracy: 0.9623 - cost: 4.7863 - val_loss: 0.1315 - val_auc: 0.9876 - val_accuracy: 0.9563 - val_cost: 5.6448\n",
            "Epoch 34/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1124 - auc: 0.9907 - accuracy: 0.9631 - cost: 4.7037 - val_loss: 0.1311 - val_auc: 0.9875 - val_accuracy: 0.9583 - val_cost: 5.2646\n",
            "Epoch 35/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1118 - auc: 0.9906 - accuracy: 0.9632 - cost: 4.6840 - val_loss: 0.1285 - val_auc: 0.9881 - val_accuracy: 0.9581 - val_cost: 5.2348\n",
            "Epoch 36/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1102 - auc: 0.9909 - accuracy: 0.9636 - cost: 4.6200 - val_loss: 0.1292 - val_auc: 0.9878 - val_accuracy: 0.9592 - val_cost: 5.2183\n",
            "Epoch 37/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1093 - auc: 0.9909 - accuracy: 0.9645 - cost: 4.5123 - val_loss: 0.1288 - val_auc: 0.9880 - val_accuracy: 0.9593 - val_cost: 5.1025\n",
            "Epoch 38/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1084 - auc: 0.9911 - accuracy: 0.9647 - cost: 4.4718 - val_loss: 0.1266 - val_auc: 0.9882 - val_accuracy: 0.9592 - val_cost: 5.1951\n",
            "Epoch 39/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1063 - auc: 0.9914 - accuracy: 0.9652 - cost: 4.4298 - val_loss: 0.1261 - val_auc: 0.9882 - val_accuracy: 0.9601 - val_cost: 4.9272\n",
            "Epoch 40/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1057 - auc: 0.9914 - accuracy: 0.9655 - cost: 4.3858 - val_loss: 0.1269 - val_auc: 0.9882 - val_accuracy: 0.9594 - val_cost: 5.0000\n",
            "Epoch 41/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1046 - auc: 0.9914 - accuracy: 0.9665 - cost: 4.2481 - val_loss: 0.1243 - val_auc: 0.9884 - val_accuracy: 0.9603 - val_cost: 5.0628\n",
            "Epoch 42/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1039 - auc: 0.9916 - accuracy: 0.9661 - cost: 4.3048 - val_loss: 0.1235 - val_auc: 0.9885 - val_accuracy: 0.9610 - val_cost: 4.9173\n",
            "Epoch 43/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1027 - auc: 0.9918 - accuracy: 0.9666 - cost: 4.2546 - val_loss: 0.1251 - val_auc: 0.9883 - val_accuracy: 0.9600 - val_cost: 4.9438\n",
            "Epoch 44/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1021 - auc: 0.9919 - accuracy: 0.9674 - cost: 4.1242 - val_loss: 0.1235 - val_auc: 0.9883 - val_accuracy: 0.9606 - val_cost: 4.9702\n",
            "Epoch 45/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1007 - auc: 0.9920 - accuracy: 0.9683 - cost: 4.0448 - val_loss: 0.1249 - val_auc: 0.9885 - val_accuracy: 0.9611 - val_cost: 4.7321\n",
            "Epoch 46/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1006 - auc: 0.9921 - accuracy: 0.9674 - cost: 4.1323 - val_loss: 0.1237 - val_auc: 0.9884 - val_accuracy: 0.9606 - val_cost: 4.9173\n",
            "Epoch 47/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0999 - auc: 0.9921 - accuracy: 0.9679 - cost: 4.0818 - val_loss: 0.1221 - val_auc: 0.9884 - val_accuracy: 0.9622 - val_cost: 4.8280\n",
            "Epoch 48/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0982 - auc: 0.9923 - accuracy: 0.9688 - cost: 3.9653 - val_loss: 0.1222 - val_auc: 0.9885 - val_accuracy: 0.9610 - val_cost: 4.8644\n",
            "Epoch 49/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0973 - auc: 0.9924 - accuracy: 0.9694 - cost: 3.8881 - val_loss: 0.1208 - val_auc: 0.9889 - val_accuracy: 0.9615 - val_cost: 4.9074\n",
            "Epoch 50/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0960 - auc: 0.9924 - accuracy: 0.9693 - cost: 3.9155 - val_loss: 0.1209 - val_auc: 0.9888 - val_accuracy: 0.9625 - val_cost: 4.7454\n",
            "Epoch 51/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0959 - auc: 0.9926 - accuracy: 0.9694 - cost: 3.8978 - val_loss: 0.1204 - val_auc: 0.9889 - val_accuracy: 0.9628 - val_cost: 4.8545\n",
            "Epoch 52/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0950 - auc: 0.9927 - accuracy: 0.9700 - cost: 3.8218 - val_loss: 0.1209 - val_auc: 0.9886 - val_accuracy: 0.9628 - val_cost: 4.6362\n",
            "Epoch 53/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0943 - auc: 0.9927 - accuracy: 0.9701 - cost: 3.8067 - val_loss: 0.1187 - val_auc: 0.9888 - val_accuracy: 0.9634 - val_cost: 4.6792\n",
            "Epoch 54/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0933 - auc: 0.9928 - accuracy: 0.9702 - cost: 3.7886 - val_loss: 0.1197 - val_auc: 0.9890 - val_accuracy: 0.9634 - val_cost: 4.3849\n",
            "Epoch 55/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0929 - auc: 0.9929 - accuracy: 0.9708 - cost: 3.7218 - val_loss: 0.1187 - val_auc: 0.9890 - val_accuracy: 0.9632 - val_cost: 4.5437\n",
            "Epoch 56/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0925 - auc: 0.9929 - accuracy: 0.9706 - cost: 3.7411 - val_loss: 0.1172 - val_auc: 0.9888 - val_accuracy: 0.9647 - val_cost: 4.4775\n",
            "Epoch 57/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0915 - auc: 0.9929 - accuracy: 0.9708 - cost: 3.7238 - val_loss: 0.1167 - val_auc: 0.9891 - val_accuracy: 0.9642 - val_cost: 4.4742\n",
            "Epoch 58/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0920 - auc: 0.9929 - accuracy: 0.9711 - cost: 3.6833 - val_loss: 0.1166 - val_auc: 0.9891 - val_accuracy: 0.9642 - val_cost: 4.4940\n",
            "Epoch 59/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0903 - auc: 0.9931 - accuracy: 0.9715 - cost: 3.6339 - val_loss: 0.1170 - val_auc: 0.9890 - val_accuracy: 0.9638 - val_cost: 4.5635\n",
            "Epoch 60/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0898 - auc: 0.9931 - accuracy: 0.9721 - cost: 3.5517 - val_loss: 0.1161 - val_auc: 0.9892 - val_accuracy: 0.9642 - val_cost: 4.5602\n",
            "Epoch 61/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0899 - auc: 0.9931 - accuracy: 0.9719 - cost: 3.5764 - val_loss: 0.1176 - val_auc: 0.9891 - val_accuracy: 0.9650 - val_cost: 4.4974\n",
            "Epoch 62/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0885 - auc: 0.9934 - accuracy: 0.9720 - cost: 3.5671 - val_loss: 0.1169 - val_auc: 0.9893 - val_accuracy: 0.9651 - val_cost: 4.3155\n",
            "Epoch 63/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0878 - auc: 0.9934 - accuracy: 0.9724 - cost: 3.5139 - val_loss: 0.1155 - val_auc: 0.9893 - val_accuracy: 0.9652 - val_cost: 4.3386\n",
            "Epoch 64/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0882 - auc: 0.9934 - accuracy: 0.9729 - cost: 3.4579 - val_loss: 0.1158 - val_auc: 0.9892 - val_accuracy: 0.9655 - val_cost: 4.3353\n",
            "Epoch 65/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0876 - auc: 0.9933 - accuracy: 0.9728 - cost: 3.4699 - val_loss: 0.1148 - val_auc: 0.9894 - val_accuracy: 0.9656 - val_cost: 4.3519\n",
            "Epoch 66/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0869 - auc: 0.9935 - accuracy: 0.9730 - cost: 3.4387 - val_loss: 0.1146 - val_auc: 0.9895 - val_accuracy: 0.9662 - val_cost: 4.2328\n",
            "Epoch 67/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0869 - auc: 0.9935 - accuracy: 0.9729 - cost: 3.4653 - val_loss: 0.1127 - val_auc: 0.9895 - val_accuracy: 0.9660 - val_cost: 4.2989\n",
            "Epoch 68/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0852 - auc: 0.9936 - accuracy: 0.9737 - cost: 3.3530 - val_loss: 0.1132 - val_auc: 0.9896 - val_accuracy: 0.9666 - val_cost: 4.1468\n",
            "Epoch 69/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0859 - auc: 0.9935 - accuracy: 0.9733 - cost: 3.3978 - val_loss: 0.1173 - val_auc: 0.9893 - val_accuracy: 0.9655 - val_cost: 4.2692\n",
            "Epoch 70/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0856 - auc: 0.9935 - accuracy: 0.9737 - cost: 3.3580 - val_loss: 0.1136 - val_auc: 0.9896 - val_accuracy: 0.9665 - val_cost: 4.1931\n",
            "Epoch 71/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0850 - auc: 0.9937 - accuracy: 0.9741 - cost: 3.2878 - val_loss: 0.1120 - val_auc: 0.9898 - val_accuracy: 0.9663 - val_cost: 4.2526\n",
            "Epoch 72/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0841 - auc: 0.9937 - accuracy: 0.9745 - cost: 3.2577 - val_loss: 0.1121 - val_auc: 0.9896 - val_accuracy: 0.9669 - val_cost: 4.1402\n",
            "Epoch 73/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0841 - auc: 0.9937 - accuracy: 0.9739 - cost: 3.3302 - val_loss: 0.1131 - val_auc: 0.9894 - val_accuracy: 0.9655 - val_cost: 4.4775\n",
            "Epoch 74/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0837 - auc: 0.9939 - accuracy: 0.9740 - cost: 3.3160 - val_loss: 0.1134 - val_auc: 0.9896 - val_accuracy: 0.9665 - val_cost: 4.1038\n",
            "Epoch 75/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0826 - auc: 0.9939 - accuracy: 0.9748 - cost: 3.2218 - val_loss: 0.1138 - val_auc: 0.9895 - val_accuracy: 0.9656 - val_cost: 4.3188\n",
            "Epoch 76/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0838 - auc: 0.9937 - accuracy: 0.9742 - cost: 3.2832 - val_loss: 0.1128 - val_auc: 0.9897 - val_accuracy: 0.9665 - val_cost: 4.2824\n",
            "Epoch 77/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0814 - auc: 0.9941 - accuracy: 0.9749 - cost: 3.2130 - val_loss: 0.1113 - val_auc: 0.9899 - val_accuracy: 0.9662 - val_cost: 4.2626\n",
            "Epoch 78/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0825 - auc: 0.9939 - accuracy: 0.9749 - cost: 3.2083 - val_loss: 0.1120 - val_auc: 0.9896 - val_accuracy: 0.9672 - val_cost: 4.0675\n",
            "Epoch 79/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0804 - auc: 0.9942 - accuracy: 0.9753 - cost: 3.1339 - val_loss: 0.1113 - val_auc: 0.9900 - val_accuracy: 0.9672 - val_cost: 4.0542\n",
            "Epoch 80/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0808 - auc: 0.9940 - accuracy: 0.9755 - cost: 3.1327 - val_loss: 0.1122 - val_auc: 0.9896 - val_accuracy: 0.9668 - val_cost: 4.1204\n",
            "Epoch 81/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0810 - auc: 0.9941 - accuracy: 0.9753 - cost: 3.1566 - val_loss: 0.1123 - val_auc: 0.9895 - val_accuracy: 0.9665 - val_cost: 4.2063\n",
            "Epoch 82/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0812 - auc: 0.9940 - accuracy: 0.9752 - cost: 3.1686 - val_loss: 0.1133 - val_auc: 0.9897 - val_accuracy: 0.9671 - val_cost: 3.9914\n",
            "Epoch 83/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0802 - auc: 0.9942 - accuracy: 0.9755 - cost: 3.1285 - val_loss: 0.1113 - val_auc: 0.9897 - val_accuracy: 0.9679 - val_cost: 4.0774\n",
            "Epoch 84/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0795 - auc: 0.9942 - accuracy: 0.9758 - cost: 3.0953 - val_loss: 0.1108 - val_auc: 0.9897 - val_accuracy: 0.9681 - val_cost: 3.9980\n",
            "Epoch 85/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0800 - auc: 0.9941 - accuracy: 0.9758 - cost: 3.0965 - val_loss: 0.1109 - val_auc: 0.9898 - val_accuracy: 0.9675 - val_cost: 3.9683\n",
            "Epoch 86/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0794 - auc: 0.9942 - accuracy: 0.9755 - cost: 3.1238 - val_loss: 0.1118 - val_auc: 0.9899 - val_accuracy: 0.9670 - val_cost: 4.1534\n",
            "Epoch 87/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0787 - auc: 0.9943 - accuracy: 0.9762 - cost: 3.0312 - val_loss: 0.1122 - val_auc: 0.9897 - val_accuracy: 0.9674 - val_cost: 3.9352\n",
            "Epoch 88/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0789 - auc: 0.9942 - accuracy: 0.9760 - cost: 3.0779 - val_loss: 0.1121 - val_auc: 0.9897 - val_accuracy: 0.9665 - val_cost: 4.1435\n",
            "Epoch 89/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0777 - auc: 0.9943 - accuracy: 0.9764 - cost: 3.0116 - val_loss: 0.1112 - val_auc: 0.9897 - val_accuracy: 0.9679 - val_cost: 4.0079\n",
            "Epoch 90/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0771 - auc: 0.9943 - accuracy: 0.9766 - cost: 2.9857 - val_loss: 0.1120 - val_auc: 0.9894 - val_accuracy: 0.9672 - val_cost: 3.9947\n",
            "Epoch 91/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0779 - auc: 0.9943 - accuracy: 0.9764 - cost: 3.0046 - val_loss: 0.1122 - val_auc: 0.9898 - val_accuracy: 0.9664 - val_cost: 4.1931\n",
            "Epoch 92/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0776 - auc: 0.9943 - accuracy: 0.9769 - cost: 2.9479 - val_loss: 0.1119 - val_auc: 0.9900 - val_accuracy: 0.9672 - val_cost: 4.0410\n",
            "Epoch 93/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0783 - auc: 0.9943 - accuracy: 0.9760 - cost: 3.0679 - val_loss: 0.1112 - val_auc: 0.9899 - val_accuracy: 0.9681 - val_cost: 3.9649\n",
            "Epoch 94/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0761 - auc: 0.9945 - accuracy: 0.9766 - cost: 2.9911 - val_loss: 0.1151 - val_auc: 0.9891 - val_accuracy: 0.9672 - val_cost: 4.0575\n",
            "Epoch 95/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0773 - auc: 0.9943 - accuracy: 0.9768 - cost: 2.9541 - val_loss: 0.1107 - val_auc: 0.9898 - val_accuracy: 0.9691 - val_cost: 3.8757\n",
            "Epoch 96/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0769 - auc: 0.9944 - accuracy: 0.9769 - cost: 2.9614 - val_loss: 0.1125 - val_auc: 0.9896 - val_accuracy: 0.9674 - val_cost: 4.0344\n",
            "Epoch 97/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0766 - auc: 0.9944 - accuracy: 0.9767 - cost: 2.9788 - val_loss: 0.1119 - val_auc: 0.9899 - val_accuracy: 0.9678 - val_cost: 4.1005\n",
            "Epoch 98/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0754 - auc: 0.9946 - accuracy: 0.9769 - cost: 2.9421 - val_loss: 0.1122 - val_auc: 0.9898 - val_accuracy: 0.9684 - val_cost: 3.8128\n",
            "Epoch 99/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0752 - auc: 0.9945 - accuracy: 0.9776 - cost: 2.8700 - val_loss: 0.1114 - val_auc: 0.9897 - val_accuracy: 0.9692 - val_cost: 3.8261\n",
            "Epoch 100/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0754 - auc: 0.9946 - accuracy: 0.9768 - cost: 2.9595 - val_loss: 0.1124 - val_auc: 0.9898 - val_accuracy: 0.9674 - val_cost: 4.0476\n",
            "Epoch 101/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0750 - auc: 0.9947 - accuracy: 0.9772 - cost: 2.9178 - val_loss: 0.1097 - val_auc: 0.9898 - val_accuracy: 0.9683 - val_cost: 4.0278\n",
            "Epoch 102/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0744 - auc: 0.9947 - accuracy: 0.9776 - cost: 2.8634 - val_loss: 0.1118 - val_auc: 0.9899 - val_accuracy: 0.9688 - val_cost: 3.8988\n",
            "Epoch 103/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0745 - auc: 0.9947 - accuracy: 0.9776 - cost: 2.8619 - val_loss: 0.1119 - val_auc: 0.9900 - val_accuracy: 0.9680 - val_cost: 4.0278\n",
            "Epoch 104/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0740 - auc: 0.9947 - accuracy: 0.9776 - cost: 2.8534 - val_loss: 0.1108 - val_auc: 0.9899 - val_accuracy: 0.9688 - val_cost: 3.9484\n",
            "Epoch 105/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0747 - auc: 0.9947 - accuracy: 0.9773 - cost: 2.9128 - val_loss: 0.1131 - val_auc: 0.9894 - val_accuracy: 0.9667 - val_cost: 4.2692\n",
            "Epoch 106/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0737 - auc: 0.9948 - accuracy: 0.9781 - cost: 2.8059 - val_loss: 0.1118 - val_auc: 0.9900 - val_accuracy: 0.9685 - val_cost: 4.0112\n",
            "Epoch 107/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0735 - auc: 0.9947 - accuracy: 0.9776 - cost: 2.8630 - val_loss: 0.1132 - val_auc: 0.9897 - val_accuracy: 0.9680 - val_cost: 4.0410\n",
            "Epoch 108/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0732 - auc: 0.9948 - accuracy: 0.9782 - cost: 2.7894 - val_loss: 0.1130 - val_auc: 0.9896 - val_accuracy: 0.9677 - val_cost: 4.0774\n",
            "Epoch 109/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0734 - auc: 0.9948 - accuracy: 0.9783 - cost: 2.7785 - val_loss: 0.1129 - val_auc: 0.9896 - val_accuracy: 0.9678 - val_cost: 4.1270\n",
            "Epoch 110/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0734 - auc: 0.9948 - accuracy: 0.9779 - cost: 2.8206 - val_loss: 0.1136 - val_auc: 0.9895 - val_accuracy: 0.9677 - val_cost: 3.9484\n",
            "Epoch 111/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0728 - auc: 0.9949 - accuracy: 0.9780 - cost: 2.8187 - val_loss: 0.1118 - val_auc: 0.9898 - val_accuracy: 0.9686 - val_cost: 3.9616\n",
            "Epoch 112/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0728 - auc: 0.9949 - accuracy: 0.9780 - cost: 2.8137 - val_loss: 0.1108 - val_auc: 0.9900 - val_accuracy: 0.9687 - val_cost: 3.9451\n",
            "Epoch 113/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0728 - auc: 0.9947 - accuracy: 0.9779 - cost: 2.8241 - val_loss: 0.1124 - val_auc: 0.9898 - val_accuracy: 0.9684 - val_cost: 3.9220\n",
            "Epoch 114/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0719 - auc: 0.9949 - accuracy: 0.9784 - cost: 2.7554 - val_loss: 0.1134 - val_auc: 0.9898 - val_accuracy: 0.9677 - val_cost: 4.1468\n",
            "Epoch 115/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0732 - auc: 0.9948 - accuracy: 0.9781 - cost: 2.7936 - val_loss: 0.1129 - val_auc: 0.9897 - val_accuracy: 0.9681 - val_cost: 4.0013\n",
            "Epoch 116/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0725 - auc: 0.9948 - accuracy: 0.9782 - cost: 2.7878 - val_loss: 0.1127 - val_auc: 0.9898 - val_accuracy: 0.9690 - val_cost: 3.7831\n",
            "Epoch 117/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0712 - auc: 0.9950 - accuracy: 0.9786 - cost: 2.7377 - val_loss: 0.1096 - val_auc: 0.9898 - val_accuracy: 0.9697 - val_cost: 3.7632\n",
            "Epoch 118/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0713 - auc: 0.9949 - accuracy: 0.9788 - cost: 2.7122 - val_loss: 0.1129 - val_auc: 0.9899 - val_accuracy: 0.9690 - val_cost: 3.7302\n",
            "Epoch 119/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0717 - auc: 0.9949 - accuracy: 0.9785 - cost: 2.7492 - val_loss: 0.1125 - val_auc: 0.9898 - val_accuracy: 0.9683 - val_cost: 3.9517\n",
            "Epoch 120/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0715 - auc: 0.9949 - accuracy: 0.9786 - cost: 2.7280 - val_loss: 0.1121 - val_auc: 0.9897 - val_accuracy: 0.9683 - val_cost: 4.0642\n",
            "Epoch 121/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0709 - auc: 0.9951 - accuracy: 0.9787 - cost: 2.7230 - val_loss: 0.1123 - val_auc: 0.9896 - val_accuracy: 0.9690 - val_cost: 3.7996\n",
            "Epoch 122/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0700 - auc: 0.9951 - accuracy: 0.9791 - cost: 2.6755 - val_loss: 0.1108 - val_auc: 0.9900 - val_accuracy: 0.9688 - val_cost: 3.9087\n",
            "Epoch 123/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0706 - auc: 0.9950 - accuracy: 0.9790 - cost: 2.6968 - val_loss: 0.1126 - val_auc: 0.9899 - val_accuracy: 0.9686 - val_cost: 3.8856\n",
            "Epoch 124/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0712 - auc: 0.9949 - accuracy: 0.9786 - cost: 2.7415 - val_loss: 0.1117 - val_auc: 0.9898 - val_accuracy: 0.9687 - val_cost: 3.9385\n",
            "Epoch 125/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0706 - auc: 0.9951 - accuracy: 0.9787 - cost: 2.7284 - val_loss: 0.1140 - val_auc: 0.9894 - val_accuracy: 0.9690 - val_cost: 3.7996\n",
            "Epoch 126/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0704 - auc: 0.9951 - accuracy: 0.9790 - cost: 2.6813 - val_loss: 0.1120 - val_auc: 0.9898 - val_accuracy: 0.9694 - val_cost: 3.8393\n",
            "Epoch 127/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0696 - auc: 0.9952 - accuracy: 0.9790 - cost: 2.6833 - val_loss: 0.1144 - val_auc: 0.9895 - val_accuracy: 0.9681 - val_cost: 4.0013\n",
            "Epoch 128/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0701 - auc: 0.9950 - accuracy: 0.9793 - cost: 2.6613 - val_loss: 0.1144 - val_auc: 0.9894 - val_accuracy: 0.9685 - val_cost: 3.8624\n",
            "Epoch 129/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0701 - auc: 0.9951 - accuracy: 0.9795 - cost: 2.6258 - val_loss: 0.1120 - val_auc: 0.9896 - val_accuracy: 0.9692 - val_cost: 3.9319\n",
            "Epoch 130/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0694 - auc: 0.9951 - accuracy: 0.9793 - cost: 2.6536 - val_loss: 0.1107 - val_auc: 0.9899 - val_accuracy: 0.9701 - val_cost: 3.7368\n",
            "Epoch 131/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0693 - auc: 0.9951 - accuracy: 0.9793 - cost: 2.6397 - val_loss: 0.1110 - val_auc: 0.9895 - val_accuracy: 0.9686 - val_cost: 4.0509\n",
            "Epoch 132/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0693 - auc: 0.9952 - accuracy: 0.9796 - cost: 2.6227 - val_loss: 0.1121 - val_auc: 0.9899 - val_accuracy: 0.9695 - val_cost: 3.8558\n",
            "Epoch 133/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0696 - auc: 0.9952 - accuracy: 0.9790 - cost: 2.6952 - val_loss: 0.1105 - val_auc: 0.9899 - val_accuracy: 0.9694 - val_cost: 3.8624\n",
            "Epoch 134/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0691 - auc: 0.9952 - accuracy: 0.9797 - cost: 2.5988 - val_loss: 0.1115 - val_auc: 0.9897 - val_accuracy: 0.9696 - val_cost: 3.7467\n",
            "Epoch 135/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0697 - auc: 0.9952 - accuracy: 0.9794 - cost: 2.6516 - val_loss: 0.1118 - val_auc: 0.9895 - val_accuracy: 0.9709 - val_cost: 3.6376\n",
            "Epoch 136/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0685 - auc: 0.9953 - accuracy: 0.9795 - cost: 2.6323 - val_loss: 0.1124 - val_auc: 0.9899 - val_accuracy: 0.9696 - val_cost: 3.8856\n",
            "Epoch 137/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0695 - auc: 0.9952 - accuracy: 0.9793 - cost: 2.6370 - val_loss: 0.1100 - val_auc: 0.9898 - val_accuracy: 0.9703 - val_cost: 3.7599\n",
            "Epoch 138/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0679 - auc: 0.9953 - accuracy: 0.9802 - cost: 2.5224 - val_loss: 0.1151 - val_auc: 0.9894 - val_accuracy: 0.9695 - val_cost: 3.8624\n",
            "Epoch 139/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0689 - auc: 0.9952 - accuracy: 0.9796 - cost: 2.6123 - val_loss: 0.1094 - val_auc: 0.9901 - val_accuracy: 0.9697 - val_cost: 3.8624\n",
            "Epoch 140/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0689 - auc: 0.9952 - accuracy: 0.9793 - cost: 2.6555 - val_loss: 0.1128 - val_auc: 0.9897 - val_accuracy: 0.9699 - val_cost: 3.7500\n",
            "Epoch 141/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0680 - auc: 0.9953 - accuracy: 0.9799 - cost: 2.5822 - val_loss: 0.1105 - val_auc: 0.9898 - val_accuracy: 0.9699 - val_cost: 3.7963\n",
            "Epoch 142/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0687 - auc: 0.9952 - accuracy: 0.9795 - cost: 2.6277 - val_loss: 0.1103 - val_auc: 0.9898 - val_accuracy: 0.9707 - val_cost: 3.6938\n",
            "Epoch 143/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0682 - auc: 0.9952 - accuracy: 0.9799 - cost: 2.5694 - val_loss: 0.1125 - val_auc: 0.9896 - val_accuracy: 0.9701 - val_cost: 3.8360\n",
            "Epoch 144/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0671 - auc: 0.9954 - accuracy: 0.9798 - cost: 2.5799 - val_loss: 0.1116 - val_auc: 0.9897 - val_accuracy: 0.9711 - val_cost: 3.6376\n",
            "Epoch 145/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0678 - auc: 0.9953 - accuracy: 0.9801 - cost: 2.5386 - val_loss: 0.1136 - val_auc: 0.9899 - val_accuracy: 0.9698 - val_cost: 3.7996\n",
            "Epoch 146/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0675 - auc: 0.9953 - accuracy: 0.9799 - cost: 2.5779 - val_loss: 0.1096 - val_auc: 0.9899 - val_accuracy: 0.9699 - val_cost: 3.7434\n",
            "Epoch 147/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0668 - auc: 0.9953 - accuracy: 0.9806 - cost: 2.4907 - val_loss: 0.1119 - val_auc: 0.9898 - val_accuracy: 0.9697 - val_cost: 3.8955\n",
            "Epoch 148/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0674 - auc: 0.9953 - accuracy: 0.9798 - cost: 2.5860 - val_loss: 0.1119 - val_auc: 0.9897 - val_accuracy: 0.9701 - val_cost: 3.7533\n",
            "Epoch 149/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0671 - auc: 0.9954 - accuracy: 0.9804 - cost: 2.5231 - val_loss: 0.1100 - val_auc: 0.9898 - val_accuracy: 0.9703 - val_cost: 3.8095\n",
            "Epoch 150/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0675 - auc: 0.9954 - accuracy: 0.9801 - cost: 2.5413 - val_loss: 0.1118 - val_auc: 0.9899 - val_accuracy: 0.9715 - val_cost: 3.6574\n",
            "Epoch 151/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0670 - auc: 0.9953 - accuracy: 0.9801 - cost: 2.5575 - val_loss: 0.1111 - val_auc: 0.9900 - val_accuracy: 0.9690 - val_cost: 3.7996\n",
            "Epoch 152/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0669 - auc: 0.9954 - accuracy: 0.9800 - cost: 2.5721 - val_loss: 0.1124 - val_auc: 0.9897 - val_accuracy: 0.9703 - val_cost: 3.7235\n",
            "Epoch 153/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0670 - auc: 0.9954 - accuracy: 0.9803 - cost: 2.5170 - val_loss: 0.1115 - val_auc: 0.9898 - val_accuracy: 0.9710 - val_cost: 3.6475\n",
            "Epoch 154/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0669 - auc: 0.9955 - accuracy: 0.9804 - cost: 2.5147 - val_loss: 0.1125 - val_auc: 0.9896 - val_accuracy: 0.9700 - val_cost: 3.8525\n",
            "Epoch 155/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0673 - auc: 0.9955 - accuracy: 0.9799 - cost: 2.5729 - val_loss: 0.1137 - val_auc: 0.9896 - val_accuracy: 0.9701 - val_cost: 3.7368\n",
            "Epoch 156/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0672 - auc: 0.9953 - accuracy: 0.9798 - cost: 2.5930 - val_loss: 0.1134 - val_auc: 0.9897 - val_accuracy: 0.9700 - val_cost: 3.6872\n",
            "Epoch 157/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0667 - auc: 0.9955 - accuracy: 0.9803 - cost: 2.5266 - val_loss: 0.1104 - val_auc: 0.9900 - val_accuracy: 0.9708 - val_cost: 3.7169\n",
            "Epoch 158/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0647 - auc: 0.9956 - accuracy: 0.9814 - cost: 2.3846 - val_loss: 0.1124 - val_auc: 0.9899 - val_accuracy: 0.9700 - val_cost: 3.8095\n",
            "Epoch 159/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0657 - auc: 0.9956 - accuracy: 0.9805 - cost: 2.5085 - val_loss: 0.1123 - val_auc: 0.9897 - val_accuracy: 0.9709 - val_cost: 3.6475\n",
            "Epoch 160/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0652 - auc: 0.9956 - accuracy: 0.9809 - cost: 2.4417 - val_loss: 0.1114 - val_auc: 0.9897 - val_accuracy: 0.9701 - val_cost: 3.7731\n",
            "Epoch 161/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0656 - auc: 0.9955 - accuracy: 0.9806 - cost: 2.4919 - val_loss: 0.1127 - val_auc: 0.9898 - val_accuracy: 0.9704 - val_cost: 3.6574\n",
            "Epoch 162/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0651 - auc: 0.9955 - accuracy: 0.9808 - cost: 2.4657 - val_loss: 0.1128 - val_auc: 0.9895 - val_accuracy: 0.9702 - val_cost: 3.7467\n",
            "Epoch 163/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0659 - auc: 0.9954 - accuracy: 0.9808 - cost: 2.4545 - val_loss: 0.1117 - val_auc: 0.9898 - val_accuracy: 0.9711 - val_cost: 3.5946\n",
            "Epoch 164/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0652 - auc: 0.9956 - accuracy: 0.9811 - cost: 2.4171 - val_loss: 0.1111 - val_auc: 0.9898 - val_accuracy: 0.9716 - val_cost: 3.5417\n",
            "Epoch 165/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0654 - auc: 0.9956 - accuracy: 0.9808 - cost: 2.4614 - val_loss: 0.1127 - val_auc: 0.9896 - val_accuracy: 0.9710 - val_cost: 3.6508\n",
            "Epoch 166/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0650 - auc: 0.9956 - accuracy: 0.9807 - cost: 2.4738 - val_loss: 0.1115 - val_auc: 0.9899 - val_accuracy: 0.9701 - val_cost: 3.8029\n",
            "Epoch 167/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0650 - auc: 0.9956 - accuracy: 0.9811 - cost: 2.4302 - val_loss: 0.1106 - val_auc: 0.9898 - val_accuracy: 0.9703 - val_cost: 3.7004\n",
            "Epoch 168/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0654 - auc: 0.9956 - accuracy: 0.9806 - cost: 2.4838 - val_loss: 0.1127 - val_auc: 0.9896 - val_accuracy: 0.9706 - val_cost: 3.6938\n",
            "Epoch 169/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0650 - auc: 0.9956 - accuracy: 0.9806 - cost: 2.4792 - val_loss: 0.1140 - val_auc: 0.9896 - val_accuracy: 0.9710 - val_cost: 3.5847\n",
            "Epoch 170/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0655 - auc: 0.9955 - accuracy: 0.9807 - cost: 2.4715 - val_loss: 0.1147 - val_auc: 0.9899 - val_accuracy: 0.9697 - val_cost: 3.6938\n",
            "Epoch 171/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0658 - auc: 0.9956 - accuracy: 0.9803 - cost: 2.5147 - val_loss: 0.1151 - val_auc: 0.9898 - val_accuracy: 0.9692 - val_cost: 3.8327\n",
            "Epoch 172/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0636 - auc: 0.9958 - accuracy: 0.9814 - cost: 2.3812 - val_loss: 0.1140 - val_auc: 0.9896 - val_accuracy: 0.9705 - val_cost: 3.7798\n",
            "Epoch 173/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0645 - auc: 0.9957 - accuracy: 0.9807 - cost: 2.4637 - val_loss: 0.1150 - val_auc: 0.9895 - val_accuracy: 0.9703 - val_cost: 3.8426\n",
            "Epoch 174/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0647 - auc: 0.9957 - accuracy: 0.9810 - cost: 2.4321 - val_loss: 0.1118 - val_auc: 0.9897 - val_accuracy: 0.9712 - val_cost: 3.6541\n",
            "Epoch 175/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0645 - auc: 0.9956 - accuracy: 0.9807 - cost: 2.4826 - val_loss: 0.1142 - val_auc: 0.9898 - val_accuracy: 0.9710 - val_cost: 3.5582\n",
            "Epoch 176/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0636 - auc: 0.9958 - accuracy: 0.9809 - cost: 2.4591 - val_loss: 0.1128 - val_auc: 0.9899 - val_accuracy: 0.9703 - val_cost: 3.7004\n",
            "Epoch 177/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0640 - auc: 0.9956 - accuracy: 0.9811 - cost: 2.4194 - val_loss: 0.1139 - val_auc: 0.9896 - val_accuracy: 0.9699 - val_cost: 3.7368\n",
            "Epoch 178/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0646 - auc: 0.9957 - accuracy: 0.9812 - cost: 2.4074 - val_loss: 0.1125 - val_auc: 0.9897 - val_accuracy: 0.9714 - val_cost: 3.5086\n",
            "Epoch 179/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0640 - auc: 0.9957 - accuracy: 0.9811 - cost: 2.4240 - val_loss: 0.1159 - val_auc: 0.9892 - val_accuracy: 0.9707 - val_cost: 3.6739\n",
            "Epoch 180/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0634 - auc: 0.9959 - accuracy: 0.9811 - cost: 2.4255 - val_loss: 0.1143 - val_auc: 0.9898 - val_accuracy: 0.9699 - val_cost: 3.8558\n",
            "Epoch 181/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0640 - auc: 0.9957 - accuracy: 0.9812 - cost: 2.4147 - val_loss: 0.1139 - val_auc: 0.9895 - val_accuracy: 0.9706 - val_cost: 3.6872\n",
            "Epoch 182/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0640 - auc: 0.9958 - accuracy: 0.9811 - cost: 2.4228 - val_loss: 0.1146 - val_auc: 0.9900 - val_accuracy: 0.9705 - val_cost: 3.6706\n",
            "Epoch 183/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0635 - auc: 0.9958 - accuracy: 0.9812 - cost: 2.4032 - val_loss: 0.1128 - val_auc: 0.9899 - val_accuracy: 0.9713 - val_cost: 3.5979\n",
            "Epoch 184/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0631 - auc: 0.9958 - accuracy: 0.9812 - cost: 2.4035 - val_loss: 0.1128 - val_auc: 0.9898 - val_accuracy: 0.9711 - val_cost: 3.6078\n",
            "Epoch 185/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0636 - auc: 0.9958 - accuracy: 0.9812 - cost: 2.4005 - val_loss: 0.1127 - val_auc: 0.9898 - val_accuracy: 0.9706 - val_cost: 3.6111\n",
            "Epoch 186/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0632 - auc: 0.9959 - accuracy: 0.9811 - cost: 2.4198 - val_loss: 0.1144 - val_auc: 0.9898 - val_accuracy: 0.9715 - val_cost: 3.5880\n",
            "Epoch 187/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0630 - auc: 0.9958 - accuracy: 0.9814 - cost: 2.3866 - val_loss: 0.1140 - val_auc: 0.9897 - val_accuracy: 0.9713 - val_cost: 3.6276\n",
            "Epoch 188/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0637 - auc: 0.9958 - accuracy: 0.9808 - cost: 2.4614 - val_loss: 0.1149 - val_auc: 0.9895 - val_accuracy: 0.9696 - val_cost: 3.8261\n",
            "Epoch 189/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0624 - auc: 0.9959 - accuracy: 0.9816 - cost: 2.3542 - val_loss: 0.1136 - val_auc: 0.9898 - val_accuracy: 0.9702 - val_cost: 3.7070\n",
            "Epoch 190/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0631 - auc: 0.9958 - accuracy: 0.9813 - cost: 2.3889 - val_loss: 0.1149 - val_auc: 0.9896 - val_accuracy: 0.9711 - val_cost: 3.6739\n",
            "Epoch 191/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0638 - auc: 0.9959 - accuracy: 0.9810 - cost: 2.4475 - val_loss: 0.1140 - val_auc: 0.9895 - val_accuracy: 0.9715 - val_cost: 3.5813\n",
            "Epoch 192/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0629 - auc: 0.9958 - accuracy: 0.9816 - cost: 2.3615 - val_loss: 0.1135 - val_auc: 0.9896 - val_accuracy: 0.9703 - val_cost: 3.7831\n",
            "Epoch 193/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0622 - auc: 0.9959 - accuracy: 0.9815 - cost: 2.3762 - val_loss: 0.1128 - val_auc: 0.9900 - val_accuracy: 0.9710 - val_cost: 3.6839\n",
            "Epoch 194/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0627 - auc: 0.9958 - accuracy: 0.9815 - cost: 2.3715 - val_loss: 0.1145 - val_auc: 0.9896 - val_accuracy: 0.9705 - val_cost: 3.6706\n",
            "Epoch 195/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0634 - auc: 0.9957 - accuracy: 0.9812 - cost: 2.4082 - val_loss: 0.1160 - val_auc: 0.9895 - val_accuracy: 0.9706 - val_cost: 3.6706\n",
            "Epoch 196/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0623 - auc: 0.9959 - accuracy: 0.9814 - cost: 2.3808 - val_loss: 0.1148 - val_auc: 0.9900 - val_accuracy: 0.9712 - val_cost: 3.5880\n",
            "Epoch 197/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0630 - auc: 0.9958 - accuracy: 0.9815 - cost: 2.3673 - val_loss: 0.1154 - val_auc: 0.9893 - val_accuracy: 0.9706 - val_cost: 3.7269\n",
            "Epoch 198/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0621 - auc: 0.9960 - accuracy: 0.9816 - cost: 2.3492 - val_loss: 0.1150 - val_auc: 0.9900 - val_accuracy: 0.9712 - val_cost: 3.7037\n",
            "Epoch 199/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0631 - auc: 0.9959 - accuracy: 0.9814 - cost: 2.3754 - val_loss: 0.1134 - val_auc: 0.9898 - val_accuracy: 0.9703 - val_cost: 3.7599\n",
            "Epoch 200/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0623 - auc: 0.9959 - accuracy: 0.9818 - cost: 2.3353 - val_loss: 0.1146 - val_auc: 0.9897 - val_accuracy: 0.9701 - val_cost: 3.7103\n",
            "Epoch 201/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0627 - auc: 0.9959 - accuracy: 0.9819 - cost: 2.3333 - val_loss: 0.1135 - val_auc: 0.9896 - val_accuracy: 0.9704 - val_cost: 3.7202\n",
            "Epoch 202/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0625 - auc: 0.9959 - accuracy: 0.9815 - cost: 2.3723 - val_loss: 0.1132 - val_auc: 0.9896 - val_accuracy: 0.9710 - val_cost: 3.5780\n",
            "Epoch 203/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0617 - auc: 0.9959 - accuracy: 0.9818 - cost: 2.3322 - val_loss: 0.1143 - val_auc: 0.9896 - val_accuracy: 0.9713 - val_cost: 3.5284\n",
            "Epoch 204/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0619 - auc: 0.9961 - accuracy: 0.9816 - cost: 2.3692 - val_loss: 0.1130 - val_auc: 0.9898 - val_accuracy: 0.9713 - val_cost: 3.5648\n",
            "Epoch 205/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0621 - auc: 0.9959 - accuracy: 0.9816 - cost: 2.3534 - val_loss: 0.1140 - val_auc: 0.9898 - val_accuracy: 0.9708 - val_cost: 3.6078\n",
            "Epoch 206/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0614 - auc: 0.9960 - accuracy: 0.9820 - cost: 2.3110 - val_loss: 0.1143 - val_auc: 0.9897 - val_accuracy: 0.9694 - val_cost: 3.8790\n",
            "Epoch 207/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0614 - auc: 0.9961 - accuracy: 0.9819 - cost: 2.3299 - val_loss: 0.1136 - val_auc: 0.9899 - val_accuracy: 0.9706 - val_cost: 3.7004\n",
            "Epoch 208/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0608 - auc: 0.9961 - accuracy: 0.9819 - cost: 2.3272 - val_loss: 0.1152 - val_auc: 0.9898 - val_accuracy: 0.9701 - val_cost: 3.7831\n",
            "Epoch 209/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0615 - auc: 0.9958 - accuracy: 0.9819 - cost: 2.3144 - val_loss: 0.1159 - val_auc: 0.9896 - val_accuracy: 0.9706 - val_cost: 3.6012\n",
            "Epoch 210/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0608 - auc: 0.9960 - accuracy: 0.9822 - cost: 2.2878 - val_loss: 0.1153 - val_auc: 0.9898 - val_accuracy: 0.9709 - val_cost: 3.6607\n",
            "Epoch 211/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0605 - auc: 0.9961 - accuracy: 0.9820 - cost: 2.3044 - val_loss: 0.1137 - val_auc: 0.9899 - val_accuracy: 0.9708 - val_cost: 3.6971\n",
            "Epoch 212/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0616 - auc: 0.9959 - accuracy: 0.9819 - cost: 2.3233 - val_loss: 0.1148 - val_auc: 0.9897 - val_accuracy: 0.9710 - val_cost: 3.6376\n",
            "Epoch 213/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0613 - auc: 0.9960 - accuracy: 0.9819 - cost: 2.3179 - val_loss: 0.1131 - val_auc: 0.9897 - val_accuracy: 0.9710 - val_cost: 3.7665\n",
            "Epoch 214/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0613 - auc: 0.9960 - accuracy: 0.9821 - cost: 2.2975 - val_loss: 0.1143 - val_auc: 0.9896 - val_accuracy: 0.9702 - val_cost: 3.7169\n",
            "Epoch 215/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0604 - auc: 0.9960 - accuracy: 0.9826 - cost: 2.2288 - val_loss: 0.1155 - val_auc: 0.9897 - val_accuracy: 0.9712 - val_cost: 3.5020\n",
            "Epoch 216/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0616 - auc: 0.9960 - accuracy: 0.9818 - cost: 2.3302 - val_loss: 0.1143 - val_auc: 0.9897 - val_accuracy: 0.9706 - val_cost: 3.7368\n",
            "Epoch 217/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0608 - auc: 0.9960 - accuracy: 0.9822 - cost: 2.2870 - val_loss: 0.1164 - val_auc: 0.9897 - val_accuracy: 0.9706 - val_cost: 3.6905\n",
            "Epoch 218/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0609 - auc: 0.9960 - accuracy: 0.9818 - cost: 2.3387 - val_loss: 0.1162 - val_auc: 0.9895 - val_accuracy: 0.9701 - val_cost: 3.7202\n",
            "Epoch 219/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0616 - auc: 0.9960 - accuracy: 0.9818 - cost: 2.3241 - val_loss: 0.1153 - val_auc: 0.9895 - val_accuracy: 0.9707 - val_cost: 3.6971\n",
            "Epoch 220/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0611 - auc: 0.9959 - accuracy: 0.9822 - cost: 2.2789 - val_loss: 0.1129 - val_auc: 0.9898 - val_accuracy: 0.9715 - val_cost: 3.6508\n",
            "Epoch 221/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0601 - auc: 0.9962 - accuracy: 0.9823 - cost: 2.2693 - val_loss: 0.1143 - val_auc: 0.9899 - val_accuracy: 0.9708 - val_cost: 3.6409\n",
            "Epoch 222/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0606 - auc: 0.9961 - accuracy: 0.9819 - cost: 2.3144 - val_loss: 0.1138 - val_auc: 0.9897 - val_accuracy: 0.9709 - val_cost: 3.6442\n",
            "Epoch 223/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0602 - auc: 0.9962 - accuracy: 0.9820 - cost: 2.3175 - val_loss: 0.1159 - val_auc: 0.9896 - val_accuracy: 0.9702 - val_cost: 3.6971\n",
            "Epoch 224/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0600 - auc: 0.9961 - accuracy: 0.9823 - cost: 2.2724 - val_loss: 0.1154 - val_auc: 0.9897 - val_accuracy: 0.9692 - val_cost: 3.8657\n",
            "Epoch 225/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0609 - auc: 0.9961 - accuracy: 0.9821 - cost: 2.2940 - val_loss: 0.1155 - val_auc: 0.9900 - val_accuracy: 0.9712 - val_cost: 3.5152\n",
            "Epoch 226/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0607 - auc: 0.9961 - accuracy: 0.9824 - cost: 2.2589 - val_loss: 0.1144 - val_auc: 0.9897 - val_accuracy: 0.9712 - val_cost: 3.5417\n",
            "Epoch 227/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0607 - auc: 0.9961 - accuracy: 0.9822 - cost: 2.2816 - val_loss: 0.1146 - val_auc: 0.9896 - val_accuracy: 0.9708 - val_cost: 3.6673\n",
            "Epoch 228/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0601 - auc: 0.9961 - accuracy: 0.9823 - cost: 2.2805 - val_loss: 0.1137 - val_auc: 0.9899 - val_accuracy: 0.9713 - val_cost: 3.5549\n",
            "Epoch 229/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0603 - auc: 0.9961 - accuracy: 0.9821 - cost: 2.2932 - val_loss: 0.1166 - val_auc: 0.9897 - val_accuracy: 0.9708 - val_cost: 3.5417\n",
            "Epoch 230/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0604 - auc: 0.9962 - accuracy: 0.9821 - cost: 2.2901 - val_loss: 0.1154 - val_auc: 0.9899 - val_accuracy: 0.9708 - val_cost: 3.6541\n",
            "Epoch 231/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0603 - auc: 0.9962 - accuracy: 0.9817 - cost: 2.3511 - val_loss: 0.1160 - val_auc: 0.9896 - val_accuracy: 0.9692 - val_cost: 3.8161\n",
            "Epoch 232/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0606 - auc: 0.9962 - accuracy: 0.9822 - cost: 2.2870 - val_loss: 0.1179 - val_auc: 0.9894 - val_accuracy: 0.9714 - val_cost: 3.6045\n",
            "Epoch 233/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0600 - auc: 0.9962 - accuracy: 0.9822 - cost: 2.2770 - val_loss: 0.1147 - val_auc: 0.9898 - val_accuracy: 0.9706 - val_cost: 3.6343\n",
            "Epoch 234/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0604 - auc: 0.9961 - accuracy: 0.9821 - cost: 2.2882 - val_loss: 0.1154 - val_auc: 0.9896 - val_accuracy: 0.9710 - val_cost: 3.5880\n",
            "Epoch 235/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0593 - auc: 0.9962 - accuracy: 0.9823 - cost: 2.2650 - val_loss: 0.1167 - val_auc: 0.9894 - val_accuracy: 0.9712 - val_cost: 3.6574\n",
            "Epoch 236/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0594 - auc: 0.9962 - accuracy: 0.9824 - cost: 2.2650 - val_loss: 0.1154 - val_auc: 0.9897 - val_accuracy: 0.9715 - val_cost: 3.5913\n",
            "Epoch 237/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0609 - auc: 0.9961 - accuracy: 0.9818 - cost: 2.3395 - val_loss: 0.1159 - val_auc: 0.9894 - val_accuracy: 0.9708 - val_cost: 3.6442\n",
            "Epoch 238/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0602 - auc: 0.9961 - accuracy: 0.9825 - cost: 2.2427 - val_loss: 0.1169 - val_auc: 0.9896 - val_accuracy: 0.9706 - val_cost: 3.6243\n",
            "Epoch 239/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0594 - auc: 0.9962 - accuracy: 0.9824 - cost: 2.2666 - val_loss: 0.1173 - val_auc: 0.9895 - val_accuracy: 0.9711 - val_cost: 3.5549\n",
            "Epoch 240/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0591 - auc: 0.9963 - accuracy: 0.9824 - cost: 2.2677 - val_loss: 0.1160 - val_auc: 0.9895 - val_accuracy: 0.9717 - val_cost: 3.5516\n",
            "Epoch 241/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0599 - auc: 0.9962 - accuracy: 0.9826 - cost: 2.2369 - val_loss: 0.1177 - val_auc: 0.9899 - val_accuracy: 0.9704 - val_cost: 3.5615\n",
            "Epoch 242/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0597 - auc: 0.9962 - accuracy: 0.9822 - cost: 2.2851 - val_loss: 0.1146 - val_auc: 0.9898 - val_accuracy: 0.9705 - val_cost: 3.6971\n",
            "Epoch 243/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0590 - auc: 0.9963 - accuracy: 0.9827 - cost: 2.2296 - val_loss: 0.1172 - val_auc: 0.9899 - val_accuracy: 0.9706 - val_cost: 3.5714\n",
            "Epoch 244/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0596 - auc: 0.9962 - accuracy: 0.9823 - cost: 2.2890 - val_loss: 0.1156 - val_auc: 0.9895 - val_accuracy: 0.9721 - val_cost: 3.4722\n",
            "Epoch 245/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0586 - auc: 0.9963 - accuracy: 0.9826 - cost: 2.2234 - val_loss: 0.1167 - val_auc: 0.9897 - val_accuracy: 0.9708 - val_cost: 3.6243\n",
            "Epoch 246/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0594 - auc: 0.9961 - accuracy: 0.9822 - cost: 2.2809 - val_loss: 0.1176 - val_auc: 0.9896 - val_accuracy: 0.9708 - val_cost: 3.5119\n",
            "Epoch 247/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0590 - auc: 0.9963 - accuracy: 0.9827 - cost: 2.2226 - val_loss: 0.1166 - val_auc: 0.9900 - val_accuracy: 0.9718 - val_cost: 3.4590\n",
            "Epoch 248/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0595 - auc: 0.9962 - accuracy: 0.9825 - cost: 2.2396 - val_loss: 0.1156 - val_auc: 0.9895 - val_accuracy: 0.9715 - val_cost: 3.5516\n",
            "Epoch 249/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0590 - auc: 0.9963 - accuracy: 0.9825 - cost: 2.2431 - val_loss: 0.1185 - val_auc: 0.9898 - val_accuracy: 0.9706 - val_cost: 3.5813\n",
            "Epoch 250/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0589 - auc: 0.9964 - accuracy: 0.9826 - cost: 2.2380 - val_loss: 0.1148 - val_auc: 0.9896 - val_accuracy: 0.9716 - val_cost: 3.5417\n",
            "Epoch 251/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0580 - auc: 0.9964 - accuracy: 0.9831 - cost: 2.1659 - val_loss: 0.1162 - val_auc: 0.9894 - val_accuracy: 0.9695 - val_cost: 3.7798\n",
            "Epoch 252/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0592 - auc: 0.9962 - accuracy: 0.9827 - cost: 2.2245 - val_loss: 0.1192 - val_auc: 0.9892 - val_accuracy: 0.9707 - val_cost: 3.6243\n",
            "Epoch 253/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0588 - auc: 0.9963 - accuracy: 0.9828 - cost: 2.2191 - val_loss: 0.1167 - val_auc: 0.9893 - val_accuracy: 0.9710 - val_cost: 3.6045\n",
            "Epoch 254/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0590 - auc: 0.9962 - accuracy: 0.9822 - cost: 2.2870 - val_loss: 0.1181 - val_auc: 0.9892 - val_accuracy: 0.9710 - val_cost: 3.7335\n",
            "Epoch 255/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0589 - auc: 0.9963 - accuracy: 0.9820 - cost: 2.3048 - val_loss: 0.1167 - val_auc: 0.9895 - val_accuracy: 0.9703 - val_cost: 3.7103\n",
            "Epoch 256/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0599 - auc: 0.9963 - accuracy: 0.9823 - cost: 2.2731 - val_loss: 0.1196 - val_auc: 0.9891 - val_accuracy: 0.9704 - val_cost: 3.6905\n",
            "Epoch 257/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0596 - auc: 0.9962 - accuracy: 0.9821 - cost: 2.2971 - val_loss: 0.1163 - val_auc: 0.9893 - val_accuracy: 0.9705 - val_cost: 3.7798\n",
            "Epoch 258/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0586 - auc: 0.9963 - accuracy: 0.9826 - cost: 2.2438 - val_loss: 0.1195 - val_auc: 0.9892 - val_accuracy: 0.9708 - val_cost: 3.5185\n",
            "Epoch 259/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0581 - auc: 0.9964 - accuracy: 0.9829 - cost: 2.1867 - val_loss: 0.1141 - val_auc: 0.9897 - val_accuracy: 0.9712 - val_cost: 3.5582\n",
            "Epoch 260/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0588 - auc: 0.9963 - accuracy: 0.9826 - cost: 2.2427 - val_loss: 0.1171 - val_auc: 0.9896 - val_accuracy: 0.9715 - val_cost: 3.5747\n",
            "Epoch 261/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0584 - auc: 0.9964 - accuracy: 0.9824 - cost: 2.2577 - val_loss: 0.1174 - val_auc: 0.9893 - val_accuracy: 0.9712 - val_cost: 3.6839\n",
            "Epoch 262/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0586 - auc: 0.9963 - accuracy: 0.9826 - cost: 2.2253 - val_loss: 0.1167 - val_auc: 0.9895 - val_accuracy: 0.9705 - val_cost: 3.7368\n",
            "Epoch 263/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0582 - auc: 0.9963 - accuracy: 0.9827 - cost: 2.2319 - val_loss: 0.1187 - val_auc: 0.9893 - val_accuracy: 0.9701 - val_cost: 3.6210\n",
            "Epoch 264/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0588 - auc: 0.9963 - accuracy: 0.9825 - cost: 2.2404 - val_loss: 0.1163 - val_auc: 0.9894 - val_accuracy: 0.9717 - val_cost: 3.5284\n",
            "Epoch 265/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0580 - auc: 0.9963 - accuracy: 0.9829 - cost: 2.2002 - val_loss: 0.1159 - val_auc: 0.9896 - val_accuracy: 0.9712 - val_cost: 3.6376\n",
            "Epoch 266/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0587 - auc: 0.9964 - accuracy: 0.9823 - cost: 2.2631 - val_loss: 0.1166 - val_auc: 0.9894 - val_accuracy: 0.9718 - val_cost: 3.5086\n",
            "Epoch 267/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0584 - auc: 0.9963 - accuracy: 0.9831 - cost: 2.1744 - val_loss: 0.1176 - val_auc: 0.9894 - val_accuracy: 0.9709 - val_cost: 3.6343\n",
            "Epoch 268/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0587 - auc: 0.9962 - accuracy: 0.9826 - cost: 2.2272 - val_loss: 0.1169 - val_auc: 0.9893 - val_accuracy: 0.9714 - val_cost: 3.6045\n",
            "Epoch 269/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0587 - auc: 0.9963 - accuracy: 0.9826 - cost: 2.2303 - val_loss: 0.1178 - val_auc: 0.9893 - val_accuracy: 0.9707 - val_cost: 3.6872\n",
            "Epoch 270/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0574 - auc: 0.9964 - accuracy: 0.9830 - cost: 2.1856 - val_loss: 0.1145 - val_auc: 0.9896 - val_accuracy: 0.9720 - val_cost: 3.5681\n",
            "Epoch 271/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0572 - auc: 0.9965 - accuracy: 0.9828 - cost: 2.2099 - val_loss: 0.1165 - val_auc: 0.9897 - val_accuracy: 0.9710 - val_cost: 3.6739\n",
            "Epoch 272/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0586 - auc: 0.9964 - accuracy: 0.9822 - cost: 2.2785 - val_loss: 0.1171 - val_auc: 0.9892 - val_accuracy: 0.9706 - val_cost: 3.7202\n",
            "Epoch 273/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0582 - auc: 0.9963 - accuracy: 0.9828 - cost: 2.2072 - val_loss: 0.1179 - val_auc: 0.9891 - val_accuracy: 0.9707 - val_cost: 3.6872\n",
            "Epoch 274/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0583 - auc: 0.9963 - accuracy: 0.9829 - cost: 2.1991 - val_loss: 0.1162 - val_auc: 0.9897 - val_accuracy: 0.9703 - val_cost: 3.6475\n",
            "Epoch 275/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0577 - auc: 0.9965 - accuracy: 0.9832 - cost: 2.1566 - val_loss: 0.1170 - val_auc: 0.9896 - val_accuracy: 0.9697 - val_cost: 3.7798\n",
            "Epoch 276/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0579 - auc: 0.9964 - accuracy: 0.9828 - cost: 2.2079 - val_loss: 0.1193 - val_auc: 0.9894 - val_accuracy: 0.9700 - val_cost: 3.7401\n",
            "Epoch 277/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0573 - auc: 0.9966 - accuracy: 0.9827 - cost: 2.2157 - val_loss: 0.1197 - val_auc: 0.9894 - val_accuracy: 0.9700 - val_cost: 3.7037\n",
            "Epoch 278/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0581 - auc: 0.9964 - accuracy: 0.9829 - cost: 2.1941 - val_loss: 0.1202 - val_auc: 0.9893 - val_accuracy: 0.9713 - val_cost: 3.6045\n",
            "Epoch 279/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0575 - auc: 0.9964 - accuracy: 0.9827 - cost: 2.2184 - val_loss: 0.1179 - val_auc: 0.9893 - val_accuracy: 0.9706 - val_cost: 3.6475\n",
            "Epoch 280/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0581 - auc: 0.9963 - accuracy: 0.9826 - cost: 2.2388 - val_loss: 0.1157 - val_auc: 0.9893 - val_accuracy: 0.9705 - val_cost: 3.7533\n",
            "Epoch 281/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0574 - auc: 0.9965 - accuracy: 0.9831 - cost: 2.1752 - val_loss: 0.1172 - val_auc: 0.9895 - val_accuracy: 0.9703 - val_cost: 3.6243\n",
            "Epoch 282/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0578 - auc: 0.9965 - accuracy: 0.9824 - cost: 2.2639 - val_loss: 0.1171 - val_auc: 0.9893 - val_accuracy: 0.9715 - val_cost: 3.5615\n",
            "Epoch 283/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0579 - auc: 0.9963 - accuracy: 0.9829 - cost: 2.1925 - val_loss: 0.1176 - val_auc: 0.9895 - val_accuracy: 0.9712 - val_cost: 3.5384\n",
            "Epoch 284/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0581 - auc: 0.9964 - accuracy: 0.9826 - cost: 2.2238 - val_loss: 0.1178 - val_auc: 0.9894 - val_accuracy: 0.9712 - val_cost: 3.5813\n",
            "Epoch 285/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0578 - auc: 0.9964 - accuracy: 0.9828 - cost: 2.2149 - val_loss: 0.1183 - val_auc: 0.9895 - val_accuracy: 0.9712 - val_cost: 3.5847\n",
            "Epoch 286/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0572 - auc: 0.9964 - accuracy: 0.9830 - cost: 2.1763 - val_loss: 0.1190 - val_auc: 0.9893 - val_accuracy: 0.9703 - val_cost: 3.7500\n",
            "Epoch 287/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0575 - auc: 0.9965 - accuracy: 0.9830 - cost: 2.1925 - val_loss: 0.1198 - val_auc: 0.9890 - val_accuracy: 0.9705 - val_cost: 3.7434\n",
            "Epoch 288/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0579 - auc: 0.9964 - accuracy: 0.9829 - cost: 2.2072 - val_loss: 0.1197 - val_auc: 0.9894 - val_accuracy: 0.9694 - val_cost: 3.7765\n",
            "Epoch 289/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0579 - auc: 0.9965 - accuracy: 0.9826 - cost: 2.2226 - val_loss: 0.1190 - val_auc: 0.9892 - val_accuracy: 0.9703 - val_cost: 3.7037\n",
            "Epoch 290/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0566 - auc: 0.9966 - accuracy: 0.9830 - cost: 2.1875 - val_loss: 0.1187 - val_auc: 0.9894 - val_accuracy: 0.9706 - val_cost: 3.6276\n",
            "Epoch 291/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0576 - auc: 0.9965 - accuracy: 0.9826 - cost: 2.2299 - val_loss: 0.1204 - val_auc: 0.9895 - val_accuracy: 0.9707 - val_cost: 3.5747\n",
            "Epoch 292/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0575 - auc: 0.9965 - accuracy: 0.9827 - cost: 2.2130 - val_loss: 0.1180 - val_auc: 0.9897 - val_accuracy: 0.9701 - val_cost: 3.7169\n",
            "Epoch 293/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0569 - auc: 0.9967 - accuracy: 0.9826 - cost: 2.2284 - val_loss: 0.1184 - val_auc: 0.9892 - val_accuracy: 0.9714 - val_cost: 3.4987\n",
            "Epoch 294/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0572 - auc: 0.9965 - accuracy: 0.9832 - cost: 2.1690 - val_loss: 0.1187 - val_auc: 0.9893 - val_accuracy: 0.9714 - val_cost: 3.5946\n",
            "Epoch 295/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0567 - auc: 0.9965 - accuracy: 0.9832 - cost: 2.1516 - val_loss: 0.1165 - val_auc: 0.9896 - val_accuracy: 0.9712 - val_cost: 3.6276\n",
            "Epoch 296/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0568 - auc: 0.9966 - accuracy: 0.9829 - cost: 2.1948 - val_loss: 0.1203 - val_auc: 0.9897 - val_accuracy: 0.9710 - val_cost: 3.5780\n",
            "Epoch 297/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0577 - auc: 0.9965 - accuracy: 0.9825 - cost: 2.2415 - val_loss: 0.1181 - val_auc: 0.9897 - val_accuracy: 0.9708 - val_cost: 3.6376\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.1096 - auc: 0.9906 - accuracy: 0.9720 - cost: 3.4688\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:02:22.337524\n",
            "fold accuracy: 0.972000002861023 - fold cost: 3.46875\n",
            "x_train shape: (144000, 67)\n",
            "Epoch 1/1000\n",
            "120/120 [==============================] - 2s 6ms/step - loss: 0.5302 - auc: 0.7974 - accuracy: 0.7280 - cost: 36.2701 - val_loss: 0.4010 - val_auc: 0.8972 - val_accuracy: 0.8259 - val_cost: 22.2156\n",
            "Epoch 2/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.3521 - auc: 0.9212 - accuracy: 0.8483 - cost: 19.3113 - val_loss: 0.3218 - val_auc: 0.9342 - val_accuracy: 0.8630 - val_cost: 16.9940\n",
            "Epoch 3/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.3027 - auc: 0.9419 - accuracy: 0.8752 - cost: 15.7971 - val_loss: 0.2904 - val_auc: 0.9467 - val_accuracy: 0.8799 - val_cost: 15.1554\n",
            "Epoch 4/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2740 - auc: 0.9526 - accuracy: 0.8879 - cost: 14.1740 - val_loss: 0.2655 - val_auc: 0.9554 - val_accuracy: 0.8921 - val_cost: 13.4954\n",
            "Epoch 5/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2500 - auc: 0.9605 - accuracy: 0.8996 - cost: 12.6975 - val_loss: 0.2448 - val_auc: 0.9621 - val_accuracy: 0.9038 - val_cost: 12.0106\n",
            "Epoch 6/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.2309 - auc: 0.9664 - accuracy: 0.9096 - cost: 11.4298 - val_loss: 0.2275 - val_auc: 0.9675 - val_accuracy: 0.9128 - val_cost: 10.8896\n",
            "Epoch 7/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.2151 - auc: 0.9707 - accuracy: 0.9166 - cost: 10.5475 - val_loss: 0.2144 - val_auc: 0.9709 - val_accuracy: 0.9194 - val_cost: 9.9967\n",
            "Epoch 8/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.2006 - auc: 0.9745 - accuracy: 0.9235 - cost: 9.6640 - val_loss: 0.2018 - val_auc: 0.9741 - val_accuracy: 0.9253 - val_cost: 9.3287\n",
            "Epoch 9/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1900 - auc: 0.9769 - accuracy: 0.9280 - cost: 9.0833 - val_loss: 0.1925 - val_auc: 0.9765 - val_accuracy: 0.9308 - val_cost: 8.4557\n",
            "Epoch 10/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1811 - auc: 0.9788 - accuracy: 0.9325 - cost: 8.5324 - val_loss: 0.1830 - val_auc: 0.9782 - val_accuracy: 0.9347 - val_cost: 8.2507\n",
            "Epoch 11/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1741 - auc: 0.9804 - accuracy: 0.9359 - cost: 8.0903 - val_loss: 0.1762 - val_auc: 0.9797 - val_accuracy: 0.9369 - val_cost: 7.8175\n",
            "Epoch 12/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1675 - auc: 0.9818 - accuracy: 0.9388 - cost: 7.7431 - val_loss: 0.1712 - val_auc: 0.9810 - val_accuracy: 0.9390 - val_cost: 7.5231\n",
            "Epoch 13/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1611 - auc: 0.9829 - accuracy: 0.9418 - cost: 7.3646 - val_loss: 0.1650 - val_auc: 0.9820 - val_accuracy: 0.9413 - val_cost: 7.4272\n",
            "Epoch 14/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1555 - auc: 0.9840 - accuracy: 0.9452 - cost: 6.9441 - val_loss: 0.1616 - val_auc: 0.9826 - val_accuracy: 0.9422 - val_cost: 7.2090\n",
            "Epoch 15/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1517 - auc: 0.9846 - accuracy: 0.9463 - cost: 6.7836 - val_loss: 0.1577 - val_auc: 0.9833 - val_accuracy: 0.9438 - val_cost: 7.0536\n",
            "Epoch 16/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.1474 - auc: 0.9854 - accuracy: 0.9477 - cost: 6.6265 - val_loss: 0.1545 - val_auc: 0.9840 - val_accuracy: 0.9464 - val_cost: 6.7956\n",
            "Epoch 17/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1438 - auc: 0.9859 - accuracy: 0.9494 - cost: 6.4167 - val_loss: 0.1517 - val_auc: 0.9845 - val_accuracy: 0.9460 - val_cost: 6.7229\n",
            "Epoch 18/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.1410 - auc: 0.9865 - accuracy: 0.9503 - cost: 6.2901 - val_loss: 0.1488 - val_auc: 0.9850 - val_accuracy: 0.9495 - val_cost: 6.4484\n",
            "Epoch 19/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.1380 - auc: 0.9869 - accuracy: 0.9520 - cost: 6.0795 - val_loss: 0.1465 - val_auc: 0.9851 - val_accuracy: 0.9491 - val_cost: 6.4782\n",
            "Epoch 20/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.1352 - auc: 0.9875 - accuracy: 0.9532 - cost: 5.9336 - val_loss: 0.1470 - val_auc: 0.9853 - val_accuracy: 0.9504 - val_cost: 6.1012\n",
            "Epoch 21/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1331 - auc: 0.9877 - accuracy: 0.9541 - cost: 5.8052 - val_loss: 0.1427 - val_auc: 0.9858 - val_accuracy: 0.9531 - val_cost: 5.9590\n",
            "Epoch 22/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1306 - auc: 0.9881 - accuracy: 0.9558 - cost: 5.6092 - val_loss: 0.1430 - val_auc: 0.9858 - val_accuracy: 0.9512 - val_cost: 6.2599\n",
            "Epoch 23/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1283 - auc: 0.9884 - accuracy: 0.9563 - cost: 5.5312 - val_loss: 0.1395 - val_auc: 0.9862 - val_accuracy: 0.9534 - val_cost: 5.8862\n",
            "Epoch 24/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1269 - auc: 0.9886 - accuracy: 0.9567 - cost: 5.4799 - val_loss: 0.1391 - val_auc: 0.9862 - val_accuracy: 0.9547 - val_cost: 5.6647\n",
            "Epoch 25/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1241 - auc: 0.9891 - accuracy: 0.9578 - cost: 5.3422 - val_loss: 0.1374 - val_auc: 0.9867 - val_accuracy: 0.9551 - val_cost: 5.5258\n",
            "Epoch 26/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1224 - auc: 0.9892 - accuracy: 0.9586 - cost: 5.2361 - val_loss: 0.1352 - val_auc: 0.9869 - val_accuracy: 0.9556 - val_cost: 5.6316\n",
            "Epoch 27/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1208 - auc: 0.9895 - accuracy: 0.9595 - cost: 5.1331 - val_loss: 0.1350 - val_auc: 0.9871 - val_accuracy: 0.9557 - val_cost: 5.4563\n",
            "Epoch 28/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1200 - auc: 0.9895 - accuracy: 0.9602 - cost: 5.0305 - val_loss: 0.1338 - val_auc: 0.9869 - val_accuracy: 0.9567 - val_cost: 5.5126\n",
            "Epoch 29/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1177 - auc: 0.9899 - accuracy: 0.9607 - cost: 4.9853 - val_loss: 0.1331 - val_auc: 0.9871 - val_accuracy: 0.9569 - val_cost: 5.4663\n",
            "Epoch 30/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1158 - auc: 0.9902 - accuracy: 0.9613 - cost: 4.9128 - val_loss: 0.1331 - val_auc: 0.9871 - val_accuracy: 0.9558 - val_cost: 5.5985\n",
            "Epoch 31/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1146 - auc: 0.9903 - accuracy: 0.9619 - cost: 4.8029 - val_loss: 0.1302 - val_auc: 0.9874 - val_accuracy: 0.9583 - val_cost: 5.1918\n",
            "Epoch 32/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.1139 - auc: 0.9904 - accuracy: 0.9624 - cost: 4.7620 - val_loss: 0.1305 - val_auc: 0.9875 - val_accuracy: 0.9572 - val_cost: 5.2811\n",
            "Epoch 33/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.1125 - auc: 0.9905 - accuracy: 0.9630 - cost: 4.6740 - val_loss: 0.1280 - val_auc: 0.9875 - val_accuracy: 0.9592 - val_cost: 5.1323\n",
            "Epoch 34/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1104 - auc: 0.9908 - accuracy: 0.9637 - cost: 4.6111 - val_loss: 0.1270 - val_auc: 0.9878 - val_accuracy: 0.9595 - val_cost: 5.1720\n",
            "Epoch 35/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1101 - auc: 0.9908 - accuracy: 0.9639 - cost: 4.5937 - val_loss: 0.1261 - val_auc: 0.9879 - val_accuracy: 0.9589 - val_cost: 5.1885\n",
            "Epoch 36/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.1079 - auc: 0.9909 - accuracy: 0.9651 - cost: 4.4209 - val_loss: 0.1259 - val_auc: 0.9880 - val_accuracy: 0.9603 - val_cost: 4.8644\n",
            "Epoch 37/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1070 - auc: 0.9912 - accuracy: 0.9651 - cost: 4.4275 - val_loss: 0.1250 - val_auc: 0.9881 - val_accuracy: 0.9603 - val_cost: 4.8975\n",
            "Epoch 38/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1057 - auc: 0.9913 - accuracy: 0.9660 - cost: 4.3125 - val_loss: 0.1238 - val_auc: 0.9883 - val_accuracy: 0.9606 - val_cost: 4.9603\n",
            "Epoch 39/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1043 - auc: 0.9915 - accuracy: 0.9661 - cost: 4.2951 - val_loss: 0.1226 - val_auc: 0.9884 - val_accuracy: 0.9618 - val_cost: 4.8016\n",
            "Epoch 40/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1036 - auc: 0.9915 - accuracy: 0.9666 - cost: 4.2315 - val_loss: 0.1229 - val_auc: 0.9883 - val_accuracy: 0.9614 - val_cost: 4.9636\n",
            "Epoch 41/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1027 - auc: 0.9916 - accuracy: 0.9670 - cost: 4.1902 - val_loss: 0.1211 - val_auc: 0.9884 - val_accuracy: 0.9624 - val_cost: 4.7817\n",
            "Epoch 42/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1016 - auc: 0.9917 - accuracy: 0.9674 - cost: 4.1350 - val_loss: 0.1201 - val_auc: 0.9887 - val_accuracy: 0.9625 - val_cost: 4.7057\n",
            "Epoch 43/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1006 - auc: 0.9919 - accuracy: 0.9677 - cost: 4.1011 - val_loss: 0.1203 - val_auc: 0.9887 - val_accuracy: 0.9621 - val_cost: 4.7851\n",
            "Epoch 44/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0982 - auc: 0.9921 - accuracy: 0.9692 - cost: 3.9001 - val_loss: 0.1177 - val_auc: 0.9891 - val_accuracy: 0.9638 - val_cost: 4.5635\n",
            "Epoch 45/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0983 - auc: 0.9921 - accuracy: 0.9687 - cost: 3.9780 - val_loss: 0.1183 - val_auc: 0.9889 - val_accuracy: 0.9640 - val_cost: 4.5370\n",
            "Epoch 46/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0965 - auc: 0.9924 - accuracy: 0.9696 - cost: 3.8553 - val_loss: 0.1179 - val_auc: 0.9891 - val_accuracy: 0.9647 - val_cost: 4.4345\n",
            "Epoch 47/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0965 - auc: 0.9924 - accuracy: 0.9692 - cost: 3.9159 - val_loss: 0.1179 - val_auc: 0.9890 - val_accuracy: 0.9641 - val_cost: 4.4114\n",
            "Epoch 48/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0959 - auc: 0.9924 - accuracy: 0.9699 - cost: 3.8225 - val_loss: 0.1163 - val_auc: 0.9891 - val_accuracy: 0.9652 - val_cost: 4.4048\n",
            "Epoch 49/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0943 - auc: 0.9926 - accuracy: 0.9707 - cost: 3.7168 - val_loss: 0.1156 - val_auc: 0.9892 - val_accuracy: 0.9650 - val_cost: 4.4874\n",
            "Epoch 50/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0938 - auc: 0.9926 - accuracy: 0.9705 - cost: 3.7512 - val_loss: 0.1150 - val_auc: 0.9891 - val_accuracy: 0.9656 - val_cost: 4.3915\n",
            "Epoch 51/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0938 - auc: 0.9927 - accuracy: 0.9704 - cost: 3.7581 - val_loss: 0.1147 - val_auc: 0.9894 - val_accuracy: 0.9663 - val_cost: 4.1832\n",
            "Epoch 52/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0924 - auc: 0.9927 - accuracy: 0.9717 - cost: 3.5965 - val_loss: 0.1131 - val_auc: 0.9895 - val_accuracy: 0.9663 - val_cost: 4.2725\n",
            "Epoch 53/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0916 - auc: 0.9928 - accuracy: 0.9716 - cost: 3.6127 - val_loss: 0.1133 - val_auc: 0.9894 - val_accuracy: 0.9684 - val_cost: 3.9616\n",
            "Epoch 54/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0916 - auc: 0.9929 - accuracy: 0.9713 - cost: 3.6559 - val_loss: 0.1134 - val_auc: 0.9894 - val_accuracy: 0.9667 - val_cost: 4.1402\n",
            "Epoch 55/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0896 - auc: 0.9931 - accuracy: 0.9723 - cost: 3.5340 - val_loss: 0.1129 - val_auc: 0.9894 - val_accuracy: 0.9653 - val_cost: 4.3816\n",
            "Epoch 56/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0902 - auc: 0.9930 - accuracy: 0.9724 - cost: 3.5231 - val_loss: 0.1111 - val_auc: 0.9897 - val_accuracy: 0.9683 - val_cost: 3.9484\n",
            "Epoch 57/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0898 - auc: 0.9930 - accuracy: 0.9723 - cost: 3.5231 - val_loss: 0.1103 - val_auc: 0.9898 - val_accuracy: 0.9680 - val_cost: 3.9385\n",
            "Epoch 58/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0881 - auc: 0.9932 - accuracy: 0.9731 - cost: 3.4228 - val_loss: 0.1106 - val_auc: 0.9895 - val_accuracy: 0.9684 - val_cost: 4.0311\n",
            "Epoch 59/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0877 - auc: 0.9932 - accuracy: 0.9729 - cost: 3.4456 - val_loss: 0.1102 - val_auc: 0.9898 - val_accuracy: 0.9685 - val_cost: 3.9153\n",
            "Epoch 60/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0883 - auc: 0.9931 - accuracy: 0.9730 - cost: 3.4410 - val_loss: 0.1107 - val_auc: 0.9896 - val_accuracy: 0.9681 - val_cost: 4.0708\n",
            "Epoch 61/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0862 - auc: 0.9935 - accuracy: 0.9740 - cost: 3.3175 - val_loss: 0.1098 - val_auc: 0.9897 - val_accuracy: 0.9686 - val_cost: 3.9220\n",
            "Epoch 62/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0868 - auc: 0.9934 - accuracy: 0.9732 - cost: 3.4217 - val_loss: 0.1094 - val_auc: 0.9899 - val_accuracy: 0.9685 - val_cost: 3.9749\n",
            "Epoch 63/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0861 - auc: 0.9934 - accuracy: 0.9739 - cost: 3.3329 - val_loss: 0.1106 - val_auc: 0.9901 - val_accuracy: 0.9685 - val_cost: 3.9153\n",
            "Epoch 64/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0852 - auc: 0.9935 - accuracy: 0.9736 - cost: 3.3573 - val_loss: 0.1077 - val_auc: 0.9899 - val_accuracy: 0.9684 - val_cost: 4.0079\n",
            "Epoch 65/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0845 - auc: 0.9936 - accuracy: 0.9740 - cost: 3.3144 - val_loss: 0.1100 - val_auc: 0.9898 - val_accuracy: 0.9685 - val_cost: 3.9286\n",
            "Epoch 66/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0847 - auc: 0.9936 - accuracy: 0.9741 - cost: 3.2940 - val_loss: 0.1090 - val_auc: 0.9901 - val_accuracy: 0.9681 - val_cost: 4.0146\n",
            "Epoch 67/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0843 - auc: 0.9936 - accuracy: 0.9741 - cost: 3.3063 - val_loss: 0.1073 - val_auc: 0.9901 - val_accuracy: 0.9694 - val_cost: 3.9385\n",
            "Epoch 68/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0832 - auc: 0.9938 - accuracy: 0.9746 - cost: 3.2365 - val_loss: 0.1068 - val_auc: 0.9901 - val_accuracy: 0.9704 - val_cost: 3.6905\n",
            "Epoch 69/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0827 - auc: 0.9938 - accuracy: 0.9748 - cost: 3.1917 - val_loss: 0.1077 - val_auc: 0.9899 - val_accuracy: 0.9690 - val_cost: 3.8922\n",
            "Epoch 70/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0830 - auc: 0.9937 - accuracy: 0.9747 - cost: 3.2130 - val_loss: 0.1072 - val_auc: 0.9900 - val_accuracy: 0.9690 - val_cost: 3.8790\n",
            "Epoch 71/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0824 - auc: 0.9938 - accuracy: 0.9755 - cost: 3.1250 - val_loss: 0.1068 - val_auc: 0.9902 - val_accuracy: 0.9692 - val_cost: 3.8690\n",
            "Epoch 72/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0808 - auc: 0.9940 - accuracy: 0.9751 - cost: 3.1721 - val_loss: 0.1078 - val_auc: 0.9902 - val_accuracy: 0.9685 - val_cost: 4.0708\n",
            "Epoch 73/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0811 - auc: 0.9940 - accuracy: 0.9752 - cost: 3.1551 - val_loss: 0.1068 - val_auc: 0.9900 - val_accuracy: 0.9692 - val_cost: 3.9517\n",
            "Epoch 74/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0805 - auc: 0.9941 - accuracy: 0.9756 - cost: 3.1215 - val_loss: 0.1076 - val_auc: 0.9902 - val_accuracy: 0.9689 - val_cost: 3.8757\n",
            "Epoch 75/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0808 - auc: 0.9939 - accuracy: 0.9761 - cost: 3.0482 - val_loss: 0.1073 - val_auc: 0.9899 - val_accuracy: 0.9697 - val_cost: 3.9716\n",
            "Epoch 76/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0802 - auc: 0.9940 - accuracy: 0.9759 - cost: 3.0729 - val_loss: 0.1062 - val_auc: 0.9902 - val_accuracy: 0.9698 - val_cost: 3.8459\n",
            "Epoch 77/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0803 - auc: 0.9940 - accuracy: 0.9756 - cost: 3.1119 - val_loss: 0.1076 - val_auc: 0.9902 - val_accuracy: 0.9678 - val_cost: 4.0344\n",
            "Epoch 78/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0792 - auc: 0.9941 - accuracy: 0.9765 - cost: 2.9988 - val_loss: 0.1065 - val_auc: 0.9902 - val_accuracy: 0.9688 - val_cost: 3.9517\n",
            "Epoch 79/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0791 - auc: 0.9941 - accuracy: 0.9765 - cost: 2.9965 - val_loss: 0.1060 - val_auc: 0.9902 - val_accuracy: 0.9699 - val_cost: 3.7434\n",
            "Epoch 80/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0789 - auc: 0.9942 - accuracy: 0.9756 - cost: 3.1165 - val_loss: 0.1056 - val_auc: 0.9904 - val_accuracy: 0.9697 - val_cost: 3.8029\n",
            "Epoch 81/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0784 - auc: 0.9942 - accuracy: 0.9762 - cost: 3.0243 - val_loss: 0.1067 - val_auc: 0.9901 - val_accuracy: 0.9703 - val_cost: 3.7335\n",
            "Epoch 82/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0782 - auc: 0.9943 - accuracy: 0.9767 - cost: 2.9718 - val_loss: 0.1054 - val_auc: 0.9903 - val_accuracy: 0.9697 - val_cost: 3.8459\n",
            "Epoch 83/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0778 - auc: 0.9942 - accuracy: 0.9765 - cost: 2.9850 - val_loss: 0.1082 - val_auc: 0.9900 - val_accuracy: 0.9688 - val_cost: 3.8525\n",
            "Epoch 84/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0768 - auc: 0.9943 - accuracy: 0.9773 - cost: 2.8943 - val_loss: 0.1051 - val_auc: 0.9904 - val_accuracy: 0.9695 - val_cost: 3.7169\n",
            "Epoch 85/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0771 - auc: 0.9944 - accuracy: 0.9770 - cost: 2.9309 - val_loss: 0.1064 - val_auc: 0.9902 - val_accuracy: 0.9688 - val_cost: 4.0509\n",
            "Epoch 86/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0775 - auc: 0.9943 - accuracy: 0.9767 - cost: 2.9726 - val_loss: 0.1062 - val_auc: 0.9902 - val_accuracy: 0.9692 - val_cost: 3.8988\n",
            "Epoch 87/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0768 - auc: 0.9945 - accuracy: 0.9769 - cost: 2.9560 - val_loss: 0.1068 - val_auc: 0.9903 - val_accuracy: 0.9692 - val_cost: 3.9021\n",
            "Epoch 88/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0762 - auc: 0.9945 - accuracy: 0.9768 - cost: 2.9622 - val_loss: 0.1067 - val_auc: 0.9902 - val_accuracy: 0.9685 - val_cost: 3.9153\n",
            "Epoch 89/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0764 - auc: 0.9944 - accuracy: 0.9771 - cost: 2.9174 - val_loss: 0.1056 - val_auc: 0.9904 - val_accuracy: 0.9694 - val_cost: 3.8922\n",
            "Epoch 90/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0761 - auc: 0.9944 - accuracy: 0.9774 - cost: 2.8762 - val_loss: 0.1067 - val_auc: 0.9904 - val_accuracy: 0.9683 - val_cost: 4.0179\n",
            "Epoch 91/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0750 - auc: 0.9946 - accuracy: 0.9780 - cost: 2.8017 - val_loss: 0.1058 - val_auc: 0.9902 - val_accuracy: 0.9694 - val_cost: 3.8393\n",
            "Epoch 92/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0757 - auc: 0.9944 - accuracy: 0.9775 - cost: 2.8692 - val_loss: 0.1043 - val_auc: 0.9907 - val_accuracy: 0.9694 - val_cost: 3.9087\n",
            "Epoch 93/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0756 - auc: 0.9945 - accuracy: 0.9776 - cost: 2.8654 - val_loss: 0.1046 - val_auc: 0.9906 - val_accuracy: 0.9690 - val_cost: 3.9716\n",
            "Epoch 94/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0752 - auc: 0.9945 - accuracy: 0.9776 - cost: 2.8704 - val_loss: 0.1042 - val_auc: 0.9903 - val_accuracy: 0.9697 - val_cost: 3.8062\n",
            "Epoch 95/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0747 - auc: 0.9945 - accuracy: 0.9775 - cost: 2.8603 - val_loss: 0.1065 - val_auc: 0.9903 - val_accuracy: 0.9688 - val_cost: 3.9253\n",
            "Epoch 96/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0741 - auc: 0.9946 - accuracy: 0.9780 - cost: 2.8098 - val_loss: 0.1057 - val_auc: 0.9903 - val_accuracy: 0.9685 - val_cost: 4.0112\n",
            "Epoch 97/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0740 - auc: 0.9946 - accuracy: 0.9779 - cost: 2.8106 - val_loss: 0.1062 - val_auc: 0.9903 - val_accuracy: 0.9688 - val_cost: 4.0509\n",
            "Epoch 98/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0741 - auc: 0.9947 - accuracy: 0.9778 - cost: 2.8268 - val_loss: 0.1048 - val_auc: 0.9904 - val_accuracy: 0.9694 - val_cost: 3.9616\n",
            "Epoch 99/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0741 - auc: 0.9947 - accuracy: 0.9782 - cost: 2.7751 - val_loss: 0.1065 - val_auc: 0.9902 - val_accuracy: 0.9691 - val_cost: 4.0146\n",
            "Epoch 100/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0734 - auc: 0.9948 - accuracy: 0.9783 - cost: 2.7712 - val_loss: 0.1060 - val_auc: 0.9903 - val_accuracy: 0.9703 - val_cost: 3.7500\n",
            "Epoch 101/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0734 - auc: 0.9948 - accuracy: 0.9783 - cost: 2.7758 - val_loss: 0.1062 - val_auc: 0.9906 - val_accuracy: 0.9697 - val_cost: 3.7632\n",
            "Epoch 102/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0732 - auc: 0.9947 - accuracy: 0.9784 - cost: 2.7650 - val_loss: 0.1084 - val_auc: 0.9902 - val_accuracy: 0.9695 - val_cost: 3.7368\n",
            "Epoch 103/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0736 - auc: 0.9947 - accuracy: 0.9782 - cost: 2.7724 - val_loss: 0.1072 - val_auc: 0.9903 - val_accuracy: 0.9688 - val_cost: 3.9749\n",
            "Epoch 104/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0735 - auc: 0.9947 - accuracy: 0.9782 - cost: 2.7863 - val_loss: 0.1063 - val_auc: 0.9905 - val_accuracy: 0.9699 - val_cost: 3.7930\n",
            "Epoch 105/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0719 - auc: 0.9948 - accuracy: 0.9787 - cost: 2.7068 - val_loss: 0.1056 - val_auc: 0.9905 - val_accuracy: 0.9700 - val_cost: 3.7599\n",
            "Epoch 106/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0729 - auc: 0.9947 - accuracy: 0.9789 - cost: 2.6914 - val_loss: 0.1060 - val_auc: 0.9904 - val_accuracy: 0.9698 - val_cost: 3.7831\n",
            "Epoch 107/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0724 - auc: 0.9949 - accuracy: 0.9788 - cost: 2.7141 - val_loss: 0.1059 - val_auc: 0.9906 - val_accuracy: 0.9692 - val_cost: 3.8922\n",
            "Epoch 108/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0727 - auc: 0.9948 - accuracy: 0.9786 - cost: 2.7245 - val_loss: 0.1049 - val_auc: 0.9907 - val_accuracy: 0.9703 - val_cost: 3.7202\n",
            "Epoch 109/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0722 - auc: 0.9949 - accuracy: 0.9787 - cost: 2.7172 - val_loss: 0.1074 - val_auc: 0.9903 - val_accuracy: 0.9694 - val_cost: 3.8029\n",
            "Epoch 110/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0719 - auc: 0.9949 - accuracy: 0.9789 - cost: 2.6914 - val_loss: 0.1068 - val_auc: 0.9906 - val_accuracy: 0.9706 - val_cost: 3.7004\n",
            "Epoch 111/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0715 - auc: 0.9949 - accuracy: 0.9789 - cost: 2.6921 - val_loss: 0.1059 - val_auc: 0.9905 - val_accuracy: 0.9708 - val_cost: 3.7103\n",
            "Epoch 112/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0712 - auc: 0.9950 - accuracy: 0.9794 - cost: 2.6211 - val_loss: 0.1047 - val_auc: 0.9905 - val_accuracy: 0.9709 - val_cost: 3.7500\n",
            "Epoch 113/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0717 - auc: 0.9949 - accuracy: 0.9790 - cost: 2.6860 - val_loss: 0.1052 - val_auc: 0.9908 - val_accuracy: 0.9699 - val_cost: 3.8062\n",
            "Epoch 114/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0705 - auc: 0.9950 - accuracy: 0.9791 - cost: 2.6698 - val_loss: 0.1050 - val_auc: 0.9905 - val_accuracy: 0.9703 - val_cost: 3.7864\n",
            "Epoch 115/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0709 - auc: 0.9949 - accuracy: 0.9793 - cost: 2.6462 - val_loss: 0.1081 - val_auc: 0.9906 - val_accuracy: 0.9695 - val_cost: 3.7632\n",
            "Epoch 116/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0712 - auc: 0.9950 - accuracy: 0.9789 - cost: 2.6929 - val_loss: 0.1060 - val_auc: 0.9905 - val_accuracy: 0.9699 - val_cost: 3.7930\n",
            "Epoch 117/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0711 - auc: 0.9949 - accuracy: 0.9794 - cost: 2.6370 - val_loss: 0.1056 - val_auc: 0.9904 - val_accuracy: 0.9697 - val_cost: 3.8790\n",
            "Epoch 118/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0707 - auc: 0.9949 - accuracy: 0.9794 - cost: 2.6412 - val_loss: 0.1058 - val_auc: 0.9905 - val_accuracy: 0.9696 - val_cost: 3.8194\n",
            "Epoch 119/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0702 - auc: 0.9951 - accuracy: 0.9794 - cost: 2.6150 - val_loss: 0.1061 - val_auc: 0.9907 - val_accuracy: 0.9694 - val_cost: 3.8624\n",
            "Epoch 120/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0712 - auc: 0.9950 - accuracy: 0.9791 - cost: 2.6597 - val_loss: 0.1066 - val_auc: 0.9906 - val_accuracy: 0.9705 - val_cost: 3.6872\n",
            "Epoch 121/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0705 - auc: 0.9950 - accuracy: 0.9792 - cost: 2.6512 - val_loss: 0.1067 - val_auc: 0.9907 - val_accuracy: 0.9718 - val_cost: 3.5384\n",
            "Epoch 122/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0692 - auc: 0.9951 - accuracy: 0.9801 - cost: 2.5390 - val_loss: 0.1048 - val_auc: 0.9906 - val_accuracy: 0.9705 - val_cost: 3.7798\n",
            "Epoch 123/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0697 - auc: 0.9951 - accuracy: 0.9794 - cost: 2.6370 - val_loss: 0.1057 - val_auc: 0.9907 - val_accuracy: 0.9700 - val_cost: 3.7665\n",
            "Epoch 124/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0691 - auc: 0.9952 - accuracy: 0.9800 - cost: 2.5556 - val_loss: 0.1058 - val_auc: 0.9907 - val_accuracy: 0.9712 - val_cost: 3.6640\n",
            "Epoch 125/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0698 - auc: 0.9950 - accuracy: 0.9794 - cost: 2.6327 - val_loss: 0.1064 - val_auc: 0.9904 - val_accuracy: 0.9702 - val_cost: 3.8228\n",
            "Epoch 126/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0692 - auc: 0.9952 - accuracy: 0.9798 - cost: 2.5853 - val_loss: 0.1080 - val_auc: 0.9904 - val_accuracy: 0.9707 - val_cost: 3.6475\n",
            "Epoch 127/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0694 - auc: 0.9952 - accuracy: 0.9792 - cost: 2.6632 - val_loss: 0.1066 - val_auc: 0.9907 - val_accuracy: 0.9699 - val_cost: 3.8261\n",
            "Epoch 128/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0694 - auc: 0.9951 - accuracy: 0.9800 - cost: 2.5559 - val_loss: 0.1057 - val_auc: 0.9906 - val_accuracy: 0.9712 - val_cost: 3.7169\n",
            "Epoch 129/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0690 - auc: 0.9951 - accuracy: 0.9798 - cost: 2.5872 - val_loss: 0.1059 - val_auc: 0.9906 - val_accuracy: 0.9703 - val_cost: 3.8062\n",
            "Epoch 130/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0688 - auc: 0.9952 - accuracy: 0.9799 - cost: 2.5810 - val_loss: 0.1078 - val_auc: 0.9904 - val_accuracy: 0.9692 - val_cost: 3.8591\n",
            "Epoch 131/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0686 - auc: 0.9953 - accuracy: 0.9800 - cost: 2.5660 - val_loss: 0.1073 - val_auc: 0.9906 - val_accuracy: 0.9711 - val_cost: 3.5946\n",
            "Epoch 132/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0691 - auc: 0.9951 - accuracy: 0.9799 - cost: 2.5606 - val_loss: 0.1100 - val_auc: 0.9902 - val_accuracy: 0.9688 - val_cost: 3.9583\n",
            "Epoch 133/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0685 - auc: 0.9952 - accuracy: 0.9797 - cost: 2.5961 - val_loss: 0.1050 - val_auc: 0.9908 - val_accuracy: 0.9703 - val_cost: 3.8128\n",
            "Epoch 134/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0692 - auc: 0.9951 - accuracy: 0.9800 - cost: 2.5637 - val_loss: 0.1068 - val_auc: 0.9908 - val_accuracy: 0.9703 - val_cost: 3.7500\n",
            "Epoch 135/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0683 - auc: 0.9952 - accuracy: 0.9802 - cost: 2.5428 - val_loss: 0.1098 - val_auc: 0.9908 - val_accuracy: 0.9691 - val_cost: 3.7169\n",
            "Epoch 136/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0685 - auc: 0.9952 - accuracy: 0.9800 - cost: 2.5610 - val_loss: 0.1068 - val_auc: 0.9908 - val_accuracy: 0.9697 - val_cost: 3.8327\n",
            "Epoch 137/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0686 - auc: 0.9952 - accuracy: 0.9796 - cost: 2.6080 - val_loss: 0.1065 - val_auc: 0.9908 - val_accuracy: 0.9702 - val_cost: 3.7302\n",
            "Epoch 138/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0689 - auc: 0.9951 - accuracy: 0.9801 - cost: 2.5397 - val_loss: 0.1066 - val_auc: 0.9906 - val_accuracy: 0.9695 - val_cost: 3.8988\n",
            "Epoch 139/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0685 - auc: 0.9952 - accuracy: 0.9796 - cost: 2.6100 - val_loss: 0.1061 - val_auc: 0.9908 - val_accuracy: 0.9699 - val_cost: 3.8294\n",
            "Epoch 140/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0681 - auc: 0.9953 - accuracy: 0.9800 - cost: 2.5575 - val_loss: 0.1088 - val_auc: 0.9906 - val_accuracy: 0.9701 - val_cost: 3.7070\n",
            "Epoch 141/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0681 - auc: 0.9954 - accuracy: 0.9798 - cost: 2.5667 - val_loss: 0.1094 - val_auc: 0.9903 - val_accuracy: 0.9699 - val_cost: 3.8393\n",
            "Epoch 142/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0679 - auc: 0.9953 - accuracy: 0.9801 - cost: 2.5482 - val_loss: 0.1080 - val_auc: 0.9905 - val_accuracy: 0.9704 - val_cost: 3.6541\n",
            "Epoch 143/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0662 - auc: 0.9954 - accuracy: 0.9807 - cost: 2.4618 - val_loss: 0.1063 - val_auc: 0.9907 - val_accuracy: 0.9708 - val_cost: 3.6376\n",
            "Epoch 144/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0671 - auc: 0.9953 - accuracy: 0.9806 - cost: 2.4842 - val_loss: 0.1077 - val_auc: 0.9908 - val_accuracy: 0.9697 - val_cost: 3.7401\n",
            "Epoch 145/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0676 - auc: 0.9953 - accuracy: 0.9802 - cost: 2.5278 - val_loss: 0.1091 - val_auc: 0.9906 - val_accuracy: 0.9708 - val_cost: 3.7235\n",
            "Epoch 146/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0664 - auc: 0.9954 - accuracy: 0.9805 - cost: 2.4954 - val_loss: 0.1080 - val_auc: 0.9909 - val_accuracy: 0.9706 - val_cost: 3.6442\n",
            "Epoch 147/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0670 - auc: 0.9954 - accuracy: 0.9804 - cost: 2.5000 - val_loss: 0.1084 - val_auc: 0.9905 - val_accuracy: 0.9708 - val_cost: 3.6409\n",
            "Epoch 148/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0672 - auc: 0.9953 - accuracy: 0.9806 - cost: 2.4788 - val_loss: 0.1067 - val_auc: 0.9908 - val_accuracy: 0.9699 - val_cost: 3.7963\n",
            "Epoch 149/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0662 - auc: 0.9955 - accuracy: 0.9804 - cost: 2.5093 - val_loss: 0.1077 - val_auc: 0.9907 - val_accuracy: 0.9699 - val_cost: 3.7599\n",
            "Epoch 150/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0668 - auc: 0.9954 - accuracy: 0.9805 - cost: 2.4823 - val_loss: 0.1084 - val_auc: 0.9906 - val_accuracy: 0.9706 - val_cost: 3.8062\n",
            "Epoch 151/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0674 - auc: 0.9954 - accuracy: 0.9805 - cost: 2.4942 - val_loss: 0.1080 - val_auc: 0.9905 - val_accuracy: 0.9706 - val_cost: 3.8029\n",
            "Epoch 152/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0658 - auc: 0.9953 - accuracy: 0.9812 - cost: 2.3978 - val_loss: 0.1080 - val_auc: 0.9907 - val_accuracy: 0.9706 - val_cost: 3.7269\n",
            "Epoch 153/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0663 - auc: 0.9955 - accuracy: 0.9808 - cost: 2.4549 - val_loss: 0.1068 - val_auc: 0.9906 - val_accuracy: 0.9710 - val_cost: 3.6706\n",
            "Epoch 154/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0660 - auc: 0.9955 - accuracy: 0.9810 - cost: 2.4286 - val_loss: 0.1098 - val_auc: 0.9902 - val_accuracy: 0.9705 - val_cost: 3.7467\n",
            "Epoch 155/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0670 - auc: 0.9953 - accuracy: 0.9804 - cost: 2.4946 - val_loss: 0.1095 - val_auc: 0.9901 - val_accuracy: 0.9696 - val_cost: 3.8459\n",
            "Epoch 156/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0662 - auc: 0.9955 - accuracy: 0.9807 - cost: 2.4672 - val_loss: 0.1070 - val_auc: 0.9909 - val_accuracy: 0.9701 - val_cost: 3.7864\n",
            "Epoch 157/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0663 - auc: 0.9954 - accuracy: 0.9805 - cost: 2.4826 - val_loss: 0.1083 - val_auc: 0.9903 - val_accuracy: 0.9706 - val_cost: 3.7434\n",
            "Epoch 158/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0662 - auc: 0.9954 - accuracy: 0.9804 - cost: 2.5039 - val_loss: 0.1069 - val_auc: 0.9909 - val_accuracy: 0.9710 - val_cost: 3.7401\n",
            "Epoch 159/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0665 - auc: 0.9954 - accuracy: 0.9805 - cost: 2.4950 - val_loss: 0.1093 - val_auc: 0.9905 - val_accuracy: 0.9705 - val_cost: 3.8492\n",
            "Epoch 160/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0659 - auc: 0.9955 - accuracy: 0.9808 - cost: 2.4603 - val_loss: 0.1085 - val_auc: 0.9904 - val_accuracy: 0.9712 - val_cost: 3.6442\n",
            "Epoch 161/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0654 - auc: 0.9956 - accuracy: 0.9806 - cost: 2.4668 - val_loss: 0.1077 - val_auc: 0.9905 - val_accuracy: 0.9701 - val_cost: 3.8128\n",
            "Epoch 162/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0654 - auc: 0.9955 - accuracy: 0.9809 - cost: 2.4421 - val_loss: 0.1074 - val_auc: 0.9910 - val_accuracy: 0.9700 - val_cost: 3.8426\n",
            "Epoch 163/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0658 - auc: 0.9955 - accuracy: 0.9806 - cost: 2.4703 - val_loss: 0.1091 - val_auc: 0.9904 - val_accuracy: 0.9710 - val_cost: 3.7004\n",
            "Epoch 164/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0652 - auc: 0.9956 - accuracy: 0.9809 - cost: 2.4421 - val_loss: 0.1067 - val_auc: 0.9907 - val_accuracy: 0.9704 - val_cost: 3.8194\n",
            "Epoch 165/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0660 - auc: 0.9955 - accuracy: 0.9804 - cost: 2.5015 - val_loss: 0.1084 - val_auc: 0.9907 - val_accuracy: 0.9703 - val_cost: 3.8161\n",
            "Epoch 166/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0655 - auc: 0.9955 - accuracy: 0.9811 - cost: 2.4178 - val_loss: 0.1083 - val_auc: 0.9906 - val_accuracy: 0.9712 - val_cost: 3.6177\n",
            "Epoch 167/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0647 - auc: 0.9956 - accuracy: 0.9811 - cost: 2.4093 - val_loss: 0.1071 - val_auc: 0.9907 - val_accuracy: 0.9714 - val_cost: 3.5813\n",
            "Epoch 168/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0657 - auc: 0.9955 - accuracy: 0.9809 - cost: 2.4414 - val_loss: 0.1112 - val_auc: 0.9904 - val_accuracy: 0.9703 - val_cost: 3.5549\n",
            "Epoch 169/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0656 - auc: 0.9955 - accuracy: 0.9810 - cost: 2.4309 - val_loss: 0.1096 - val_auc: 0.9905 - val_accuracy: 0.9705 - val_cost: 3.6276\n",
            "Epoch 170/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0648 - auc: 0.9955 - accuracy: 0.9812 - cost: 2.3846 - val_loss: 0.1102 - val_auc: 0.9902 - val_accuracy: 0.9699 - val_cost: 3.7831\n",
            "Epoch 171/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0657 - auc: 0.9955 - accuracy: 0.9808 - cost: 2.4522 - val_loss: 0.1094 - val_auc: 0.9903 - val_accuracy: 0.9707 - val_cost: 3.6806\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.1072 - auc: 0.9906 - accuracy: 0.9684 - cost: 3.9813\n",
            "500/500 [==============================] - 1s 949us/step\n",
            "fold train/predict time: 0:01:22.891088\n",
            "fold accuracy: 0.968375027179718 - fold cost: 3.981250047683716\n",
            "x_train shape: (144000, 67)\n",
            "Epoch 1/1000\n",
            "120/120 [==============================] - 2s 5ms/step - loss: 0.5310 - auc: 0.7969 - accuracy: 0.7281 - cost: 36.2218 - val_loss: 0.4002 - val_auc: 0.8974 - val_accuracy: 0.8238 - val_cost: 22.9134\n",
            "Epoch 2/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.3518 - auc: 0.9213 - accuracy: 0.8489 - cost: 19.2512 - val_loss: 0.3178 - val_auc: 0.9359 - val_accuracy: 0.8644 - val_cost: 17.2057\n",
            "Epoch 3/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.3022 - auc: 0.9423 - accuracy: 0.8751 - cost: 15.8071 - val_loss: 0.2880 - val_auc: 0.9475 - val_accuracy: 0.8808 - val_cost: 14.8413\n",
            "Epoch 4/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.2739 - auc: 0.9526 - accuracy: 0.8885 - cost: 14.1015 - val_loss: 0.2644 - val_auc: 0.9560 - val_accuracy: 0.8935 - val_cost: 13.5813\n",
            "Epoch 5/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.2507 - auc: 0.9604 - accuracy: 0.8995 - cost: 12.6998 - val_loss: 0.2456 - val_auc: 0.9620 - val_accuracy: 0.9031 - val_cost: 12.0701\n",
            "Epoch 6/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.2324 - auc: 0.9659 - accuracy: 0.9082 - cost: 11.6169 - val_loss: 0.2300 - val_auc: 0.9666 - val_accuracy: 0.9104 - val_cost: 11.1938\n",
            "Epoch 7/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.2164 - auc: 0.9704 - accuracy: 0.9157 - cost: 10.6289 - val_loss: 0.2159 - val_auc: 0.9705 - val_accuracy: 0.9176 - val_cost: 10.4530\n",
            "Epoch 8/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.2030 - auc: 0.9738 - accuracy: 0.9220 - cost: 9.8615 - val_loss: 0.2049 - val_auc: 0.9733 - val_accuracy: 0.9235 - val_cost: 9.6164\n",
            "Epoch 9/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1921 - auc: 0.9764 - accuracy: 0.9270 - cost: 9.2106 - val_loss: 0.1958 - val_auc: 0.9756 - val_accuracy: 0.9287 - val_cost: 8.7930\n",
            "Epoch 10/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1827 - auc: 0.9785 - accuracy: 0.9315 - cost: 8.6516 - val_loss: 0.1880 - val_auc: 0.9772 - val_accuracy: 0.9334 - val_cost: 8.2606\n",
            "Epoch 11/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1762 - auc: 0.9799 - accuracy: 0.9342 - cost: 8.3198 - val_loss: 0.1814 - val_auc: 0.9786 - val_accuracy: 0.9355 - val_cost: 8.1746\n",
            "Epoch 12/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1694 - auc: 0.9813 - accuracy: 0.9374 - cost: 7.9201 - val_loss: 0.1768 - val_auc: 0.9795 - val_accuracy: 0.9381 - val_cost: 7.8869\n",
            "Epoch 13/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1636 - auc: 0.9825 - accuracy: 0.9402 - cost: 7.5679 - val_loss: 0.1734 - val_auc: 0.9803 - val_accuracy: 0.9395 - val_cost: 7.7315\n",
            "Epoch 14/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1591 - auc: 0.9833 - accuracy: 0.9428 - cost: 7.2110 - val_loss: 0.1680 - val_auc: 0.9813 - val_accuracy: 0.9428 - val_cost: 7.1230\n",
            "Epoch 15/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1537 - auc: 0.9843 - accuracy: 0.9454 - cost: 6.9271 - val_loss: 0.1651 - val_auc: 0.9819 - val_accuracy: 0.9438 - val_cost: 6.9246\n",
            "Epoch 16/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1506 - auc: 0.9849 - accuracy: 0.9463 - cost: 6.7959 - val_loss: 0.1623 - val_auc: 0.9824 - val_accuracy: 0.9449 - val_cost: 6.9015\n",
            "Epoch 17/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1469 - auc: 0.9856 - accuracy: 0.9483 - cost: 6.5417 - val_loss: 0.1588 - val_auc: 0.9833 - val_accuracy: 0.9459 - val_cost: 6.6700\n",
            "Epoch 18/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1439 - auc: 0.9860 - accuracy: 0.9488 - cost: 6.5004 - val_loss: 0.1560 - val_auc: 0.9836 - val_accuracy: 0.9458 - val_cost: 6.8188\n",
            "Epoch 19/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1407 - auc: 0.9865 - accuracy: 0.9506 - cost: 6.2604 - val_loss: 0.1540 - val_auc: 0.9839 - val_accuracy: 0.9482 - val_cost: 6.4517\n",
            "Epoch 20/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1386 - auc: 0.9869 - accuracy: 0.9522 - cost: 6.0440 - val_loss: 0.1522 - val_auc: 0.9842 - val_accuracy: 0.9488 - val_cost: 6.4385\n",
            "Epoch 21/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1355 - auc: 0.9875 - accuracy: 0.9529 - cost: 5.9726 - val_loss: 0.1516 - val_auc: 0.9843 - val_accuracy: 0.9497 - val_cost: 6.4451\n",
            "Epoch 22/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1335 - auc: 0.9877 - accuracy: 0.9534 - cost: 5.9016 - val_loss: 0.1490 - val_auc: 0.9848 - val_accuracy: 0.9497 - val_cost: 6.2401\n",
            "Epoch 23/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1314 - auc: 0.9880 - accuracy: 0.9544 - cost: 5.7531 - val_loss: 0.1483 - val_auc: 0.9848 - val_accuracy: 0.9508 - val_cost: 6.0813\n",
            "Epoch 24/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1299 - auc: 0.9883 - accuracy: 0.9548 - cost: 5.7315 - val_loss: 0.1470 - val_auc: 0.9852 - val_accuracy: 0.9511 - val_cost: 6.0185\n",
            "Epoch 25/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1279 - auc: 0.9885 - accuracy: 0.9560 - cost: 5.5617 - val_loss: 0.1459 - val_auc: 0.9853 - val_accuracy: 0.9515 - val_cost: 6.0714\n",
            "Epoch 26/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1256 - auc: 0.9889 - accuracy: 0.9574 - cost: 5.4012 - val_loss: 0.1441 - val_auc: 0.9855 - val_accuracy: 0.9534 - val_cost: 5.8730\n",
            "Epoch 27/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1233 - auc: 0.9893 - accuracy: 0.9584 - cost: 5.2766 - val_loss: 0.1436 - val_auc: 0.9856 - val_accuracy: 0.9534 - val_cost: 5.8003\n",
            "Epoch 28/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1229 - auc: 0.9892 - accuracy: 0.9582 - cost: 5.2959 - val_loss: 0.1412 - val_auc: 0.9861 - val_accuracy: 0.9547 - val_cost: 5.7242\n",
            "Epoch 29/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1213 - auc: 0.9895 - accuracy: 0.9592 - cost: 5.1655 - val_loss: 0.1412 - val_auc: 0.9860 - val_accuracy: 0.9551 - val_cost: 5.5589\n",
            "Epoch 30/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1187 - auc: 0.9899 - accuracy: 0.9600 - cost: 5.0725 - val_loss: 0.1390 - val_auc: 0.9863 - val_accuracy: 0.9553 - val_cost: 5.5952\n",
            "Epoch 31/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1188 - auc: 0.9899 - accuracy: 0.9602 - cost: 5.0424 - val_loss: 0.1384 - val_auc: 0.9863 - val_accuracy: 0.9569 - val_cost: 5.4167\n",
            "Epoch 32/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1161 - auc: 0.9902 - accuracy: 0.9613 - cost: 4.9097 - val_loss: 0.1372 - val_auc: 0.9866 - val_accuracy: 0.9562 - val_cost: 5.5622\n",
            "Epoch 33/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1150 - auc: 0.9903 - accuracy: 0.9619 - cost: 4.8268 - val_loss: 0.1362 - val_auc: 0.9868 - val_accuracy: 0.9564 - val_cost: 5.5126\n",
            "Epoch 34/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1138 - auc: 0.9905 - accuracy: 0.9623 - cost: 4.7805 - val_loss: 0.1362 - val_auc: 0.9866 - val_accuracy: 0.9559 - val_cost: 5.5952\n",
            "Epoch 35/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1123 - auc: 0.9906 - accuracy: 0.9634 - cost: 4.6134 - val_loss: 0.1344 - val_auc: 0.9870 - val_accuracy: 0.9573 - val_cost: 5.2844\n",
            "Epoch 36/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1116 - auc: 0.9907 - accuracy: 0.9634 - cost: 4.6493 - val_loss: 0.1338 - val_auc: 0.9871 - val_accuracy: 0.9575 - val_cost: 5.3406\n",
            "Epoch 37/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1105 - auc: 0.9908 - accuracy: 0.9638 - cost: 4.5814 - val_loss: 0.1316 - val_auc: 0.9872 - val_accuracy: 0.9589 - val_cost: 5.1058\n",
            "Epoch 38/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1085 - auc: 0.9911 - accuracy: 0.9646 - cost: 4.4923 - val_loss: 0.1309 - val_auc: 0.9875 - val_accuracy: 0.9585 - val_cost: 5.1885\n",
            "Epoch 39/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1078 - auc: 0.9912 - accuracy: 0.9650 - cost: 4.4383 - val_loss: 0.1308 - val_auc: 0.9874 - val_accuracy: 0.9585 - val_cost: 5.2050\n",
            "Epoch 40/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1066 - auc: 0.9914 - accuracy: 0.9651 - cost: 4.4379 - val_loss: 0.1291 - val_auc: 0.9877 - val_accuracy: 0.9599 - val_cost: 5.0595\n",
            "Epoch 41/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1047 - auc: 0.9916 - accuracy: 0.9657 - cost: 4.3380 - val_loss: 0.1315 - val_auc: 0.9875 - val_accuracy: 0.9582 - val_cost: 5.0265\n",
            "Epoch 42/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1046 - auc: 0.9915 - accuracy: 0.9663 - cost: 4.2593 - val_loss: 0.1292 - val_auc: 0.9877 - val_accuracy: 0.9597 - val_cost: 4.9868\n",
            "Epoch 43/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1030 - auc: 0.9919 - accuracy: 0.9666 - cost: 4.2434 - val_loss: 0.1288 - val_auc: 0.9876 - val_accuracy: 0.9601 - val_cost: 4.9471\n",
            "Epoch 44/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1029 - auc: 0.9918 - accuracy: 0.9670 - cost: 4.1898 - val_loss: 0.1279 - val_auc: 0.9879 - val_accuracy: 0.9601 - val_cost: 4.9173\n",
            "Epoch 45/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1015 - auc: 0.9918 - accuracy: 0.9675 - cost: 4.1381 - val_loss: 0.1269 - val_auc: 0.9878 - val_accuracy: 0.9599 - val_cost: 4.9405\n",
            "Epoch 46/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1006 - auc: 0.9920 - accuracy: 0.9680 - cost: 4.0613 - val_loss: 0.1253 - val_auc: 0.9882 - val_accuracy: 0.9614 - val_cost: 4.8512\n",
            "Epoch 47/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0995 - auc: 0.9922 - accuracy: 0.9680 - cost: 4.0721 - val_loss: 0.1251 - val_auc: 0.9882 - val_accuracy: 0.9617 - val_cost: 4.7156\n",
            "Epoch 48/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0988 - auc: 0.9922 - accuracy: 0.9686 - cost: 3.9857 - val_loss: 0.1254 - val_auc: 0.9880 - val_accuracy: 0.9604 - val_cost: 4.9504\n",
            "Epoch 49/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0969 - auc: 0.9924 - accuracy: 0.9694 - cost: 3.8870 - val_loss: 0.1240 - val_auc: 0.9883 - val_accuracy: 0.9611 - val_cost: 4.8843\n",
            "Epoch 50/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0972 - auc: 0.9924 - accuracy: 0.9691 - cost: 3.9398 - val_loss: 0.1240 - val_auc: 0.9882 - val_accuracy: 0.9618 - val_cost: 4.7751\n",
            "Epoch 51/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0973 - auc: 0.9925 - accuracy: 0.9689 - cost: 3.9448 - val_loss: 0.1230 - val_auc: 0.9884 - val_accuracy: 0.9619 - val_cost: 4.7057\n",
            "Epoch 52/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0960 - auc: 0.9926 - accuracy: 0.9694 - cost: 3.8823 - val_loss: 0.1215 - val_auc: 0.9885 - val_accuracy: 0.9626 - val_cost: 4.7288\n",
            "Epoch 53/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0953 - auc: 0.9927 - accuracy: 0.9694 - cost: 3.8935 - val_loss: 0.1228 - val_auc: 0.9885 - val_accuracy: 0.9624 - val_cost: 4.6759\n",
            "Epoch 54/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0947 - auc: 0.9928 - accuracy: 0.9706 - cost: 3.7400 - val_loss: 0.1211 - val_auc: 0.9888 - val_accuracy: 0.9626 - val_cost: 4.5767\n",
            "Epoch 55/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0944 - auc: 0.9927 - accuracy: 0.9704 - cost: 3.7600 - val_loss: 0.1206 - val_auc: 0.9887 - val_accuracy: 0.9633 - val_cost: 4.5899\n",
            "Epoch 56/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0924 - auc: 0.9930 - accuracy: 0.9707 - cost: 3.7238 - val_loss: 0.1202 - val_auc: 0.9888 - val_accuracy: 0.9644 - val_cost: 4.3552\n",
            "Epoch 57/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0919 - auc: 0.9931 - accuracy: 0.9712 - cost: 3.6609 - val_loss: 0.1213 - val_auc: 0.9886 - val_accuracy: 0.9633 - val_cost: 4.6296\n",
            "Epoch 58/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0920 - auc: 0.9929 - accuracy: 0.9714 - cost: 3.6404 - val_loss: 0.1202 - val_auc: 0.9890 - val_accuracy: 0.9637 - val_cost: 4.4312\n",
            "Epoch 59/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0913 - auc: 0.9930 - accuracy: 0.9714 - cost: 3.6532 - val_loss: 0.1189 - val_auc: 0.9890 - val_accuracy: 0.9631 - val_cost: 4.6627\n",
            "Epoch 60/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0911 - auc: 0.9931 - accuracy: 0.9714 - cost: 3.6478 - val_loss: 0.1184 - val_auc: 0.9888 - val_accuracy: 0.9644 - val_cost: 4.4577\n",
            "Epoch 61/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0891 - auc: 0.9933 - accuracy: 0.9719 - cost: 3.5818 - val_loss: 0.1194 - val_auc: 0.9885 - val_accuracy: 0.9644 - val_cost: 4.5238\n",
            "Epoch 62/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0893 - auc: 0.9933 - accuracy: 0.9722 - cost: 3.5409 - val_loss: 0.1175 - val_auc: 0.9891 - val_accuracy: 0.9655 - val_cost: 4.2493\n",
            "Epoch 63/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0884 - auc: 0.9934 - accuracy: 0.9726 - cost: 3.4865 - val_loss: 0.1169 - val_auc: 0.9889 - val_accuracy: 0.9654 - val_cost: 4.2758\n",
            "Epoch 64/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0880 - auc: 0.9934 - accuracy: 0.9728 - cost: 3.4711 - val_loss: 0.1165 - val_auc: 0.9890 - val_accuracy: 0.9653 - val_cost: 4.5172\n",
            "Epoch 65/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0876 - auc: 0.9935 - accuracy: 0.9724 - cost: 3.5243 - val_loss: 0.1162 - val_auc: 0.9894 - val_accuracy: 0.9643 - val_cost: 4.4775\n",
            "Epoch 66/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0872 - auc: 0.9936 - accuracy: 0.9730 - cost: 3.4518 - val_loss: 0.1163 - val_auc: 0.9890 - val_accuracy: 0.9660 - val_cost: 4.3585\n",
            "Epoch 67/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0865 - auc: 0.9936 - accuracy: 0.9726 - cost: 3.5062 - val_loss: 0.1159 - val_auc: 0.9890 - val_accuracy: 0.9654 - val_cost: 4.4312\n",
            "Epoch 68/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0850 - auc: 0.9938 - accuracy: 0.9733 - cost: 3.4039 - val_loss: 0.1166 - val_auc: 0.9890 - val_accuracy: 0.9659 - val_cost: 4.3056\n",
            "Epoch 69/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0853 - auc: 0.9935 - accuracy: 0.9739 - cost: 3.3356 - val_loss: 0.1172 - val_auc: 0.9890 - val_accuracy: 0.9658 - val_cost: 4.2427\n",
            "Epoch 70/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0845 - auc: 0.9937 - accuracy: 0.9737 - cost: 3.3553 - val_loss: 0.1150 - val_auc: 0.9893 - val_accuracy: 0.9652 - val_cost: 4.3948\n",
            "Epoch 71/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0843 - auc: 0.9938 - accuracy: 0.9741 - cost: 3.3036 - val_loss: 0.1154 - val_auc: 0.9893 - val_accuracy: 0.9658 - val_cost: 4.2526\n",
            "Epoch 72/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0846 - auc: 0.9938 - accuracy: 0.9737 - cost: 3.3646 - val_loss: 0.1133 - val_auc: 0.9896 - val_accuracy: 0.9666 - val_cost: 4.1766\n",
            "Epoch 73/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0836 - auc: 0.9938 - accuracy: 0.9738 - cost: 3.3395 - val_loss: 0.1158 - val_auc: 0.9893 - val_accuracy: 0.9658 - val_cost: 4.2097\n",
            "Epoch 74/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0827 - auc: 0.9940 - accuracy: 0.9746 - cost: 3.2481 - val_loss: 0.1149 - val_auc: 0.9893 - val_accuracy: 0.9660 - val_cost: 4.2196\n",
            "Epoch 75/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0820 - auc: 0.9940 - accuracy: 0.9750 - cost: 3.1871 - val_loss: 0.1146 - val_auc: 0.9895 - val_accuracy: 0.9663 - val_cost: 4.2262\n",
            "Epoch 76/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0821 - auc: 0.9940 - accuracy: 0.9747 - cost: 3.2218 - val_loss: 0.1165 - val_auc: 0.9893 - val_accuracy: 0.9655 - val_cost: 4.1997\n",
            "Epoch 77/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0814 - auc: 0.9940 - accuracy: 0.9752 - cost: 3.1609 - val_loss: 0.1134 - val_auc: 0.9894 - val_accuracy: 0.9672 - val_cost: 4.1303\n",
            "Epoch 78/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0810 - auc: 0.9941 - accuracy: 0.9755 - cost: 3.1285 - val_loss: 0.1138 - val_auc: 0.9895 - val_accuracy: 0.9667 - val_cost: 4.1435\n",
            "Epoch 79/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0817 - auc: 0.9940 - accuracy: 0.9749 - cost: 3.1944 - val_loss: 0.1143 - val_auc: 0.9895 - val_accuracy: 0.9671 - val_cost: 4.1667\n",
            "Epoch 80/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0806 - auc: 0.9941 - accuracy: 0.9752 - cost: 3.1574 - val_loss: 0.1165 - val_auc: 0.9892 - val_accuracy: 0.9666 - val_cost: 4.0708\n",
            "Epoch 81/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0802 - auc: 0.9941 - accuracy: 0.9756 - cost: 3.1146 - val_loss: 0.1144 - val_auc: 0.9893 - val_accuracy: 0.9669 - val_cost: 4.1501\n",
            "Epoch 82/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0793 - auc: 0.9942 - accuracy: 0.9759 - cost: 3.0656 - val_loss: 0.1132 - val_auc: 0.9895 - val_accuracy: 0.9679 - val_cost: 4.1038\n",
            "Epoch 83/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0798 - auc: 0.9941 - accuracy: 0.9757 - cost: 3.0953 - val_loss: 0.1146 - val_auc: 0.9890 - val_accuracy: 0.9676 - val_cost: 4.0509\n",
            "Epoch 84/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0792 - auc: 0.9942 - accuracy: 0.9756 - cost: 3.1211 - val_loss: 0.1141 - val_auc: 0.9895 - val_accuracy: 0.9683 - val_cost: 3.9749\n",
            "Epoch 85/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0789 - auc: 0.9942 - accuracy: 0.9762 - cost: 3.0386 - val_loss: 0.1155 - val_auc: 0.9891 - val_accuracy: 0.9657 - val_cost: 4.2427\n",
            "Epoch 86/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0783 - auc: 0.9943 - accuracy: 0.9763 - cost: 3.0212 - val_loss: 0.1147 - val_auc: 0.9894 - val_accuracy: 0.9661 - val_cost: 4.3915\n",
            "Epoch 87/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0779 - auc: 0.9944 - accuracy: 0.9761 - cost: 3.0401 - val_loss: 0.1139 - val_auc: 0.9894 - val_accuracy: 0.9684 - val_cost: 3.9815\n",
            "Epoch 88/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0769 - auc: 0.9945 - accuracy: 0.9769 - cost: 2.9479 - val_loss: 0.1126 - val_auc: 0.9896 - val_accuracy: 0.9679 - val_cost: 4.0112\n",
            "Epoch 89/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0770 - auc: 0.9946 - accuracy: 0.9767 - cost: 2.9676 - val_loss: 0.1144 - val_auc: 0.9895 - val_accuracy: 0.9678 - val_cost: 4.0245\n",
            "Epoch 90/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0765 - auc: 0.9945 - accuracy: 0.9773 - cost: 2.9001 - val_loss: 0.1141 - val_auc: 0.9893 - val_accuracy: 0.9674 - val_cost: 4.0675\n",
            "Epoch 91/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0767 - auc: 0.9946 - accuracy: 0.9768 - cost: 2.9695 - val_loss: 0.1127 - val_auc: 0.9898 - val_accuracy: 0.9688 - val_cost: 3.8988\n",
            "Epoch 92/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0760 - auc: 0.9945 - accuracy: 0.9772 - cost: 2.9267 - val_loss: 0.1134 - val_auc: 0.9895 - val_accuracy: 0.9672 - val_cost: 4.1005\n",
            "Epoch 93/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0759 - auc: 0.9945 - accuracy: 0.9769 - cost: 2.9429 - val_loss: 0.1128 - val_auc: 0.9897 - val_accuracy: 0.9680 - val_cost: 3.9980\n",
            "Epoch 94/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0753 - auc: 0.9947 - accuracy: 0.9772 - cost: 2.8981 - val_loss: 0.1126 - val_auc: 0.9898 - val_accuracy: 0.9683 - val_cost: 3.9749\n",
            "Epoch 95/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0753 - auc: 0.9946 - accuracy: 0.9775 - cost: 2.8750 - val_loss: 0.1128 - val_auc: 0.9898 - val_accuracy: 0.9688 - val_cost: 3.8657\n",
            "Epoch 96/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0753 - auc: 0.9947 - accuracy: 0.9773 - cost: 2.9008 - val_loss: 0.1130 - val_auc: 0.9898 - val_accuracy: 0.9669 - val_cost: 4.1237\n",
            "Epoch 97/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0743 - auc: 0.9947 - accuracy: 0.9776 - cost: 2.8681 - val_loss: 0.1115 - val_auc: 0.9898 - val_accuracy: 0.9673 - val_cost: 4.0840\n",
            "Epoch 98/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0739 - auc: 0.9947 - accuracy: 0.9780 - cost: 2.8110 - val_loss: 0.1132 - val_auc: 0.9897 - val_accuracy: 0.9683 - val_cost: 4.0344\n",
            "Epoch 99/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0736 - auc: 0.9948 - accuracy: 0.9779 - cost: 2.8202 - val_loss: 0.1132 - val_auc: 0.9895 - val_accuracy: 0.9676 - val_cost: 4.1435\n",
            "Epoch 100/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0742 - auc: 0.9946 - accuracy: 0.9776 - cost: 2.8630 - val_loss: 0.1133 - val_auc: 0.9895 - val_accuracy: 0.9672 - val_cost: 4.1005\n",
            "Epoch 101/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0735 - auc: 0.9948 - accuracy: 0.9778 - cost: 2.8403 - val_loss: 0.1147 - val_auc: 0.9893 - val_accuracy: 0.9673 - val_cost: 4.0708\n",
            "Epoch 102/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0738 - auc: 0.9947 - accuracy: 0.9779 - cost: 2.8368 - val_loss: 0.1158 - val_auc: 0.9894 - val_accuracy: 0.9681 - val_cost: 3.9550\n",
            "Epoch 103/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0738 - auc: 0.9947 - accuracy: 0.9779 - cost: 2.8252 - val_loss: 0.1146 - val_auc: 0.9896 - val_accuracy: 0.9682 - val_cost: 3.9484\n",
            "Epoch 104/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0730 - auc: 0.9950 - accuracy: 0.9779 - cost: 2.8160 - val_loss: 0.1149 - val_auc: 0.9896 - val_accuracy: 0.9690 - val_cost: 3.8029\n",
            "Epoch 105/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0732 - auc: 0.9949 - accuracy: 0.9779 - cost: 2.8345 - val_loss: 0.1152 - val_auc: 0.9895 - val_accuracy: 0.9683 - val_cost: 3.9120\n",
            "Epoch 106/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0721 - auc: 0.9950 - accuracy: 0.9781 - cost: 2.8002 - val_loss: 0.1133 - val_auc: 0.9895 - val_accuracy: 0.9688 - val_cost: 3.8690\n",
            "Epoch 107/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0723 - auc: 0.9948 - accuracy: 0.9787 - cost: 2.7257 - val_loss: 0.1129 - val_auc: 0.9896 - val_accuracy: 0.9682 - val_cost: 4.0278\n",
            "Epoch 108/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0719 - auc: 0.9950 - accuracy: 0.9783 - cost: 2.7770 - val_loss: 0.1156 - val_auc: 0.9895 - val_accuracy: 0.9673 - val_cost: 3.9815\n",
            "Epoch 109/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0733 - auc: 0.9948 - accuracy: 0.9783 - cost: 2.7735 - val_loss: 0.1147 - val_auc: 0.9896 - val_accuracy: 0.9686 - val_cost: 3.8988\n",
            "Epoch 110/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0715 - auc: 0.9950 - accuracy: 0.9789 - cost: 2.6860 - val_loss: 0.1140 - val_auc: 0.9896 - val_accuracy: 0.9697 - val_cost: 3.7831\n",
            "Epoch 111/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0714 - auc: 0.9950 - accuracy: 0.9786 - cost: 2.7334 - val_loss: 0.1159 - val_auc: 0.9894 - val_accuracy: 0.9675 - val_cost: 4.0642\n",
            "Epoch 112/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0714 - auc: 0.9950 - accuracy: 0.9792 - cost: 2.6682 - val_loss: 0.1146 - val_auc: 0.9896 - val_accuracy: 0.9678 - val_cost: 4.0741\n",
            "Epoch 113/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0712 - auc: 0.9950 - accuracy: 0.9787 - cost: 2.7292 - val_loss: 0.1133 - val_auc: 0.9897 - val_accuracy: 0.9674 - val_cost: 4.0642\n",
            "Epoch 114/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0712 - auc: 0.9950 - accuracy: 0.9790 - cost: 2.6875 - val_loss: 0.1142 - val_auc: 0.9896 - val_accuracy: 0.9681 - val_cost: 3.9848\n",
            "Epoch 115/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0704 - auc: 0.9951 - accuracy: 0.9788 - cost: 2.7079 - val_loss: 0.1159 - val_auc: 0.9894 - val_accuracy: 0.9685 - val_cost: 3.9021\n",
            "Epoch 116/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0698 - auc: 0.9951 - accuracy: 0.9790 - cost: 2.6817 - val_loss: 0.1136 - val_auc: 0.9896 - val_accuracy: 0.9690 - val_cost: 3.9352\n",
            "Epoch 117/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0697 - auc: 0.9951 - accuracy: 0.9795 - cost: 2.6219 - val_loss: 0.1148 - val_auc: 0.9894 - val_accuracy: 0.9683 - val_cost: 4.1237\n",
            "Epoch 118/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0694 - auc: 0.9952 - accuracy: 0.9795 - cost: 2.6204 - val_loss: 0.1143 - val_auc: 0.9897 - val_accuracy: 0.9681 - val_cost: 3.9253\n",
            "Epoch 119/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0704 - auc: 0.9951 - accuracy: 0.9785 - cost: 2.7442 - val_loss: 0.1146 - val_auc: 0.9897 - val_accuracy: 0.9672 - val_cost: 4.0079\n",
            "Epoch 120/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0697 - auc: 0.9951 - accuracy: 0.9794 - cost: 2.6389 - val_loss: 0.1132 - val_auc: 0.9896 - val_accuracy: 0.9686 - val_cost: 3.9583\n",
            "Epoch 121/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0694 - auc: 0.9952 - accuracy: 0.9794 - cost: 2.6350 - val_loss: 0.1125 - val_auc: 0.9898 - val_accuracy: 0.9684 - val_cost: 3.9451\n",
            "Epoch 122/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0691 - auc: 0.9953 - accuracy: 0.9796 - cost: 2.6103 - val_loss: 0.1143 - val_auc: 0.9895 - val_accuracy: 0.9692 - val_cost: 3.9286\n",
            "Epoch 123/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0693 - auc: 0.9953 - accuracy: 0.9797 - cost: 2.6030 - val_loss: 0.1159 - val_auc: 0.9892 - val_accuracy: 0.9686 - val_cost: 3.9683\n",
            "Epoch 124/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0684 - auc: 0.9954 - accuracy: 0.9794 - cost: 2.6427 - val_loss: 0.1135 - val_auc: 0.9897 - val_accuracy: 0.9681 - val_cost: 4.0377\n",
            "Epoch 125/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0692 - auc: 0.9953 - accuracy: 0.9792 - cost: 2.6532 - val_loss: 0.1115 - val_auc: 0.9900 - val_accuracy: 0.9689 - val_cost: 3.8790\n",
            "Epoch 126/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0682 - auc: 0.9953 - accuracy: 0.9798 - cost: 2.5791 - val_loss: 0.1151 - val_auc: 0.9896 - val_accuracy: 0.9685 - val_cost: 3.9153\n",
            "Epoch 127/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0681 - auc: 0.9953 - accuracy: 0.9801 - cost: 2.5336 - val_loss: 0.1137 - val_auc: 0.9897 - val_accuracy: 0.9683 - val_cost: 4.0807\n",
            "Epoch 128/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0683 - auc: 0.9952 - accuracy: 0.9800 - cost: 2.5490 - val_loss: 0.1132 - val_auc: 0.9898 - val_accuracy: 0.9696 - val_cost: 3.8062\n",
            "Epoch 129/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0688 - auc: 0.9952 - accuracy: 0.9794 - cost: 2.6289 - val_loss: 0.1143 - val_auc: 0.9897 - val_accuracy: 0.9686 - val_cost: 3.9914\n",
            "Epoch 130/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0683 - auc: 0.9952 - accuracy: 0.9798 - cost: 2.5849 - val_loss: 0.1159 - val_auc: 0.9896 - val_accuracy: 0.9692 - val_cost: 3.7169\n",
            "Epoch 131/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0674 - auc: 0.9954 - accuracy: 0.9801 - cost: 2.5463 - val_loss: 0.1158 - val_auc: 0.9895 - val_accuracy: 0.9687 - val_cost: 3.9517\n",
            "Epoch 132/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0687 - auc: 0.9953 - accuracy: 0.9797 - cost: 2.5961 - val_loss: 0.1166 - val_auc: 0.9893 - val_accuracy: 0.9674 - val_cost: 4.1766\n",
            "Epoch 133/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0670 - auc: 0.9955 - accuracy: 0.9800 - cost: 2.5517 - val_loss: 0.1157 - val_auc: 0.9895 - val_accuracy: 0.9690 - val_cost: 3.8426\n",
            "Epoch 134/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0676 - auc: 0.9953 - accuracy: 0.9801 - cost: 2.5544 - val_loss: 0.1132 - val_auc: 0.9896 - val_accuracy: 0.9688 - val_cost: 3.8790\n",
            "Epoch 135/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0672 - auc: 0.9954 - accuracy: 0.9802 - cost: 2.5432 - val_loss: 0.1157 - val_auc: 0.9899 - val_accuracy: 0.9678 - val_cost: 3.9980\n",
            "Epoch 136/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0674 - auc: 0.9954 - accuracy: 0.9800 - cost: 2.5625 - val_loss: 0.1154 - val_auc: 0.9898 - val_accuracy: 0.9689 - val_cost: 3.9286\n",
            "Epoch 137/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0668 - auc: 0.9954 - accuracy: 0.9801 - cost: 2.5367 - val_loss: 0.1149 - val_auc: 0.9894 - val_accuracy: 0.9696 - val_cost: 3.8492\n",
            "Epoch 138/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0666 - auc: 0.9956 - accuracy: 0.9806 - cost: 2.4776 - val_loss: 0.1143 - val_auc: 0.9897 - val_accuracy: 0.9685 - val_cost: 4.0046\n",
            "Epoch 139/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0670 - auc: 0.9955 - accuracy: 0.9803 - cost: 2.5328 - val_loss: 0.1136 - val_auc: 0.9897 - val_accuracy: 0.9694 - val_cost: 3.8360\n",
            "Epoch 140/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0664 - auc: 0.9955 - accuracy: 0.9801 - cost: 2.5413 - val_loss: 0.1171 - val_auc: 0.9896 - val_accuracy: 0.9697 - val_cost: 3.7599\n",
            "Epoch 141/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0666 - auc: 0.9955 - accuracy: 0.9801 - cost: 2.5448 - val_loss: 0.1148 - val_auc: 0.9897 - val_accuracy: 0.9701 - val_cost: 3.7500\n",
            "Epoch 142/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0665 - auc: 0.9955 - accuracy: 0.9801 - cost: 2.5502 - val_loss: 0.1147 - val_auc: 0.9897 - val_accuracy: 0.9692 - val_cost: 3.9649\n",
            "Epoch 143/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0662 - auc: 0.9955 - accuracy: 0.9804 - cost: 2.5100 - val_loss: 0.1141 - val_auc: 0.9899 - val_accuracy: 0.9690 - val_cost: 3.8757\n",
            "Epoch 144/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0662 - auc: 0.9955 - accuracy: 0.9805 - cost: 2.4934 - val_loss: 0.1163 - val_auc: 0.9895 - val_accuracy: 0.9683 - val_cost: 4.0509\n",
            "Epoch 145/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0654 - auc: 0.9956 - accuracy: 0.9807 - cost: 2.4680 - val_loss: 0.1170 - val_auc: 0.9896 - val_accuracy: 0.9686 - val_cost: 4.1005\n",
            "Epoch 146/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0656 - auc: 0.9955 - accuracy: 0.9805 - cost: 2.4888 - val_loss: 0.1154 - val_auc: 0.9897 - val_accuracy: 0.9694 - val_cost: 3.8657\n",
            "Epoch 147/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0655 - auc: 0.9955 - accuracy: 0.9803 - cost: 2.5324 - val_loss: 0.1171 - val_auc: 0.9897 - val_accuracy: 0.9680 - val_cost: 3.9683\n",
            "Epoch 148/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0660 - auc: 0.9955 - accuracy: 0.9803 - cost: 2.5208 - val_loss: 0.1147 - val_auc: 0.9892 - val_accuracy: 0.9688 - val_cost: 3.9385\n",
            "Epoch 149/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0660 - auc: 0.9955 - accuracy: 0.9803 - cost: 2.5170 - val_loss: 0.1153 - val_auc: 0.9895 - val_accuracy: 0.9681 - val_cost: 3.9484\n",
            "Epoch 150/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0650 - auc: 0.9957 - accuracy: 0.9806 - cost: 2.4792 - val_loss: 0.1172 - val_auc: 0.9893 - val_accuracy: 0.9694 - val_cost: 3.8492\n",
            "Epoch 151/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0655 - auc: 0.9956 - accuracy: 0.9807 - cost: 2.4734 - val_loss: 0.1207 - val_auc: 0.9890 - val_accuracy: 0.9672 - val_cost: 4.2130\n",
            "Epoch 152/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0646 - auc: 0.9957 - accuracy: 0.9807 - cost: 2.4657 - val_loss: 0.1171 - val_auc: 0.9892 - val_accuracy: 0.9690 - val_cost: 3.9616\n",
            "Epoch 153/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0641 - auc: 0.9957 - accuracy: 0.9810 - cost: 2.4279 - val_loss: 0.1178 - val_auc: 0.9893 - val_accuracy: 0.9688 - val_cost: 4.0509\n",
            "Epoch 154/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0648 - auc: 0.9956 - accuracy: 0.9807 - cost: 2.4707 - val_loss: 0.1165 - val_auc: 0.9897 - val_accuracy: 0.9691 - val_cost: 3.8459\n",
            "Epoch 155/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0639 - auc: 0.9959 - accuracy: 0.9808 - cost: 2.4387 - val_loss: 0.1178 - val_auc: 0.9895 - val_accuracy: 0.9692 - val_cost: 3.8261\n",
            "Epoch 156/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0645 - auc: 0.9957 - accuracy: 0.9812 - cost: 2.4101 - val_loss: 0.1159 - val_auc: 0.9894 - val_accuracy: 0.9689 - val_cost: 3.8426\n",
            "Epoch 157/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0651 - auc: 0.9957 - accuracy: 0.9811 - cost: 2.4186 - val_loss: 0.1190 - val_auc: 0.9895 - val_accuracy: 0.9688 - val_cost: 3.8029\n",
            "Epoch 158/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0645 - auc: 0.9958 - accuracy: 0.9809 - cost: 2.4510 - val_loss: 0.1162 - val_auc: 0.9895 - val_accuracy: 0.9688 - val_cost: 3.9187\n",
            "Epoch 159/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0650 - auc: 0.9957 - accuracy: 0.9809 - cost: 2.4498 - val_loss: 0.1153 - val_auc: 0.9895 - val_accuracy: 0.9687 - val_cost: 3.9352\n",
            "Epoch 160/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0644 - auc: 0.9957 - accuracy: 0.9811 - cost: 2.4159 - val_loss: 0.1166 - val_auc: 0.9897 - val_accuracy: 0.9691 - val_cost: 3.9021\n",
            "Epoch 161/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0642 - auc: 0.9958 - accuracy: 0.9812 - cost: 2.4120 - val_loss: 0.1178 - val_auc: 0.9895 - val_accuracy: 0.9690 - val_cost: 3.8856\n",
            "Epoch 162/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0643 - auc: 0.9957 - accuracy: 0.9809 - cost: 2.4522 - val_loss: 0.1146 - val_auc: 0.9895 - val_accuracy: 0.9692 - val_cost: 3.8525\n",
            "Epoch 163/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0642 - auc: 0.9957 - accuracy: 0.9810 - cost: 2.4244 - val_loss: 0.1175 - val_auc: 0.9895 - val_accuracy: 0.9690 - val_cost: 3.9187\n",
            "Epoch 164/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0641 - auc: 0.9957 - accuracy: 0.9809 - cost: 2.4541 - val_loss: 0.1185 - val_auc: 0.9890 - val_accuracy: 0.9686 - val_cost: 4.0179\n",
            "Epoch 165/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0636 - auc: 0.9958 - accuracy: 0.9814 - cost: 2.3951 - val_loss: 0.1180 - val_auc: 0.9894 - val_accuracy: 0.9683 - val_cost: 3.9286\n",
            "Epoch 166/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0646 - auc: 0.9957 - accuracy: 0.9808 - cost: 2.4549 - val_loss: 0.1177 - val_auc: 0.9894 - val_accuracy: 0.9685 - val_cost: 4.0179\n",
            "Epoch 167/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0637 - auc: 0.9958 - accuracy: 0.9814 - cost: 2.3873 - val_loss: 0.1181 - val_auc: 0.9893 - val_accuracy: 0.9678 - val_cost: 4.0476\n",
            "Epoch 168/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0629 - auc: 0.9959 - accuracy: 0.9812 - cost: 2.4039 - val_loss: 0.1174 - val_auc: 0.9894 - val_accuracy: 0.9694 - val_cost: 3.8790\n",
            "Epoch 169/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0631 - auc: 0.9958 - accuracy: 0.9813 - cost: 2.3943 - val_loss: 0.1188 - val_auc: 0.9893 - val_accuracy: 0.9681 - val_cost: 3.9550\n",
            "Epoch 170/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0629 - auc: 0.9958 - accuracy: 0.9813 - cost: 2.3889 - val_loss: 0.1162 - val_auc: 0.9895 - val_accuracy: 0.9680 - val_cost: 3.9716\n",
            "Epoch 171/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0633 - auc: 0.9959 - accuracy: 0.9817 - cost: 2.3488 - val_loss: 0.1187 - val_auc: 0.9892 - val_accuracy: 0.9689 - val_cost: 3.8657\n",
            "Epoch 172/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0645 - auc: 0.9956 - accuracy: 0.9811 - cost: 2.4120 - val_loss: 0.1172 - val_auc: 0.9893 - val_accuracy: 0.9694 - val_cost: 3.8228\n",
            "Epoch 173/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0626 - auc: 0.9958 - accuracy: 0.9813 - cost: 2.3816 - val_loss: 0.1182 - val_auc: 0.9894 - val_accuracy: 0.9690 - val_cost: 3.8492\n",
            "Epoch 174/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0621 - auc: 0.9959 - accuracy: 0.9817 - cost: 2.3391 - val_loss: 0.1189 - val_auc: 0.9893 - val_accuracy: 0.9692 - val_cost: 3.8657\n",
            "Epoch 175/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0615 - auc: 0.9960 - accuracy: 0.9815 - cost: 2.3681 - val_loss: 0.1204 - val_auc: 0.9892 - val_accuracy: 0.9694 - val_cost: 3.8591\n",
            "Epoch 176/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0629 - auc: 0.9959 - accuracy: 0.9811 - cost: 2.4117 - val_loss: 0.1175 - val_auc: 0.9893 - val_accuracy: 0.9683 - val_cost: 3.9914\n",
            "Epoch 177/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0624 - auc: 0.9958 - accuracy: 0.9812 - cost: 2.4097 - val_loss: 0.1181 - val_auc: 0.9894 - val_accuracy: 0.9692 - val_cost: 3.8558\n",
            "Epoch 178/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0620 - auc: 0.9959 - accuracy: 0.9818 - cost: 2.3326 - val_loss: 0.1175 - val_auc: 0.9894 - val_accuracy: 0.9702 - val_cost: 3.7864\n",
            "Epoch 179/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0627 - auc: 0.9958 - accuracy: 0.9813 - cost: 2.4070 - val_loss: 0.1183 - val_auc: 0.9893 - val_accuracy: 0.9703 - val_cost: 3.7467\n",
            "Epoch 180/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0619 - auc: 0.9960 - accuracy: 0.9816 - cost: 2.3588 - val_loss: 0.1219 - val_auc: 0.9886 - val_accuracy: 0.9680 - val_cost: 4.0079\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.1050 - auc: 0.9909 - accuracy: 0.9696 - cost: 3.7531\n",
            "500/500 [==============================] - 1s 962us/step\n",
            "fold train/predict time: 0:01:23.817172\n",
            "fold accuracy: 0.9695624709129333 - fold cost: 3.753124952316284\n",
            "x_train shape: (144000, 67)\n",
            "Epoch 1/1000\n",
            "120/120 [==============================] - 2s 6ms/step - loss: 0.5305 - auc: 0.7972 - accuracy: 0.7281 - cost: 36.2566 - val_loss: 0.3996 - val_auc: 0.8989 - val_accuracy: 0.8243 - val_cost: 22.8274\n",
            "Epoch 2/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.3518 - auc: 0.9213 - accuracy: 0.8488 - cost: 19.2631 - val_loss: 0.3196 - val_auc: 0.9350 - val_accuracy: 0.8646 - val_cost: 17.2553\n",
            "Epoch 3/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.3013 - auc: 0.9425 - accuracy: 0.8748 - cost: 15.8692 - val_loss: 0.2898 - val_auc: 0.9468 - val_accuracy: 0.8793 - val_cost: 15.2910\n",
            "Epoch 4/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2730 - auc: 0.9529 - accuracy: 0.8891 - cost: 14.0297 - val_loss: 0.2627 - val_auc: 0.9565 - val_accuracy: 0.8928 - val_cost: 13.3862\n",
            "Epoch 5/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2497 - auc: 0.9606 - accuracy: 0.9004 - cost: 12.5953 - val_loss: 0.2428 - val_auc: 0.9627 - val_accuracy: 0.9047 - val_cost: 11.9345\n",
            "Epoch 6/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2308 - auc: 0.9663 - accuracy: 0.9099 - cost: 11.3958 - val_loss: 0.2277 - val_auc: 0.9671 - val_accuracy: 0.9128 - val_cost: 10.9656\n",
            "Epoch 7/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2147 - auc: 0.9708 - accuracy: 0.9165 - cost: 10.5521 - val_loss: 0.2136 - val_auc: 0.9713 - val_accuracy: 0.9207 - val_cost: 9.7586\n",
            "Epoch 8/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.2021 - auc: 0.9739 - accuracy: 0.9223 - cost: 9.7978 - val_loss: 0.2028 - val_auc: 0.9745 - val_accuracy: 0.9242 - val_cost: 9.2163\n",
            "Epoch 9/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1916 - auc: 0.9765 - accuracy: 0.9272 - cost: 9.2006 - val_loss: 0.1911 - val_auc: 0.9768 - val_accuracy: 0.9282 - val_cost: 9.0146\n",
            "Epoch 10/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1823 - auc: 0.9786 - accuracy: 0.9319 - cost: 8.6165 - val_loss: 0.1826 - val_auc: 0.9784 - val_accuracy: 0.9330 - val_cost: 8.5979\n",
            "Epoch 11/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1737 - auc: 0.9805 - accuracy: 0.9358 - cost: 8.1184 - val_loss: 0.1765 - val_auc: 0.9798 - val_accuracy: 0.9363 - val_cost: 7.8968\n",
            "Epoch 12/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1679 - auc: 0.9816 - accuracy: 0.9386 - cost: 7.7708 - val_loss: 0.1708 - val_auc: 0.9809 - val_accuracy: 0.9395 - val_cost: 7.5728\n",
            "Epoch 13/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1615 - auc: 0.9829 - accuracy: 0.9410 - cost: 7.4792 - val_loss: 0.1666 - val_auc: 0.9818 - val_accuracy: 0.9418 - val_cost: 7.1825\n",
            "Epoch 14/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1562 - auc: 0.9838 - accuracy: 0.9439 - cost: 7.0945 - val_loss: 0.1610 - val_auc: 0.9827 - val_accuracy: 0.9453 - val_cost: 6.9775\n",
            "Epoch 15/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1528 - auc: 0.9845 - accuracy: 0.9452 - cost: 6.9390 - val_loss: 0.1579 - val_auc: 0.9834 - val_accuracy: 0.9445 - val_cost: 6.9841\n",
            "Epoch 16/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1480 - auc: 0.9853 - accuracy: 0.9472 - cost: 6.6991 - val_loss: 0.1550 - val_auc: 0.9840 - val_accuracy: 0.9459 - val_cost: 6.7791\n",
            "Epoch 17/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1460 - auc: 0.9855 - accuracy: 0.9484 - cost: 6.5440 - val_loss: 0.1541 - val_auc: 0.9841 - val_accuracy: 0.9461 - val_cost: 6.7890\n",
            "Epoch 18/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1419 - auc: 0.9863 - accuracy: 0.9504 - cost: 6.2843 - val_loss: 0.1529 - val_auc: 0.9842 - val_accuracy: 0.9464 - val_cost: 6.7659\n",
            "Epoch 19/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1401 - auc: 0.9866 - accuracy: 0.9507 - cost: 6.2577 - val_loss: 0.1505 - val_auc: 0.9847 - val_accuracy: 0.9472 - val_cost: 6.6402\n",
            "Epoch 20/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1384 - auc: 0.9868 - accuracy: 0.9519 - cost: 6.0922 - val_loss: 0.1472 - val_auc: 0.9852 - val_accuracy: 0.9490 - val_cost: 6.5311\n",
            "Epoch 21/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1346 - auc: 0.9875 - accuracy: 0.9536 - cost: 5.8866 - val_loss: 0.1468 - val_auc: 0.9851 - val_accuracy: 0.9498 - val_cost: 6.3492\n",
            "Epoch 22/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1323 - auc: 0.9879 - accuracy: 0.9541 - cost: 5.8164 - val_loss: 0.1454 - val_auc: 0.9855 - val_accuracy: 0.9496 - val_cost: 6.4749\n",
            "Epoch 23/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1303 - auc: 0.9882 - accuracy: 0.9556 - cost: 5.6370 - val_loss: 0.1427 - val_auc: 0.9859 - val_accuracy: 0.9517 - val_cost: 6.0880\n",
            "Epoch 24/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1282 - auc: 0.9885 - accuracy: 0.9561 - cost: 5.5652 - val_loss: 0.1433 - val_auc: 0.9858 - val_accuracy: 0.9515 - val_cost: 6.0483\n",
            "Epoch 25/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1278 - auc: 0.9885 - accuracy: 0.9564 - cost: 5.5201 - val_loss: 0.1410 - val_auc: 0.9861 - val_accuracy: 0.9529 - val_cost: 6.0615\n",
            "Epoch 26/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1246 - auc: 0.9889 - accuracy: 0.9580 - cost: 5.3183 - val_loss: 0.1411 - val_auc: 0.9861 - val_accuracy: 0.9536 - val_cost: 5.8300\n",
            "Epoch 27/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1234 - auc: 0.9893 - accuracy: 0.9582 - cost: 5.2978 - val_loss: 0.1396 - val_auc: 0.9861 - val_accuracy: 0.9546 - val_cost: 5.8267\n",
            "Epoch 28/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1219 - auc: 0.9894 - accuracy: 0.9588 - cost: 5.2265 - val_loss: 0.1394 - val_auc: 0.9862 - val_accuracy: 0.9534 - val_cost: 5.9524\n",
            "Epoch 29/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1201 - auc: 0.9897 - accuracy: 0.9594 - cost: 5.1485 - val_loss: 0.1386 - val_auc: 0.9862 - val_accuracy: 0.9551 - val_cost: 5.6415\n",
            "Epoch 30/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1193 - auc: 0.9897 - accuracy: 0.9598 - cost: 5.1061 - val_loss: 0.1364 - val_auc: 0.9867 - val_accuracy: 0.9554 - val_cost: 5.5589\n",
            "Epoch 31/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1177 - auc: 0.9900 - accuracy: 0.9607 - cost: 4.9730 - val_loss: 0.1351 - val_auc: 0.9868 - val_accuracy: 0.9573 - val_cost: 5.3803\n",
            "Epoch 32/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1160 - auc: 0.9902 - accuracy: 0.9611 - cost: 4.9302 - val_loss: 0.1335 - val_auc: 0.9869 - val_accuracy: 0.9572 - val_cost: 5.3604\n",
            "Epoch 33/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1150 - auc: 0.9902 - accuracy: 0.9617 - cost: 4.8584 - val_loss: 0.1334 - val_auc: 0.9871 - val_accuracy: 0.9576 - val_cost: 5.2414\n",
            "Epoch 34/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1124 - auc: 0.9906 - accuracy: 0.9626 - cost: 4.7504 - val_loss: 0.1338 - val_auc: 0.9870 - val_accuracy: 0.9566 - val_cost: 5.5159\n",
            "Epoch 35/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1120 - auc: 0.9907 - accuracy: 0.9630 - cost: 4.6902 - val_loss: 0.1314 - val_auc: 0.9872 - val_accuracy: 0.9590 - val_cost: 5.1720\n",
            "Epoch 36/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1118 - auc: 0.9907 - accuracy: 0.9636 - cost: 4.6211 - val_loss: 0.1333 - val_auc: 0.9873 - val_accuracy: 0.9576 - val_cost: 5.1786\n",
            "Epoch 37/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1099 - auc: 0.9910 - accuracy: 0.9639 - cost: 4.5810 - val_loss: 0.1314 - val_auc: 0.9873 - val_accuracy: 0.9591 - val_cost: 5.1290\n",
            "Epoch 38/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1082 - auc: 0.9912 - accuracy: 0.9648 - cost: 4.4583 - val_loss: 0.1322 - val_auc: 0.9870 - val_accuracy: 0.9593 - val_cost: 5.0033\n",
            "Epoch 39/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1072 - auc: 0.9912 - accuracy: 0.9649 - cost: 4.4587 - val_loss: 0.1289 - val_auc: 0.9876 - val_accuracy: 0.9613 - val_cost: 4.8909\n",
            "Epoch 40/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1063 - auc: 0.9914 - accuracy: 0.9653 - cost: 4.4063 - val_loss: 0.1277 - val_auc: 0.9877 - val_accuracy: 0.9603 - val_cost: 5.0959\n",
            "Epoch 41/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1046 - auc: 0.9916 - accuracy: 0.9657 - cost: 4.3519 - val_loss: 0.1291 - val_auc: 0.9875 - val_accuracy: 0.9599 - val_cost: 4.9702\n",
            "Epoch 42/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1043 - auc: 0.9916 - accuracy: 0.9663 - cost: 4.2901 - val_loss: 0.1283 - val_auc: 0.9874 - val_accuracy: 0.9608 - val_cost: 4.8710\n",
            "Epoch 43/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1035 - auc: 0.9917 - accuracy: 0.9666 - cost: 4.2531 - val_loss: 0.1254 - val_auc: 0.9879 - val_accuracy: 0.9620 - val_cost: 4.7784\n",
            "Epoch 44/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.1015 - auc: 0.9920 - accuracy: 0.9672 - cost: 4.1813 - val_loss: 0.1260 - val_auc: 0.9879 - val_accuracy: 0.9617 - val_cost: 4.7851\n",
            "Epoch 45/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1004 - auc: 0.9921 - accuracy: 0.9676 - cost: 4.1242 - val_loss: 0.1252 - val_auc: 0.9879 - val_accuracy: 0.9613 - val_cost: 4.9438\n",
            "Epoch 46/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0992 - auc: 0.9922 - accuracy: 0.9682 - cost: 4.0579 - val_loss: 0.1269 - val_auc: 0.9879 - val_accuracy: 0.9620 - val_cost: 4.5833\n",
            "Epoch 47/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0992 - auc: 0.9922 - accuracy: 0.9682 - cost: 4.0428 - val_loss: 0.1243 - val_auc: 0.9881 - val_accuracy: 0.9624 - val_cost: 4.7685\n",
            "Epoch 48/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0976 - auc: 0.9923 - accuracy: 0.9689 - cost: 3.9564 - val_loss: 0.1241 - val_auc: 0.9879 - val_accuracy: 0.9625 - val_cost: 4.5966\n",
            "Epoch 49/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0970 - auc: 0.9925 - accuracy: 0.9691 - cost: 3.9228 - val_loss: 0.1211 - val_auc: 0.9884 - val_accuracy: 0.9636 - val_cost: 4.7024\n",
            "Epoch 50/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0959 - auc: 0.9925 - accuracy: 0.9692 - cost: 3.9271 - val_loss: 0.1223 - val_auc: 0.9884 - val_accuracy: 0.9629 - val_cost: 4.5966\n",
            "Epoch 51/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0956 - auc: 0.9925 - accuracy: 0.9696 - cost: 3.8507 - val_loss: 0.1214 - val_auc: 0.9883 - val_accuracy: 0.9638 - val_cost: 4.4676\n",
            "Epoch 52/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0950 - auc: 0.9926 - accuracy: 0.9695 - cost: 3.8738 - val_loss: 0.1211 - val_auc: 0.9884 - val_accuracy: 0.9626 - val_cost: 4.8479\n",
            "Epoch 53/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0942 - auc: 0.9928 - accuracy: 0.9701 - cost: 3.8137 - val_loss: 0.1206 - val_auc: 0.9884 - val_accuracy: 0.9633 - val_cost: 4.6131\n",
            "Epoch 54/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0933 - auc: 0.9928 - accuracy: 0.9705 - cost: 3.7431 - val_loss: 0.1198 - val_auc: 0.9885 - val_accuracy: 0.9640 - val_cost: 4.5271\n",
            "Epoch 55/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0928 - auc: 0.9929 - accuracy: 0.9709 - cost: 3.7091 - val_loss: 0.1196 - val_auc: 0.9887 - val_accuracy: 0.9649 - val_cost: 4.5271\n",
            "Epoch 56/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0922 - auc: 0.9930 - accuracy: 0.9709 - cost: 3.7010 - val_loss: 0.1188 - val_auc: 0.9887 - val_accuracy: 0.9644 - val_cost: 4.3981\n",
            "Epoch 57/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0916 - auc: 0.9930 - accuracy: 0.9708 - cost: 3.7122 - val_loss: 0.1181 - val_auc: 0.9887 - val_accuracy: 0.9660 - val_cost: 4.2791\n",
            "Epoch 58/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0904 - auc: 0.9931 - accuracy: 0.9717 - cost: 3.5961 - val_loss: 0.1186 - val_auc: 0.9885 - val_accuracy: 0.9656 - val_cost: 4.2097\n",
            "Epoch 59/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0902 - auc: 0.9931 - accuracy: 0.9717 - cost: 3.6061 - val_loss: 0.1180 - val_auc: 0.9888 - val_accuracy: 0.9657 - val_cost: 4.2758\n",
            "Epoch 60/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0894 - auc: 0.9931 - accuracy: 0.9722 - cost: 3.5332 - val_loss: 0.1179 - val_auc: 0.9888 - val_accuracy: 0.9655 - val_cost: 4.3552\n",
            "Epoch 61/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0886 - auc: 0.9932 - accuracy: 0.9721 - cost: 3.5598 - val_loss: 0.1152 - val_auc: 0.9890 - val_accuracy: 0.9661 - val_cost: 4.2526\n",
            "Epoch 62/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0879 - auc: 0.9933 - accuracy: 0.9723 - cost: 3.5231 - val_loss: 0.1144 - val_auc: 0.9892 - val_accuracy: 0.9680 - val_cost: 3.9517\n",
            "Epoch 63/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0878 - auc: 0.9933 - accuracy: 0.9727 - cost: 3.4811 - val_loss: 0.1161 - val_auc: 0.9891 - val_accuracy: 0.9658 - val_cost: 4.3056\n",
            "Epoch 64/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0865 - auc: 0.9935 - accuracy: 0.9728 - cost: 3.4653 - val_loss: 0.1159 - val_auc: 0.9890 - val_accuracy: 0.9669 - val_cost: 4.1336\n",
            "Epoch 65/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0859 - auc: 0.9936 - accuracy: 0.9732 - cost: 3.4155 - val_loss: 0.1142 - val_auc: 0.9891 - val_accuracy: 0.9675 - val_cost: 4.0476\n",
            "Epoch 66/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0867 - auc: 0.9934 - accuracy: 0.9731 - cost: 3.4225 - val_loss: 0.1153 - val_auc: 0.9889 - val_accuracy: 0.9663 - val_cost: 4.2130\n",
            "Epoch 67/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0853 - auc: 0.9936 - accuracy: 0.9731 - cost: 3.4271 - val_loss: 0.1137 - val_auc: 0.9889 - val_accuracy: 0.9669 - val_cost: 4.1237\n",
            "Epoch 68/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0850 - auc: 0.9937 - accuracy: 0.9734 - cost: 3.4008 - val_loss: 0.1146 - val_auc: 0.9895 - val_accuracy: 0.9676 - val_cost: 4.0476\n",
            "Epoch 69/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0844 - auc: 0.9937 - accuracy: 0.9736 - cost: 3.3731 - val_loss: 0.1134 - val_auc: 0.9891 - val_accuracy: 0.9676 - val_cost: 4.0344\n",
            "Epoch 70/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0828 - auc: 0.9939 - accuracy: 0.9745 - cost: 3.2496 - val_loss: 0.1122 - val_auc: 0.9893 - val_accuracy: 0.9667 - val_cost: 4.1799\n",
            "Epoch 71/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0828 - auc: 0.9938 - accuracy: 0.9744 - cost: 3.2643 - val_loss: 0.1121 - val_auc: 0.9894 - val_accuracy: 0.9681 - val_cost: 3.9550\n",
            "Epoch 72/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0834 - auc: 0.9938 - accuracy: 0.9746 - cost: 3.2458 - val_loss: 0.1126 - val_auc: 0.9891 - val_accuracy: 0.9681 - val_cost: 4.0443\n",
            "Epoch 73/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0821 - auc: 0.9940 - accuracy: 0.9747 - cost: 3.2384 - val_loss: 0.1134 - val_auc: 0.9892 - val_accuracy: 0.9678 - val_cost: 3.9517\n",
            "Epoch 74/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0821 - auc: 0.9939 - accuracy: 0.9747 - cost: 3.2261 - val_loss: 0.1115 - val_auc: 0.9892 - val_accuracy: 0.9686 - val_cost: 3.9517\n",
            "Epoch 75/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0822 - auc: 0.9940 - accuracy: 0.9748 - cost: 3.1975 - val_loss: 0.1128 - val_auc: 0.9893 - val_accuracy: 0.9676 - val_cost: 4.1303\n",
            "Epoch 76/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0812 - auc: 0.9940 - accuracy: 0.9754 - cost: 3.1431 - val_loss: 0.1110 - val_auc: 0.9894 - val_accuracy: 0.9688 - val_cost: 3.8856\n",
            "Epoch 77/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0807 - auc: 0.9940 - accuracy: 0.9753 - cost: 3.1358 - val_loss: 0.1116 - val_auc: 0.9892 - val_accuracy: 0.9685 - val_cost: 3.9550\n",
            "Epoch 78/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0803 - auc: 0.9941 - accuracy: 0.9754 - cost: 3.1377 - val_loss: 0.1131 - val_auc: 0.9890 - val_accuracy: 0.9678 - val_cost: 3.9649\n",
            "Epoch 79/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0797 - auc: 0.9941 - accuracy: 0.9754 - cost: 3.1539 - val_loss: 0.1119 - val_auc: 0.9893 - val_accuracy: 0.9681 - val_cost: 4.0112\n",
            "Epoch 80/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0787 - auc: 0.9943 - accuracy: 0.9761 - cost: 3.0613 - val_loss: 0.1108 - val_auc: 0.9896 - val_accuracy: 0.9683 - val_cost: 3.9947\n",
            "Epoch 81/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0798 - auc: 0.9942 - accuracy: 0.9756 - cost: 3.1119 - val_loss: 0.1107 - val_auc: 0.9891 - val_accuracy: 0.9696 - val_cost: 3.7632\n",
            "Epoch 82/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0788 - auc: 0.9943 - accuracy: 0.9759 - cost: 3.0883 - val_loss: 0.1102 - val_auc: 0.9893 - val_accuracy: 0.9694 - val_cost: 3.8194\n",
            "Epoch 83/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0791 - auc: 0.9942 - accuracy: 0.9754 - cost: 3.1481 - val_loss: 0.1110 - val_auc: 0.9894 - val_accuracy: 0.9687 - val_cost: 4.0013\n",
            "Epoch 84/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0779 - auc: 0.9943 - accuracy: 0.9764 - cost: 3.0062 - val_loss: 0.1100 - val_auc: 0.9894 - val_accuracy: 0.9688 - val_cost: 3.9782\n",
            "Epoch 85/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0782 - auc: 0.9944 - accuracy: 0.9763 - cost: 3.0397 - val_loss: 0.1106 - val_auc: 0.9893 - val_accuracy: 0.9692 - val_cost: 3.8790\n",
            "Epoch 86/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0776 - auc: 0.9943 - accuracy: 0.9761 - cost: 3.0532 - val_loss: 0.1099 - val_auc: 0.9893 - val_accuracy: 0.9694 - val_cost: 3.9120\n",
            "Epoch 87/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0785 - auc: 0.9942 - accuracy: 0.9757 - cost: 3.0864 - val_loss: 0.1111 - val_auc: 0.9895 - val_accuracy: 0.9694 - val_cost: 3.9319\n",
            "Epoch 88/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0768 - auc: 0.9944 - accuracy: 0.9763 - cost: 3.0208 - val_loss: 0.1100 - val_auc: 0.9894 - val_accuracy: 0.9686 - val_cost: 4.0245\n",
            "Epoch 89/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0773 - auc: 0.9944 - accuracy: 0.9766 - cost: 2.9923 - val_loss: 0.1085 - val_auc: 0.9896 - val_accuracy: 0.9690 - val_cost: 3.9616\n",
            "Epoch 90/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0759 - auc: 0.9945 - accuracy: 0.9773 - cost: 2.8997 - val_loss: 0.1100 - val_auc: 0.9893 - val_accuracy: 0.9690 - val_cost: 3.8955\n",
            "Epoch 91/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0763 - auc: 0.9945 - accuracy: 0.9770 - cost: 2.9267 - val_loss: 0.1105 - val_auc: 0.9893 - val_accuracy: 0.9686 - val_cost: 3.9319\n",
            "Epoch 92/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0758 - auc: 0.9946 - accuracy: 0.9770 - cost: 2.9421 - val_loss: 0.1130 - val_auc: 0.9893 - val_accuracy: 0.9681 - val_cost: 3.9187\n",
            "Epoch 93/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0752 - auc: 0.9945 - accuracy: 0.9770 - cost: 2.9394 - val_loss: 0.1093 - val_auc: 0.9895 - val_accuracy: 0.9689 - val_cost: 3.9021\n",
            "Epoch 94/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0748 - auc: 0.9947 - accuracy: 0.9774 - cost: 2.8908 - val_loss: 0.1105 - val_auc: 0.9895 - val_accuracy: 0.9700 - val_cost: 3.6938\n",
            "Epoch 95/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0751 - auc: 0.9947 - accuracy: 0.9770 - cost: 2.9321 - val_loss: 0.1098 - val_auc: 0.9895 - val_accuracy: 0.9697 - val_cost: 3.8393\n",
            "Epoch 96/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0751 - auc: 0.9946 - accuracy: 0.9770 - cost: 2.9309 - val_loss: 0.1110 - val_auc: 0.9895 - val_accuracy: 0.9688 - val_cost: 4.0476\n",
            "Epoch 97/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0744 - auc: 0.9946 - accuracy: 0.9776 - cost: 2.8615 - val_loss: 0.1091 - val_auc: 0.9895 - val_accuracy: 0.9697 - val_cost: 3.8757\n",
            "Epoch 98/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0743 - auc: 0.9946 - accuracy: 0.9771 - cost: 2.9201 - val_loss: 0.1100 - val_auc: 0.9896 - val_accuracy: 0.9690 - val_cost: 3.8095\n",
            "Epoch 99/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0745 - auc: 0.9947 - accuracy: 0.9776 - cost: 2.8561 - val_loss: 0.1093 - val_auc: 0.9895 - val_accuracy: 0.9697 - val_cost: 3.7533\n",
            "Epoch 100/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0730 - auc: 0.9949 - accuracy: 0.9774 - cost: 2.8754 - val_loss: 0.1099 - val_auc: 0.9894 - val_accuracy: 0.9691 - val_cost: 3.9021\n",
            "Epoch 101/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0738 - auc: 0.9948 - accuracy: 0.9775 - cost: 2.8657 - val_loss: 0.1115 - val_auc: 0.9894 - val_accuracy: 0.9684 - val_cost: 4.0311\n",
            "Epoch 102/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0730 - auc: 0.9949 - accuracy: 0.9776 - cost: 2.8546 - val_loss: 0.1084 - val_auc: 0.9896 - val_accuracy: 0.9699 - val_cost: 3.8459\n",
            "Epoch 103/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0726 - auc: 0.9949 - accuracy: 0.9780 - cost: 2.8056 - val_loss: 0.1118 - val_auc: 0.9894 - val_accuracy: 0.9701 - val_cost: 3.7467\n",
            "Epoch 104/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0733 - auc: 0.9947 - accuracy: 0.9777 - cost: 2.8492 - val_loss: 0.1111 - val_auc: 0.9894 - val_accuracy: 0.9699 - val_cost: 3.7434\n",
            "Epoch 105/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0724 - auc: 0.9949 - accuracy: 0.9783 - cost: 2.7674 - val_loss: 0.1097 - val_auc: 0.9897 - val_accuracy: 0.9697 - val_cost: 3.8459\n",
            "Epoch 106/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0726 - auc: 0.9948 - accuracy: 0.9781 - cost: 2.8113 - val_loss: 0.1109 - val_auc: 0.9894 - val_accuracy: 0.9685 - val_cost: 3.9517\n",
            "Epoch 107/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0734 - auc: 0.9948 - accuracy: 0.9776 - cost: 2.8654 - val_loss: 0.1107 - val_auc: 0.9894 - val_accuracy: 0.9694 - val_cost: 3.9021\n",
            "Epoch 108/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0718 - auc: 0.9951 - accuracy: 0.9780 - cost: 2.8110 - val_loss: 0.1110 - val_auc: 0.9896 - val_accuracy: 0.9697 - val_cost: 3.8426\n",
            "Epoch 109/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0724 - auc: 0.9949 - accuracy: 0.9781 - cost: 2.7978 - val_loss: 0.1109 - val_auc: 0.9896 - val_accuracy: 0.9695 - val_cost: 3.7930\n",
            "Epoch 110/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0713 - auc: 0.9949 - accuracy: 0.9788 - cost: 2.7114 - val_loss: 0.1096 - val_auc: 0.9896 - val_accuracy: 0.9700 - val_cost: 3.7996\n",
            "Epoch 111/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0714 - auc: 0.9949 - accuracy: 0.9782 - cost: 2.7867 - val_loss: 0.1109 - val_auc: 0.9896 - val_accuracy: 0.9702 - val_cost: 3.8128\n",
            "Epoch 112/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0706 - auc: 0.9950 - accuracy: 0.9790 - cost: 2.6875 - val_loss: 0.1095 - val_auc: 0.9895 - val_accuracy: 0.9698 - val_cost: 3.8360\n",
            "Epoch 113/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0713 - auc: 0.9950 - accuracy: 0.9786 - cost: 2.7346 - val_loss: 0.1115 - val_auc: 0.9894 - val_accuracy: 0.9684 - val_cost: 3.8657\n",
            "Epoch 114/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0715 - auc: 0.9949 - accuracy: 0.9785 - cost: 2.7473 - val_loss: 0.1091 - val_auc: 0.9898 - val_accuracy: 0.9699 - val_cost: 3.9087\n",
            "Epoch 115/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0713 - auc: 0.9950 - accuracy: 0.9783 - cost: 2.7762 - val_loss: 0.1089 - val_auc: 0.9899 - val_accuracy: 0.9700 - val_cost: 3.8194\n",
            "Epoch 116/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0703 - auc: 0.9950 - accuracy: 0.9790 - cost: 2.6755 - val_loss: 0.1089 - val_auc: 0.9899 - val_accuracy: 0.9701 - val_cost: 3.8360\n",
            "Epoch 117/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0715 - auc: 0.9949 - accuracy: 0.9787 - cost: 2.7222 - val_loss: 0.1100 - val_auc: 0.9895 - val_accuracy: 0.9701 - val_cost: 3.7798\n",
            "Epoch 118/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0707 - auc: 0.9950 - accuracy: 0.9791 - cost: 2.6559 - val_loss: 0.1107 - val_auc: 0.9896 - val_accuracy: 0.9694 - val_cost: 3.8360\n",
            "Epoch 119/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0705 - auc: 0.9952 - accuracy: 0.9789 - cost: 2.6979 - val_loss: 0.1106 - val_auc: 0.9896 - val_accuracy: 0.9696 - val_cost: 3.8360\n",
            "Epoch 120/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0703 - auc: 0.9951 - accuracy: 0.9789 - cost: 2.6902 - val_loss: 0.1089 - val_auc: 0.9899 - val_accuracy: 0.9694 - val_cost: 3.9087\n",
            "Epoch 121/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0701 - auc: 0.9951 - accuracy: 0.9786 - cost: 2.7307 - val_loss: 0.1115 - val_auc: 0.9896 - val_accuracy: 0.9693 - val_cost: 3.9749\n",
            "Epoch 122/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0699 - auc: 0.9951 - accuracy: 0.9791 - cost: 2.6786 - val_loss: 0.1102 - val_auc: 0.9899 - val_accuracy: 0.9694 - val_cost: 3.8558\n",
            "Epoch 123/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0699 - auc: 0.9951 - accuracy: 0.9789 - cost: 2.6975 - val_loss: 0.1097 - val_auc: 0.9897 - val_accuracy: 0.9696 - val_cost: 3.9120\n",
            "Epoch 124/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0690 - auc: 0.9952 - accuracy: 0.9793 - cost: 2.6528 - val_loss: 0.1114 - val_auc: 0.9898 - val_accuracy: 0.9689 - val_cost: 3.9583\n",
            "Epoch 125/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0688 - auc: 0.9953 - accuracy: 0.9790 - cost: 2.6736 - val_loss: 0.1112 - val_auc: 0.9895 - val_accuracy: 0.9699 - val_cost: 3.8161\n",
            "Epoch 126/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0690 - auc: 0.9953 - accuracy: 0.9791 - cost: 2.6809 - val_loss: 0.1115 - val_auc: 0.9897 - val_accuracy: 0.9687 - val_cost: 4.0079\n",
            "Epoch 127/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0682 - auc: 0.9953 - accuracy: 0.9794 - cost: 2.6385 - val_loss: 0.1119 - val_auc: 0.9897 - val_accuracy: 0.9699 - val_cost: 3.8062\n",
            "Epoch 128/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0690 - auc: 0.9953 - accuracy: 0.9794 - cost: 2.6316 - val_loss: 0.1126 - val_auc: 0.9898 - val_accuracy: 0.9690 - val_cost: 3.8624\n",
            "Epoch 129/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0681 - auc: 0.9953 - accuracy: 0.9797 - cost: 2.5795 - val_loss: 0.1114 - val_auc: 0.9896 - val_accuracy: 0.9698 - val_cost: 3.9319\n",
            "Epoch 130/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0686 - auc: 0.9953 - accuracy: 0.9792 - cost: 2.6443 - val_loss: 0.1118 - val_auc: 0.9896 - val_accuracy: 0.9694 - val_cost: 3.9120\n",
            "Epoch 131/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0682 - auc: 0.9953 - accuracy: 0.9791 - cost: 2.6728 - val_loss: 0.1104 - val_auc: 0.9899 - val_accuracy: 0.9699 - val_cost: 3.8690\n",
            "Epoch 132/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0685 - auc: 0.9953 - accuracy: 0.9797 - cost: 2.5899 - val_loss: 0.1136 - val_auc: 0.9896 - val_accuracy: 0.9686 - val_cost: 3.9418\n",
            "Epoch 133/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0675 - auc: 0.9954 - accuracy: 0.9795 - cost: 2.6250 - val_loss: 0.1120 - val_auc: 0.9897 - val_accuracy: 0.9698 - val_cost: 3.8889\n",
            "Epoch 134/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0687 - auc: 0.9953 - accuracy: 0.9795 - cost: 2.6285 - val_loss: 0.1114 - val_auc: 0.9899 - val_accuracy: 0.9689 - val_cost: 3.9484\n",
            "Epoch 135/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0673 - auc: 0.9954 - accuracy: 0.9797 - cost: 2.5934 - val_loss: 0.1118 - val_auc: 0.9898 - val_accuracy: 0.9689 - val_cost: 3.9616\n",
            "Epoch 136/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0681 - auc: 0.9954 - accuracy: 0.9796 - cost: 2.6073 - val_loss: 0.1123 - val_auc: 0.9896 - val_accuracy: 0.9694 - val_cost: 3.9716\n",
            "Epoch 137/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0674 - auc: 0.9954 - accuracy: 0.9797 - cost: 2.5953 - val_loss: 0.1121 - val_auc: 0.9897 - val_accuracy: 0.9696 - val_cost: 3.9583\n",
            "Epoch 138/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0670 - auc: 0.9955 - accuracy: 0.9799 - cost: 2.5644 - val_loss: 0.1108 - val_auc: 0.9896 - val_accuracy: 0.9699 - val_cost: 3.8459\n",
            "Epoch 139/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0668 - auc: 0.9955 - accuracy: 0.9798 - cost: 2.5895 - val_loss: 0.1093 - val_auc: 0.9901 - val_accuracy: 0.9696 - val_cost: 3.9418\n",
            "Epoch 140/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0667 - auc: 0.9955 - accuracy: 0.9797 - cost: 2.5883 - val_loss: 0.1115 - val_auc: 0.9898 - val_accuracy: 0.9686 - val_cost: 3.9683\n",
            "Epoch 141/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0666 - auc: 0.9954 - accuracy: 0.9805 - cost: 2.4961 - val_loss: 0.1131 - val_auc: 0.9896 - val_accuracy: 0.9689 - val_cost: 3.9716\n",
            "Epoch 142/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0660 - auc: 0.9956 - accuracy: 0.9804 - cost: 2.5019 - val_loss: 0.1117 - val_auc: 0.9900 - val_accuracy: 0.9692 - val_cost: 3.9616\n",
            "Epoch 143/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0668 - auc: 0.9954 - accuracy: 0.9806 - cost: 2.4873 - val_loss: 0.1126 - val_auc: 0.9897 - val_accuracy: 0.9700 - val_cost: 3.8889\n",
            "Epoch 144/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0665 - auc: 0.9955 - accuracy: 0.9800 - cost: 2.5490 - val_loss: 0.1123 - val_auc: 0.9897 - val_accuracy: 0.9697 - val_cost: 3.8095\n",
            "Epoch 145/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0664 - auc: 0.9955 - accuracy: 0.9800 - cost: 2.5733 - val_loss: 0.1121 - val_auc: 0.9896 - val_accuracy: 0.9694 - val_cost: 4.0278\n",
            "Epoch 146/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0666 - auc: 0.9954 - accuracy: 0.9801 - cost: 2.5444 - val_loss: 0.1128 - val_auc: 0.9895 - val_accuracy: 0.9693 - val_cost: 3.9749\n",
            "Epoch 147/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0662 - auc: 0.9956 - accuracy: 0.9803 - cost: 2.5131 - val_loss: 0.1118 - val_auc: 0.9898 - val_accuracy: 0.9700 - val_cost: 3.8790\n",
            "Epoch 148/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0661 - auc: 0.9956 - accuracy: 0.9798 - cost: 2.5787 - val_loss: 0.1129 - val_auc: 0.9895 - val_accuracy: 0.9688 - val_cost: 3.9054\n",
            "Epoch 149/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0661 - auc: 0.9955 - accuracy: 0.9804 - cost: 2.5089 - val_loss: 0.1125 - val_auc: 0.9897 - val_accuracy: 0.9706 - val_cost: 3.7963\n",
            "Epoch 150/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0661 - auc: 0.9955 - accuracy: 0.9801 - cost: 2.5332 - val_loss: 0.1171 - val_auc: 0.9894 - val_accuracy: 0.9691 - val_cost: 3.8360\n",
            "Epoch 151/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0658 - auc: 0.9955 - accuracy: 0.9807 - cost: 2.4699 - val_loss: 0.1111 - val_auc: 0.9900 - val_accuracy: 0.9695 - val_cost: 3.9319\n",
            "Epoch 152/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0653 - auc: 0.9956 - accuracy: 0.9805 - cost: 2.5039 - val_loss: 0.1111 - val_auc: 0.9899 - val_accuracy: 0.9700 - val_cost: 3.7930\n",
            "Epoch 153/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0657 - auc: 0.9956 - accuracy: 0.9801 - cost: 2.5417 - val_loss: 0.1135 - val_auc: 0.9899 - val_accuracy: 0.9699 - val_cost: 3.9649\n",
            "Epoch 154/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0650 - auc: 0.9956 - accuracy: 0.9806 - cost: 2.4711 - val_loss: 0.1120 - val_auc: 0.9897 - val_accuracy: 0.9698 - val_cost: 3.8988\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.1055 - auc: 0.9905 - accuracy: 0.9703 - cost: 3.7469\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:01:15.901574\n",
            "fold accuracy: 0.9702500104904175 - fold cost: 3.746875047683716\n",
            "x_train shape: (144000, 67)\n",
            "Epoch 1/1000\n",
            "120/120 [==============================] - 2s 6ms/step - loss: 0.5329 - auc: 0.7947 - accuracy: 0.7258 - cost: 36.5664 - val_loss: 0.4023 - val_auc: 0.8973 - val_accuracy: 0.8249 - val_cost: 22.0403\n",
            "Epoch 2/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.3524 - auc: 0.9209 - accuracy: 0.8481 - cost: 19.3711 - val_loss: 0.3195 - val_auc: 0.9355 - val_accuracy: 0.8640 - val_cost: 16.6567\n",
            "Epoch 3/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.3027 - auc: 0.9420 - accuracy: 0.8746 - cost: 15.8654 - val_loss: 0.2882 - val_auc: 0.9476 - val_accuracy: 0.8817 - val_cost: 14.7751\n",
            "Epoch 4/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2740 - auc: 0.9526 - accuracy: 0.8887 - cost: 14.0911 - val_loss: 0.2632 - val_auc: 0.9565 - val_accuracy: 0.8944 - val_cost: 12.9464\n",
            "Epoch 5/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2511 - auc: 0.9603 - accuracy: 0.8995 - cost: 12.7141 - val_loss: 0.2438 - val_auc: 0.9626 - val_accuracy: 0.9023 - val_cost: 12.1925\n",
            "Epoch 6/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2322 - auc: 0.9659 - accuracy: 0.9084 - cost: 11.5783 - val_loss: 0.2264 - val_auc: 0.9675 - val_accuracy: 0.9135 - val_cost: 10.7341\n",
            "Epoch 7/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2152 - auc: 0.9707 - accuracy: 0.9165 - cost: 10.5498 - val_loss: 0.2126 - val_auc: 0.9716 - val_accuracy: 0.9210 - val_cost: 9.6495\n",
            "Epoch 8/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2027 - auc: 0.9739 - accuracy: 0.9221 - cost: 9.8318 - val_loss: 0.1988 - val_auc: 0.9748 - val_accuracy: 0.9271 - val_cost: 9.0873\n",
            "Epoch 9/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1901 - auc: 0.9769 - accuracy: 0.9279 - cost: 9.1127 - val_loss: 0.1908 - val_auc: 0.9766 - val_accuracy: 0.9306 - val_cost: 8.6210\n",
            "Epoch 10/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1815 - auc: 0.9789 - accuracy: 0.9322 - cost: 8.5610 - val_loss: 0.1829 - val_auc: 0.9782 - val_accuracy: 0.9342 - val_cost: 8.1911\n",
            "Epoch 11/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1730 - auc: 0.9806 - accuracy: 0.9366 - cost: 8.0185 - val_loss: 0.1757 - val_auc: 0.9797 - val_accuracy: 0.9384 - val_cost: 7.6058\n",
            "Epoch 12/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1670 - auc: 0.9817 - accuracy: 0.9386 - cost: 7.7828 - val_loss: 0.1698 - val_auc: 0.9809 - val_accuracy: 0.9398 - val_cost: 7.5595\n",
            "Epoch 13/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1615 - auc: 0.9828 - accuracy: 0.9410 - cost: 7.4753 - val_loss: 0.1671 - val_auc: 0.9815 - val_accuracy: 0.9419 - val_cost: 7.4537\n",
            "Epoch 14/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1571 - auc: 0.9837 - accuracy: 0.9434 - cost: 7.1686 - val_loss: 0.1628 - val_auc: 0.9824 - val_accuracy: 0.9435 - val_cost: 6.9048\n",
            "Epoch 15/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1531 - auc: 0.9843 - accuracy: 0.9451 - cost: 6.9452 - val_loss: 0.1581 - val_auc: 0.9831 - val_accuracy: 0.9445 - val_cost: 6.9808\n",
            "Epoch 16/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1492 - auc: 0.9851 - accuracy: 0.9470 - cost: 6.7064 - val_loss: 0.1574 - val_auc: 0.9833 - val_accuracy: 0.9460 - val_cost: 6.6435\n",
            "Epoch 17/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1457 - auc: 0.9857 - accuracy: 0.9488 - cost: 6.4807 - val_loss: 0.1529 - val_auc: 0.9842 - val_accuracy: 0.9470 - val_cost: 6.6303\n",
            "Epoch 18/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1424 - auc: 0.9863 - accuracy: 0.9500 - cost: 6.3287 - val_loss: 0.1520 - val_auc: 0.9842 - val_accuracy: 0.9479 - val_cost: 6.5509\n",
            "Epoch 19/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1396 - auc: 0.9867 - accuracy: 0.9516 - cost: 6.1454 - val_loss: 0.1492 - val_auc: 0.9847 - val_accuracy: 0.9508 - val_cost: 6.2533\n",
            "Epoch 20/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1371 - auc: 0.9871 - accuracy: 0.9524 - cost: 6.0417 - val_loss: 0.1486 - val_auc: 0.9847 - val_accuracy: 0.9508 - val_cost: 6.1739\n",
            "Epoch 21/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1354 - auc: 0.9873 - accuracy: 0.9534 - cost: 5.9035 - val_loss: 0.1468 - val_auc: 0.9851 - val_accuracy: 0.9521 - val_cost: 5.9722\n",
            "Epoch 22/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1335 - auc: 0.9877 - accuracy: 0.9542 - cost: 5.8179 - val_loss: 0.1468 - val_auc: 0.9854 - val_accuracy: 0.9519 - val_cost: 5.8730\n",
            "Epoch 23/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1299 - auc: 0.9883 - accuracy: 0.9552 - cost: 5.6863 - val_loss: 0.1454 - val_auc: 0.9856 - val_accuracy: 0.9524 - val_cost: 5.7474\n",
            "Epoch 24/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1286 - auc: 0.9885 - accuracy: 0.9559 - cost: 5.5961 - val_loss: 0.1438 - val_auc: 0.9856 - val_accuracy: 0.9523 - val_cost: 5.8598\n",
            "Epoch 25/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1275 - auc: 0.9885 - accuracy: 0.9565 - cost: 5.5239 - val_loss: 0.1446 - val_auc: 0.9855 - val_accuracy: 0.9533 - val_cost: 5.6448\n",
            "Epoch 26/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1255 - auc: 0.9888 - accuracy: 0.9572 - cost: 5.4441 - val_loss: 0.1413 - val_auc: 0.9857 - val_accuracy: 0.9548 - val_cost: 5.5820\n",
            "Epoch 27/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1240 - auc: 0.9890 - accuracy: 0.9580 - cost: 5.3476 - val_loss: 0.1389 - val_auc: 0.9861 - val_accuracy: 0.9558 - val_cost: 5.5390\n",
            "Epoch 28/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1220 - auc: 0.9894 - accuracy: 0.9587 - cost: 5.2539 - val_loss: 0.1391 - val_auc: 0.9860 - val_accuracy: 0.9560 - val_cost: 5.5126\n",
            "Epoch 29/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1208 - auc: 0.9895 - accuracy: 0.9596 - cost: 5.1617 - val_loss: 0.1390 - val_auc: 0.9863 - val_accuracy: 0.9551 - val_cost: 5.4200\n",
            "Epoch 30/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1196 - auc: 0.9896 - accuracy: 0.9596 - cost: 5.1416 - val_loss: 0.1382 - val_auc: 0.9861 - val_accuracy: 0.9572 - val_cost: 5.2480\n",
            "Epoch 31/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1181 - auc: 0.9898 - accuracy: 0.9599 - cost: 5.1053 - val_loss: 0.1368 - val_auc: 0.9863 - val_accuracy: 0.9572 - val_cost: 5.3472\n",
            "Epoch 32/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1164 - auc: 0.9901 - accuracy: 0.9614 - cost: 4.9171 - val_loss: 0.1374 - val_auc: 0.9864 - val_accuracy: 0.9565 - val_cost: 5.4134\n",
            "Epoch 33/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1160 - auc: 0.9902 - accuracy: 0.9613 - cost: 4.9201 - val_loss: 0.1354 - val_auc: 0.9866 - val_accuracy: 0.9581 - val_cost: 5.2183\n",
            "Epoch 34/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1139 - auc: 0.9904 - accuracy: 0.9626 - cost: 4.7519 - val_loss: 0.1358 - val_auc: 0.9865 - val_accuracy: 0.9569 - val_cost: 5.3042\n",
            "Epoch 35/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1136 - auc: 0.9905 - accuracy: 0.9623 - cost: 4.8002 - val_loss: 0.1332 - val_auc: 0.9867 - val_accuracy: 0.9586 - val_cost: 5.1389\n",
            "Epoch 36/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1127 - auc: 0.9905 - accuracy: 0.9630 - cost: 4.7180 - val_loss: 0.1332 - val_auc: 0.9869 - val_accuracy: 0.9589 - val_cost: 5.1521\n",
            "Epoch 37/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.1115 - auc: 0.9908 - accuracy: 0.9634 - cost: 4.6647 - val_loss: 0.1329 - val_auc: 0.9869 - val_accuracy: 0.9601 - val_cost: 4.9372\n",
            "Epoch 38/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1103 - auc: 0.9909 - accuracy: 0.9637 - cost: 4.6123 - val_loss: 0.1318 - val_auc: 0.9870 - val_accuracy: 0.9590 - val_cost: 5.1587\n",
            "Epoch 39/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1088 - auc: 0.9910 - accuracy: 0.9642 - cost: 4.5652 - val_loss: 0.1318 - val_auc: 0.9869 - val_accuracy: 0.9598 - val_cost: 5.0331\n",
            "Epoch 40/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1077 - auc: 0.9912 - accuracy: 0.9646 - cost: 4.5154 - val_loss: 0.1319 - val_auc: 0.9869 - val_accuracy: 0.9594 - val_cost: 5.0265\n",
            "Epoch 41/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1067 - auc: 0.9913 - accuracy: 0.9648 - cost: 4.4834 - val_loss: 0.1306 - val_auc: 0.9872 - val_accuracy: 0.9606 - val_cost: 4.9074\n",
            "Epoch 42/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1056 - auc: 0.9915 - accuracy: 0.9653 - cost: 4.4205 - val_loss: 0.1303 - val_auc: 0.9871 - val_accuracy: 0.9594 - val_cost: 5.1058\n",
            "Epoch 43/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1056 - auc: 0.9914 - accuracy: 0.9654 - cost: 4.4063 - val_loss: 0.1291 - val_auc: 0.9873 - val_accuracy: 0.9619 - val_cost: 4.6362\n",
            "Epoch 44/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1047 - auc: 0.9916 - accuracy: 0.9659 - cost: 4.3515 - val_loss: 0.1283 - val_auc: 0.9875 - val_accuracy: 0.9610 - val_cost: 4.7619\n",
            "Epoch 45/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1034 - auc: 0.9917 - accuracy: 0.9666 - cost: 4.2554 - val_loss: 0.1272 - val_auc: 0.9877 - val_accuracy: 0.9615 - val_cost: 4.7288\n",
            "Epoch 46/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1036 - auc: 0.9917 - accuracy: 0.9665 - cost: 4.2593 - val_loss: 0.1282 - val_auc: 0.9874 - val_accuracy: 0.9617 - val_cost: 4.7685\n",
            "Epoch 47/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1027 - auc: 0.9918 - accuracy: 0.9667 - cost: 4.2434 - val_loss: 0.1285 - val_auc: 0.9874 - val_accuracy: 0.9615 - val_cost: 4.8214\n",
            "Epoch 48/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1025 - auc: 0.9919 - accuracy: 0.9664 - cost: 4.2913 - val_loss: 0.1269 - val_auc: 0.9876 - val_accuracy: 0.9617 - val_cost: 4.7685\n",
            "Epoch 49/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1006 - auc: 0.9921 - accuracy: 0.9674 - cost: 4.1617 - val_loss: 0.1266 - val_auc: 0.9877 - val_accuracy: 0.9622 - val_cost: 4.6462\n",
            "Epoch 50/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0989 - auc: 0.9922 - accuracy: 0.9684 - cost: 4.0247 - val_loss: 0.1270 - val_auc: 0.9875 - val_accuracy: 0.9619 - val_cost: 4.8611\n",
            "Epoch 51/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0994 - auc: 0.9922 - accuracy: 0.9684 - cost: 4.0390 - val_loss: 0.1252 - val_auc: 0.9878 - val_accuracy: 0.9617 - val_cost: 4.8016\n",
            "Epoch 52/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0991 - auc: 0.9922 - accuracy: 0.9680 - cost: 4.0764 - val_loss: 0.1252 - val_auc: 0.9879 - val_accuracy: 0.9633 - val_cost: 4.5205\n",
            "Epoch 53/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0973 - auc: 0.9925 - accuracy: 0.9690 - cost: 3.9552 - val_loss: 0.1235 - val_auc: 0.9879 - val_accuracy: 0.9639 - val_cost: 4.3915\n",
            "Epoch 54/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0978 - auc: 0.9924 - accuracy: 0.9687 - cost: 3.9934 - val_loss: 0.1229 - val_auc: 0.9881 - val_accuracy: 0.9640 - val_cost: 4.4511\n",
            "Epoch 55/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0962 - auc: 0.9924 - accuracy: 0.9690 - cost: 3.9603 - val_loss: 0.1228 - val_auc: 0.9881 - val_accuracy: 0.9638 - val_cost: 4.5007\n",
            "Epoch 56/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0956 - auc: 0.9926 - accuracy: 0.9692 - cost: 3.9329 - val_loss: 0.1213 - val_auc: 0.9884 - val_accuracy: 0.9643 - val_cost: 4.4511\n",
            "Epoch 57/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0949 - auc: 0.9927 - accuracy: 0.9696 - cost: 3.8777 - val_loss: 0.1230 - val_auc: 0.9882 - val_accuracy: 0.9629 - val_cost: 4.6495\n",
            "Epoch 58/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0944 - auc: 0.9927 - accuracy: 0.9701 - cost: 3.8241 - val_loss: 0.1217 - val_auc: 0.9884 - val_accuracy: 0.9652 - val_cost: 4.2493\n",
            "Epoch 59/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0939 - auc: 0.9928 - accuracy: 0.9695 - cost: 3.8885 - val_loss: 0.1224 - val_auc: 0.9882 - val_accuracy: 0.9642 - val_cost: 4.4345\n",
            "Epoch 60/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0939 - auc: 0.9927 - accuracy: 0.9697 - cost: 3.8700 - val_loss: 0.1212 - val_auc: 0.9885 - val_accuracy: 0.9638 - val_cost: 4.4874\n",
            "Epoch 61/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0922 - auc: 0.9930 - accuracy: 0.9708 - cost: 3.7326 - val_loss: 0.1210 - val_auc: 0.9883 - val_accuracy: 0.9651 - val_cost: 4.3089\n",
            "Epoch 62/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0917 - auc: 0.9930 - accuracy: 0.9710 - cost: 3.7018 - val_loss: 0.1207 - val_auc: 0.9886 - val_accuracy: 0.9651 - val_cost: 4.2196\n",
            "Epoch 63/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0927 - auc: 0.9929 - accuracy: 0.9702 - cost: 3.8098 - val_loss: 0.1205 - val_auc: 0.9885 - val_accuracy: 0.9651 - val_cost: 4.2493\n",
            "Epoch 64/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0907 - auc: 0.9930 - accuracy: 0.9719 - cost: 3.5968 - val_loss: 0.1214 - val_auc: 0.9887 - val_accuracy: 0.9654 - val_cost: 4.2328\n",
            "Epoch 65/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0907 - auc: 0.9931 - accuracy: 0.9714 - cost: 3.6644 - val_loss: 0.1202 - val_auc: 0.9886 - val_accuracy: 0.9662 - val_cost: 4.1104\n",
            "Epoch 66/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0898 - auc: 0.9932 - accuracy: 0.9717 - cost: 3.6208 - val_loss: 0.1217 - val_auc: 0.9887 - val_accuracy: 0.9656 - val_cost: 4.3089\n",
            "Epoch 67/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0897 - auc: 0.9932 - accuracy: 0.9719 - cost: 3.5860 - val_loss: 0.1211 - val_auc: 0.9886 - val_accuracy: 0.9638 - val_cost: 4.3585\n",
            "Epoch 68/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0893 - auc: 0.9933 - accuracy: 0.9717 - cost: 3.6235 - val_loss: 0.1202 - val_auc: 0.9887 - val_accuracy: 0.9651 - val_cost: 4.2163\n",
            "Epoch 69/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0890 - auc: 0.9932 - accuracy: 0.9722 - cost: 3.5687 - val_loss: 0.1188 - val_auc: 0.9887 - val_accuracy: 0.9659 - val_cost: 4.1435\n",
            "Epoch 70/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0881 - auc: 0.9934 - accuracy: 0.9730 - cost: 3.4518 - val_loss: 0.1194 - val_auc: 0.9886 - val_accuracy: 0.9655 - val_cost: 4.2593\n",
            "Epoch 71/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0874 - auc: 0.9934 - accuracy: 0.9725 - cost: 3.5104 - val_loss: 0.1192 - val_auc: 0.9888 - val_accuracy: 0.9669 - val_cost: 4.1204\n",
            "Epoch 72/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0872 - auc: 0.9935 - accuracy: 0.9730 - cost: 3.4579 - val_loss: 0.1186 - val_auc: 0.9887 - val_accuracy: 0.9656 - val_cost: 4.2593\n",
            "Epoch 73/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0873 - auc: 0.9934 - accuracy: 0.9723 - cost: 3.5490 - val_loss: 0.1182 - val_auc: 0.9888 - val_accuracy: 0.9668 - val_cost: 4.1204\n",
            "Epoch 74/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0864 - auc: 0.9936 - accuracy: 0.9729 - cost: 3.4784 - val_loss: 0.1188 - val_auc: 0.9889 - val_accuracy: 0.9666 - val_cost: 4.0642\n",
            "Epoch 75/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0856 - auc: 0.9936 - accuracy: 0.9735 - cost: 3.3885 - val_loss: 0.1184 - val_auc: 0.9889 - val_accuracy: 0.9658 - val_cost: 4.2097\n",
            "Epoch 76/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0852 - auc: 0.9937 - accuracy: 0.9733 - cost: 3.4055 - val_loss: 0.1189 - val_auc: 0.9887 - val_accuracy: 0.9653 - val_cost: 4.2857\n",
            "Epoch 77/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0842 - auc: 0.9938 - accuracy: 0.9737 - cost: 3.3669 - val_loss: 0.1188 - val_auc: 0.9887 - val_accuracy: 0.9658 - val_cost: 4.2097\n",
            "Epoch 78/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0845 - auc: 0.9938 - accuracy: 0.9738 - cost: 3.3557 - val_loss: 0.1177 - val_auc: 0.9889 - val_accuracy: 0.9657 - val_cost: 4.2163\n",
            "Epoch 79/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0843 - auc: 0.9937 - accuracy: 0.9740 - cost: 3.3291 - val_loss: 0.1182 - val_auc: 0.9887 - val_accuracy: 0.9658 - val_cost: 4.3022\n",
            "Epoch 80/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0834 - auc: 0.9939 - accuracy: 0.9744 - cost: 3.2731 - val_loss: 0.1180 - val_auc: 0.9890 - val_accuracy: 0.9669 - val_cost: 4.0708\n",
            "Epoch 81/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0831 - auc: 0.9938 - accuracy: 0.9744 - cost: 3.2793 - val_loss: 0.1155 - val_auc: 0.9892 - val_accuracy: 0.9663 - val_cost: 4.1766\n",
            "Epoch 82/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0828 - auc: 0.9938 - accuracy: 0.9745 - cost: 3.2608 - val_loss: 0.1174 - val_auc: 0.9888 - val_accuracy: 0.9654 - val_cost: 4.2758\n",
            "Epoch 83/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0827 - auc: 0.9938 - accuracy: 0.9744 - cost: 3.2739 - val_loss: 0.1176 - val_auc: 0.9890 - val_accuracy: 0.9660 - val_cost: 4.2361\n",
            "Epoch 84/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0831 - auc: 0.9937 - accuracy: 0.9748 - cost: 3.2242 - val_loss: 0.1179 - val_auc: 0.9890 - val_accuracy: 0.9667 - val_cost: 4.1336\n",
            "Epoch 85/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0817 - auc: 0.9940 - accuracy: 0.9749 - cost: 3.2126 - val_loss: 0.1171 - val_auc: 0.9889 - val_accuracy: 0.9676 - val_cost: 4.0311\n",
            "Epoch 86/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0818 - auc: 0.9940 - accuracy: 0.9746 - cost: 3.2658 - val_loss: 0.1179 - val_auc: 0.9888 - val_accuracy: 0.9666 - val_cost: 4.0774\n",
            "Epoch 87/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0805 - auc: 0.9940 - accuracy: 0.9754 - cost: 3.1497 - val_loss: 0.1190 - val_auc: 0.9886 - val_accuracy: 0.9656 - val_cost: 4.2361\n",
            "Epoch 88/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0803 - auc: 0.9942 - accuracy: 0.9751 - cost: 3.1933 - val_loss: 0.1186 - val_auc: 0.9887 - val_accuracy: 0.9669 - val_cost: 4.1138\n",
            "Epoch 89/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0802 - auc: 0.9941 - accuracy: 0.9750 - cost: 3.1906 - val_loss: 0.1172 - val_auc: 0.9890 - val_accuracy: 0.9663 - val_cost: 4.1501\n",
            "Epoch 90/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0805 - auc: 0.9941 - accuracy: 0.9750 - cost: 3.2025 - val_loss: 0.1191 - val_auc: 0.9887 - val_accuracy: 0.9662 - val_cost: 4.3287\n",
            "Epoch 91/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0804 - auc: 0.9941 - accuracy: 0.9750 - cost: 3.2079 - val_loss: 0.1185 - val_auc: 0.9884 - val_accuracy: 0.9665 - val_cost: 4.2493\n",
            "Epoch 92/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0801 - auc: 0.9940 - accuracy: 0.9755 - cost: 3.1381 - val_loss: 0.1173 - val_auc: 0.9887 - val_accuracy: 0.9667 - val_cost: 4.1634\n",
            "Epoch 93/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0801 - auc: 0.9941 - accuracy: 0.9755 - cost: 3.1285 - val_loss: 0.1186 - val_auc: 0.9885 - val_accuracy: 0.9664 - val_cost: 4.2063\n",
            "Epoch 94/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0796 - auc: 0.9942 - accuracy: 0.9756 - cost: 3.1304 - val_loss: 0.1169 - val_auc: 0.9891 - val_accuracy: 0.9664 - val_cost: 4.1071\n",
            "Epoch 95/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0798 - auc: 0.9942 - accuracy: 0.9755 - cost: 3.1300 - val_loss: 0.1166 - val_auc: 0.9891 - val_accuracy: 0.9675 - val_cost: 4.1270\n",
            "Epoch 96/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0785 - auc: 0.9943 - accuracy: 0.9760 - cost: 3.0814 - val_loss: 0.1175 - val_auc: 0.9891 - val_accuracy: 0.9668 - val_cost: 4.1733\n",
            "Epoch 97/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0783 - auc: 0.9941 - accuracy: 0.9766 - cost: 2.9992 - val_loss: 0.1175 - val_auc: 0.9889 - val_accuracy: 0.9661 - val_cost: 4.3056\n",
            "Epoch 98/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0777 - auc: 0.9943 - accuracy: 0.9762 - cost: 3.0613 - val_loss: 0.1191 - val_auc: 0.9888 - val_accuracy: 0.9660 - val_cost: 4.1964\n",
            "Epoch 99/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0771 - auc: 0.9945 - accuracy: 0.9762 - cost: 3.0475 - val_loss: 0.1178 - val_auc: 0.9888 - val_accuracy: 0.9686 - val_cost: 3.8459\n",
            "Epoch 100/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0775 - auc: 0.9944 - accuracy: 0.9763 - cost: 3.0251 - val_loss: 0.1192 - val_auc: 0.9887 - val_accuracy: 0.9663 - val_cost: 4.2097\n",
            "Epoch 101/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0771 - auc: 0.9944 - accuracy: 0.9766 - cost: 2.9942 - val_loss: 0.1181 - val_auc: 0.9890 - val_accuracy: 0.9668 - val_cost: 4.0410\n",
            "Epoch 102/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0777 - auc: 0.9943 - accuracy: 0.9764 - cost: 3.0274 - val_loss: 0.1197 - val_auc: 0.9884 - val_accuracy: 0.9666 - val_cost: 4.0410\n",
            "Epoch 103/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0766 - auc: 0.9945 - accuracy: 0.9767 - cost: 2.9738 - val_loss: 0.1174 - val_auc: 0.9890 - val_accuracy: 0.9676 - val_cost: 4.1567\n",
            "Epoch 104/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0760 - auc: 0.9945 - accuracy: 0.9768 - cost: 2.9796 - val_loss: 0.1166 - val_auc: 0.9888 - val_accuracy: 0.9664 - val_cost: 4.2560\n",
            "Epoch 105/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0768 - auc: 0.9944 - accuracy: 0.9764 - cost: 3.0258 - val_loss: 0.1171 - val_auc: 0.9890 - val_accuracy: 0.9675 - val_cost: 4.1104\n",
            "Epoch 106/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0761 - auc: 0.9945 - accuracy: 0.9766 - cost: 2.9969 - val_loss: 0.1204 - val_auc: 0.9890 - val_accuracy: 0.9660 - val_cost: 4.0939\n",
            "Epoch 107/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0759 - auc: 0.9946 - accuracy: 0.9767 - cost: 2.9826 - val_loss: 0.1200 - val_auc: 0.9887 - val_accuracy: 0.9663 - val_cost: 4.2593\n",
            "Epoch 108/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0770 - auc: 0.9943 - accuracy: 0.9767 - cost: 2.9846 - val_loss: 0.1168 - val_auc: 0.9889 - val_accuracy: 0.9674 - val_cost: 4.1038\n",
            "Epoch 109/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0760 - auc: 0.9946 - accuracy: 0.9766 - cost: 2.9838 - val_loss: 0.1196 - val_auc: 0.9889 - val_accuracy: 0.9675 - val_cost: 3.9782\n",
            "Epoch 110/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0746 - auc: 0.9948 - accuracy: 0.9772 - cost: 2.9271 - val_loss: 0.1196 - val_auc: 0.9887 - val_accuracy: 0.9670 - val_cost: 4.0542\n",
            "Epoch 111/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0755 - auc: 0.9946 - accuracy: 0.9776 - cost: 2.8738 - val_loss: 0.1190 - val_auc: 0.9890 - val_accuracy: 0.9673 - val_cost: 4.0410\n",
            "Epoch 112/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0752 - auc: 0.9946 - accuracy: 0.9771 - cost: 2.9236 - val_loss: 0.1168 - val_auc: 0.9891 - val_accuracy: 0.9671 - val_cost: 4.1931\n",
            "Epoch 113/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0741 - auc: 0.9947 - accuracy: 0.9776 - cost: 2.8812 - val_loss: 0.1186 - val_auc: 0.9889 - val_accuracy: 0.9678 - val_cost: 3.9649\n",
            "Epoch 114/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0749 - auc: 0.9947 - accuracy: 0.9776 - cost: 2.8696 - val_loss: 0.1194 - val_auc: 0.9888 - val_accuracy: 0.9664 - val_cost: 4.2824\n",
            "Epoch 115/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0756 - auc: 0.9945 - accuracy: 0.9767 - cost: 2.9772 - val_loss: 0.1197 - val_auc: 0.9888 - val_accuracy: 0.9674 - val_cost: 3.9550\n",
            "Epoch 116/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0746 - auc: 0.9946 - accuracy: 0.9777 - cost: 2.8603 - val_loss: 0.1214 - val_auc: 0.9886 - val_accuracy: 0.9672 - val_cost: 3.9517\n",
            "Epoch 117/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0744 - auc: 0.9946 - accuracy: 0.9777 - cost: 2.8576 - val_loss: 0.1182 - val_auc: 0.9891 - val_accuracy: 0.9679 - val_cost: 3.9815\n",
            "Epoch 118/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0741 - auc: 0.9947 - accuracy: 0.9777 - cost: 2.8627 - val_loss: 0.1188 - val_auc: 0.9889 - val_accuracy: 0.9678 - val_cost: 4.0079\n",
            "Epoch 119/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0735 - auc: 0.9948 - accuracy: 0.9778 - cost: 2.8596 - val_loss: 0.1192 - val_auc: 0.9890 - val_accuracy: 0.9676 - val_cost: 4.0079\n",
            "Epoch 120/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0736 - auc: 0.9948 - accuracy: 0.9778 - cost: 2.8507 - val_loss: 0.1204 - val_auc: 0.9887 - val_accuracy: 0.9674 - val_cost: 4.0079\n",
            "Epoch 121/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0735 - auc: 0.9947 - accuracy: 0.9777 - cost: 2.8592 - val_loss: 0.1186 - val_auc: 0.9888 - val_accuracy: 0.9679 - val_cost: 3.9815\n",
            "Epoch 122/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0727 - auc: 0.9949 - accuracy: 0.9781 - cost: 2.8063 - val_loss: 0.1192 - val_auc: 0.9889 - val_accuracy: 0.9679 - val_cost: 3.9716\n",
            "Epoch 123/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0731 - auc: 0.9949 - accuracy: 0.9779 - cost: 2.8461 - val_loss: 0.1185 - val_auc: 0.9889 - val_accuracy: 0.9670 - val_cost: 4.1038\n",
            "Epoch 124/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0725 - auc: 0.9949 - accuracy: 0.9785 - cost: 2.7546 - val_loss: 0.1183 - val_auc: 0.9889 - val_accuracy: 0.9680 - val_cost: 3.9815\n",
            "Epoch 125/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0721 - auc: 0.9950 - accuracy: 0.9785 - cost: 2.7600 - val_loss: 0.1195 - val_auc: 0.9890 - val_accuracy: 0.9676 - val_cost: 4.0377\n",
            "Epoch 126/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0719 - auc: 0.9950 - accuracy: 0.9781 - cost: 2.7990 - val_loss: 0.1184 - val_auc: 0.9891 - val_accuracy: 0.9669 - val_cost: 4.1733\n",
            "Epoch 127/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0724 - auc: 0.9948 - accuracy: 0.9782 - cost: 2.7990 - val_loss: 0.1202 - val_auc: 0.9890 - val_accuracy: 0.9674 - val_cost: 4.0146\n",
            "Epoch 128/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0717 - auc: 0.9950 - accuracy: 0.9782 - cost: 2.7878 - val_loss: 0.1200 - val_auc: 0.9885 - val_accuracy: 0.9668 - val_cost: 4.1997\n",
            "Epoch 129/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0721 - auc: 0.9949 - accuracy: 0.9784 - cost: 2.7747 - val_loss: 0.1179 - val_auc: 0.9890 - val_accuracy: 0.9678 - val_cost: 4.1071\n",
            "Epoch 130/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0719 - auc: 0.9949 - accuracy: 0.9783 - cost: 2.7851 - val_loss: 0.1218 - val_auc: 0.9886 - val_accuracy: 0.9673 - val_cost: 3.9947\n",
            "Epoch 131/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0717 - auc: 0.9950 - accuracy: 0.9785 - cost: 2.7612 - val_loss: 0.1183 - val_auc: 0.9891 - val_accuracy: 0.9665 - val_cost: 4.2262\n",
            "Epoch 132/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0711 - auc: 0.9950 - accuracy: 0.9786 - cost: 2.7369 - val_loss: 0.1200 - val_auc: 0.9890 - val_accuracy: 0.9668 - val_cost: 4.0972\n",
            "Epoch 133/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0713 - auc: 0.9949 - accuracy: 0.9789 - cost: 2.7168 - val_loss: 0.1193 - val_auc: 0.9888 - val_accuracy: 0.9674 - val_cost: 4.0774\n",
            "Epoch 134/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0708 - auc: 0.9950 - accuracy: 0.9789 - cost: 2.7103 - val_loss: 0.1189 - val_auc: 0.9891 - val_accuracy: 0.9676 - val_cost: 4.0939\n",
            "Epoch 135/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0713 - auc: 0.9949 - accuracy: 0.9786 - cost: 2.7473 - val_loss: 0.1196 - val_auc: 0.9889 - val_accuracy: 0.9676 - val_cost: 3.9749\n",
            "Epoch 136/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0710 - auc: 0.9950 - accuracy: 0.9786 - cost: 2.7427 - val_loss: 0.1183 - val_auc: 0.9888 - val_accuracy: 0.9683 - val_cost: 3.9484\n",
            "Epoch 137/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0698 - auc: 0.9951 - accuracy: 0.9790 - cost: 2.6852 - val_loss: 0.1167 - val_auc: 0.9892 - val_accuracy: 0.9678 - val_cost: 4.1898\n",
            "Epoch 138/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0700 - auc: 0.9952 - accuracy: 0.9793 - cost: 2.6590 - val_loss: 0.1210 - val_auc: 0.9887 - val_accuracy: 0.9681 - val_cost: 3.9683\n",
            "Epoch 139/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0699 - auc: 0.9951 - accuracy: 0.9789 - cost: 2.7052 - val_loss: 0.1198 - val_auc: 0.9891 - val_accuracy: 0.9679 - val_cost: 4.0443\n",
            "Epoch 140/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0709 - auc: 0.9951 - accuracy: 0.9788 - cost: 2.7172 - val_loss: 0.1185 - val_auc: 0.9892 - val_accuracy: 0.9679 - val_cost: 4.0708\n",
            "Epoch 141/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0701 - auc: 0.9950 - accuracy: 0.9791 - cost: 2.6875 - val_loss: 0.1180 - val_auc: 0.9890 - val_accuracy: 0.9681 - val_cost: 3.9616\n",
            "Epoch 142/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0691 - auc: 0.9951 - accuracy: 0.9789 - cost: 2.7106 - val_loss: 0.1216 - val_auc: 0.9888 - val_accuracy: 0.9674 - val_cost: 3.9583\n",
            "Epoch 143/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0699 - auc: 0.9952 - accuracy: 0.9789 - cost: 2.7160 - val_loss: 0.1217 - val_auc: 0.9883 - val_accuracy: 0.9673 - val_cost: 4.0344\n",
            "Epoch 144/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0702 - auc: 0.9951 - accuracy: 0.9786 - cost: 2.7488 - val_loss: 0.1191 - val_auc: 0.9889 - val_accuracy: 0.9681 - val_cost: 3.9815\n",
            "Epoch 145/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0690 - auc: 0.9953 - accuracy: 0.9792 - cost: 2.6717 - val_loss: 0.1195 - val_auc: 0.9889 - val_accuracy: 0.9680 - val_cost: 4.0708\n",
            "Epoch 146/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0694 - auc: 0.9952 - accuracy: 0.9790 - cost: 2.7006 - val_loss: 0.1199 - val_auc: 0.9888 - val_accuracy: 0.9682 - val_cost: 4.0046\n",
            "Epoch 147/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0694 - auc: 0.9952 - accuracy: 0.9795 - cost: 2.6265 - val_loss: 0.1175 - val_auc: 0.9888 - val_accuracy: 0.9685 - val_cost: 4.0112\n",
            "Epoch 148/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0694 - auc: 0.9952 - accuracy: 0.9793 - cost: 2.6551 - val_loss: 0.1197 - val_auc: 0.9890 - val_accuracy: 0.9676 - val_cost: 4.0708\n",
            "Epoch 149/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0690 - auc: 0.9952 - accuracy: 0.9794 - cost: 2.6516 - val_loss: 0.1200 - val_auc: 0.9889 - val_accuracy: 0.9665 - val_cost: 4.0807\n",
            "Epoch 150/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0695 - auc: 0.9952 - accuracy: 0.9793 - cost: 2.6501 - val_loss: 0.1194 - val_auc: 0.9889 - val_accuracy: 0.9677 - val_cost: 4.1171\n",
            "Epoch 151/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0689 - auc: 0.9952 - accuracy: 0.9791 - cost: 2.6833 - val_loss: 0.1220 - val_auc: 0.9884 - val_accuracy: 0.9674 - val_cost: 3.9980\n",
            "Epoch 152/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0682 - auc: 0.9954 - accuracy: 0.9798 - cost: 2.5860 - val_loss: 0.1188 - val_auc: 0.9892 - val_accuracy: 0.9677 - val_cost: 4.1138\n",
            "Epoch 153/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0679 - auc: 0.9953 - accuracy: 0.9793 - cost: 2.6539 - val_loss: 0.1206 - val_auc: 0.9891 - val_accuracy: 0.9679 - val_cost: 3.9087\n",
            "Epoch 154/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0693 - auc: 0.9952 - accuracy: 0.9796 - cost: 2.6235 - val_loss: 0.1200 - val_auc: 0.9888 - val_accuracy: 0.9681 - val_cost: 4.0278\n",
            "Epoch 155/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0688 - auc: 0.9954 - accuracy: 0.9793 - cost: 2.6566 - val_loss: 0.1196 - val_auc: 0.9890 - val_accuracy: 0.9680 - val_cost: 4.0046\n",
            "Epoch 156/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0685 - auc: 0.9953 - accuracy: 0.9798 - cost: 2.5918 - val_loss: 0.1208 - val_auc: 0.9890 - val_accuracy: 0.9674 - val_cost: 4.0476\n",
            "Epoch 157/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0672 - auc: 0.9954 - accuracy: 0.9802 - cost: 2.5367 - val_loss: 0.1209 - val_auc: 0.9886 - val_accuracy: 0.9682 - val_cost: 3.9980\n",
            "Epoch 158/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0684 - auc: 0.9955 - accuracy: 0.9795 - cost: 2.6277 - val_loss: 0.1189 - val_auc: 0.9888 - val_accuracy: 0.9681 - val_cost: 3.9716\n",
            "Epoch 159/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0675 - auc: 0.9954 - accuracy: 0.9796 - cost: 2.6119 - val_loss: 0.1198 - val_auc: 0.9890 - val_accuracy: 0.9678 - val_cost: 3.9319\n",
            "Epoch 160/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0680 - auc: 0.9954 - accuracy: 0.9795 - cost: 2.6300 - val_loss: 0.1198 - val_auc: 0.9888 - val_accuracy: 0.9682 - val_cost: 4.0344\n",
            "Epoch 161/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0678 - auc: 0.9953 - accuracy: 0.9797 - cost: 2.6096 - val_loss: 0.1187 - val_auc: 0.9890 - val_accuracy: 0.9678 - val_cost: 4.0278\n",
            "Epoch 162/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0682 - auc: 0.9954 - accuracy: 0.9794 - cost: 2.6478 - val_loss: 0.1200 - val_auc: 0.9892 - val_accuracy: 0.9667 - val_cost: 4.1601\n",
            "Epoch 163/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0670 - auc: 0.9955 - accuracy: 0.9797 - cost: 2.6127 - val_loss: 0.1204 - val_auc: 0.9890 - val_accuracy: 0.9685 - val_cost: 3.9087\n",
            "Epoch 164/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0676 - auc: 0.9954 - accuracy: 0.9797 - cost: 2.5984 - val_loss: 0.1186 - val_auc: 0.9892 - val_accuracy: 0.9688 - val_cost: 3.9187\n",
            "Epoch 165/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0671 - auc: 0.9955 - accuracy: 0.9797 - cost: 2.6022 - val_loss: 0.1189 - val_auc: 0.9887 - val_accuracy: 0.9681 - val_cost: 4.0708\n",
            "Epoch 166/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0662 - auc: 0.9955 - accuracy: 0.9803 - cost: 2.5197 - val_loss: 0.1201 - val_auc: 0.9885 - val_accuracy: 0.9682 - val_cost: 3.9815\n",
            "Epoch 167/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0671 - auc: 0.9954 - accuracy: 0.9798 - cost: 2.5856 - val_loss: 0.1202 - val_auc: 0.9887 - val_accuracy: 0.9682 - val_cost: 3.9021\n",
            "Epoch 168/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0668 - auc: 0.9955 - accuracy: 0.9800 - cost: 2.5702 - val_loss: 0.1195 - val_auc: 0.9888 - val_accuracy: 0.9686 - val_cost: 3.8757\n",
            "Epoch 169/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0675 - auc: 0.9954 - accuracy: 0.9797 - cost: 2.6096 - val_loss: 0.1202 - val_auc: 0.9890 - val_accuracy: 0.9677 - val_cost: 3.9716\n",
            "Epoch 170/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0672 - auc: 0.9954 - accuracy: 0.9797 - cost: 2.5903 - val_loss: 0.1212 - val_auc: 0.9886 - val_accuracy: 0.9686 - val_cost: 3.9054\n",
            "Epoch 171/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0677 - auc: 0.9953 - accuracy: 0.9800 - cost: 2.5772 - val_loss: 0.1200 - val_auc: 0.9887 - val_accuracy: 0.9682 - val_cost: 3.9451\n",
            "Epoch 172/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0671 - auc: 0.9955 - accuracy: 0.9799 - cost: 2.5745 - val_loss: 0.1211 - val_auc: 0.9890 - val_accuracy: 0.9682 - val_cost: 4.0377\n",
            "Epoch 173/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0669 - auc: 0.9954 - accuracy: 0.9802 - cost: 2.5343 - val_loss: 0.1205 - val_auc: 0.9887 - val_accuracy: 0.9681 - val_cost: 4.0013\n",
            "Epoch 174/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0666 - auc: 0.9955 - accuracy: 0.9801 - cost: 2.5451 - val_loss: 0.1216 - val_auc: 0.9889 - val_accuracy: 0.9669 - val_cost: 4.1270\n",
            "Epoch 175/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0663 - auc: 0.9955 - accuracy: 0.9806 - cost: 2.4923 - val_loss: 0.1208 - val_auc: 0.9889 - val_accuracy: 0.9675 - val_cost: 4.0079\n",
            "Epoch 176/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0656 - auc: 0.9957 - accuracy: 0.9807 - cost: 2.4877 - val_loss: 0.1208 - val_auc: 0.9891 - val_accuracy: 0.9676 - val_cost: 4.0013\n",
            "Epoch 177/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0656 - auc: 0.9957 - accuracy: 0.9802 - cost: 2.5421 - val_loss: 0.1219 - val_auc: 0.9887 - val_accuracy: 0.9678 - val_cost: 4.0245\n",
            "Epoch 178/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0671 - auc: 0.9955 - accuracy: 0.9797 - cost: 2.6007 - val_loss: 0.1251 - val_auc: 0.9885 - val_accuracy: 0.9672 - val_cost: 4.0112\n",
            "Epoch 179/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0670 - auc: 0.9954 - accuracy: 0.9802 - cost: 2.5382 - val_loss: 0.1215 - val_auc: 0.9891 - val_accuracy: 0.9679 - val_cost: 3.9980\n",
            "Epoch 180/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0656 - auc: 0.9956 - accuracy: 0.9806 - cost: 2.4950 - val_loss: 0.1198 - val_auc: 0.9888 - val_accuracy: 0.9682 - val_cost: 4.0046\n",
            "Epoch 181/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0653 - auc: 0.9956 - accuracy: 0.9804 - cost: 2.5143 - val_loss: 0.1202 - val_auc: 0.9889 - val_accuracy: 0.9683 - val_cost: 3.9352\n",
            "Epoch 182/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0651 - auc: 0.9957 - accuracy: 0.9804 - cost: 2.5112 - val_loss: 0.1224 - val_auc: 0.9887 - val_accuracy: 0.9682 - val_cost: 4.0179\n",
            "Epoch 183/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0662 - auc: 0.9956 - accuracy: 0.9801 - cost: 2.5536 - val_loss: 0.1223 - val_auc: 0.9891 - val_accuracy: 0.9678 - val_cost: 3.9616\n",
            "Epoch 184/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0661 - auc: 0.9956 - accuracy: 0.9803 - cost: 2.5390 - val_loss: 0.1219 - val_auc: 0.9886 - val_accuracy: 0.9679 - val_cost: 4.0112\n",
            "Epoch 185/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0658 - auc: 0.9957 - accuracy: 0.9801 - cost: 2.5536 - val_loss: 0.1225 - val_auc: 0.9889 - val_accuracy: 0.9669 - val_cost: 4.2063\n",
            "Epoch 186/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0656 - auc: 0.9956 - accuracy: 0.9805 - cost: 2.5096 - val_loss: 0.1258 - val_auc: 0.9886 - val_accuracy: 0.9680 - val_cost: 3.9848\n",
            "Epoch 187/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0655 - auc: 0.9956 - accuracy: 0.9806 - cost: 2.4946 - val_loss: 0.1218 - val_auc: 0.9890 - val_accuracy: 0.9669 - val_cost: 4.1700\n",
            "Epoch 188/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0651 - auc: 0.9957 - accuracy: 0.9803 - cost: 2.5247 - val_loss: 0.1216 - val_auc: 0.9890 - val_accuracy: 0.9681 - val_cost: 3.9683\n",
            "Epoch 189/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0654 - auc: 0.9957 - accuracy: 0.9804 - cost: 2.5158 - val_loss: 0.1220 - val_auc: 0.9888 - val_accuracy: 0.9681 - val_cost: 3.9352\n",
            "Epoch 190/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0649 - auc: 0.9958 - accuracy: 0.9806 - cost: 2.4873 - val_loss: 0.1225 - val_auc: 0.9886 - val_accuracy: 0.9679 - val_cost: 4.0377\n",
            "Epoch 191/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0644 - auc: 0.9956 - accuracy: 0.9811 - cost: 2.4290 - val_loss: 0.1237 - val_auc: 0.9886 - val_accuracy: 0.9679 - val_cost: 3.9914\n",
            "Epoch 192/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0647 - auc: 0.9957 - accuracy: 0.9802 - cost: 2.5436 - val_loss: 0.1222 - val_auc: 0.9888 - val_accuracy: 0.9678 - val_cost: 4.1303\n",
            "Epoch 193/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0655 - auc: 0.9957 - accuracy: 0.9803 - cost: 2.5228 - val_loss: 0.1223 - val_auc: 0.9888 - val_accuracy: 0.9678 - val_cost: 4.0443\n",
            "Epoch 194/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0657 - auc: 0.9956 - accuracy: 0.9802 - cost: 2.5285 - val_loss: 0.1219 - val_auc: 0.9888 - val_accuracy: 0.9690 - val_cost: 3.8690\n",
            "Epoch 195/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0645 - auc: 0.9957 - accuracy: 0.9811 - cost: 2.4240 - val_loss: 0.1216 - val_auc: 0.9886 - val_accuracy: 0.9675 - val_cost: 4.0906\n",
            "Epoch 196/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0646 - auc: 0.9958 - accuracy: 0.9805 - cost: 2.5027 - val_loss: 0.1251 - val_auc: 0.9885 - val_accuracy: 0.9681 - val_cost: 4.0179\n",
            "Epoch 197/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0654 - auc: 0.9957 - accuracy: 0.9802 - cost: 2.5432 - val_loss: 0.1226 - val_auc: 0.9890 - val_accuracy: 0.9678 - val_cost: 3.9782\n",
            "Epoch 198/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0649 - auc: 0.9957 - accuracy: 0.9808 - cost: 2.4653 - val_loss: 0.1227 - val_auc: 0.9885 - val_accuracy: 0.9683 - val_cost: 4.0311\n",
            "Epoch 199/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0640 - auc: 0.9958 - accuracy: 0.9808 - cost: 2.4630 - val_loss: 0.1220 - val_auc: 0.9886 - val_accuracy: 0.9683 - val_cost: 3.9749\n",
            "Epoch 200/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0643 - auc: 0.9958 - accuracy: 0.9804 - cost: 2.5135 - val_loss: 0.1219 - val_auc: 0.9887 - val_accuracy: 0.9688 - val_cost: 3.9881\n",
            "Epoch 201/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0639 - auc: 0.9958 - accuracy: 0.9805 - cost: 2.4988 - val_loss: 0.1229 - val_auc: 0.9887 - val_accuracy: 0.9683 - val_cost: 3.9848\n",
            "Epoch 202/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0651 - auc: 0.9957 - accuracy: 0.9804 - cost: 2.5185 - val_loss: 0.1244 - val_auc: 0.9888 - val_accuracy: 0.9679 - val_cost: 3.8922\n",
            "Epoch 203/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0638 - auc: 0.9958 - accuracy: 0.9808 - cost: 2.4560 - val_loss: 0.1234 - val_auc: 0.9886 - val_accuracy: 0.9684 - val_cost: 3.9319\n",
            "Epoch 204/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0639 - auc: 0.9959 - accuracy: 0.9806 - cost: 2.4927 - val_loss: 0.1237 - val_auc: 0.9884 - val_accuracy: 0.9678 - val_cost: 4.0575\n",
            "Epoch 205/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0644 - auc: 0.9958 - accuracy: 0.9811 - cost: 2.4271 - val_loss: 0.1233 - val_auc: 0.9888 - val_accuracy: 0.9686 - val_cost: 3.9716\n",
            "Epoch 206/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0642 - auc: 0.9958 - accuracy: 0.9810 - cost: 2.4402 - val_loss: 0.1240 - val_auc: 0.9886 - val_accuracy: 0.9678 - val_cost: 4.0873\n",
            "Epoch 207/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0638 - auc: 0.9958 - accuracy: 0.9808 - cost: 2.4595 - val_loss: 0.1228 - val_auc: 0.9887 - val_accuracy: 0.9687 - val_cost: 4.0112\n",
            "Epoch 208/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0638 - auc: 0.9958 - accuracy: 0.9810 - cost: 2.4375 - val_loss: 0.1243 - val_auc: 0.9886 - val_accuracy: 0.9686 - val_cost: 3.9187\n",
            "Epoch 209/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0640 - auc: 0.9958 - accuracy: 0.9808 - cost: 2.4599 - val_loss: 0.1221 - val_auc: 0.9886 - val_accuracy: 0.9685 - val_cost: 3.9087\n",
            "Epoch 210/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0635 - auc: 0.9958 - accuracy: 0.9813 - cost: 2.3997 - val_loss: 0.1251 - val_auc: 0.9883 - val_accuracy: 0.9680 - val_cost: 3.9716\n",
            "Epoch 211/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0640 - auc: 0.9958 - accuracy: 0.9808 - cost: 2.4711 - val_loss: 0.1231 - val_auc: 0.9884 - val_accuracy: 0.9680 - val_cost: 4.0972\n",
            "Epoch 212/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0643 - auc: 0.9957 - accuracy: 0.9805 - cost: 2.5073 - val_loss: 0.1238 - val_auc: 0.9889 - val_accuracy: 0.9690 - val_cost: 3.9153\n",
            "Epoch 213/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0639 - auc: 0.9958 - accuracy: 0.9805 - cost: 2.5096 - val_loss: 0.1245 - val_auc: 0.9889 - val_accuracy: 0.9681 - val_cost: 3.9153\n",
            "Epoch 214/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0638 - auc: 0.9959 - accuracy: 0.9806 - cost: 2.4911 - val_loss: 0.1235 - val_auc: 0.9885 - val_accuracy: 0.9675 - val_cost: 4.1766\n",
            "Epoch 215/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0620 - auc: 0.9960 - accuracy: 0.9814 - cost: 2.3831 - val_loss: 0.1233 - val_auc: 0.9887 - val_accuracy: 0.9681 - val_cost: 4.0642\n",
            "Epoch 216/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0641 - auc: 0.9958 - accuracy: 0.9807 - cost: 2.4707 - val_loss: 0.1235 - val_auc: 0.9886 - val_accuracy: 0.9681 - val_cost: 4.0112\n",
            "Epoch 217/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0640 - auc: 0.9958 - accuracy: 0.9808 - cost: 2.4715 - val_loss: 0.1234 - val_auc: 0.9888 - val_accuracy: 0.9675 - val_cost: 4.1038\n",
            "Epoch 218/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0631 - auc: 0.9958 - accuracy: 0.9810 - cost: 2.4456 - val_loss: 0.1249 - val_auc: 0.9884 - val_accuracy: 0.9674 - val_cost: 4.1071\n",
            "Epoch 219/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0626 - auc: 0.9960 - accuracy: 0.9812 - cost: 2.4120 - val_loss: 0.1248 - val_auc: 0.9889 - val_accuracy: 0.9676 - val_cost: 4.0939\n",
            "Epoch 220/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0626 - auc: 0.9959 - accuracy: 0.9810 - cost: 2.4444 - val_loss: 0.1245 - val_auc: 0.9883 - val_accuracy: 0.9677 - val_cost: 4.0906\n",
            "Epoch 221/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0633 - auc: 0.9960 - accuracy: 0.9812 - cost: 2.4147 - val_loss: 0.1248 - val_auc: 0.9885 - val_accuracy: 0.9678 - val_cost: 4.0245\n",
            "Epoch 222/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0629 - auc: 0.9960 - accuracy: 0.9808 - cost: 2.4645 - val_loss: 0.1233 - val_auc: 0.9887 - val_accuracy: 0.9679 - val_cost: 4.0509\n",
            "Epoch 223/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0630 - auc: 0.9959 - accuracy: 0.9807 - cost: 2.4672 - val_loss: 0.1259 - val_auc: 0.9882 - val_accuracy: 0.9686 - val_cost: 3.9220\n",
            "Epoch 224/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0621 - auc: 0.9962 - accuracy: 0.9814 - cost: 2.3850 - val_loss: 0.1245 - val_auc: 0.9881 - val_accuracy: 0.9680 - val_cost: 4.0509\n",
            "Epoch 225/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0619 - auc: 0.9961 - accuracy: 0.9811 - cost: 2.4271 - val_loss: 0.1250 - val_auc: 0.9887 - val_accuracy: 0.9681 - val_cost: 3.9947\n",
            "Epoch 226/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0628 - auc: 0.9959 - accuracy: 0.9810 - cost: 2.4437 - val_loss: 0.1268 - val_auc: 0.9888 - val_accuracy: 0.9683 - val_cost: 3.9484\n",
            "Epoch 227/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0624 - auc: 0.9959 - accuracy: 0.9813 - cost: 2.3989 - val_loss: 0.1230 - val_auc: 0.9889 - val_accuracy: 0.9681 - val_cost: 3.9616\n",
            "Epoch 228/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0626 - auc: 0.9960 - accuracy: 0.9809 - cost: 2.4537 - val_loss: 0.1263 - val_auc: 0.9883 - val_accuracy: 0.9672 - val_cost: 4.0608\n",
            "Epoch 229/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0629 - auc: 0.9958 - accuracy: 0.9814 - cost: 2.4032 - val_loss: 0.1248 - val_auc: 0.9884 - val_accuracy: 0.9684 - val_cost: 3.9848\n",
            "Epoch 230/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0624 - auc: 0.9959 - accuracy: 0.9809 - cost: 2.4545 - val_loss: 0.1246 - val_auc: 0.9884 - val_accuracy: 0.9685 - val_cost: 3.9153\n",
            "Epoch 231/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0621 - auc: 0.9961 - accuracy: 0.9809 - cost: 2.4460 - val_loss: 0.1253 - val_auc: 0.9885 - val_accuracy: 0.9681 - val_cost: 3.8856\n",
            "Epoch 232/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0624 - auc: 0.9960 - accuracy: 0.9811 - cost: 2.4282 - val_loss: 0.1253 - val_auc: 0.9882 - val_accuracy: 0.9678 - val_cost: 3.9616\n",
            "Epoch 233/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0621 - auc: 0.9960 - accuracy: 0.9812 - cost: 2.4209 - val_loss: 0.1266 - val_auc: 0.9885 - val_accuracy: 0.9676 - val_cost: 3.9914\n",
            "Epoch 234/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0626 - auc: 0.9960 - accuracy: 0.9814 - cost: 2.3862 - val_loss: 0.1268 - val_auc: 0.9884 - val_accuracy: 0.9678 - val_cost: 3.9749\n",
            "Epoch 235/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0614 - auc: 0.9962 - accuracy: 0.9814 - cost: 2.3850 - val_loss: 0.1264 - val_auc: 0.9886 - val_accuracy: 0.9685 - val_cost: 3.9220\n",
            "Epoch 236/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0619 - auc: 0.9961 - accuracy: 0.9813 - cost: 2.4128 - val_loss: 0.1272 - val_auc: 0.9884 - val_accuracy: 0.9675 - val_cost: 4.0212\n",
            "Epoch 237/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0609 - auc: 0.9962 - accuracy: 0.9818 - cost: 2.3252 - val_loss: 0.1254 - val_auc: 0.9886 - val_accuracy: 0.9683 - val_cost: 3.9385\n",
            "Epoch 238/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0623 - auc: 0.9960 - accuracy: 0.9809 - cost: 2.4448 - val_loss: 0.1270 - val_auc: 0.9883 - val_accuracy: 0.9676 - val_cost: 4.0476\n",
            "Epoch 239/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0613 - auc: 0.9961 - accuracy: 0.9812 - cost: 2.4086 - val_loss: 0.1260 - val_auc: 0.9883 - val_accuracy: 0.9674 - val_cost: 4.1799\n",
            "Epoch 240/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0614 - auc: 0.9961 - accuracy: 0.9814 - cost: 2.3808 - val_loss: 0.1273 - val_auc: 0.9882 - val_accuracy: 0.9683 - val_cost: 3.9153\n",
            "Epoch 241/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0620 - auc: 0.9961 - accuracy: 0.9806 - cost: 2.4865 - val_loss: 0.1280 - val_auc: 0.9881 - val_accuracy: 0.9677 - val_cost: 3.9914\n",
            "Epoch 242/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0618 - auc: 0.9962 - accuracy: 0.9811 - cost: 2.4340 - val_loss: 0.1267 - val_auc: 0.9883 - val_accuracy: 0.9669 - val_cost: 4.1369\n",
            "Epoch 243/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0611 - auc: 0.9962 - accuracy: 0.9814 - cost: 2.3947 - val_loss: 0.1274 - val_auc: 0.9881 - val_accuracy: 0.9681 - val_cost: 3.9087\n",
            "Epoch 244/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0612 - auc: 0.9961 - accuracy: 0.9817 - cost: 2.3534 - val_loss: 0.1259 - val_auc: 0.9882 - val_accuracy: 0.9676 - val_cost: 4.0476\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.1096 - auc: 0.9904 - accuracy: 0.9697 - cost: 3.7594\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:01:57.323113\n",
            "fold accuracy: 0.9697499871253967 - fold cost: 3.7593750953674316\n",
            "x_train shape: (144000, 67)\n",
            "Epoch 1/1000\n",
            "120/120 [==============================] - 2s 6ms/step - loss: 0.5296 - auc: 0.7983 - accuracy: 0.7292 - cost: 36.1088 - val_loss: 0.3988 - val_auc: 0.9005 - val_accuracy: 0.8259 - val_cost: 21.8585\n",
            "Epoch 2/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.3523 - auc: 0.9210 - accuracy: 0.8490 - cost: 19.2496 - val_loss: 0.3143 - val_auc: 0.9375 - val_accuracy: 0.8660 - val_cost: 16.6766\n",
            "Epoch 3/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.3026 - auc: 0.9419 - accuracy: 0.8742 - cost: 15.9595 - val_loss: 0.2848 - val_auc: 0.9486 - val_accuracy: 0.8803 - val_cost: 15.0397\n",
            "Epoch 4/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2744 - auc: 0.9524 - accuracy: 0.8889 - cost: 14.0583 - val_loss: 0.2587 - val_auc: 0.9579 - val_accuracy: 0.8960 - val_cost: 13.1052\n",
            "Epoch 5/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2510 - auc: 0.9602 - accuracy: 0.8992 - cost: 12.7623 - val_loss: 0.2394 - val_auc: 0.9636 - val_accuracy: 0.9040 - val_cost: 12.0106\n",
            "Epoch 6/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2326 - auc: 0.9658 - accuracy: 0.9085 - cost: 11.5737 - val_loss: 0.2228 - val_auc: 0.9686 - val_accuracy: 0.9124 - val_cost: 10.8234\n",
            "Epoch 7/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2169 - auc: 0.9702 - accuracy: 0.9159 - cost: 10.6038 - val_loss: 0.2095 - val_auc: 0.9723 - val_accuracy: 0.9203 - val_cost: 9.8347\n",
            "Epoch 8/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.2035 - auc: 0.9737 - accuracy: 0.9222 - cost: 9.8426 - val_loss: 0.1977 - val_auc: 0.9754 - val_accuracy: 0.9250 - val_cost: 9.1700\n",
            "Epoch 9/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1928 - auc: 0.9762 - accuracy: 0.9277 - cost: 9.1339 - val_loss: 0.1869 - val_auc: 0.9775 - val_accuracy: 0.9317 - val_cost: 8.5516\n",
            "Epoch 10/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1824 - auc: 0.9787 - accuracy: 0.9317 - cost: 8.6400 - val_loss: 0.1804 - val_auc: 0.9790 - val_accuracy: 0.9331 - val_cost: 8.5251\n",
            "Epoch 11/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1754 - auc: 0.9801 - accuracy: 0.9349 - cost: 8.2473 - val_loss: 0.1724 - val_auc: 0.9805 - val_accuracy: 0.9387 - val_cost: 7.7480\n",
            "Epoch 12/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1689 - auc: 0.9815 - accuracy: 0.9379 - cost: 7.8642 - val_loss: 0.1668 - val_auc: 0.9817 - val_accuracy: 0.9398 - val_cost: 7.3909\n",
            "Epoch 13/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1625 - auc: 0.9828 - accuracy: 0.9410 - cost: 7.4811 - val_loss: 0.1618 - val_auc: 0.9827 - val_accuracy: 0.9413 - val_cost: 7.3810\n",
            "Epoch 14/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1576 - auc: 0.9835 - accuracy: 0.9435 - cost: 7.1871 - val_loss: 0.1619 - val_auc: 0.9832 - val_accuracy: 0.9428 - val_cost: 6.8155\n",
            "Epoch 15/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1529 - auc: 0.9844 - accuracy: 0.9453 - cost: 6.9340 - val_loss: 0.1558 - val_auc: 0.9836 - val_accuracy: 0.9447 - val_cost: 6.9345\n",
            "Epoch 16/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1489 - auc: 0.9852 - accuracy: 0.9474 - cost: 6.6748 - val_loss: 0.1519 - val_auc: 0.9846 - val_accuracy: 0.9473 - val_cost: 6.4319\n",
            "Epoch 17/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1449 - auc: 0.9858 - accuracy: 0.9483 - cost: 6.5718 - val_loss: 0.1497 - val_auc: 0.9848 - val_accuracy: 0.9483 - val_cost: 6.3558\n",
            "Epoch 18/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1427 - auc: 0.9862 - accuracy: 0.9496 - cost: 6.3858 - val_loss: 0.1456 - val_auc: 0.9854 - val_accuracy: 0.9483 - val_cost: 6.4484\n",
            "Epoch 19/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1382 - auc: 0.9869 - accuracy: 0.9514 - cost: 6.1617 - val_loss: 0.1439 - val_auc: 0.9859 - val_accuracy: 0.9496 - val_cost: 6.2070\n",
            "Epoch 20/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1363 - auc: 0.9872 - accuracy: 0.9533 - cost: 5.9367 - val_loss: 0.1424 - val_auc: 0.9860 - val_accuracy: 0.9507 - val_cost: 6.1475\n",
            "Epoch 21/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1331 - auc: 0.9878 - accuracy: 0.9539 - cost: 5.8476 - val_loss: 0.1412 - val_auc: 0.9861 - val_accuracy: 0.9508 - val_cost: 6.1574\n",
            "Epoch 22/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1311 - auc: 0.9880 - accuracy: 0.9549 - cost: 5.7303 - val_loss: 0.1386 - val_auc: 0.9865 - val_accuracy: 0.9524 - val_cost: 5.9722\n",
            "Epoch 23/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1287 - auc: 0.9884 - accuracy: 0.9561 - cost: 5.5656 - val_loss: 0.1352 - val_auc: 0.9869 - val_accuracy: 0.9553 - val_cost: 5.6250\n",
            "Epoch 24/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1255 - auc: 0.9888 - accuracy: 0.9567 - cost: 5.5008 - val_loss: 0.1351 - val_auc: 0.9870 - val_accuracy: 0.9538 - val_cost: 5.8565\n",
            "Epoch 25/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1237 - auc: 0.9892 - accuracy: 0.9579 - cost: 5.3468 - val_loss: 0.1326 - val_auc: 0.9873 - val_accuracy: 0.9561 - val_cost: 5.5522\n",
            "Epoch 26/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1227 - auc: 0.9892 - accuracy: 0.9584 - cost: 5.2836 - val_loss: 0.1335 - val_auc: 0.9874 - val_accuracy: 0.9553 - val_cost: 5.4101\n",
            "Epoch 27/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.1200 - auc: 0.9896 - accuracy: 0.9601 - cost: 5.0814 - val_loss: 0.1318 - val_auc: 0.9874 - val_accuracy: 0.9576 - val_cost: 5.3935\n",
            "Epoch 28/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1176 - auc: 0.9899 - accuracy: 0.9605 - cost: 5.0274 - val_loss: 0.1299 - val_auc: 0.9876 - val_accuracy: 0.9581 - val_cost: 5.2910\n",
            "Epoch 29/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1167 - auc: 0.9900 - accuracy: 0.9609 - cost: 4.9734 - val_loss: 0.1286 - val_auc: 0.9876 - val_accuracy: 0.9586 - val_cost: 5.1025\n",
            "Epoch 30/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1141 - auc: 0.9904 - accuracy: 0.9622 - cost: 4.8094 - val_loss: 0.1282 - val_auc: 0.9877 - val_accuracy: 0.9599 - val_cost: 4.8909\n",
            "Epoch 31/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1131 - auc: 0.9905 - accuracy: 0.9625 - cost: 4.7581 - val_loss: 0.1262 - val_auc: 0.9880 - val_accuracy: 0.9592 - val_cost: 5.1290\n",
            "Epoch 32/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1115 - auc: 0.9908 - accuracy: 0.9630 - cost: 4.7006 - val_loss: 0.1271 - val_auc: 0.9878 - val_accuracy: 0.9585 - val_cost: 5.1025\n",
            "Epoch 33/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1096 - auc: 0.9910 - accuracy: 0.9640 - cost: 4.5860 - val_loss: 0.1262 - val_auc: 0.9880 - val_accuracy: 0.9599 - val_cost: 5.0827\n",
            "Epoch 34/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1091 - auc: 0.9910 - accuracy: 0.9644 - cost: 4.5332 - val_loss: 0.1247 - val_auc: 0.9883 - val_accuracy: 0.9603 - val_cost: 4.9372\n",
            "Epoch 35/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1073 - auc: 0.9913 - accuracy: 0.9651 - cost: 4.4367 - val_loss: 0.1255 - val_auc: 0.9884 - val_accuracy: 0.9593 - val_cost: 4.8743\n",
            "Epoch 36/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.1061 - auc: 0.9914 - accuracy: 0.9658 - cost: 4.3472 - val_loss: 0.1229 - val_auc: 0.9884 - val_accuracy: 0.9602 - val_cost: 4.9636\n",
            "Epoch 37/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1045 - auc: 0.9915 - accuracy: 0.9655 - cost: 4.3931 - val_loss: 0.1219 - val_auc: 0.9885 - val_accuracy: 0.9611 - val_cost: 4.7189\n",
            "Epoch 38/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1033 - auc: 0.9916 - accuracy: 0.9670 - cost: 4.1983 - val_loss: 0.1229 - val_auc: 0.9884 - val_accuracy: 0.9607 - val_cost: 4.8810\n",
            "Epoch 39/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1030 - auc: 0.9917 - accuracy: 0.9667 - cost: 4.2365 - val_loss: 0.1225 - val_auc: 0.9886 - val_accuracy: 0.9616 - val_cost: 4.6098\n",
            "Epoch 40/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1023 - auc: 0.9917 - accuracy: 0.9674 - cost: 4.1474 - val_loss: 0.1202 - val_auc: 0.9887 - val_accuracy: 0.9629 - val_cost: 4.6925\n",
            "Epoch 41/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.1013 - auc: 0.9919 - accuracy: 0.9671 - cost: 4.2029 - val_loss: 0.1208 - val_auc: 0.9887 - val_accuracy: 0.9612 - val_cost: 4.7553\n",
            "Epoch 42/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1002 - auc: 0.9919 - accuracy: 0.9677 - cost: 4.1076 - val_loss: 0.1186 - val_auc: 0.9889 - val_accuracy: 0.9640 - val_cost: 4.5569\n",
            "Epoch 43/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0988 - auc: 0.9922 - accuracy: 0.9685 - cost: 4.0150 - val_loss: 0.1189 - val_auc: 0.9891 - val_accuracy: 0.9627 - val_cost: 4.6759\n",
            "Epoch 44/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0976 - auc: 0.9922 - accuracy: 0.9690 - cost: 3.9545 - val_loss: 0.1183 - val_auc: 0.9890 - val_accuracy: 0.9626 - val_cost: 4.5899\n",
            "Epoch 45/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0969 - auc: 0.9924 - accuracy: 0.9691 - cost: 3.9406 - val_loss: 0.1174 - val_auc: 0.9892 - val_accuracy: 0.9644 - val_cost: 4.3188\n",
            "Epoch 46/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0958 - auc: 0.9925 - accuracy: 0.9695 - cost: 3.8866 - val_loss: 0.1171 - val_auc: 0.9891 - val_accuracy: 0.9637 - val_cost: 4.5635\n",
            "Epoch 47/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0955 - auc: 0.9926 - accuracy: 0.9697 - cost: 3.8630 - val_loss: 0.1175 - val_auc: 0.9892 - val_accuracy: 0.9634 - val_cost: 4.4180\n",
            "Epoch 48/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0948 - auc: 0.9926 - accuracy: 0.9697 - cost: 3.8515 - val_loss: 0.1161 - val_auc: 0.9895 - val_accuracy: 0.9644 - val_cost: 4.5073\n",
            "Epoch 49/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0939 - auc: 0.9927 - accuracy: 0.9705 - cost: 3.7666 - val_loss: 0.1156 - val_auc: 0.9894 - val_accuracy: 0.9651 - val_cost: 4.3485\n",
            "Epoch 50/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0926 - auc: 0.9928 - accuracy: 0.9710 - cost: 3.6968 - val_loss: 0.1163 - val_auc: 0.9891 - val_accuracy: 0.9655 - val_cost: 4.3981\n",
            "Epoch 51/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0920 - auc: 0.9929 - accuracy: 0.9710 - cost: 3.6964 - val_loss: 0.1143 - val_auc: 0.9894 - val_accuracy: 0.9658 - val_cost: 4.2328\n",
            "Epoch 52/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0907 - auc: 0.9929 - accuracy: 0.9716 - cost: 3.6285 - val_loss: 0.1141 - val_auc: 0.9895 - val_accuracy: 0.9653 - val_cost: 4.2593\n",
            "Epoch 53/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0907 - auc: 0.9929 - accuracy: 0.9714 - cost: 3.6512 - val_loss: 0.1140 - val_auc: 0.9897 - val_accuracy: 0.9648 - val_cost: 4.3287\n",
            "Epoch 54/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0898 - auc: 0.9932 - accuracy: 0.9724 - cost: 3.5174 - val_loss: 0.1143 - val_auc: 0.9894 - val_accuracy: 0.9661 - val_cost: 4.2163\n",
            "Epoch 55/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0893 - auc: 0.9932 - accuracy: 0.9724 - cost: 3.5251 - val_loss: 0.1142 - val_auc: 0.9895 - val_accuracy: 0.9664 - val_cost: 4.2626\n",
            "Epoch 56/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0879 - auc: 0.9933 - accuracy: 0.9723 - cost: 3.5475 - val_loss: 0.1131 - val_auc: 0.9896 - val_accuracy: 0.9674 - val_cost: 3.9980\n",
            "Epoch 57/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0883 - auc: 0.9933 - accuracy: 0.9724 - cost: 3.5154 - val_loss: 0.1121 - val_auc: 0.9899 - val_accuracy: 0.9664 - val_cost: 4.2295\n",
            "Epoch 58/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0873 - auc: 0.9934 - accuracy: 0.9729 - cost: 3.4591 - val_loss: 0.1114 - val_auc: 0.9898 - val_accuracy: 0.9674 - val_cost: 4.0575\n",
            "Epoch 59/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0873 - auc: 0.9933 - accuracy: 0.9731 - cost: 3.4398 - val_loss: 0.1127 - val_auc: 0.9895 - val_accuracy: 0.9672 - val_cost: 4.0675\n",
            "Epoch 60/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0864 - auc: 0.9934 - accuracy: 0.9737 - cost: 3.3584 - val_loss: 0.1134 - val_auc: 0.9895 - val_accuracy: 0.9667 - val_cost: 4.2824\n",
            "Epoch 61/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0858 - auc: 0.9935 - accuracy: 0.9731 - cost: 3.4275 - val_loss: 0.1119 - val_auc: 0.9898 - val_accuracy: 0.9669 - val_cost: 4.0840\n",
            "Epoch 62/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0847 - auc: 0.9937 - accuracy: 0.9736 - cost: 3.3785 - val_loss: 0.1110 - val_auc: 0.9898 - val_accuracy: 0.9680 - val_cost: 3.9782\n",
            "Epoch 63/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0841 - auc: 0.9938 - accuracy: 0.9739 - cost: 3.3295 - val_loss: 0.1117 - val_auc: 0.9900 - val_accuracy: 0.9675 - val_cost: 4.1799\n",
            "Epoch 64/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0838 - auc: 0.9938 - accuracy: 0.9742 - cost: 3.3071 - val_loss: 0.1099 - val_auc: 0.9899 - val_accuracy: 0.9672 - val_cost: 4.0476\n",
            "Epoch 65/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0833 - auc: 0.9938 - accuracy: 0.9748 - cost: 3.2176 - val_loss: 0.1094 - val_auc: 0.9901 - val_accuracy: 0.9690 - val_cost: 3.9120\n",
            "Epoch 66/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0839 - auc: 0.9937 - accuracy: 0.9739 - cost: 3.3426 - val_loss: 0.1097 - val_auc: 0.9898 - val_accuracy: 0.9683 - val_cost: 3.9352\n",
            "Epoch 67/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0827 - auc: 0.9939 - accuracy: 0.9743 - cost: 3.2716 - val_loss: 0.1092 - val_auc: 0.9900 - val_accuracy: 0.9690 - val_cost: 3.8459\n",
            "Epoch 68/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0826 - auc: 0.9939 - accuracy: 0.9746 - cost: 3.2473 - val_loss: 0.1105 - val_auc: 0.9896 - val_accuracy: 0.9688 - val_cost: 3.9054\n",
            "Epoch 69/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0812 - auc: 0.9941 - accuracy: 0.9748 - cost: 3.2234 - val_loss: 0.1104 - val_auc: 0.9899 - val_accuracy: 0.9680 - val_cost: 4.0146\n",
            "Epoch 70/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0817 - auc: 0.9940 - accuracy: 0.9747 - cost: 3.2234 - val_loss: 0.1114 - val_auc: 0.9898 - val_accuracy: 0.9681 - val_cost: 4.0642\n",
            "Epoch 71/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0820 - auc: 0.9939 - accuracy: 0.9750 - cost: 3.2006 - val_loss: 0.1101 - val_auc: 0.9900 - val_accuracy: 0.9683 - val_cost: 3.9815\n",
            "Epoch 72/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0800 - auc: 0.9942 - accuracy: 0.9751 - cost: 3.1902 - val_loss: 0.1099 - val_auc: 0.9899 - val_accuracy: 0.9690 - val_cost: 3.7897\n",
            "Epoch 73/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0799 - auc: 0.9942 - accuracy: 0.9752 - cost: 3.1613 - val_loss: 0.1122 - val_auc: 0.9897 - val_accuracy: 0.9673 - val_cost: 3.9187\n",
            "Epoch 74/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0799 - auc: 0.9941 - accuracy: 0.9755 - cost: 3.1223 - val_loss: 0.1091 - val_auc: 0.9900 - val_accuracy: 0.9693 - val_cost: 3.8128\n",
            "Epoch 75/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0786 - auc: 0.9942 - accuracy: 0.9761 - cost: 3.0478 - val_loss: 0.1112 - val_auc: 0.9900 - val_accuracy: 0.9684 - val_cost: 3.9649\n",
            "Epoch 76/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0792 - auc: 0.9942 - accuracy: 0.9759 - cost: 3.0810 - val_loss: 0.1084 - val_auc: 0.9902 - val_accuracy: 0.9699 - val_cost: 3.7500\n",
            "Epoch 77/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0789 - auc: 0.9942 - accuracy: 0.9760 - cost: 3.0617 - val_loss: 0.1108 - val_auc: 0.9902 - val_accuracy: 0.9679 - val_cost: 3.9484\n",
            "Epoch 78/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0779 - auc: 0.9943 - accuracy: 0.9762 - cost: 3.0409 - val_loss: 0.1098 - val_auc: 0.9904 - val_accuracy: 0.9686 - val_cost: 3.9451\n",
            "Epoch 79/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0785 - auc: 0.9943 - accuracy: 0.9761 - cost: 3.0606 - val_loss: 0.1105 - val_auc: 0.9903 - val_accuracy: 0.9687 - val_cost: 3.9815\n",
            "Epoch 80/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0772 - auc: 0.9944 - accuracy: 0.9767 - cost: 2.9738 - val_loss: 0.1133 - val_auc: 0.9899 - val_accuracy: 0.9673 - val_cost: 4.0509\n",
            "Epoch 81/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0776 - auc: 0.9943 - accuracy: 0.9761 - cost: 3.0525 - val_loss: 0.1114 - val_auc: 0.9900 - val_accuracy: 0.9683 - val_cost: 4.0311\n",
            "Epoch 82/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0781 - auc: 0.9943 - accuracy: 0.9765 - cost: 2.9965 - val_loss: 0.1099 - val_auc: 0.9901 - val_accuracy: 0.9694 - val_cost: 3.7765\n",
            "Epoch 83/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0770 - auc: 0.9944 - accuracy: 0.9768 - cost: 2.9672 - val_loss: 0.1098 - val_auc: 0.9902 - val_accuracy: 0.9701 - val_cost: 3.8228\n",
            "Epoch 84/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0765 - auc: 0.9945 - accuracy: 0.9769 - cost: 2.9576 - val_loss: 0.1113 - val_auc: 0.9899 - val_accuracy: 0.9694 - val_cost: 3.7798\n",
            "Epoch 85/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0764 - auc: 0.9945 - accuracy: 0.9772 - cost: 2.9290 - val_loss: 0.1104 - val_auc: 0.9900 - val_accuracy: 0.9695 - val_cost: 3.7831\n",
            "Epoch 86/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0756 - auc: 0.9946 - accuracy: 0.9768 - cost: 2.9684 - val_loss: 0.1123 - val_auc: 0.9899 - val_accuracy: 0.9693 - val_cost: 3.6673\n",
            "Epoch 87/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0763 - auc: 0.9944 - accuracy: 0.9770 - cost: 2.9468 - val_loss: 0.1104 - val_auc: 0.9902 - val_accuracy: 0.9690 - val_cost: 3.8790\n",
            "Epoch 88/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0753 - auc: 0.9946 - accuracy: 0.9770 - cost: 2.9367 - val_loss: 0.1087 - val_auc: 0.9901 - val_accuracy: 0.9697 - val_cost: 3.7897\n",
            "Epoch 89/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0757 - auc: 0.9945 - accuracy: 0.9774 - cost: 2.8939 - val_loss: 0.1083 - val_auc: 0.9901 - val_accuracy: 0.9699 - val_cost: 3.8095\n",
            "Epoch 90/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0741 - auc: 0.9947 - accuracy: 0.9779 - cost: 2.8279 - val_loss: 0.1107 - val_auc: 0.9900 - val_accuracy: 0.9691 - val_cost: 3.8591\n",
            "Epoch 91/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0741 - auc: 0.9947 - accuracy: 0.9777 - cost: 2.8569 - val_loss: 0.1101 - val_auc: 0.9901 - val_accuracy: 0.9702 - val_cost: 3.6442\n",
            "Epoch 92/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0744 - auc: 0.9947 - accuracy: 0.9781 - cost: 2.7901 - val_loss: 0.1111 - val_auc: 0.9900 - val_accuracy: 0.9701 - val_cost: 3.7632\n",
            "Epoch 93/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0745 - auc: 0.9946 - accuracy: 0.9774 - cost: 2.8989 - val_loss: 0.1099 - val_auc: 0.9900 - val_accuracy: 0.9694 - val_cost: 3.8757\n",
            "Epoch 94/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0742 - auc: 0.9946 - accuracy: 0.9777 - cost: 2.8576 - val_loss: 0.1104 - val_auc: 0.9901 - val_accuracy: 0.9697 - val_cost: 3.8062\n",
            "Epoch 95/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0728 - auc: 0.9948 - accuracy: 0.9780 - cost: 2.8198 - val_loss: 0.1105 - val_auc: 0.9899 - val_accuracy: 0.9688 - val_cost: 3.9187\n",
            "Epoch 96/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0742 - auc: 0.9946 - accuracy: 0.9777 - cost: 2.8534 - val_loss: 0.1096 - val_auc: 0.9900 - val_accuracy: 0.9699 - val_cost: 3.7037\n",
            "Epoch 97/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0737 - auc: 0.9947 - accuracy: 0.9774 - cost: 2.8985 - val_loss: 0.1123 - val_auc: 0.9901 - val_accuracy: 0.9690 - val_cost: 4.0013\n",
            "Epoch 98/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0726 - auc: 0.9947 - accuracy: 0.9781 - cost: 2.8102 - val_loss: 0.1109 - val_auc: 0.9899 - val_accuracy: 0.9701 - val_cost: 3.6343\n",
            "Epoch 99/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0726 - auc: 0.9950 - accuracy: 0.9784 - cost: 2.7654 - val_loss: 0.1103 - val_auc: 0.9899 - val_accuracy: 0.9697 - val_cost: 3.8624\n",
            "Epoch 100/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0724 - auc: 0.9949 - accuracy: 0.9785 - cost: 2.7539 - val_loss: 0.1132 - val_auc: 0.9898 - val_accuracy: 0.9703 - val_cost: 3.5747\n",
            "Epoch 101/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0732 - auc: 0.9949 - accuracy: 0.9781 - cost: 2.8086 - val_loss: 0.1128 - val_auc: 0.9898 - val_accuracy: 0.9692 - val_cost: 3.9385\n",
            "Epoch 102/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0729 - auc: 0.9948 - accuracy: 0.9782 - cost: 2.7948 - val_loss: 0.1107 - val_auc: 0.9900 - val_accuracy: 0.9700 - val_cost: 3.7500\n",
            "Epoch 103/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0721 - auc: 0.9949 - accuracy: 0.9783 - cost: 2.7809 - val_loss: 0.1107 - val_auc: 0.9903 - val_accuracy: 0.9709 - val_cost: 3.6177\n",
            "Epoch 104/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0720 - auc: 0.9949 - accuracy: 0.9783 - cost: 2.7647 - val_loss: 0.1112 - val_auc: 0.9898 - val_accuracy: 0.9694 - val_cost: 3.8690\n",
            "Epoch 105/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0712 - auc: 0.9950 - accuracy: 0.9784 - cost: 2.7616 - val_loss: 0.1108 - val_auc: 0.9903 - val_accuracy: 0.9702 - val_cost: 3.7566\n",
            "Epoch 106/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0719 - auc: 0.9949 - accuracy: 0.9782 - cost: 2.7855 - val_loss: 0.1114 - val_auc: 0.9898 - val_accuracy: 0.9697 - val_cost: 3.7963\n",
            "Epoch 107/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0711 - auc: 0.9950 - accuracy: 0.9790 - cost: 2.6995 - val_loss: 0.1129 - val_auc: 0.9897 - val_accuracy: 0.9695 - val_cost: 3.8790\n",
            "Epoch 108/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0714 - auc: 0.9950 - accuracy: 0.9785 - cost: 2.7589 - val_loss: 0.1109 - val_auc: 0.9899 - val_accuracy: 0.9698 - val_cost: 3.7599\n",
            "Epoch 109/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0718 - auc: 0.9948 - accuracy: 0.9784 - cost: 2.7461 - val_loss: 0.1104 - val_auc: 0.9901 - val_accuracy: 0.9700 - val_cost: 3.7798\n",
            "Epoch 110/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0712 - auc: 0.9949 - accuracy: 0.9787 - cost: 2.7203 - val_loss: 0.1107 - val_auc: 0.9900 - val_accuracy: 0.9703 - val_cost: 3.7368\n",
            "Epoch 111/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0719 - auc: 0.9949 - accuracy: 0.9782 - cost: 2.7894 - val_loss: 0.1112 - val_auc: 0.9899 - val_accuracy: 0.9701 - val_cost: 3.7269\n",
            "Epoch 112/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0700 - auc: 0.9951 - accuracy: 0.9789 - cost: 2.6987 - val_loss: 0.1127 - val_auc: 0.9899 - val_accuracy: 0.9695 - val_cost: 3.7235\n",
            "Epoch 113/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0707 - auc: 0.9949 - accuracy: 0.9789 - cost: 2.7037 - val_loss: 0.1106 - val_auc: 0.9897 - val_accuracy: 0.9704 - val_cost: 3.6475\n",
            "Epoch 114/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0698 - auc: 0.9950 - accuracy: 0.9791 - cost: 2.6744 - val_loss: 0.1096 - val_auc: 0.9903 - val_accuracy: 0.9701 - val_cost: 3.7037\n",
            "Epoch 115/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0706 - auc: 0.9951 - accuracy: 0.9790 - cost: 2.6964 - val_loss: 0.1112 - val_auc: 0.9897 - val_accuracy: 0.9708 - val_cost: 3.6574\n",
            "Epoch 116/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0698 - auc: 0.9951 - accuracy: 0.9792 - cost: 2.6644 - val_loss: 0.1122 - val_auc: 0.9897 - val_accuracy: 0.9698 - val_cost: 3.6938\n",
            "Epoch 117/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0697 - auc: 0.9951 - accuracy: 0.9796 - cost: 2.6204 - val_loss: 0.1113 - val_auc: 0.9901 - val_accuracy: 0.9703 - val_cost: 3.6574\n",
            "Epoch 118/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0700 - auc: 0.9949 - accuracy: 0.9792 - cost: 2.6705 - val_loss: 0.1095 - val_auc: 0.9902 - val_accuracy: 0.9703 - val_cost: 3.6839\n",
            "Epoch 119/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0693 - auc: 0.9952 - accuracy: 0.9795 - cost: 2.6292 - val_loss: 0.1126 - val_auc: 0.9898 - val_accuracy: 0.9701 - val_cost: 3.6905\n",
            "Epoch 120/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0697 - auc: 0.9951 - accuracy: 0.9794 - cost: 2.6319 - val_loss: 0.1107 - val_auc: 0.9900 - val_accuracy: 0.9706 - val_cost: 3.7202\n",
            "Epoch 121/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0689 - auc: 0.9952 - accuracy: 0.9796 - cost: 2.6177 - val_loss: 0.1124 - val_auc: 0.9899 - val_accuracy: 0.9718 - val_cost: 3.4226\n",
            "Epoch 122/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0686 - auc: 0.9952 - accuracy: 0.9795 - cost: 2.6308 - val_loss: 0.1120 - val_auc: 0.9901 - val_accuracy: 0.9708 - val_cost: 3.5714\n",
            "Epoch 123/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0683 - auc: 0.9953 - accuracy: 0.9795 - cost: 2.6235 - val_loss: 0.1139 - val_auc: 0.9897 - val_accuracy: 0.9699 - val_cost: 3.6806\n",
            "Epoch 124/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0692 - auc: 0.9952 - accuracy: 0.9791 - cost: 2.6836 - val_loss: 0.1125 - val_auc: 0.9898 - val_accuracy: 0.9708 - val_cost: 3.6739\n",
            "Epoch 125/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0686 - auc: 0.9952 - accuracy: 0.9798 - cost: 2.5907 - val_loss: 0.1114 - val_auc: 0.9900 - val_accuracy: 0.9705 - val_cost: 3.7202\n",
            "Epoch 126/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0679 - auc: 0.9953 - accuracy: 0.9803 - cost: 2.5313 - val_loss: 0.1143 - val_auc: 0.9896 - val_accuracy: 0.9697 - val_cost: 3.7335\n",
            "Epoch 127/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0682 - auc: 0.9953 - accuracy: 0.9798 - cost: 2.5876 - val_loss: 0.1129 - val_auc: 0.9902 - val_accuracy: 0.9701 - val_cost: 3.8790\n",
            "Epoch 128/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0687 - auc: 0.9953 - accuracy: 0.9793 - cost: 2.6485 - val_loss: 0.1132 - val_auc: 0.9899 - val_accuracy: 0.9705 - val_cost: 3.6739\n",
            "Epoch 129/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0681 - auc: 0.9951 - accuracy: 0.9798 - cost: 2.5937 - val_loss: 0.1122 - val_auc: 0.9897 - val_accuracy: 0.9700 - val_cost: 3.7037\n",
            "Epoch 130/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0687 - auc: 0.9952 - accuracy: 0.9797 - cost: 2.6007 - val_loss: 0.1121 - val_auc: 0.9898 - val_accuracy: 0.9712 - val_cost: 3.5946\n",
            "Epoch 131/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0688 - auc: 0.9951 - accuracy: 0.9797 - cost: 2.6019 - val_loss: 0.1130 - val_auc: 0.9898 - val_accuracy: 0.9698 - val_cost: 3.8095\n",
            "Epoch 132/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0686 - auc: 0.9952 - accuracy: 0.9797 - cost: 2.6080 - val_loss: 0.1103 - val_auc: 0.9901 - val_accuracy: 0.9705 - val_cost: 3.6574\n",
            "Epoch 133/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0677 - auc: 0.9952 - accuracy: 0.9798 - cost: 2.5791 - val_loss: 0.1142 - val_auc: 0.9898 - val_accuracy: 0.9706 - val_cost: 3.5880\n",
            "Epoch 134/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0675 - auc: 0.9952 - accuracy: 0.9800 - cost: 2.5656 - val_loss: 0.1129 - val_auc: 0.9896 - val_accuracy: 0.9697 - val_cost: 3.7632\n",
            "Epoch 135/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0671 - auc: 0.9953 - accuracy: 0.9801 - cost: 2.5498 - val_loss: 0.1158 - val_auc: 0.9893 - val_accuracy: 0.9708 - val_cost: 3.5946\n",
            "Epoch 136/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0679 - auc: 0.9953 - accuracy: 0.9799 - cost: 2.5752 - val_loss: 0.1100 - val_auc: 0.9902 - val_accuracy: 0.9710 - val_cost: 3.6144\n",
            "Epoch 137/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0672 - auc: 0.9953 - accuracy: 0.9803 - cost: 2.5282 - val_loss: 0.1126 - val_auc: 0.9897 - val_accuracy: 0.9704 - val_cost: 3.6442\n",
            "Epoch 138/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0687 - auc: 0.9953 - accuracy: 0.9792 - cost: 2.6752 - val_loss: 0.1102 - val_auc: 0.9901 - val_accuracy: 0.9704 - val_cost: 3.7566\n",
            "Epoch 139/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0675 - auc: 0.9954 - accuracy: 0.9799 - cost: 2.5826 - val_loss: 0.1118 - val_auc: 0.9897 - val_accuracy: 0.9708 - val_cost: 3.6574\n",
            "Epoch 140/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0677 - auc: 0.9953 - accuracy: 0.9799 - cost: 2.5787 - val_loss: 0.1124 - val_auc: 0.9900 - val_accuracy: 0.9699 - val_cost: 3.7632\n",
            "Epoch 141/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0670 - auc: 0.9955 - accuracy: 0.9797 - cost: 2.5995 - val_loss: 0.1129 - val_auc: 0.9897 - val_accuracy: 0.9699 - val_cost: 3.7235\n",
            "Epoch 142/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0663 - auc: 0.9955 - accuracy: 0.9804 - cost: 2.5174 - val_loss: 0.1128 - val_auc: 0.9899 - val_accuracy: 0.9703 - val_cost: 3.5714\n",
            "Epoch 143/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0664 - auc: 0.9954 - accuracy: 0.9802 - cost: 2.5397 - val_loss: 0.1134 - val_auc: 0.9897 - val_accuracy: 0.9701 - val_cost: 3.6673\n",
            "Epoch 144/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0667 - auc: 0.9953 - accuracy: 0.9802 - cost: 2.5405 - val_loss: 0.1119 - val_auc: 0.9901 - val_accuracy: 0.9707 - val_cost: 3.6376\n",
            "Epoch 145/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0667 - auc: 0.9954 - accuracy: 0.9804 - cost: 2.5143 - val_loss: 0.1106 - val_auc: 0.9901 - val_accuracy: 0.9708 - val_cost: 3.6607\n",
            "Epoch 146/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0664 - auc: 0.9955 - accuracy: 0.9807 - cost: 2.4753 - val_loss: 0.1143 - val_auc: 0.9898 - val_accuracy: 0.9710 - val_cost: 3.5086\n",
            "Epoch 147/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0669 - auc: 0.9953 - accuracy: 0.9804 - cost: 2.5197 - val_loss: 0.1128 - val_auc: 0.9900 - val_accuracy: 0.9711 - val_cost: 3.5946\n",
            "Epoch 148/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0664 - auc: 0.9954 - accuracy: 0.9804 - cost: 2.5131 - val_loss: 0.1136 - val_auc: 0.9896 - val_accuracy: 0.9706 - val_cost: 3.6276\n",
            "Epoch 149/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0667 - auc: 0.9953 - accuracy: 0.9805 - cost: 2.4977 - val_loss: 0.1121 - val_auc: 0.9900 - val_accuracy: 0.9712 - val_cost: 3.5813\n",
            "Epoch 150/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0662 - auc: 0.9955 - accuracy: 0.9806 - cost: 2.4834 - val_loss: 0.1137 - val_auc: 0.9899 - val_accuracy: 0.9714 - val_cost: 3.5119\n",
            "Epoch 151/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0659 - auc: 0.9955 - accuracy: 0.9805 - cost: 2.4992 - val_loss: 0.1111 - val_auc: 0.9902 - val_accuracy: 0.9717 - val_cost: 3.4921\n",
            "Epoch 152/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0661 - auc: 0.9954 - accuracy: 0.9804 - cost: 2.5147 - val_loss: 0.1129 - val_auc: 0.9898 - val_accuracy: 0.9710 - val_cost: 3.5384\n",
            "Epoch 153/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0652 - auc: 0.9955 - accuracy: 0.9806 - cost: 2.4823 - val_loss: 0.1112 - val_auc: 0.9902 - val_accuracy: 0.9716 - val_cost: 3.4854\n",
            "Epoch 154/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0662 - auc: 0.9955 - accuracy: 0.9806 - cost: 2.4915 - val_loss: 0.1125 - val_auc: 0.9902 - val_accuracy: 0.9717 - val_cost: 3.5218\n",
            "Epoch 155/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0659 - auc: 0.9954 - accuracy: 0.9804 - cost: 2.5197 - val_loss: 0.1115 - val_auc: 0.9899 - val_accuracy: 0.9713 - val_cost: 3.6210\n",
            "Epoch 156/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0656 - auc: 0.9955 - accuracy: 0.9808 - cost: 2.4606 - val_loss: 0.1122 - val_auc: 0.9901 - val_accuracy: 0.9712 - val_cost: 3.5714\n",
            "Epoch 157/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0654 - auc: 0.9954 - accuracy: 0.9803 - cost: 2.5285 - val_loss: 0.1134 - val_auc: 0.9899 - val_accuracy: 0.9709 - val_cost: 3.5913\n",
            "Epoch 158/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0660 - auc: 0.9955 - accuracy: 0.9803 - cost: 2.5258 - val_loss: 0.1120 - val_auc: 0.9900 - val_accuracy: 0.9715 - val_cost: 3.5317\n",
            "Epoch 159/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0657 - auc: 0.9955 - accuracy: 0.9803 - cost: 2.5347 - val_loss: 0.1128 - val_auc: 0.9900 - val_accuracy: 0.9717 - val_cost: 3.4854\n",
            "Epoch 160/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0648 - auc: 0.9956 - accuracy: 0.9811 - cost: 2.4221 - val_loss: 0.1119 - val_auc: 0.9901 - val_accuracy: 0.9711 - val_cost: 3.5780\n",
            "Epoch 161/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0651 - auc: 0.9956 - accuracy: 0.9805 - cost: 2.4946 - val_loss: 0.1125 - val_auc: 0.9899 - val_accuracy: 0.9717 - val_cost: 3.4987\n",
            "Epoch 162/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0646 - auc: 0.9956 - accuracy: 0.9811 - cost: 2.4232 - val_loss: 0.1127 - val_auc: 0.9899 - val_accuracy: 0.9712 - val_cost: 3.4689\n",
            "Epoch 163/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0653 - auc: 0.9956 - accuracy: 0.9809 - cost: 2.4487 - val_loss: 0.1128 - val_auc: 0.9900 - val_accuracy: 0.9720 - val_cost: 3.4325\n",
            "Epoch 164/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0656 - auc: 0.9956 - accuracy: 0.9809 - cost: 2.4529 - val_loss: 0.1126 - val_auc: 0.9900 - val_accuracy: 0.9710 - val_cost: 3.6177\n",
            "Epoch 165/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0650 - auc: 0.9956 - accuracy: 0.9808 - cost: 2.4641 - val_loss: 0.1152 - val_auc: 0.9897 - val_accuracy: 0.9715 - val_cost: 3.5913\n",
            "Epoch 166/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0650 - auc: 0.9956 - accuracy: 0.9805 - cost: 2.5031 - val_loss: 0.1110 - val_auc: 0.9901 - val_accuracy: 0.9716 - val_cost: 3.5284\n",
            "Epoch 167/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0645 - auc: 0.9956 - accuracy: 0.9810 - cost: 2.4356 - val_loss: 0.1138 - val_auc: 0.9896 - val_accuracy: 0.9712 - val_cost: 3.4954\n",
            "Epoch 168/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0643 - auc: 0.9957 - accuracy: 0.9808 - cost: 2.4549 - val_loss: 0.1134 - val_auc: 0.9898 - val_accuracy: 0.9712 - val_cost: 3.4855\n",
            "Epoch 169/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0635 - auc: 0.9958 - accuracy: 0.9813 - cost: 2.4008 - val_loss: 0.1153 - val_auc: 0.9894 - val_accuracy: 0.9719 - val_cost: 3.4127\n",
            "Epoch 170/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0642 - auc: 0.9956 - accuracy: 0.9810 - cost: 2.4282 - val_loss: 0.1123 - val_auc: 0.9897 - val_accuracy: 0.9713 - val_cost: 3.6276\n",
            "Epoch 171/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0641 - auc: 0.9957 - accuracy: 0.9812 - cost: 2.4082 - val_loss: 0.1122 - val_auc: 0.9898 - val_accuracy: 0.9713 - val_cost: 3.6012\n",
            "Epoch 172/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0644 - auc: 0.9958 - accuracy: 0.9810 - cost: 2.4360 - val_loss: 0.1125 - val_auc: 0.9899 - val_accuracy: 0.9713 - val_cost: 3.4888\n",
            "Epoch 173/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0643 - auc: 0.9957 - accuracy: 0.9811 - cost: 2.4167 - val_loss: 0.1129 - val_auc: 0.9899 - val_accuracy: 0.9706 - val_cost: 3.6806\n",
            "Epoch 174/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0646 - auc: 0.9956 - accuracy: 0.9811 - cost: 2.4259 - val_loss: 0.1129 - val_auc: 0.9902 - val_accuracy: 0.9712 - val_cost: 3.5582\n",
            "Epoch 175/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0646 - auc: 0.9957 - accuracy: 0.9810 - cost: 2.4325 - val_loss: 0.1139 - val_auc: 0.9897 - val_accuracy: 0.9712 - val_cost: 3.5086\n",
            "Epoch 176/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0644 - auc: 0.9956 - accuracy: 0.9807 - cost: 2.4846 - val_loss: 0.1135 - val_auc: 0.9902 - val_accuracy: 0.9712 - val_cost: 3.5979\n",
            "Epoch 177/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0638 - auc: 0.9956 - accuracy: 0.9812 - cost: 2.4109 - val_loss: 0.1147 - val_auc: 0.9900 - val_accuracy: 0.9719 - val_cost: 3.4425\n",
            "Epoch 178/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0634 - auc: 0.9958 - accuracy: 0.9810 - cost: 2.4363 - val_loss: 0.1131 - val_auc: 0.9900 - val_accuracy: 0.9708 - val_cost: 3.6045\n",
            "Epoch 179/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0644 - auc: 0.9957 - accuracy: 0.9813 - cost: 2.3989 - val_loss: 0.1117 - val_auc: 0.9900 - val_accuracy: 0.9717 - val_cost: 3.5152\n",
            "Epoch 180/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0639 - auc: 0.9957 - accuracy: 0.9810 - cost: 2.4406 - val_loss: 0.1139 - val_auc: 0.9899 - val_accuracy: 0.9717 - val_cost: 3.5020\n",
            "Epoch 181/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0636 - auc: 0.9957 - accuracy: 0.9813 - cost: 2.3881 - val_loss: 0.1140 - val_auc: 0.9898 - val_accuracy: 0.9711 - val_cost: 3.5880\n",
            "Epoch 182/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0630 - auc: 0.9957 - accuracy: 0.9819 - cost: 2.3306 - val_loss: 0.1133 - val_auc: 0.9897 - val_accuracy: 0.9701 - val_cost: 3.7434\n",
            "Epoch 183/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0635 - auc: 0.9958 - accuracy: 0.9812 - cost: 2.4066 - val_loss: 0.1147 - val_auc: 0.9900 - val_accuracy: 0.9722 - val_cost: 3.4325\n",
            "Epoch 184/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0631 - auc: 0.9958 - accuracy: 0.9818 - cost: 2.3395 - val_loss: 0.1135 - val_auc: 0.9899 - val_accuracy: 0.9717 - val_cost: 3.5417\n",
            "Epoch 185/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0632 - auc: 0.9958 - accuracy: 0.9814 - cost: 2.3920 - val_loss: 0.1147 - val_auc: 0.9898 - val_accuracy: 0.9712 - val_cost: 3.5251\n",
            "Epoch 186/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0634 - auc: 0.9958 - accuracy: 0.9813 - cost: 2.4032 - val_loss: 0.1148 - val_auc: 0.9898 - val_accuracy: 0.9699 - val_cost: 3.7864\n",
            "Epoch 187/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0624 - auc: 0.9959 - accuracy: 0.9817 - cost: 2.3519 - val_loss: 0.1159 - val_auc: 0.9897 - val_accuracy: 0.9712 - val_cost: 3.5582\n",
            "Epoch 188/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0630 - auc: 0.9958 - accuracy: 0.9813 - cost: 2.4051 - val_loss: 0.1164 - val_auc: 0.9896 - val_accuracy: 0.9717 - val_cost: 3.4656\n",
            "Epoch 189/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0631 - auc: 0.9958 - accuracy: 0.9812 - cost: 2.4090 - val_loss: 0.1139 - val_auc: 0.9899 - val_accuracy: 0.9712 - val_cost: 3.5351\n",
            "Epoch 190/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0630 - auc: 0.9959 - accuracy: 0.9815 - cost: 2.3846 - val_loss: 0.1158 - val_auc: 0.9897 - val_accuracy: 0.9714 - val_cost: 3.5813\n",
            "Epoch 191/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0631 - auc: 0.9958 - accuracy: 0.9813 - cost: 2.3993 - val_loss: 0.1150 - val_auc: 0.9898 - val_accuracy: 0.9714 - val_cost: 3.4557\n",
            "Epoch 192/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0625 - auc: 0.9958 - accuracy: 0.9818 - cost: 2.3341 - val_loss: 0.1155 - val_auc: 0.9901 - val_accuracy: 0.9704 - val_cost: 3.6508\n",
            "Epoch 193/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0630 - auc: 0.9958 - accuracy: 0.9814 - cost: 2.3935 - val_loss: 0.1154 - val_auc: 0.9899 - val_accuracy: 0.9716 - val_cost: 3.4788\n",
            "Epoch 194/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0631 - auc: 0.9958 - accuracy: 0.9814 - cost: 2.3846 - val_loss: 0.1146 - val_auc: 0.9902 - val_accuracy: 0.9708 - val_cost: 3.7269\n",
            "Epoch 195/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0633 - auc: 0.9957 - accuracy: 0.9815 - cost: 2.3723 - val_loss: 0.1156 - val_auc: 0.9897 - val_accuracy: 0.9711 - val_cost: 3.5218\n",
            "Epoch 196/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0629 - auc: 0.9959 - accuracy: 0.9813 - cost: 2.3951 - val_loss: 0.1149 - val_auc: 0.9900 - val_accuracy: 0.9710 - val_cost: 3.5251\n",
            "Epoch 197/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0623 - auc: 0.9959 - accuracy: 0.9812 - cost: 2.4105 - val_loss: 0.1153 - val_auc: 0.9900 - val_accuracy: 0.9705 - val_cost: 3.6243\n",
            "Epoch 198/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0621 - auc: 0.9960 - accuracy: 0.9818 - cost: 2.3418 - val_loss: 0.1138 - val_auc: 0.9900 - val_accuracy: 0.9727 - val_cost: 3.3466\n",
            "Epoch 199/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0613 - auc: 0.9959 - accuracy: 0.9819 - cost: 2.3268 - val_loss: 0.1165 - val_auc: 0.9900 - val_accuracy: 0.9701 - val_cost: 3.7004\n",
            "Epoch 200/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0629 - auc: 0.9957 - accuracy: 0.9815 - cost: 2.3773 - val_loss: 0.1147 - val_auc: 0.9901 - val_accuracy: 0.9706 - val_cost: 3.6210\n",
            "Epoch 201/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0621 - auc: 0.9959 - accuracy: 0.9818 - cost: 2.3422 - val_loss: 0.1145 - val_auc: 0.9899 - val_accuracy: 0.9726 - val_cost: 3.3796\n",
            "Epoch 202/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0627 - auc: 0.9958 - accuracy: 0.9817 - cost: 2.3453 - val_loss: 0.1150 - val_auc: 0.9897 - val_accuracy: 0.9713 - val_cost: 3.4722\n",
            "Epoch 203/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0620 - auc: 0.9959 - accuracy: 0.9817 - cost: 2.3661 - val_loss: 0.1141 - val_auc: 0.9898 - val_accuracy: 0.9717 - val_cost: 3.5218\n",
            "Epoch 204/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0614 - auc: 0.9959 - accuracy: 0.9819 - cost: 2.3206 - val_loss: 0.1154 - val_auc: 0.9898 - val_accuracy: 0.9708 - val_cost: 3.5714\n",
            "Epoch 205/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0611 - auc: 0.9959 - accuracy: 0.9820 - cost: 2.3225 - val_loss: 0.1176 - val_auc: 0.9898 - val_accuracy: 0.9704 - val_cost: 3.6673\n",
            "Epoch 206/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0616 - auc: 0.9959 - accuracy: 0.9819 - cost: 2.3264 - val_loss: 0.1145 - val_auc: 0.9900 - val_accuracy: 0.9703 - val_cost: 3.7996\n",
            "Epoch 207/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0617 - auc: 0.9960 - accuracy: 0.9819 - cost: 2.3326 - val_loss: 0.1162 - val_auc: 0.9897 - val_accuracy: 0.9728 - val_cost: 3.2540\n",
            "Epoch 208/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0616 - auc: 0.9959 - accuracy: 0.9819 - cost: 2.3167 - val_loss: 0.1149 - val_auc: 0.9897 - val_accuracy: 0.9713 - val_cost: 3.6409\n",
            "Epoch 209/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0622 - auc: 0.9959 - accuracy: 0.9814 - cost: 2.3873 - val_loss: 0.1154 - val_auc: 0.9900 - val_accuracy: 0.9710 - val_cost: 3.5020\n",
            "Epoch 210/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0615 - auc: 0.9960 - accuracy: 0.9817 - cost: 2.3457 - val_loss: 0.1163 - val_auc: 0.9893 - val_accuracy: 0.9706 - val_cost: 3.5946\n",
            "Epoch 211/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0608 - auc: 0.9960 - accuracy: 0.9823 - cost: 2.2874 - val_loss: 0.1164 - val_auc: 0.9900 - val_accuracy: 0.9711 - val_cost: 3.5351\n",
            "Epoch 212/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0617 - auc: 0.9959 - accuracy: 0.9816 - cost: 2.3735 - val_loss: 0.1160 - val_auc: 0.9895 - val_accuracy: 0.9712 - val_cost: 3.5615\n",
            "Epoch 213/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0612 - auc: 0.9959 - accuracy: 0.9822 - cost: 2.2886 - val_loss: 0.1149 - val_auc: 0.9898 - val_accuracy: 0.9707 - val_cost: 3.6276\n",
            "Epoch 214/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0605 - auc: 0.9962 - accuracy: 0.9822 - cost: 2.2890 - val_loss: 0.1160 - val_auc: 0.9897 - val_accuracy: 0.9705 - val_cost: 3.6045\n",
            "Epoch 215/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0613 - auc: 0.9960 - accuracy: 0.9820 - cost: 2.3090 - val_loss: 0.1167 - val_auc: 0.9897 - val_accuracy: 0.9708 - val_cost: 3.5847\n",
            "Epoch 216/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0612 - auc: 0.9960 - accuracy: 0.9822 - cost: 2.2863 - val_loss: 0.1162 - val_auc: 0.9898 - val_accuracy: 0.9711 - val_cost: 3.5946\n",
            "Epoch 217/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0610 - auc: 0.9961 - accuracy: 0.9820 - cost: 2.3094 - val_loss: 0.1170 - val_auc: 0.9899 - val_accuracy: 0.9705 - val_cost: 3.6078\n",
            "Epoch 218/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0611 - auc: 0.9960 - accuracy: 0.9822 - cost: 2.2874 - val_loss: 0.1166 - val_auc: 0.9893 - val_accuracy: 0.9707 - val_cost: 3.6442\n",
            "Epoch 219/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0608 - auc: 0.9961 - accuracy: 0.9820 - cost: 2.3113 - val_loss: 0.1181 - val_auc: 0.9897 - val_accuracy: 0.9717 - val_cost: 3.4623\n",
            "Epoch 220/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0617 - auc: 0.9959 - accuracy: 0.9819 - cost: 2.3179 - val_loss: 0.1167 - val_auc: 0.9895 - val_accuracy: 0.9714 - val_cost: 3.4954\n",
            "Epoch 221/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0618 - auc: 0.9958 - accuracy: 0.9819 - cost: 2.3279 - val_loss: 0.1172 - val_auc: 0.9896 - val_accuracy: 0.9705 - val_cost: 3.7004\n",
            "Epoch 222/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0601 - auc: 0.9960 - accuracy: 0.9825 - cost: 2.2481 - val_loss: 0.1172 - val_auc: 0.9897 - val_accuracy: 0.9717 - val_cost: 3.4061\n",
            "Epoch 223/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0605 - auc: 0.9961 - accuracy: 0.9822 - cost: 2.2878 - val_loss: 0.1165 - val_auc: 0.9896 - val_accuracy: 0.9714 - val_cost: 3.5351\n",
            "Epoch 224/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0611 - auc: 0.9960 - accuracy: 0.9816 - cost: 2.3603 - val_loss: 0.1169 - val_auc: 0.9898 - val_accuracy: 0.9717 - val_cost: 3.4656\n",
            "Epoch 225/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0601 - auc: 0.9961 - accuracy: 0.9821 - cost: 2.3021 - val_loss: 0.1158 - val_auc: 0.9900 - val_accuracy: 0.9710 - val_cost: 3.5979\n",
            "Epoch 226/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0605 - auc: 0.9960 - accuracy: 0.9824 - cost: 2.2697 - val_loss: 0.1180 - val_auc: 0.9898 - val_accuracy: 0.9704 - val_cost: 3.6276\n",
            "Epoch 227/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0609 - auc: 0.9960 - accuracy: 0.9819 - cost: 2.3272 - val_loss: 0.1160 - val_auc: 0.9900 - val_accuracy: 0.9721 - val_cost: 3.3763\n",
            "Epoch 228/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0613 - auc: 0.9960 - accuracy: 0.9821 - cost: 2.2940 - val_loss: 0.1172 - val_auc: 0.9897 - val_accuracy: 0.9710 - val_cost: 3.6144\n",
            "Epoch 229/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0605 - auc: 0.9960 - accuracy: 0.9821 - cost: 2.3098 - val_loss: 0.1167 - val_auc: 0.9900 - val_accuracy: 0.9710 - val_cost: 3.4987\n",
            "Epoch 230/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0604 - auc: 0.9961 - accuracy: 0.9823 - cost: 2.2739 - val_loss: 0.1159 - val_auc: 0.9898 - val_accuracy: 0.9714 - val_cost: 3.5847\n",
            "Epoch 231/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0603 - auc: 0.9960 - accuracy: 0.9824 - cost: 2.2674 - val_loss: 0.1166 - val_auc: 0.9901 - val_accuracy: 0.9718 - val_cost: 3.4921\n",
            "Epoch 232/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0599 - auc: 0.9961 - accuracy: 0.9823 - cost: 2.2643 - val_loss: 0.1163 - val_auc: 0.9899 - val_accuracy: 0.9714 - val_cost: 3.5648\n",
            "Epoch 233/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0597 - auc: 0.9962 - accuracy: 0.9825 - cost: 2.2542 - val_loss: 0.1158 - val_auc: 0.9900 - val_accuracy: 0.9708 - val_cost: 3.6905\n",
            "Epoch 234/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0603 - auc: 0.9959 - accuracy: 0.9824 - cost: 2.2577 - val_loss: 0.1191 - val_auc: 0.9898 - val_accuracy: 0.9708 - val_cost: 3.5251\n",
            "Epoch 235/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0609 - auc: 0.9960 - accuracy: 0.9818 - cost: 2.3430 - val_loss: 0.1177 - val_auc: 0.9894 - val_accuracy: 0.9719 - val_cost: 3.4623\n",
            "Epoch 236/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0596 - auc: 0.9960 - accuracy: 0.9824 - cost: 2.2635 - val_loss: 0.1185 - val_auc: 0.9896 - val_accuracy: 0.9707 - val_cost: 3.5880\n",
            "Epoch 237/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0604 - auc: 0.9960 - accuracy: 0.9823 - cost: 2.2728 - val_loss: 0.1194 - val_auc: 0.9894 - val_accuracy: 0.9712 - val_cost: 3.5516\n",
            "Epoch 238/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0602 - auc: 0.9961 - accuracy: 0.9823 - cost: 2.2654 - val_loss: 0.1174 - val_auc: 0.9893 - val_accuracy: 0.9712 - val_cost: 3.6111\n",
            "Epoch 239/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0596 - auc: 0.9962 - accuracy: 0.9823 - cost: 2.2758 - val_loss: 0.1165 - val_auc: 0.9900 - val_accuracy: 0.9711 - val_cost: 3.5384\n",
            "Epoch 240/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0598 - auc: 0.9961 - accuracy: 0.9825 - cost: 2.2400 - val_loss: 0.1178 - val_auc: 0.9897 - val_accuracy: 0.9708 - val_cost: 3.7235\n",
            "Epoch 241/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0589 - auc: 0.9963 - accuracy: 0.9829 - cost: 2.1941 - val_loss: 0.1190 - val_auc: 0.9899 - val_accuracy: 0.9719 - val_cost: 3.4226\n",
            "Epoch 242/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0593 - auc: 0.9963 - accuracy: 0.9825 - cost: 2.2434 - val_loss: 0.1163 - val_auc: 0.9897 - val_accuracy: 0.9711 - val_cost: 3.6177\n",
            "Epoch 243/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0595 - auc: 0.9962 - accuracy: 0.9827 - cost: 2.2245 - val_loss: 0.1187 - val_auc: 0.9896 - val_accuracy: 0.9701 - val_cost: 3.6541\n",
            "Epoch 244/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0600 - auc: 0.9962 - accuracy: 0.9821 - cost: 2.3021 - val_loss: 0.1186 - val_auc: 0.9896 - val_accuracy: 0.9710 - val_cost: 3.4954\n",
            "Epoch 245/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0589 - auc: 0.9962 - accuracy: 0.9826 - cost: 2.2265 - val_loss: 0.1171 - val_auc: 0.9895 - val_accuracy: 0.9709 - val_cost: 3.6177\n",
            "Epoch 246/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0593 - auc: 0.9962 - accuracy: 0.9825 - cost: 2.2585 - val_loss: 0.1190 - val_auc: 0.9894 - val_accuracy: 0.9708 - val_cost: 3.6508\n",
            "Epoch 247/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0593 - auc: 0.9962 - accuracy: 0.9823 - cost: 2.2809 - val_loss: 0.1170 - val_auc: 0.9896 - val_accuracy: 0.9713 - val_cost: 3.4855\n",
            "Epoch 248/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0587 - auc: 0.9963 - accuracy: 0.9827 - cost: 2.2215 - val_loss: 0.1193 - val_auc: 0.9894 - val_accuracy: 0.9710 - val_cost: 3.6541\n",
            "Epoch 249/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0599 - auc: 0.9962 - accuracy: 0.9823 - cost: 2.2785 - val_loss: 0.1183 - val_auc: 0.9896 - val_accuracy: 0.9717 - val_cost: 3.4788\n",
            "Epoch 250/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0610 - auc: 0.9960 - accuracy: 0.9823 - cost: 2.2708 - val_loss: 0.1182 - val_auc: 0.9894 - val_accuracy: 0.9699 - val_cost: 3.7434\n",
            "Epoch 251/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0581 - auc: 0.9963 - accuracy: 0.9829 - cost: 2.1979 - val_loss: 0.1176 - val_auc: 0.9898 - val_accuracy: 0.9722 - val_cost: 3.4656\n",
            "Epoch 252/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0603 - auc: 0.9962 - accuracy: 0.9823 - cost: 2.2782 - val_loss: 0.1177 - val_auc: 0.9897 - val_accuracy: 0.9710 - val_cost: 3.5780\n",
            "Epoch 253/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0595 - auc: 0.9962 - accuracy: 0.9823 - cost: 2.2735 - val_loss: 0.1186 - val_auc: 0.9897 - val_accuracy: 0.9712 - val_cost: 3.5384\n",
            "Epoch 254/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0591 - auc: 0.9963 - accuracy: 0.9825 - cost: 2.2535 - val_loss: 0.1185 - val_auc: 0.9897 - val_accuracy: 0.9719 - val_cost: 3.4392\n",
            "Epoch 255/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0589 - auc: 0.9961 - accuracy: 0.9829 - cost: 2.2025 - val_loss: 0.1191 - val_auc: 0.9894 - val_accuracy: 0.9713 - val_cost: 3.5516\n",
            "Epoch 256/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0591 - auc: 0.9962 - accuracy: 0.9828 - cost: 2.2106 - val_loss: 0.1183 - val_auc: 0.9894 - val_accuracy: 0.9710 - val_cost: 3.5417\n",
            "Epoch 257/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0593 - auc: 0.9962 - accuracy: 0.9826 - cost: 2.2400 - val_loss: 0.1192 - val_auc: 0.9895 - val_accuracy: 0.9712 - val_cost: 3.5516\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.1144 - auc: 0.9905 - accuracy: 0.9695 - cost: 3.7875\n",
            "500/500 [==============================] - 0s 835us/step\n",
            "fold train/predict time: 0:01:50.467014\n",
            "fold accuracy: 0.9695000052452087 - fold cost: 3.7874999046325684\n",
            "total train/predict time: 0:16:59.496230\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m4_results = fold_results"
      ],
      "metadata": {
        "id": "fszFGfDwmD7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds_m4 = np.zeros(len(y))\n",
        "for i in fold_results.keys():\n",
        "  for j in range(len(fold_results.get(i).get('predictions'))):\n",
        "    idx = fold_results.get(i).get('index')[j]\n",
        "    preds_m4[idx] = np.round(fold_results.get(i).get('predictions')[j],0)\n",
        "m4_cost = cost_func(y,preds_m4)\n",
        "m4_cost"
      ],
      "metadata": {
        "id": "WMZkaNGNeKT0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70649305-7d18-413b-a1cf-032959c2117f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "587650"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds_new = np.zeros(len(y))\n",
        "for i in m4_results.keys():\n",
        "  for j in range(len(m4_results.get(i).get('predictions'))):\n",
        "    idx = m4_results.get(i).get('index')[j]\n",
        "    if m4_results.get(i).get('predictions')[j] > 0.6:\n",
        "      preds_new[idx] = 1\n",
        "    else:\n",
        "      preds_new[idx] = 0\n",
        "m4_cost_t = cost_func(y,preds_new)\n",
        "m4_cost_t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3X7K7DWxmHit",
        "outputId": "ca4b2860-1649-45c8-a8bf-622b6546f251"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "579700"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.plot_model(model4, show_shapes=True, rankdir=\"LR\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "btrT6ETQQIe4",
        "outputId": "b2457088-db65-4cd2-c527-03a91378faef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model4.summary()\n"
      ],
      "metadata": {
        "id": "7jg2oQFvH2QS",
        "outputId": "7423f56b-2270-41e2-b367-c1427c91d6c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Relu1 (Dense)               (None, 64)                4352      \n",
            "                                                                 \n",
            " Relu2 (Dense)               (None, 64)                4160      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " Activation (Dense)          (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,577\n",
            "Trainable params: 8,577\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model4.save('model4.keras')"
      ],
      "metadata": {
        "id": "IwcfGqFmC4nv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "es = EarlyStopping(monitor='val_cost', mode='min',patience=150,restore_best_weights=True,start_from_epoch=350) #earliest possible stop is 500\n",
        "fold_results = {}\n",
        "t_tot = now()\n",
        "for i, (train_index, test_index) in enumerate(skf.split(X,y)):\n",
        "  # building model within loop to reset weights each time\n",
        "  tf.keras.backend.clear_session()\n",
        "  tf.keras.utils.set_random_seed(807)\n",
        "  model5 = tf.keras.Sequential()\n",
        "  model5.add(tf.keras.Input(shape=(X.shape[1],)))\n",
        "  model5.add(tf.keras.layers.Dense(64, activation='relu',name=\"Relu1\"))\n",
        "  model5.add(tf.keras.layers.Dense(64, activation='relu', name=\"Relu2\"))\n",
        "  model5.add(tf.keras.layers.Dropout(0.2))\n",
        "  model5.add(tf.keras.layers.Dense(1, activation='sigmoid', name=\"Activation\"))\n",
        "  model5.compile(optimizer='adam',\n",
        "                loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
        "                metrics = [tf.keras.metrics.AUC(from_logits=False), 'accuracy',cost])\n",
        "  t_fold = now()\n",
        "  print('x_train shape:', X[train_index].shape)\n",
        "  model5.fit(X[train_index],y[train_index],epochs=1000,batch_size=1080,validation_split=0.1,callbacks=[es])\n",
        "  score = model5.evaluate(X[test_index],y[test_index])\n",
        "  fold_results.update({i:{'predictions':model5.predict(X[test_index]).flatten(),'index':test_index,'y_true':y[test_index]}})\n",
        "  print('fold train/predict time: %s' % (now()-t_fold))\n",
        "  print('fold accuracy: {} - fold cost: {}'.format(score[2],score[3]))\n",
        "print('total train/predict time: %s' % (now()-t_tot))"
      ],
      "metadata": {
        "id": "DVNOkJr3oYGb",
        "outputId": "7c2268ed-cae5-4cc9-9647-f8ea943ccc02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0575 - auc: 0.9965 - accuracy: 0.9830 - cost: 2.1748 - val_loss: 0.1193 - val_auc: 0.9892 - val_accuracy: 0.9697 - val_cost: 3.8856\n",
            "Epoch 303/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0572 - auc: 0.9963 - accuracy: 0.9834 - cost: 2.1177 - val_loss: 0.1174 - val_auc: 0.9893 - val_accuracy: 0.9709 - val_cost: 3.6574\n",
            "Epoch 304/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0573 - auc: 0.9965 - accuracy: 0.9828 - cost: 2.1921 - val_loss: 0.1181 - val_auc: 0.9893 - val_accuracy: 0.9713 - val_cost: 3.6409\n",
            "Epoch 305/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0576 - auc: 0.9963 - accuracy: 0.9829 - cost: 2.1960 - val_loss: 0.1199 - val_auc: 0.9892 - val_accuracy: 0.9710 - val_cost: 3.6177\n",
            "Epoch 306/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0574 - auc: 0.9964 - accuracy: 0.9830 - cost: 2.1740 - val_loss: 0.1197 - val_auc: 0.9896 - val_accuracy: 0.9703 - val_cost: 3.7963\n",
            "Epoch 307/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0578 - auc: 0.9964 - accuracy: 0.9829 - cost: 2.1817 - val_loss: 0.1205 - val_auc: 0.9891 - val_accuracy: 0.9703 - val_cost: 3.7765\n",
            "Epoch 308/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0567 - auc: 0.9966 - accuracy: 0.9833 - cost: 2.1435 - val_loss: 0.1194 - val_auc: 0.9894 - val_accuracy: 0.9711 - val_cost: 3.5747\n",
            "Epoch 309/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0570 - auc: 0.9965 - accuracy: 0.9831 - cost: 2.1555 - val_loss: 0.1195 - val_auc: 0.9892 - val_accuracy: 0.9700 - val_cost: 3.7731\n",
            "Epoch 310/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0584 - auc: 0.9963 - accuracy: 0.9829 - cost: 2.2029 - val_loss: 0.1200 - val_auc: 0.9895 - val_accuracy: 0.9706 - val_cost: 3.5714\n",
            "Epoch 311/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0573 - auc: 0.9964 - accuracy: 0.9831 - cost: 2.1628 - val_loss: 0.1209 - val_auc: 0.9891 - val_accuracy: 0.9712 - val_cost: 3.6508\n",
            "Epoch 312/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0572 - auc: 0.9964 - accuracy: 0.9836 - cost: 2.0937 - val_loss: 0.1199 - val_auc: 0.9893 - val_accuracy: 0.9699 - val_cost: 3.6806\n",
            "Epoch 313/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0565 - auc: 0.9966 - accuracy: 0.9834 - cost: 2.1177 - val_loss: 0.1209 - val_auc: 0.9891 - val_accuracy: 0.9706 - val_cost: 3.7731\n",
            "Epoch 314/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0574 - auc: 0.9963 - accuracy: 0.9830 - cost: 2.1883 - val_loss: 0.1208 - val_auc: 0.9888 - val_accuracy: 0.9709 - val_cost: 3.6673\n",
            "Epoch 315/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0572 - auc: 0.9965 - accuracy: 0.9831 - cost: 2.1628 - val_loss: 0.1191 - val_auc: 0.9891 - val_accuracy: 0.9710 - val_cost: 3.6607\n",
            "Epoch 316/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0570 - auc: 0.9966 - accuracy: 0.9832 - cost: 2.1470 - val_loss: 0.1198 - val_auc: 0.9891 - val_accuracy: 0.9702 - val_cost: 3.7500\n",
            "Epoch 317/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0577 - auc: 0.9964 - accuracy: 0.9830 - cost: 2.1771 - val_loss: 0.1206 - val_auc: 0.9893 - val_accuracy: 0.9696 - val_cost: 3.7698\n",
            "Epoch 318/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0569 - auc: 0.9964 - accuracy: 0.9833 - cost: 2.1447 - val_loss: 0.1196 - val_auc: 0.9893 - val_accuracy: 0.9708 - val_cost: 3.7004\n",
            "Epoch 319/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0569 - auc: 0.9964 - accuracy: 0.9835 - cost: 2.1053 - val_loss: 0.1180 - val_auc: 0.9896 - val_accuracy: 0.9701 - val_cost: 3.8360\n",
            "Epoch 320/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0570 - auc: 0.9965 - accuracy: 0.9833 - cost: 2.1354 - val_loss: 0.1210 - val_auc: 0.9890 - val_accuracy: 0.9697 - val_cost: 3.8062\n",
            "Epoch 321/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0568 - auc: 0.9964 - accuracy: 0.9832 - cost: 2.1539 - val_loss: 0.1205 - val_auc: 0.9895 - val_accuracy: 0.9707 - val_cost: 3.7136\n",
            "Epoch 322/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0563 - auc: 0.9966 - accuracy: 0.9831 - cost: 2.1651 - val_loss: 0.1216 - val_auc: 0.9894 - val_accuracy: 0.9712 - val_cost: 3.6012\n",
            "Epoch 323/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0569 - auc: 0.9964 - accuracy: 0.9840 - cost: 2.0544 - val_loss: 0.1189 - val_auc: 0.9897 - val_accuracy: 0.9706 - val_cost: 3.7368\n",
            "Epoch 324/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0559 - auc: 0.9965 - accuracy: 0.9838 - cost: 2.0741 - val_loss: 0.1207 - val_auc: 0.9892 - val_accuracy: 0.9699 - val_cost: 3.8360\n",
            "Epoch 325/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0572 - auc: 0.9964 - accuracy: 0.9831 - cost: 2.1694 - val_loss: 0.1205 - val_auc: 0.9895 - val_accuracy: 0.9716 - val_cost: 3.5681\n",
            "Epoch 326/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0571 - auc: 0.9964 - accuracy: 0.9831 - cost: 2.1690 - val_loss: 0.1206 - val_auc: 0.9891 - val_accuracy: 0.9694 - val_cost: 3.8393\n",
            "Epoch 327/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0565 - auc: 0.9966 - accuracy: 0.9834 - cost: 2.1281 - val_loss: 0.1226 - val_auc: 0.9889 - val_accuracy: 0.9715 - val_cost: 3.5549\n",
            "Epoch 328/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0569 - auc: 0.9965 - accuracy: 0.9832 - cost: 2.1566 - val_loss: 0.1232 - val_auc: 0.9893 - val_accuracy: 0.9705 - val_cost: 3.7401\n",
            "Epoch 329/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0564 - auc: 0.9965 - accuracy: 0.9836 - cost: 2.0876 - val_loss: 0.1197 - val_auc: 0.9893 - val_accuracy: 0.9701 - val_cost: 3.6839\n",
            "Epoch 330/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0566 - auc: 0.9965 - accuracy: 0.9834 - cost: 2.1289 - val_loss: 0.1194 - val_auc: 0.9895 - val_accuracy: 0.9707 - val_cost: 3.6872\n",
            "Epoch 331/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0561 - auc: 0.9967 - accuracy: 0.9838 - cost: 2.0714 - val_loss: 0.1182 - val_auc: 0.9895 - val_accuracy: 0.9715 - val_cost: 3.7004\n",
            "Epoch 332/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0562 - auc: 0.9965 - accuracy: 0.9840 - cost: 2.0583 - val_loss: 0.1202 - val_auc: 0.9892 - val_accuracy: 0.9715 - val_cost: 3.5946\n",
            "Epoch 333/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0571 - auc: 0.9965 - accuracy: 0.9833 - cost: 2.1238 - val_loss: 0.1195 - val_auc: 0.9893 - val_accuracy: 0.9713 - val_cost: 3.6409\n",
            "Epoch 334/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0566 - auc: 0.9965 - accuracy: 0.9834 - cost: 2.1157 - val_loss: 0.1191 - val_auc: 0.9894 - val_accuracy: 0.9710 - val_cost: 3.5681\n",
            "Epoch 335/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0569 - auc: 0.9965 - accuracy: 0.9836 - cost: 2.1030 - val_loss: 0.1205 - val_auc: 0.9892 - val_accuracy: 0.9707 - val_cost: 3.6971\n",
            "Epoch 336/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0569 - auc: 0.9965 - accuracy: 0.9831 - cost: 2.1524 - val_loss: 0.1207 - val_auc: 0.9892 - val_accuracy: 0.9696 - val_cost: 3.9021\n",
            "Epoch 337/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0563 - auc: 0.9965 - accuracy: 0.9834 - cost: 2.1269 - val_loss: 0.1202 - val_auc: 0.9896 - val_accuracy: 0.9704 - val_cost: 3.7169\n",
            "Epoch 338/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0562 - auc: 0.9966 - accuracy: 0.9833 - cost: 2.1343 - val_loss: 0.1220 - val_auc: 0.9889 - val_accuracy: 0.9713 - val_cost: 3.5615\n",
            "Epoch 339/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0568 - auc: 0.9966 - accuracy: 0.9830 - cost: 2.1651 - val_loss: 0.1225 - val_auc: 0.9894 - val_accuracy: 0.9703 - val_cost: 3.7897\n",
            "Epoch 340/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0559 - auc: 0.9966 - accuracy: 0.9838 - cost: 2.0833 - val_loss: 0.1217 - val_auc: 0.9893 - val_accuracy: 0.9709 - val_cost: 3.5615\n",
            "Epoch 341/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0559 - auc: 0.9966 - accuracy: 0.9836 - cost: 2.1061 - val_loss: 0.1212 - val_auc: 0.9894 - val_accuracy: 0.9709 - val_cost: 3.6640\n",
            "Epoch 342/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0562 - auc: 0.9966 - accuracy: 0.9833 - cost: 2.1323 - val_loss: 0.1219 - val_auc: 0.9892 - val_accuracy: 0.9697 - val_cost: 3.8128\n",
            "Epoch 343/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0558 - auc: 0.9966 - accuracy: 0.9837 - cost: 2.0860 - val_loss: 0.1243 - val_auc: 0.9891 - val_accuracy: 0.9697 - val_cost: 3.7004\n",
            "Epoch 344/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0563 - auc: 0.9965 - accuracy: 0.9834 - cost: 2.1254 - val_loss: 0.1194 - val_auc: 0.9891 - val_accuracy: 0.9714 - val_cost: 3.5681\n",
            "Epoch 345/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0558 - auc: 0.9966 - accuracy: 0.9836 - cost: 2.1092 - val_loss: 0.1210 - val_auc: 0.9897 - val_accuracy: 0.9712 - val_cost: 3.6607\n",
            "Epoch 346/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0555 - auc: 0.9966 - accuracy: 0.9836 - cost: 2.0961 - val_loss: 0.1206 - val_auc: 0.9894 - val_accuracy: 0.9702 - val_cost: 3.8525\n",
            "Epoch 347/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0552 - auc: 0.9967 - accuracy: 0.9837 - cost: 2.0968 - val_loss: 0.1217 - val_auc: 0.9891 - val_accuracy: 0.9697 - val_cost: 3.8029\n",
            "Epoch 348/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0568 - auc: 0.9965 - accuracy: 0.9834 - cost: 2.1292 - val_loss: 0.1196 - val_auc: 0.9893 - val_accuracy: 0.9708 - val_cost: 3.7368\n",
            "Epoch 349/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0562 - auc: 0.9965 - accuracy: 0.9834 - cost: 2.1316 - val_loss: 0.1221 - val_auc: 0.9892 - val_accuracy: 0.9703 - val_cost: 3.7103\n",
            "Epoch 350/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0569 - auc: 0.9965 - accuracy: 0.9837 - cost: 2.1003 - val_loss: 0.1220 - val_auc: 0.9895 - val_accuracy: 0.9701 - val_cost: 3.7401\n",
            "Epoch 351/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0556 - auc: 0.9965 - accuracy: 0.9836 - cost: 2.0887 - val_loss: 0.1213 - val_auc: 0.9894 - val_accuracy: 0.9700 - val_cost: 3.8128\n",
            "Epoch 352/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0563 - auc: 0.9966 - accuracy: 0.9835 - cost: 2.1150 - val_loss: 0.1242 - val_auc: 0.9893 - val_accuracy: 0.9705 - val_cost: 3.7731\n",
            "Epoch 353/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0566 - auc: 0.9965 - accuracy: 0.9832 - cost: 2.1547 - val_loss: 0.1238 - val_auc: 0.9893 - val_accuracy: 0.9701 - val_cost: 3.8161\n",
            "Epoch 354/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0557 - auc: 0.9967 - accuracy: 0.9833 - cost: 2.1393 - val_loss: 0.1215 - val_auc: 0.9891 - val_accuracy: 0.9704 - val_cost: 3.6574\n",
            "Epoch 355/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0554 - auc: 0.9967 - accuracy: 0.9838 - cost: 2.0802 - val_loss: 0.1207 - val_auc: 0.9894 - val_accuracy: 0.9710 - val_cost: 3.6673\n",
            "Epoch 356/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0560 - auc: 0.9966 - accuracy: 0.9832 - cost: 2.1458 - val_loss: 0.1220 - val_auc: 0.9893 - val_accuracy: 0.9707 - val_cost: 3.6905\n",
            "Epoch 357/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0568 - auc: 0.9965 - accuracy: 0.9832 - cost: 2.1462 - val_loss: 0.1218 - val_auc: 0.9891 - val_accuracy: 0.9695 - val_cost: 3.9286\n",
            "Epoch 358/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0555 - auc: 0.9967 - accuracy: 0.9834 - cost: 2.1319 - val_loss: 0.1219 - val_auc: 0.9892 - val_accuracy: 0.9709 - val_cost: 3.6376\n",
            "Epoch 359/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0561 - auc: 0.9966 - accuracy: 0.9834 - cost: 2.1273 - val_loss: 0.1224 - val_auc: 0.9891 - val_accuracy: 0.9703 - val_cost: 3.6806\n",
            "Epoch 360/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0552 - auc: 0.9966 - accuracy: 0.9840 - cost: 2.0451 - val_loss: 0.1221 - val_auc: 0.9898 - val_accuracy: 0.9703 - val_cost: 3.8261\n",
            "Epoch 361/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0560 - auc: 0.9965 - accuracy: 0.9835 - cost: 2.1115 - val_loss: 0.1212 - val_auc: 0.9894 - val_accuracy: 0.9702 - val_cost: 3.8492\n",
            "Epoch 362/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0558 - auc: 0.9966 - accuracy: 0.9835 - cost: 2.1022 - val_loss: 0.1210 - val_auc: 0.9894 - val_accuracy: 0.9710 - val_cost: 3.7070\n",
            "Epoch 363/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0548 - auc: 0.9967 - accuracy: 0.9841 - cost: 2.0367 - val_loss: 0.1232 - val_auc: 0.9892 - val_accuracy: 0.9708 - val_cost: 3.6078\n",
            "Epoch 364/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0555 - auc: 0.9966 - accuracy: 0.9841 - cost: 2.0529 - val_loss: 0.1251 - val_auc: 0.9892 - val_accuracy: 0.9712 - val_cost: 3.5946\n",
            "Epoch 365/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0548 - auc: 0.9967 - accuracy: 0.9839 - cost: 2.0748 - val_loss: 0.1235 - val_auc: 0.9895 - val_accuracy: 0.9710 - val_cost: 3.6343\n",
            "Epoch 366/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0560 - auc: 0.9966 - accuracy: 0.9838 - cost: 2.0814 - val_loss: 0.1236 - val_auc: 0.9892 - val_accuracy: 0.9710 - val_cost: 3.7070\n",
            "Epoch 367/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0554 - auc: 0.9967 - accuracy: 0.9837 - cost: 2.0930 - val_loss: 0.1234 - val_auc: 0.9888 - val_accuracy: 0.9701 - val_cost: 3.8095\n",
            "Epoch 368/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0560 - auc: 0.9966 - accuracy: 0.9833 - cost: 2.1481 - val_loss: 0.1227 - val_auc: 0.9890 - val_accuracy: 0.9707 - val_cost: 3.6706\n",
            "Epoch 369/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0553 - auc: 0.9966 - accuracy: 0.9838 - cost: 2.0772 - val_loss: 0.1229 - val_auc: 0.9892 - val_accuracy: 0.9709 - val_cost: 3.6806\n",
            "Epoch 370/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0544 - auc: 0.9967 - accuracy: 0.9841 - cost: 2.0316 - val_loss: 0.1259 - val_auc: 0.9889 - val_accuracy: 0.9707 - val_cost: 3.6971\n",
            "Epoch 371/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0553 - auc: 0.9968 - accuracy: 0.9832 - cost: 2.1439 - val_loss: 0.1246 - val_auc: 0.9891 - val_accuracy: 0.9706 - val_cost: 3.6012\n",
            "Epoch 372/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0560 - auc: 0.9965 - accuracy: 0.9835 - cost: 2.1092 - val_loss: 0.1227 - val_auc: 0.9896 - val_accuracy: 0.9715 - val_cost: 3.5582\n",
            "Epoch 373/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0562 - auc: 0.9965 - accuracy: 0.9833 - cost: 2.1416 - val_loss: 0.1231 - val_auc: 0.9895 - val_accuracy: 0.9706 - val_cost: 3.7202\n",
            "Epoch 374/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0552 - auc: 0.9966 - accuracy: 0.9838 - cost: 2.0752 - val_loss: 0.1235 - val_auc: 0.9893 - val_accuracy: 0.9703 - val_cost: 3.7368\n",
            "Epoch 375/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0547 - auc: 0.9967 - accuracy: 0.9839 - cost: 2.0683 - val_loss: 0.1229 - val_auc: 0.9894 - val_accuracy: 0.9701 - val_cost: 3.7665\n",
            "Epoch 376/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0550 - auc: 0.9968 - accuracy: 0.9834 - cost: 2.1235 - val_loss: 0.1252 - val_auc: 0.9893 - val_accuracy: 0.9701 - val_cost: 3.8228\n",
            "Epoch 377/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0544 - auc: 0.9967 - accuracy: 0.9839 - cost: 2.0725 - val_loss: 0.1234 - val_auc: 0.9890 - val_accuracy: 0.9705 - val_cost: 3.6574\n",
            "Epoch 378/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0561 - auc: 0.9966 - accuracy: 0.9837 - cost: 2.0968 - val_loss: 0.1233 - val_auc: 0.9892 - val_accuracy: 0.9714 - val_cost: 3.5351\n",
            "Epoch 379/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0553 - auc: 0.9967 - accuracy: 0.9836 - cost: 2.0976 - val_loss: 0.1249 - val_auc: 0.9891 - val_accuracy: 0.9708 - val_cost: 3.6607\n",
            "Epoch 380/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0548 - auc: 0.9967 - accuracy: 0.9837 - cost: 2.0903 - val_loss: 0.1232 - val_auc: 0.9890 - val_accuracy: 0.9704 - val_cost: 3.6607\n",
            "Epoch 381/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0559 - auc: 0.9965 - accuracy: 0.9836 - cost: 2.0937 - val_loss: 0.1225 - val_auc: 0.9892 - val_accuracy: 0.9708 - val_cost: 3.6210\n",
            "Epoch 382/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0536 - auc: 0.9969 - accuracy: 0.9839 - cost: 2.0644 - val_loss: 0.1246 - val_auc: 0.9893 - val_accuracy: 0.9707 - val_cost: 3.6706\n",
            "Epoch 383/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0539 - auc: 0.9968 - accuracy: 0.9842 - cost: 2.0274 - val_loss: 0.1250 - val_auc: 0.9891 - val_accuracy: 0.9699 - val_cost: 3.7533\n",
            "Epoch 384/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0560 - auc: 0.9966 - accuracy: 0.9834 - cost: 2.1258 - val_loss: 0.1247 - val_auc: 0.9888 - val_accuracy: 0.9700 - val_cost: 3.7269\n",
            "Epoch 385/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0551 - auc: 0.9967 - accuracy: 0.9836 - cost: 2.0938 - val_loss: 0.1289 - val_auc: 0.9888 - val_accuracy: 0.9695 - val_cost: 3.7765\n",
            "Epoch 386/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0548 - auc: 0.9967 - accuracy: 0.9838 - cost: 2.0718 - val_loss: 0.1233 - val_auc: 0.9893 - val_accuracy: 0.9706 - val_cost: 3.7169\n",
            "Epoch 387/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0547 - auc: 0.9967 - accuracy: 0.9837 - cost: 2.0914 - val_loss: 0.1237 - val_auc: 0.9891 - val_accuracy: 0.9708 - val_cost: 3.7202\n",
            "Epoch 388/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0550 - auc: 0.9967 - accuracy: 0.9836 - cost: 2.1019 - val_loss: 0.1245 - val_auc: 0.9892 - val_accuracy: 0.9708 - val_cost: 3.6938\n",
            "Epoch 389/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0541 - auc: 0.9968 - accuracy: 0.9842 - cost: 2.0147 - val_loss: 0.1251 - val_auc: 0.9891 - val_accuracy: 0.9706 - val_cost: 3.6409\n",
            "Epoch 390/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0553 - auc: 0.9967 - accuracy: 0.9837 - cost: 2.0876 - val_loss: 0.1257 - val_auc: 0.9895 - val_accuracy: 0.9704 - val_cost: 3.7202\n",
            "Epoch 391/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0551 - auc: 0.9967 - accuracy: 0.9840 - cost: 2.0633 - val_loss: 0.1247 - val_auc: 0.9894 - val_accuracy: 0.9703 - val_cost: 3.7566\n",
            "Epoch 392/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0546 - auc: 0.9967 - accuracy: 0.9837 - cost: 2.0845 - val_loss: 0.1255 - val_auc: 0.9891 - val_accuracy: 0.9713 - val_cost: 3.6376\n",
            "Epoch 393/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0557 - auc: 0.9967 - accuracy: 0.9838 - cost: 2.0691 - val_loss: 0.1261 - val_auc: 0.9890 - val_accuracy: 0.9699 - val_cost: 3.7335\n",
            "Epoch 394/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0542 - auc: 0.9969 - accuracy: 0.9839 - cost: 2.0671 - val_loss: 0.1260 - val_auc: 0.9892 - val_accuracy: 0.9707 - val_cost: 3.6971\n",
            "Epoch 395/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0553 - auc: 0.9967 - accuracy: 0.9838 - cost: 2.0756 - val_loss: 0.1221 - val_auc: 0.9892 - val_accuracy: 0.9706 - val_cost: 3.7731\n",
            "Epoch 396/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0537 - auc: 0.9969 - accuracy: 0.9844 - cost: 2.0093 - val_loss: 0.1230 - val_auc: 0.9897 - val_accuracy: 0.9705 - val_cost: 3.7202\n",
            "Epoch 397/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0545 - auc: 0.9967 - accuracy: 0.9839 - cost: 2.0567 - val_loss: 0.1224 - val_auc: 0.9894 - val_accuracy: 0.9699 - val_cost: 3.8459\n",
            "Epoch 398/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0547 - auc: 0.9967 - accuracy: 0.9841 - cost: 2.0428 - val_loss: 0.1270 - val_auc: 0.9889 - val_accuracy: 0.9693 - val_cost: 3.7368\n",
            "Epoch 399/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0546 - auc: 0.9968 - accuracy: 0.9841 - cost: 2.0394 - val_loss: 0.1234 - val_auc: 0.9894 - val_accuracy: 0.9707 - val_cost: 3.6806\n",
            "Epoch 400/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0544 - auc: 0.9968 - accuracy: 0.9836 - cost: 2.1049 - val_loss: 0.1251 - val_auc: 0.9893 - val_accuracy: 0.9706 - val_cost: 3.7070\n",
            "Epoch 401/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0535 - auc: 0.9969 - accuracy: 0.9838 - cost: 2.0745 - val_loss: 0.1260 - val_auc: 0.9891 - val_accuracy: 0.9705 - val_cost: 3.7004\n",
            "Epoch 402/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0546 - auc: 0.9968 - accuracy: 0.9837 - cost: 2.0934 - val_loss: 0.1254 - val_auc: 0.9890 - val_accuracy: 0.9699 - val_cost: 3.8393\n",
            "Epoch 403/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0547 - auc: 0.9967 - accuracy: 0.9838 - cost: 2.0768 - val_loss: 0.1250 - val_auc: 0.9895 - val_accuracy: 0.9697 - val_cost: 3.8360\n",
            "Epoch 404/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0552 - auc: 0.9968 - accuracy: 0.9833 - cost: 2.1439 - val_loss: 0.1232 - val_auc: 0.9893 - val_accuracy: 0.9710 - val_cost: 3.6806\n",
            "Epoch 405/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0537 - auc: 0.9968 - accuracy: 0.9839 - cost: 2.0606 - val_loss: 0.1283 - val_auc: 0.9894 - val_accuracy: 0.9703 - val_cost: 3.6739\n",
            "Epoch 406/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0549 - auc: 0.9967 - accuracy: 0.9838 - cost: 2.0799 - val_loss: 0.1275 - val_auc: 0.9887 - val_accuracy: 0.9703 - val_cost: 3.7235\n",
            "Epoch 407/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0545 - auc: 0.9969 - accuracy: 0.9837 - cost: 2.0876 - val_loss: 0.1240 - val_auc: 0.9893 - val_accuracy: 0.9704 - val_cost: 3.7731\n",
            "Epoch 408/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0540 - auc: 0.9968 - accuracy: 0.9843 - cost: 2.0131 - val_loss: 0.1272 - val_auc: 0.9888 - val_accuracy: 0.9695 - val_cost: 3.8029\n",
            "Epoch 409/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0549 - auc: 0.9967 - accuracy: 0.9836 - cost: 2.1107 - val_loss: 0.1279 - val_auc: 0.9888 - val_accuracy: 0.9699 - val_cost: 3.8095\n",
            "Epoch 410/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0543 - auc: 0.9968 - accuracy: 0.9840 - cost: 2.0598 - val_loss: 0.1247 - val_auc: 0.9893 - val_accuracy: 0.9715 - val_cost: 3.6343\n",
            "Epoch 411/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0547 - auc: 0.9968 - accuracy: 0.9837 - cost: 2.0953 - val_loss: 0.1250 - val_auc: 0.9891 - val_accuracy: 0.9698 - val_cost: 3.8657\n",
            "Epoch 412/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0534 - auc: 0.9969 - accuracy: 0.9842 - cost: 2.0285 - val_loss: 0.1243 - val_auc: 0.9892 - val_accuracy: 0.9705 - val_cost: 3.8228\n",
            "Epoch 413/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0532 - auc: 0.9969 - accuracy: 0.9838 - cost: 2.0706 - val_loss: 0.1250 - val_auc: 0.9892 - val_accuracy: 0.9707 - val_cost: 3.7070\n",
            "Epoch 414/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0535 - auc: 0.9970 - accuracy: 0.9839 - cost: 2.0575 - val_loss: 0.1257 - val_auc: 0.9894 - val_accuracy: 0.9708 - val_cost: 3.7566\n",
            "Epoch 415/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0538 - auc: 0.9968 - accuracy: 0.9839 - cost: 2.0667 - val_loss: 0.1279 - val_auc: 0.9889 - val_accuracy: 0.9703 - val_cost: 3.7500\n",
            "Epoch 416/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0544 - auc: 0.9968 - accuracy: 0.9836 - cost: 2.0980 - val_loss: 0.1258 - val_auc: 0.9892 - val_accuracy: 0.9696 - val_cost: 3.8327\n",
            "Epoch 417/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0543 - auc: 0.9968 - accuracy: 0.9841 - cost: 2.0324 - val_loss: 0.1280 - val_auc: 0.9888 - val_accuracy: 0.9689 - val_cost: 3.8194\n",
            "Epoch 418/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0538 - auc: 0.9968 - accuracy: 0.9841 - cost: 2.0394 - val_loss: 0.1257 - val_auc: 0.9893 - val_accuracy: 0.9709 - val_cost: 3.7533\n",
            "Epoch 419/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0536 - auc: 0.9969 - accuracy: 0.9838 - cost: 2.0698 - val_loss: 0.1254 - val_auc: 0.9893 - val_accuracy: 0.9692 - val_cost: 3.9649\n",
            "Epoch 420/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0540 - auc: 0.9969 - accuracy: 0.9840 - cost: 2.0525 - val_loss: 0.1271 - val_auc: 0.9892 - val_accuracy: 0.9704 - val_cost: 3.7302\n",
            "Epoch 421/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0545 - auc: 0.9968 - accuracy: 0.9840 - cost: 2.0494 - val_loss: 0.1284 - val_auc: 0.9892 - val_accuracy: 0.9704 - val_cost: 3.7202\n",
            "Epoch 422/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0532 - auc: 0.9970 - accuracy: 0.9840 - cost: 2.0374 - val_loss: 0.1274 - val_auc: 0.9889 - val_accuracy: 0.9702 - val_cost: 3.6806\n",
            "Epoch 423/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0541 - auc: 0.9969 - accuracy: 0.9838 - cost: 2.0941 - val_loss: 0.1319 - val_auc: 0.9886 - val_accuracy: 0.9706 - val_cost: 3.6045\n",
            "Epoch 424/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0539 - auc: 0.9969 - accuracy: 0.9837 - cost: 2.0826 - val_loss: 0.1273 - val_auc: 0.9889 - val_accuracy: 0.9706 - val_cost: 3.6739\n",
            "Epoch 425/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0541 - auc: 0.9969 - accuracy: 0.9836 - cost: 2.0980 - val_loss: 0.1279 - val_auc: 0.9886 - val_accuracy: 0.9701 - val_cost: 3.8128\n",
            "Epoch 426/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0534 - auc: 0.9969 - accuracy: 0.9842 - cost: 2.0282 - val_loss: 0.1270 - val_auc: 0.9888 - val_accuracy: 0.9708 - val_cost: 3.6607\n",
            "Epoch 427/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0539 - auc: 0.9968 - accuracy: 0.9840 - cost: 2.0548 - val_loss: 0.1296 - val_auc: 0.9887 - val_accuracy: 0.9691 - val_cost: 3.8922\n",
            "Epoch 428/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0538 - auc: 0.9969 - accuracy: 0.9839 - cost: 2.0683 - val_loss: 0.1334 - val_auc: 0.9885 - val_accuracy: 0.9695 - val_cost: 3.8029\n",
            "Epoch 429/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0536 - auc: 0.9968 - accuracy: 0.9841 - cost: 2.0448 - val_loss: 0.1299 - val_auc: 0.9889 - val_accuracy: 0.9700 - val_cost: 3.7302\n",
            "Epoch 430/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0540 - auc: 0.9969 - accuracy: 0.9838 - cost: 2.0706 - val_loss: 0.1280 - val_auc: 0.9891 - val_accuracy: 0.9698 - val_cost: 3.9385\n",
            "Epoch 431/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0545 - auc: 0.9968 - accuracy: 0.9836 - cost: 2.1042 - val_loss: 0.1266 - val_auc: 0.9889 - val_accuracy: 0.9702 - val_cost: 3.7533\n",
            "Epoch 432/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0538 - auc: 0.9969 - accuracy: 0.9841 - cost: 2.0459 - val_loss: 0.1279 - val_auc: 0.9893 - val_accuracy: 0.9693 - val_cost: 3.9253\n",
            "Epoch 433/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0537 - auc: 0.9968 - accuracy: 0.9841 - cost: 2.0486 - val_loss: 0.1274 - val_auc: 0.9890 - val_accuracy: 0.9696 - val_cost: 3.8327\n",
            "Epoch 434/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0544 - auc: 0.9968 - accuracy: 0.9841 - cost: 2.0386 - val_loss: 0.1294 - val_auc: 0.9890 - val_accuracy: 0.9690 - val_cost: 3.9980\n",
            "Epoch 435/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0539 - auc: 0.9968 - accuracy: 0.9840 - cost: 2.0548 - val_loss: 0.1271 - val_auc: 0.9887 - val_accuracy: 0.9698 - val_cost: 3.8029\n",
            "Epoch 436/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0536 - auc: 0.9969 - accuracy: 0.9842 - cost: 2.0285 - val_loss: 0.1265 - val_auc: 0.9889 - val_accuracy: 0.9712 - val_cost: 3.7202\n",
            "Epoch 437/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0542 - auc: 0.9967 - accuracy: 0.9841 - cost: 2.0324 - val_loss: 0.1284 - val_auc: 0.9887 - val_accuracy: 0.9697 - val_cost: 3.8095\n",
            "Epoch 438/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0529 - auc: 0.9969 - accuracy: 0.9842 - cost: 2.0224 - val_loss: 0.1269 - val_auc: 0.9893 - val_accuracy: 0.9711 - val_cost: 3.6508\n",
            "Epoch 439/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0537 - auc: 0.9969 - accuracy: 0.9841 - cost: 2.0436 - val_loss: 0.1260 - val_auc: 0.9893 - val_accuracy: 0.9705 - val_cost: 3.7037\n",
            "Epoch 440/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0531 - auc: 0.9969 - accuracy: 0.9845 - cost: 1.9857 - val_loss: 0.1285 - val_auc: 0.9893 - val_accuracy: 0.9706 - val_cost: 3.6508\n",
            "Epoch 441/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0530 - auc: 0.9969 - accuracy: 0.9844 - cost: 1.9946 - val_loss: 0.1302 - val_auc: 0.9887 - val_accuracy: 0.9706 - val_cost: 3.7269\n",
            "Epoch 442/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0540 - auc: 0.9968 - accuracy: 0.9840 - cost: 2.0532 - val_loss: 0.1301 - val_auc: 0.9889 - val_accuracy: 0.9704 - val_cost: 3.6772\n",
            "Epoch 443/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0534 - auc: 0.9970 - accuracy: 0.9838 - cost: 2.0694 - val_loss: 0.1304 - val_auc: 0.9890 - val_accuracy: 0.9697 - val_cost: 3.8988\n",
            "Epoch 444/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0530 - auc: 0.9969 - accuracy: 0.9844 - cost: 2.0023 - val_loss: 0.1264 - val_auc: 0.9891 - val_accuracy: 0.9697 - val_cost: 3.8426\n",
            "Epoch 445/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0542 - auc: 0.9969 - accuracy: 0.9838 - cost: 2.0849 - val_loss: 0.1299 - val_auc: 0.9889 - val_accuracy: 0.9697 - val_cost: 3.8128\n",
            "Epoch 446/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0535 - auc: 0.9968 - accuracy: 0.9842 - cost: 2.0332 - val_loss: 0.1279 - val_auc: 0.9890 - val_accuracy: 0.9701 - val_cost: 3.7004\n",
            "Epoch 447/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0536 - auc: 0.9968 - accuracy: 0.9842 - cost: 2.0374 - val_loss: 0.1273 - val_auc: 0.9887 - val_accuracy: 0.9698 - val_cost: 3.8294\n",
            "Epoch 448/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0538 - auc: 0.9969 - accuracy: 0.9842 - cost: 2.0289 - val_loss: 0.1273 - val_auc: 0.9892 - val_accuracy: 0.9700 - val_cost: 3.7103\n",
            "Epoch 449/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0528 - auc: 0.9969 - accuracy: 0.9843 - cost: 2.0131 - val_loss: 0.1296 - val_auc: 0.9892 - val_accuracy: 0.9703 - val_cost: 3.7070\n",
            "Epoch 450/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0527 - auc: 0.9970 - accuracy: 0.9841 - cost: 2.0394 - val_loss: 0.1299 - val_auc: 0.9887 - val_accuracy: 0.9692 - val_cost: 3.8624\n",
            "Epoch 451/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0527 - auc: 0.9969 - accuracy: 0.9845 - cost: 1.9846 - val_loss: 0.1280 - val_auc: 0.9888 - val_accuracy: 0.9694 - val_cost: 3.8426\n",
            "Epoch 452/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0528 - auc: 0.9969 - accuracy: 0.9844 - cost: 2.0085 - val_loss: 0.1315 - val_auc: 0.9892 - val_accuracy: 0.9701 - val_cost: 3.7269\n",
            "Epoch 453/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0538 - auc: 0.9970 - accuracy: 0.9840 - cost: 2.0505 - val_loss: 0.1305 - val_auc: 0.9890 - val_accuracy: 0.9701 - val_cost: 3.8062\n",
            "Epoch 454/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0535 - auc: 0.9969 - accuracy: 0.9841 - cost: 2.0320 - val_loss: 0.1289 - val_auc: 0.9888 - val_accuracy: 0.9699 - val_cost: 3.8095\n",
            "Epoch 455/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0528 - auc: 0.9969 - accuracy: 0.9843 - cost: 2.0135 - val_loss: 0.1327 - val_auc: 0.9888 - val_accuracy: 0.9699 - val_cost: 3.7335\n",
            "Epoch 456/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0534 - auc: 0.9970 - accuracy: 0.9839 - cost: 2.0598 - val_loss: 0.1277 - val_auc: 0.9891 - val_accuracy: 0.9703 - val_cost: 3.7103\n",
            "Epoch 457/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0533 - auc: 0.9969 - accuracy: 0.9842 - cost: 2.0297 - val_loss: 0.1291 - val_auc: 0.9891 - val_accuracy: 0.9701 - val_cost: 3.7235\n",
            "Epoch 458/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0534 - auc: 0.9970 - accuracy: 0.9840 - cost: 2.0490 - val_loss: 0.1323 - val_auc: 0.9889 - val_accuracy: 0.9697 - val_cost: 3.8194\n",
            "Epoch 459/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0529 - auc: 0.9970 - accuracy: 0.9844 - cost: 2.0019 - val_loss: 0.1301 - val_auc: 0.9891 - val_accuracy: 0.9703 - val_cost: 3.6442\n",
            "Epoch 460/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0522 - auc: 0.9970 - accuracy: 0.9844 - cost: 2.0015 - val_loss: 0.1318 - val_auc: 0.9888 - val_accuracy: 0.9699 - val_cost: 3.7202\n",
            "Epoch 461/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0538 - auc: 0.9970 - accuracy: 0.9838 - cost: 2.0802 - val_loss: 0.1289 - val_auc: 0.9892 - val_accuracy: 0.9699 - val_cost: 3.8029\n",
            "Epoch 462/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0541 - auc: 0.9968 - accuracy: 0.9842 - cost: 2.0332 - val_loss: 0.1298 - val_auc: 0.9891 - val_accuracy: 0.9707 - val_cost: 3.7037\n",
            "Epoch 463/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0516 - auc: 0.9971 - accuracy: 0.9844 - cost: 1.9938 - val_loss: 0.1345 - val_auc: 0.9887 - val_accuracy: 0.9696 - val_cost: 3.6739\n",
            "Epoch 464/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0544 - auc: 0.9969 - accuracy: 0.9838 - cost: 2.0802 - val_loss: 0.1306 - val_auc: 0.9888 - val_accuracy: 0.9691 - val_cost: 3.9153\n",
            "Epoch 465/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0528 - auc: 0.9970 - accuracy: 0.9841 - cost: 2.0509 - val_loss: 0.1330 - val_auc: 0.9886 - val_accuracy: 0.9703 - val_cost: 3.6541\n",
            "Epoch 466/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0538 - auc: 0.9969 - accuracy: 0.9840 - cost: 2.0567 - val_loss: 0.1273 - val_auc: 0.9892 - val_accuracy: 0.9709 - val_cost: 3.6310\n",
            "Epoch 467/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0521 - auc: 0.9971 - accuracy: 0.9847 - cost: 1.9595 - val_loss: 0.1273 - val_auc: 0.9890 - val_accuracy: 0.9698 - val_cost: 3.7996\n",
            "Epoch 468/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0528 - auc: 0.9970 - accuracy: 0.9845 - cost: 1.9934 - val_loss: 0.1312 - val_auc: 0.9886 - val_accuracy: 0.9708 - val_cost: 3.6376\n",
            "Epoch 469/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0522 - auc: 0.9970 - accuracy: 0.9841 - cost: 2.0382 - val_loss: 0.1325 - val_auc: 0.9884 - val_accuracy: 0.9699 - val_cost: 3.6442\n",
            "Epoch 470/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0539 - auc: 0.9968 - accuracy: 0.9841 - cost: 2.0471 - val_loss: 0.1266 - val_auc: 0.9893 - val_accuracy: 0.9701 - val_cost: 3.7765\n",
            "Epoch 471/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0523 - auc: 0.9970 - accuracy: 0.9843 - cost: 2.0039 - val_loss: 0.1303 - val_auc: 0.9888 - val_accuracy: 0.9701 - val_cost: 3.6310\n",
            "Epoch 472/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0528 - auc: 0.9970 - accuracy: 0.9843 - cost: 2.0143 - val_loss: 0.1310 - val_auc: 0.9890 - val_accuracy: 0.9703 - val_cost: 3.7269\n",
            "Epoch 473/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0526 - auc: 0.9969 - accuracy: 0.9840 - cost: 2.0486 - val_loss: 0.1265 - val_auc: 0.9893 - val_accuracy: 0.9703 - val_cost: 3.8459\n",
            "Epoch 474/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0525 - auc: 0.9970 - accuracy: 0.9847 - cost: 1.9684 - val_loss: 0.1299 - val_auc: 0.9892 - val_accuracy: 0.9711 - val_cost: 3.6508\n",
            "Epoch 475/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0526 - auc: 0.9970 - accuracy: 0.9839 - cost: 2.0563 - val_loss: 0.1290 - val_auc: 0.9890 - val_accuracy: 0.9696 - val_cost: 3.9120\n",
            "Epoch 476/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0525 - auc: 0.9970 - accuracy: 0.9842 - cost: 2.0297 - val_loss: 0.1281 - val_auc: 0.9895 - val_accuracy: 0.9710 - val_cost: 3.6640\n",
            "Epoch 477/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0521 - auc: 0.9970 - accuracy: 0.9848 - cost: 1.9541 - val_loss: 0.1294 - val_auc: 0.9891 - val_accuracy: 0.9703 - val_cost: 3.7500\n",
            "Epoch 478/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0532 - auc: 0.9969 - accuracy: 0.9843 - cost: 2.0139 - val_loss: 0.1277 - val_auc: 0.9893 - val_accuracy: 0.9704 - val_cost: 3.6772\n",
            "Epoch 479/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0518 - auc: 0.9970 - accuracy: 0.9845 - cost: 1.9815 - val_loss: 0.1319 - val_auc: 0.9887 - val_accuracy: 0.9708 - val_cost: 3.7269\n",
            "Epoch 480/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0533 - auc: 0.9969 - accuracy: 0.9841 - cost: 2.0463 - val_loss: 0.1318 - val_auc: 0.9890 - val_accuracy: 0.9699 - val_cost: 3.7864\n",
            "Epoch 481/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0522 - auc: 0.9970 - accuracy: 0.9842 - cost: 2.0309 - val_loss: 0.1307 - val_auc: 0.9889 - val_accuracy: 0.9703 - val_cost: 3.7269\n",
            "Epoch 482/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0529 - auc: 0.9969 - accuracy: 0.9843 - cost: 2.0015 - val_loss: 0.1274 - val_auc: 0.9891 - val_accuracy: 0.9706 - val_cost: 3.8029\n",
            "Epoch 483/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0522 - auc: 0.9970 - accuracy: 0.9845 - cost: 1.9965 - val_loss: 0.1288 - val_auc: 0.9893 - val_accuracy: 0.9708 - val_cost: 3.6971\n",
            "Epoch 484/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0522 - auc: 0.9970 - accuracy: 0.9844 - cost: 1.9988 - val_loss: 0.1307 - val_auc: 0.9887 - val_accuracy: 0.9702 - val_cost: 3.8062\n",
            "Epoch 485/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0521 - auc: 0.9970 - accuracy: 0.9842 - cost: 2.0301 - val_loss: 0.1355 - val_auc: 0.9886 - val_accuracy: 0.9697 - val_cost: 3.7665\n",
            "Epoch 486/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0530 - auc: 0.9970 - accuracy: 0.9843 - cost: 2.0193 - val_loss: 0.1310 - val_auc: 0.9886 - val_accuracy: 0.9702 - val_cost: 3.8426\n",
            "Epoch 487/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0528 - auc: 0.9970 - accuracy: 0.9842 - cost: 2.0378 - val_loss: 0.1297 - val_auc: 0.9892 - val_accuracy: 0.9703 - val_cost: 3.7632\n",
            "Epoch 488/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0526 - auc: 0.9970 - accuracy: 0.9842 - cost: 2.0212 - val_loss: 0.1342 - val_auc: 0.9887 - val_accuracy: 0.9699 - val_cost: 3.6442\n",
            "Epoch 489/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0535 - auc: 0.9969 - accuracy: 0.9841 - cost: 2.0432 - val_loss: 0.1312 - val_auc: 0.9887 - val_accuracy: 0.9706 - val_cost: 3.6541\n",
            "Epoch 490/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0525 - auc: 0.9970 - accuracy: 0.9843 - cost: 2.0112 - val_loss: 0.1297 - val_auc: 0.9889 - val_accuracy: 0.9704 - val_cost: 3.7401\n",
            "Epoch 491/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0525 - auc: 0.9969 - accuracy: 0.9847 - cost: 1.9626 - val_loss: 0.1309 - val_auc: 0.9887 - val_accuracy: 0.9705 - val_cost: 3.7136\n",
            "Epoch 492/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0522 - auc: 0.9970 - accuracy: 0.9843 - cost: 2.0139 - val_loss: 0.1298 - val_auc: 0.9892 - val_accuracy: 0.9707 - val_cost: 3.7335\n",
            "Epoch 493/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0529 - auc: 0.9969 - accuracy: 0.9841 - cost: 2.0394 - val_loss: 0.1308 - val_auc: 0.9885 - val_accuracy: 0.9696 - val_cost: 3.8360\n",
            "Epoch 494/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0525 - auc: 0.9969 - accuracy: 0.9843 - cost: 2.0135 - val_loss: 0.1300 - val_auc: 0.9886 - val_accuracy: 0.9703 - val_cost: 3.7235\n",
            "Epoch 495/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0517 - auc: 0.9969 - accuracy: 0.9848 - cost: 1.9498 - val_loss: 0.1319 - val_auc: 0.9890 - val_accuracy: 0.9695 - val_cost: 3.7599\n",
            "Epoch 496/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0526 - auc: 0.9971 - accuracy: 0.9841 - cost: 2.0436 - val_loss: 0.1313 - val_auc: 0.9891 - val_accuracy: 0.9699 - val_cost: 3.8327\n",
            "Epoch 497/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0517 - auc: 0.9970 - accuracy: 0.9848 - cost: 1.9603 - val_loss: 0.1308 - val_auc: 0.9889 - val_accuracy: 0.9694 - val_cost: 3.8194\n",
            "Epoch 498/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0520 - auc: 0.9970 - accuracy: 0.9847 - cost: 1.9579 - val_loss: 0.1302 - val_auc: 0.9887 - val_accuracy: 0.9706 - val_cost: 3.6144\n",
            "Epoch 499/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0532 - auc: 0.9970 - accuracy: 0.9839 - cost: 2.0579 - val_loss: 0.1275 - val_auc: 0.9892 - val_accuracy: 0.9714 - val_cost: 3.6376\n",
            "Epoch 500/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0526 - auc: 0.9970 - accuracy: 0.9845 - cost: 1.9865 - val_loss: 0.1333 - val_auc: 0.9891 - val_accuracy: 0.9706 - val_cost: 3.6409\n",
            "Epoch 501/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0523 - auc: 0.9970 - accuracy: 0.9843 - cost: 2.0204 - val_loss: 0.1307 - val_auc: 0.9888 - val_accuracy: 0.9705 - val_cost: 3.7302\n",
            "Epoch 502/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0523 - auc: 0.9970 - accuracy: 0.9844 - cost: 2.0112 - val_loss: 0.1325 - val_auc: 0.9888 - val_accuracy: 0.9703 - val_cost: 3.7434\n",
            "Epoch 503/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0516 - auc: 0.9971 - accuracy: 0.9846 - cost: 1.9803 - val_loss: 0.1307 - val_auc: 0.9890 - val_accuracy: 0.9699 - val_cost: 3.7897\n",
            "Epoch 504/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0518 - auc: 0.9971 - accuracy: 0.9844 - cost: 2.0035 - val_loss: 0.1309 - val_auc: 0.9889 - val_accuracy: 0.9697 - val_cost: 3.8790\n",
            "Epoch 505/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0515 - auc: 0.9970 - accuracy: 0.9847 - cost: 1.9699 - val_loss: 0.1313 - val_auc: 0.9894 - val_accuracy: 0.9686 - val_cost: 3.9319\n",
            "Epoch 506/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0525 - auc: 0.9970 - accuracy: 0.9842 - cost: 2.0285 - val_loss: 0.1330 - val_auc: 0.9889 - val_accuracy: 0.9702 - val_cost: 3.7930\n",
            "Epoch 507/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0518 - auc: 0.9971 - accuracy: 0.9842 - cost: 2.0255 - val_loss: 0.1332 - val_auc: 0.9890 - val_accuracy: 0.9700 - val_cost: 3.7996\n",
            "Epoch 508/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0520 - auc: 0.9970 - accuracy: 0.9844 - cost: 1.9988 - val_loss: 0.1307 - val_auc: 0.9887 - val_accuracy: 0.9703 - val_cost: 3.8294\n",
            "Epoch 509/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0528 - auc: 0.9969 - accuracy: 0.9841 - cost: 2.0428 - val_loss: 0.1303 - val_auc: 0.9887 - val_accuracy: 0.9703 - val_cost: 3.7566\n",
            "Epoch 510/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0524 - auc: 0.9970 - accuracy: 0.9842 - cost: 2.0235 - val_loss: 0.1327 - val_auc: 0.9886 - val_accuracy: 0.9698 - val_cost: 3.7401\n",
            "Epoch 511/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0526 - auc: 0.9969 - accuracy: 0.9846 - cost: 1.9722 - val_loss: 0.1303 - val_auc: 0.9890 - val_accuracy: 0.9701 - val_cost: 3.6971\n",
            "Epoch 512/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0521 - auc: 0.9970 - accuracy: 0.9845 - cost: 1.9954 - val_loss: 0.1326 - val_auc: 0.9889 - val_accuracy: 0.9707 - val_cost: 3.6442\n",
            "Epoch 513/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0511 - auc: 0.9971 - accuracy: 0.9845 - cost: 1.9900 - val_loss: 0.1320 - val_auc: 0.9888 - val_accuracy: 0.9706 - val_cost: 3.7963\n",
            "Epoch 514/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0508 - auc: 0.9972 - accuracy: 0.9847 - cost: 1.9649 - val_loss: 0.1324 - val_auc: 0.9885 - val_accuracy: 0.9697 - val_cost: 3.8459\n",
            "Epoch 515/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0527 - auc: 0.9969 - accuracy: 0.9844 - cost: 2.0039 - val_loss: 0.1363 - val_auc: 0.9882 - val_accuracy: 0.9682 - val_cost: 4.1534\n",
            "Epoch 516/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0517 - auc: 0.9972 - accuracy: 0.9843 - cost: 2.0162 - val_loss: 0.1323 - val_auc: 0.9888 - val_accuracy: 0.9701 - val_cost: 3.7202\n",
            "Epoch 517/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0513 - auc: 0.9970 - accuracy: 0.9849 - cost: 1.9514 - val_loss: 0.1352 - val_auc: 0.9887 - val_accuracy: 0.9699 - val_cost: 3.7897\n",
            "Epoch 518/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0517 - auc: 0.9971 - accuracy: 0.9848 - cost: 1.9491 - val_loss: 0.1353 - val_auc: 0.9886 - val_accuracy: 0.9710 - val_cost: 3.6376\n",
            "Epoch 519/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0524 - auc: 0.9971 - accuracy: 0.9843 - cost: 2.0120 - val_loss: 0.1341 - val_auc: 0.9885 - val_accuracy: 0.9702 - val_cost: 3.7136\n",
            "Epoch 520/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0515 - auc: 0.9971 - accuracy: 0.9848 - cost: 1.9444 - val_loss: 0.1332 - val_auc: 0.9892 - val_accuracy: 0.9705 - val_cost: 3.7798\n",
            "Epoch 521/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0516 - auc: 0.9970 - accuracy: 0.9847 - cost: 1.9684 - val_loss: 0.1359 - val_auc: 0.9886 - val_accuracy: 0.9692 - val_cost: 3.8029\n",
            "Epoch 522/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0509 - auc: 0.9972 - accuracy: 0.9848 - cost: 1.9491 - val_loss: 0.1353 - val_auc: 0.9889 - val_accuracy: 0.9701 - val_cost: 3.7731\n",
            "Epoch 523/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0521 - auc: 0.9970 - accuracy: 0.9842 - cost: 2.0266 - val_loss: 0.1294 - val_auc: 0.9892 - val_accuracy: 0.9698 - val_cost: 3.8426\n",
            "Epoch 524/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0523 - auc: 0.9970 - accuracy: 0.9843 - cost: 2.0139 - val_loss: 0.1329 - val_auc: 0.9889 - val_accuracy: 0.9712 - val_cost: 3.6210\n",
            "Epoch 525/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0517 - auc: 0.9971 - accuracy: 0.9845 - cost: 1.9884 - val_loss: 0.1320 - val_auc: 0.9890 - val_accuracy: 0.9706 - val_cost: 3.7930\n",
            "Epoch 526/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0521 - auc: 0.9970 - accuracy: 0.9841 - cost: 2.0463 - val_loss: 0.1337 - val_auc: 0.9888 - val_accuracy: 0.9689 - val_cost: 3.9947\n",
            "Epoch 527/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0523 - auc: 0.9971 - accuracy: 0.9843 - cost: 2.0158 - val_loss: 0.1313 - val_auc: 0.9889 - val_accuracy: 0.9699 - val_cost: 3.7765\n",
            "Epoch 528/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0515 - auc: 0.9971 - accuracy: 0.9848 - cost: 1.9460 - val_loss: 0.1344 - val_auc: 0.9889 - val_accuracy: 0.9708 - val_cost: 3.6376\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.1221 - auc: 0.9891 - accuracy: 0.9711 - cost: 3.6250\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:03:55.320076\n",
            "fold accuracy: 0.9711250066757202 - fold cost: 3.625\n",
            "x_train shape: (144000, 67)\n",
            "Epoch 1/1000\n",
            "120/120 [==============================] - 2s 6ms/step - loss: 0.5310 - auc: 0.7969 - accuracy: 0.7281 - cost: 36.2218 - val_loss: 0.4002 - val_auc: 0.8974 - val_accuracy: 0.8238 - val_cost: 22.9134\n",
            "Epoch 2/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.3518 - auc: 0.9213 - accuracy: 0.8489 - cost: 19.2512 - val_loss: 0.3178 - val_auc: 0.9359 - val_accuracy: 0.8644 - val_cost: 17.2057\n",
            "Epoch 3/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.3022 - auc: 0.9423 - accuracy: 0.8752 - cost: 15.8032 - val_loss: 0.2880 - val_auc: 0.9475 - val_accuracy: 0.8808 - val_cost: 14.8380\n",
            "Epoch 4/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.2739 - auc: 0.9526 - accuracy: 0.8885 - cost: 14.1022 - val_loss: 0.2643 - val_auc: 0.9560 - val_accuracy: 0.8938 - val_cost: 13.5549\n",
            "Epoch 5/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.2507 - auc: 0.9604 - accuracy: 0.8995 - cost: 12.7025 - val_loss: 0.2456 - val_auc: 0.9620 - val_accuracy: 0.9033 - val_cost: 12.0569\n",
            "Epoch 6/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.2324 - auc: 0.9659 - accuracy: 0.9082 - cost: 11.6096 - val_loss: 0.2300 - val_auc: 0.9666 - val_accuracy: 0.9103 - val_cost: 11.2235\n",
            "Epoch 7/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.2164 - auc: 0.9704 - accuracy: 0.9156 - cost: 10.6393 - val_loss: 0.2159 - val_auc: 0.9705 - val_accuracy: 0.9178 - val_cost: 10.3935\n",
            "Epoch 8/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.2029 - auc: 0.9738 - accuracy: 0.9221 - cost: 9.8499 - val_loss: 0.2047 - val_auc: 0.9733 - val_accuracy: 0.9232 - val_cost: 9.6594\n",
            "Epoch 9/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1920 - auc: 0.9764 - accuracy: 0.9272 - cost: 9.1860 - val_loss: 0.1956 - val_auc: 0.9757 - val_accuracy: 0.9292 - val_cost: 8.7434\n",
            "Epoch 10/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1826 - auc: 0.9785 - accuracy: 0.9316 - cost: 8.6470 - val_loss: 0.1879 - val_auc: 0.9773 - val_accuracy: 0.9332 - val_cost: 8.2837\n",
            "Epoch 11/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1762 - auc: 0.9799 - accuracy: 0.9344 - cost: 8.2975 - val_loss: 0.1814 - val_auc: 0.9785 - val_accuracy: 0.9353 - val_cost: 8.2077\n",
            "Epoch 12/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.1693 - auc: 0.9814 - accuracy: 0.9375 - cost: 7.9012 - val_loss: 0.1767 - val_auc: 0.9796 - val_accuracy: 0.9376 - val_cost: 7.9696\n",
            "Epoch 13/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1637 - auc: 0.9825 - accuracy: 0.9400 - cost: 7.5880 - val_loss: 0.1734 - val_auc: 0.9803 - val_accuracy: 0.9394 - val_cost: 7.7844\n",
            "Epoch 14/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1591 - auc: 0.9833 - accuracy: 0.9429 - cost: 7.1987 - val_loss: 0.1680 - val_auc: 0.9813 - val_accuracy: 0.9426 - val_cost: 7.1627\n",
            "Epoch 15/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1537 - auc: 0.9843 - accuracy: 0.9455 - cost: 6.9059 - val_loss: 0.1648 - val_auc: 0.9819 - val_accuracy: 0.9438 - val_cost: 6.9378\n",
            "Epoch 16/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.1505 - auc: 0.9849 - accuracy: 0.9463 - cost: 6.8029 - val_loss: 0.1622 - val_auc: 0.9824 - val_accuracy: 0.9451 - val_cost: 6.8783\n",
            "Epoch 17/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.1468 - auc: 0.9856 - accuracy: 0.9482 - cost: 6.5552 - val_loss: 0.1587 - val_auc: 0.9833 - val_accuracy: 0.9458 - val_cost: 6.6733\n",
            "Epoch 18/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1439 - auc: 0.9860 - accuracy: 0.9490 - cost: 6.4715 - val_loss: 0.1560 - val_auc: 0.9836 - val_accuracy: 0.9460 - val_cost: 6.8022\n",
            "Epoch 19/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1406 - auc: 0.9865 - accuracy: 0.9506 - cost: 6.2589 - val_loss: 0.1540 - val_auc: 0.9839 - val_accuracy: 0.9482 - val_cost: 6.4517\n",
            "Epoch 20/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1387 - auc: 0.9868 - accuracy: 0.9522 - cost: 6.0463 - val_loss: 0.1524 - val_auc: 0.9842 - val_accuracy: 0.9490 - val_cost: 6.3922\n",
            "Epoch 21/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.1355 - auc: 0.9875 - accuracy: 0.9528 - cost: 5.9965 - val_loss: 0.1517 - val_auc: 0.9843 - val_accuracy: 0.9494 - val_cost: 6.4914\n",
            "Epoch 22/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1335 - auc: 0.9877 - accuracy: 0.9537 - cost: 5.8727 - val_loss: 0.1491 - val_auc: 0.9848 - val_accuracy: 0.9495 - val_cost: 6.2500\n",
            "Epoch 23/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1313 - auc: 0.9880 - accuracy: 0.9543 - cost: 5.7731 - val_loss: 0.1483 - val_auc: 0.9848 - val_accuracy: 0.9501 - val_cost: 6.1310\n",
            "Epoch 24/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.1298 - auc: 0.9883 - accuracy: 0.9546 - cost: 5.7465 - val_loss: 0.1468 - val_auc: 0.9852 - val_accuracy: 0.9511 - val_cost: 6.0251\n",
            "Epoch 25/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1279 - auc: 0.9885 - accuracy: 0.9562 - cost: 5.5505 - val_loss: 0.1456 - val_auc: 0.9853 - val_accuracy: 0.9517 - val_cost: 6.0417\n",
            "Epoch 26/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1256 - auc: 0.9889 - accuracy: 0.9575 - cost: 5.3893 - val_loss: 0.1441 - val_auc: 0.9854 - val_accuracy: 0.9526 - val_cost: 5.9557\n",
            "Epoch 27/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.1234 - auc: 0.9893 - accuracy: 0.9582 - cost: 5.3063 - val_loss: 0.1438 - val_auc: 0.9855 - val_accuracy: 0.9533 - val_cost: 5.8036\n",
            "Epoch 28/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.1228 - auc: 0.9892 - accuracy: 0.9584 - cost: 5.2635 - val_loss: 0.1413 - val_auc: 0.9860 - val_accuracy: 0.9543 - val_cost: 5.7771\n",
            "Epoch 29/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1213 - auc: 0.9895 - accuracy: 0.9592 - cost: 5.1709 - val_loss: 0.1409 - val_auc: 0.9860 - val_accuracy: 0.9547 - val_cost: 5.6052\n",
            "Epoch 30/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1187 - auc: 0.9899 - accuracy: 0.9600 - cost: 5.0737 - val_loss: 0.1391 - val_auc: 0.9863 - val_accuracy: 0.9555 - val_cost: 5.5754\n",
            "Epoch 31/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1186 - auc: 0.9899 - accuracy: 0.9600 - cost: 5.0648 - val_loss: 0.1379 - val_auc: 0.9865 - val_accuracy: 0.9574 - val_cost: 5.3307\n",
            "Epoch 32/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1160 - auc: 0.9903 - accuracy: 0.9610 - cost: 4.9448 - val_loss: 0.1370 - val_auc: 0.9866 - val_accuracy: 0.9567 - val_cost: 5.5026\n",
            "Epoch 33/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.1149 - auc: 0.9904 - accuracy: 0.9621 - cost: 4.8090 - val_loss: 0.1359 - val_auc: 0.9867 - val_accuracy: 0.9569 - val_cost: 5.4398\n",
            "Epoch 34/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1136 - auc: 0.9905 - accuracy: 0.9623 - cost: 4.7894 - val_loss: 0.1362 - val_auc: 0.9865 - val_accuracy: 0.9556 - val_cost: 5.6448\n",
            "Epoch 35/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1122 - auc: 0.9907 - accuracy: 0.9631 - cost: 4.6570 - val_loss: 0.1340 - val_auc: 0.9869 - val_accuracy: 0.9574 - val_cost: 5.3075\n",
            "Epoch 36/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1114 - auc: 0.9907 - accuracy: 0.9633 - cost: 4.6582 - val_loss: 0.1335 - val_auc: 0.9871 - val_accuracy: 0.9577 - val_cost: 5.3009\n",
            "Epoch 37/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1102 - auc: 0.9909 - accuracy: 0.9642 - cost: 4.5378 - val_loss: 0.1313 - val_auc: 0.9873 - val_accuracy: 0.9590 - val_cost: 5.1124\n",
            "Epoch 38/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1083 - auc: 0.9912 - accuracy: 0.9647 - cost: 4.4815 - val_loss: 0.1313 - val_auc: 0.9873 - val_accuracy: 0.9594 - val_cost: 5.1323\n",
            "Epoch 39/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1075 - auc: 0.9912 - accuracy: 0.9650 - cost: 4.4375 - val_loss: 0.1308 - val_auc: 0.9874 - val_accuracy: 0.9587 - val_cost: 5.2050\n",
            "Epoch 40/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1063 - auc: 0.9914 - accuracy: 0.9653 - cost: 4.3981 - val_loss: 0.1291 - val_auc: 0.9877 - val_accuracy: 0.9593 - val_cost: 5.1124\n",
            "Epoch 41/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1044 - auc: 0.9916 - accuracy: 0.9660 - cost: 4.3063 - val_loss: 0.1316 - val_auc: 0.9874 - val_accuracy: 0.9588 - val_cost: 4.9570\n",
            "Epoch 42/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1044 - auc: 0.9916 - accuracy: 0.9668 - cost: 4.1987 - val_loss: 0.1290 - val_auc: 0.9875 - val_accuracy: 0.9601 - val_cost: 4.9173\n",
            "Epoch 43/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1027 - auc: 0.9919 - accuracy: 0.9671 - cost: 4.1871 - val_loss: 0.1288 - val_auc: 0.9877 - val_accuracy: 0.9608 - val_cost: 4.8479\n",
            "Epoch 44/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1025 - auc: 0.9919 - accuracy: 0.9672 - cost: 4.1570 - val_loss: 0.1271 - val_auc: 0.9880 - val_accuracy: 0.9610 - val_cost: 4.8214\n",
            "Epoch 45/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1012 - auc: 0.9918 - accuracy: 0.9677 - cost: 4.1100 - val_loss: 0.1267 - val_auc: 0.9877 - val_accuracy: 0.9603 - val_cost: 4.9074\n",
            "Epoch 46/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1003 - auc: 0.9920 - accuracy: 0.9684 - cost: 4.0023 - val_loss: 0.1257 - val_auc: 0.9880 - val_accuracy: 0.9619 - val_cost: 4.7685\n",
            "Epoch 47/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0990 - auc: 0.9923 - accuracy: 0.9682 - cost: 4.0451 - val_loss: 0.1260 - val_auc: 0.9881 - val_accuracy: 0.9608 - val_cost: 4.8115\n",
            "Epoch 48/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0985 - auc: 0.9922 - accuracy: 0.9686 - cost: 3.9853 - val_loss: 0.1257 - val_auc: 0.9879 - val_accuracy: 0.9608 - val_cost: 4.8975\n",
            "Epoch 49/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0966 - auc: 0.9925 - accuracy: 0.9694 - cost: 3.8831 - val_loss: 0.1244 - val_auc: 0.9881 - val_accuracy: 0.9617 - val_cost: 4.8016\n",
            "Epoch 50/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0968 - auc: 0.9925 - accuracy: 0.9694 - cost: 3.8974 - val_loss: 0.1242 - val_auc: 0.9880 - val_accuracy: 0.9612 - val_cost: 4.8876\n",
            "Epoch 51/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0968 - auc: 0.9925 - accuracy: 0.9688 - cost: 3.9606 - val_loss: 0.1231 - val_auc: 0.9883 - val_accuracy: 0.9615 - val_cost: 4.7586\n",
            "Epoch 52/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0956 - auc: 0.9926 - accuracy: 0.9698 - cost: 3.8441 - val_loss: 0.1217 - val_auc: 0.9883 - val_accuracy: 0.9631 - val_cost: 4.6164\n",
            "Epoch 53/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0949 - auc: 0.9927 - accuracy: 0.9695 - cost: 3.8777 - val_loss: 0.1222 - val_auc: 0.9885 - val_accuracy: 0.9621 - val_cost: 4.7553\n",
            "Epoch 54/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0942 - auc: 0.9928 - accuracy: 0.9705 - cost: 3.7515 - val_loss: 0.1217 - val_auc: 0.9885 - val_accuracy: 0.9629 - val_cost: 4.5767\n",
            "Epoch 55/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0939 - auc: 0.9928 - accuracy: 0.9707 - cost: 3.7187 - val_loss: 0.1210 - val_auc: 0.9884 - val_accuracy: 0.9630 - val_cost: 4.6495\n",
            "Epoch 56/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0920 - auc: 0.9930 - accuracy: 0.9707 - cost: 3.7218 - val_loss: 0.1210 - val_auc: 0.9886 - val_accuracy: 0.9642 - val_cost: 4.3981\n",
            "Epoch 57/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0914 - auc: 0.9931 - accuracy: 0.9712 - cost: 3.6620 - val_loss: 0.1216 - val_auc: 0.9883 - val_accuracy: 0.9630 - val_cost: 4.6925\n",
            "Epoch 58/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0913 - auc: 0.9930 - accuracy: 0.9716 - cost: 3.6215 - val_loss: 0.1204 - val_auc: 0.9889 - val_accuracy: 0.9638 - val_cost: 4.4015\n",
            "Epoch 59/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0907 - auc: 0.9931 - accuracy: 0.9715 - cost: 3.6323 - val_loss: 0.1192 - val_auc: 0.9888 - val_accuracy: 0.9637 - val_cost: 4.6065\n",
            "Epoch 60/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0905 - auc: 0.9931 - accuracy: 0.9715 - cost: 3.6285 - val_loss: 0.1186 - val_auc: 0.9887 - val_accuracy: 0.9640 - val_cost: 4.5503\n",
            "Epoch 61/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0886 - auc: 0.9933 - accuracy: 0.9719 - cost: 3.5853 - val_loss: 0.1198 - val_auc: 0.9885 - val_accuracy: 0.9637 - val_cost: 4.6296\n",
            "Epoch 62/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0888 - auc: 0.9933 - accuracy: 0.9725 - cost: 3.4896 - val_loss: 0.1181 - val_auc: 0.9889 - val_accuracy: 0.9645 - val_cost: 4.3948\n",
            "Epoch 63/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0878 - auc: 0.9935 - accuracy: 0.9727 - cost: 3.4657 - val_loss: 0.1172 - val_auc: 0.9888 - val_accuracy: 0.9656 - val_cost: 4.2923\n",
            "Epoch 64/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0875 - auc: 0.9934 - accuracy: 0.9730 - cost: 3.4452 - val_loss: 0.1163 - val_auc: 0.9889 - val_accuracy: 0.9656 - val_cost: 4.4808\n",
            "Epoch 65/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0869 - auc: 0.9935 - accuracy: 0.9728 - cost: 3.4715 - val_loss: 0.1165 - val_auc: 0.9891 - val_accuracy: 0.9646 - val_cost: 4.4676\n",
            "Epoch 66/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0867 - auc: 0.9936 - accuracy: 0.9727 - cost: 3.4915 - val_loss: 0.1166 - val_auc: 0.9889 - val_accuracy: 0.9656 - val_cost: 4.4312\n",
            "Epoch 67/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0860 - auc: 0.9936 - accuracy: 0.9727 - cost: 3.4807 - val_loss: 0.1160 - val_auc: 0.9888 - val_accuracy: 0.9652 - val_cost: 4.4411\n",
            "Epoch 68/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0845 - auc: 0.9938 - accuracy: 0.9737 - cost: 3.3553 - val_loss: 0.1169 - val_auc: 0.9889 - val_accuracy: 0.9659 - val_cost: 4.3122\n",
            "Epoch 69/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0848 - auc: 0.9936 - accuracy: 0.9741 - cost: 3.3152 - val_loss: 0.1169 - val_auc: 0.9889 - val_accuracy: 0.9660 - val_cost: 4.2394\n",
            "Epoch 70/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0840 - auc: 0.9938 - accuracy: 0.9741 - cost: 3.3036 - val_loss: 0.1149 - val_auc: 0.9894 - val_accuracy: 0.9659 - val_cost: 4.2758\n",
            "Epoch 71/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0841 - auc: 0.9938 - accuracy: 0.9746 - cost: 3.2446 - val_loss: 0.1158 - val_auc: 0.9890 - val_accuracy: 0.9660 - val_cost: 4.2295\n",
            "Epoch 72/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0841 - auc: 0.9938 - accuracy: 0.9741 - cost: 3.3117 - val_loss: 0.1138 - val_auc: 0.9894 - val_accuracy: 0.9665 - val_cost: 4.1634\n",
            "Epoch 73/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0832 - auc: 0.9939 - accuracy: 0.9741 - cost: 3.3133 - val_loss: 0.1160 - val_auc: 0.9891 - val_accuracy: 0.9660 - val_cost: 4.1700\n",
            "Epoch 74/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0823 - auc: 0.9940 - accuracy: 0.9745 - cost: 3.2616 - val_loss: 0.1150 - val_auc: 0.9892 - val_accuracy: 0.9663 - val_cost: 4.1733\n",
            "Epoch 75/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0815 - auc: 0.9940 - accuracy: 0.9752 - cost: 3.1717 - val_loss: 0.1151 - val_auc: 0.9890 - val_accuracy: 0.9667 - val_cost: 4.1733\n",
            "Epoch 76/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0817 - auc: 0.9941 - accuracy: 0.9753 - cost: 3.1497 - val_loss: 0.1172 - val_auc: 0.9892 - val_accuracy: 0.9656 - val_cost: 4.1733\n",
            "Epoch 77/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0810 - auc: 0.9940 - accuracy: 0.9754 - cost: 3.1381 - val_loss: 0.1131 - val_auc: 0.9891 - val_accuracy: 0.9676 - val_cost: 4.1237\n",
            "Epoch 78/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0807 - auc: 0.9941 - accuracy: 0.9758 - cost: 3.0984 - val_loss: 0.1148 - val_auc: 0.9891 - val_accuracy: 0.9660 - val_cost: 4.2989\n",
            "Epoch 79/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0815 - auc: 0.9940 - accuracy: 0.9753 - cost: 3.1535 - val_loss: 0.1151 - val_auc: 0.9889 - val_accuracy: 0.9665 - val_cost: 4.2626\n",
            "Epoch 80/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0803 - auc: 0.9941 - accuracy: 0.9755 - cost: 3.1238 - val_loss: 0.1172 - val_auc: 0.9889 - val_accuracy: 0.9665 - val_cost: 4.0708\n",
            "Epoch 81/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0798 - auc: 0.9942 - accuracy: 0.9756 - cost: 3.1080 - val_loss: 0.1154 - val_auc: 0.9891 - val_accuracy: 0.9671 - val_cost: 4.1171\n",
            "Epoch 82/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0790 - auc: 0.9943 - accuracy: 0.9761 - cost: 3.0440 - val_loss: 0.1146 - val_auc: 0.9893 - val_accuracy: 0.9672 - val_cost: 4.1898\n",
            "Epoch 83/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0795 - auc: 0.9942 - accuracy: 0.9756 - cost: 3.1130 - val_loss: 0.1143 - val_auc: 0.9890 - val_accuracy: 0.9674 - val_cost: 4.1005\n",
            "Epoch 84/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0787 - auc: 0.9943 - accuracy: 0.9757 - cost: 3.0961 - val_loss: 0.1148 - val_auc: 0.9892 - val_accuracy: 0.9683 - val_cost: 3.9848\n",
            "Epoch 85/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0782 - auc: 0.9943 - accuracy: 0.9765 - cost: 3.0015 - val_loss: 0.1148 - val_auc: 0.9890 - val_accuracy: 0.9673 - val_cost: 4.0906\n",
            "Epoch 86/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0777 - auc: 0.9944 - accuracy: 0.9767 - cost: 2.9788 - val_loss: 0.1147 - val_auc: 0.9891 - val_accuracy: 0.9674 - val_cost: 4.1964\n",
            "Epoch 87/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0773 - auc: 0.9945 - accuracy: 0.9767 - cost: 2.9819 - val_loss: 0.1144 - val_auc: 0.9892 - val_accuracy: 0.9685 - val_cost: 3.9550\n",
            "Epoch 88/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0767 - auc: 0.9945 - accuracy: 0.9771 - cost: 2.9194 - val_loss: 0.1137 - val_auc: 0.9895 - val_accuracy: 0.9680 - val_cost: 3.9947\n",
            "Epoch 89/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0767 - auc: 0.9946 - accuracy: 0.9769 - cost: 2.9468 - val_loss: 0.1152 - val_auc: 0.9892 - val_accuracy: 0.9672 - val_cost: 4.0939\n",
            "Epoch 90/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0761 - auc: 0.9946 - accuracy: 0.9773 - cost: 2.8935 - val_loss: 0.1146 - val_auc: 0.9893 - val_accuracy: 0.9669 - val_cost: 4.0972\n",
            "Epoch 91/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0763 - auc: 0.9946 - accuracy: 0.9771 - cost: 2.9406 - val_loss: 0.1141 - val_auc: 0.9897 - val_accuracy: 0.9685 - val_cost: 3.9087\n",
            "Epoch 92/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0755 - auc: 0.9945 - accuracy: 0.9775 - cost: 2.8758 - val_loss: 0.1145 - val_auc: 0.9894 - val_accuracy: 0.9665 - val_cost: 4.1865\n",
            "Epoch 93/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0756 - auc: 0.9945 - accuracy: 0.9771 - cost: 2.9309 - val_loss: 0.1132 - val_auc: 0.9895 - val_accuracy: 0.9680 - val_cost: 4.0112\n",
            "Epoch 94/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0749 - auc: 0.9948 - accuracy: 0.9775 - cost: 2.8715 - val_loss: 0.1131 - val_auc: 0.9898 - val_accuracy: 0.9685 - val_cost: 3.9087\n",
            "Epoch 95/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0750 - auc: 0.9947 - accuracy: 0.9774 - cost: 2.8877 - val_loss: 0.1131 - val_auc: 0.9898 - val_accuracy: 0.9683 - val_cost: 3.9253\n",
            "Epoch 96/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0750 - auc: 0.9948 - accuracy: 0.9774 - cost: 2.8951 - val_loss: 0.1134 - val_auc: 0.9896 - val_accuracy: 0.9674 - val_cost: 3.9980\n",
            "Epoch 97/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0739 - auc: 0.9947 - accuracy: 0.9778 - cost: 2.8430 - val_loss: 0.1125 - val_auc: 0.9895 - val_accuracy: 0.9677 - val_cost: 4.0112\n",
            "Epoch 98/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0737 - auc: 0.9948 - accuracy: 0.9778 - cost: 2.8403 - val_loss: 0.1131 - val_auc: 0.9895 - val_accuracy: 0.9688 - val_cost: 3.9286\n",
            "Epoch 99/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0731 - auc: 0.9948 - accuracy: 0.9780 - cost: 2.8083 - val_loss: 0.1127 - val_auc: 0.9896 - val_accuracy: 0.9677 - val_cost: 4.0774\n",
            "Epoch 100/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0739 - auc: 0.9947 - accuracy: 0.9777 - cost: 2.8519 - val_loss: 0.1125 - val_auc: 0.9896 - val_accuracy: 0.9675 - val_cost: 4.0675\n",
            "Epoch 101/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0729 - auc: 0.9948 - accuracy: 0.9782 - cost: 2.7940 - val_loss: 0.1150 - val_auc: 0.9896 - val_accuracy: 0.9679 - val_cost: 3.9881\n",
            "Epoch 102/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0738 - auc: 0.9947 - accuracy: 0.9777 - cost: 2.8557 - val_loss: 0.1155 - val_auc: 0.9895 - val_accuracy: 0.9674 - val_cost: 4.0509\n",
            "Epoch 103/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0733 - auc: 0.9948 - accuracy: 0.9780 - cost: 2.8218 - val_loss: 0.1143 - val_auc: 0.9895 - val_accuracy: 0.9684 - val_cost: 3.8558\n",
            "Epoch 104/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0726 - auc: 0.9949 - accuracy: 0.9782 - cost: 2.7859 - val_loss: 0.1148 - val_auc: 0.9896 - val_accuracy: 0.9687 - val_cost: 3.8128\n",
            "Epoch 105/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0730 - auc: 0.9948 - accuracy: 0.9781 - cost: 2.8017 - val_loss: 0.1139 - val_auc: 0.9896 - val_accuracy: 0.9686 - val_cost: 3.8955\n",
            "Epoch 106/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0716 - auc: 0.9950 - accuracy: 0.9786 - cost: 2.7431 - val_loss: 0.1133 - val_auc: 0.9896 - val_accuracy: 0.9690 - val_cost: 3.8988\n",
            "Epoch 107/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0718 - auc: 0.9949 - accuracy: 0.9791 - cost: 2.6809 - val_loss: 0.1123 - val_auc: 0.9897 - val_accuracy: 0.9689 - val_cost: 3.8955\n",
            "Epoch 108/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0716 - auc: 0.9950 - accuracy: 0.9784 - cost: 2.7523 - val_loss: 0.1151 - val_auc: 0.9894 - val_accuracy: 0.9683 - val_cost: 3.8823\n",
            "Epoch 109/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0728 - auc: 0.9949 - accuracy: 0.9785 - cost: 2.7380 - val_loss: 0.1138 - val_auc: 0.9897 - val_accuracy: 0.9691 - val_cost: 3.8128\n",
            "Epoch 110/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0713 - auc: 0.9951 - accuracy: 0.9788 - cost: 2.6960 - val_loss: 0.1129 - val_auc: 0.9897 - val_accuracy: 0.9689 - val_cost: 3.8889\n",
            "Epoch 111/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0711 - auc: 0.9950 - accuracy: 0.9787 - cost: 2.7211 - val_loss: 0.1155 - val_auc: 0.9894 - val_accuracy: 0.9681 - val_cost: 3.9286\n",
            "Epoch 112/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0710 - auc: 0.9951 - accuracy: 0.9790 - cost: 2.6825 - val_loss: 0.1143 - val_auc: 0.9895 - val_accuracy: 0.9680 - val_cost: 4.0509\n",
            "Epoch 113/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0709 - auc: 0.9951 - accuracy: 0.9785 - cost: 2.7500 - val_loss: 0.1129 - val_auc: 0.9895 - val_accuracy: 0.9685 - val_cost: 3.9319\n",
            "Epoch 114/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0707 - auc: 0.9951 - accuracy: 0.9789 - cost: 2.6983 - val_loss: 0.1141 - val_auc: 0.9895 - val_accuracy: 0.9694 - val_cost: 3.8261\n",
            "Epoch 115/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0701 - auc: 0.9951 - accuracy: 0.9787 - cost: 2.7211 - val_loss: 0.1155 - val_auc: 0.9894 - val_accuracy: 0.9688 - val_cost: 3.8426\n",
            "Epoch 116/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0697 - auc: 0.9951 - accuracy: 0.9790 - cost: 2.6933 - val_loss: 0.1142 - val_auc: 0.9897 - val_accuracy: 0.9692 - val_cost: 3.8757\n",
            "Epoch 117/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0694 - auc: 0.9951 - accuracy: 0.9794 - cost: 2.6215 - val_loss: 0.1153 - val_auc: 0.9893 - val_accuracy: 0.9690 - val_cost: 3.9583\n",
            "Epoch 118/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0691 - auc: 0.9953 - accuracy: 0.9794 - cost: 2.6300 - val_loss: 0.1153 - val_auc: 0.9894 - val_accuracy: 0.9683 - val_cost: 3.9054\n",
            "Epoch 119/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0694 - auc: 0.9952 - accuracy: 0.9790 - cost: 2.6782 - val_loss: 0.1151 - val_auc: 0.9896 - val_accuracy: 0.9675 - val_cost: 3.9848\n",
            "Epoch 120/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0693 - auc: 0.9953 - accuracy: 0.9794 - cost: 2.6358 - val_loss: 0.1132 - val_auc: 0.9896 - val_accuracy: 0.9682 - val_cost: 3.9451\n",
            "Epoch 121/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0692 - auc: 0.9952 - accuracy: 0.9795 - cost: 2.6304 - val_loss: 0.1133 - val_auc: 0.9896 - val_accuracy: 0.9685 - val_cost: 3.9187\n",
            "Epoch 122/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0689 - auc: 0.9953 - accuracy: 0.9795 - cost: 2.6211 - val_loss: 0.1147 - val_auc: 0.9895 - val_accuracy: 0.9677 - val_cost: 4.1336\n",
            "Epoch 123/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0688 - auc: 0.9953 - accuracy: 0.9797 - cost: 2.6096 - val_loss: 0.1166 - val_auc: 0.9890 - val_accuracy: 0.9680 - val_cost: 4.0575\n",
            "Epoch 124/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0678 - auc: 0.9954 - accuracy: 0.9798 - cost: 2.5899 - val_loss: 0.1144 - val_auc: 0.9895 - val_accuracy: 0.9689 - val_cost: 3.9286\n",
            "Epoch 125/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0686 - auc: 0.9954 - accuracy: 0.9791 - cost: 2.6728 - val_loss: 0.1127 - val_auc: 0.9898 - val_accuracy: 0.9688 - val_cost: 3.8657\n",
            "Epoch 126/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0678 - auc: 0.9954 - accuracy: 0.9798 - cost: 2.5837 - val_loss: 0.1156 - val_auc: 0.9894 - val_accuracy: 0.9690 - val_cost: 3.8856\n",
            "Epoch 127/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0676 - auc: 0.9954 - accuracy: 0.9800 - cost: 2.5536 - val_loss: 0.1135 - val_auc: 0.9896 - val_accuracy: 0.9692 - val_cost: 3.9716\n",
            "Epoch 128/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0681 - auc: 0.9953 - accuracy: 0.9801 - cost: 2.5455 - val_loss: 0.1136 - val_auc: 0.9893 - val_accuracy: 0.9700 - val_cost: 3.6971\n",
            "Epoch 129/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0687 - auc: 0.9953 - accuracy: 0.9793 - cost: 2.6562 - val_loss: 0.1145 - val_auc: 0.9892 - val_accuracy: 0.9688 - val_cost: 3.9187\n",
            "Epoch 130/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0678 - auc: 0.9953 - accuracy: 0.9799 - cost: 2.5799 - val_loss: 0.1161 - val_auc: 0.9895 - val_accuracy: 0.9679 - val_cost: 3.9087\n",
            "Epoch 131/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0669 - auc: 0.9955 - accuracy: 0.9800 - cost: 2.5571 - val_loss: 0.1154 - val_auc: 0.9894 - val_accuracy: 0.9688 - val_cost: 3.9484\n",
            "Epoch 132/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0682 - auc: 0.9953 - accuracy: 0.9796 - cost: 2.6042 - val_loss: 0.1164 - val_auc: 0.9891 - val_accuracy: 0.9685 - val_cost: 3.9848\n",
            "Epoch 133/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0668 - auc: 0.9956 - accuracy: 0.9800 - cost: 2.5586 - val_loss: 0.1162 - val_auc: 0.9893 - val_accuracy: 0.9690 - val_cost: 3.8624\n",
            "Epoch 134/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0674 - auc: 0.9953 - accuracy: 0.9798 - cost: 2.5826 - val_loss: 0.1135 - val_auc: 0.9894 - val_accuracy: 0.9697 - val_cost: 3.7368\n",
            "Epoch 135/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0667 - auc: 0.9956 - accuracy: 0.9801 - cost: 2.5459 - val_loss: 0.1160 - val_auc: 0.9895 - val_accuracy: 0.9685 - val_cost: 3.9021\n",
            "Epoch 136/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0673 - auc: 0.9955 - accuracy: 0.9798 - cost: 2.5922 - val_loss: 0.1156 - val_auc: 0.9895 - val_accuracy: 0.9685 - val_cost: 3.9848\n",
            "Epoch 137/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0664 - auc: 0.9955 - accuracy: 0.9802 - cost: 2.5301 - val_loss: 0.1158 - val_auc: 0.9893 - val_accuracy: 0.9685 - val_cost: 3.9616\n",
            "Epoch 138/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0667 - auc: 0.9956 - accuracy: 0.9801 - cost: 2.5490 - val_loss: 0.1146 - val_auc: 0.9895 - val_accuracy: 0.9688 - val_cost: 4.0013\n",
            "Epoch 139/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0666 - auc: 0.9955 - accuracy: 0.9801 - cost: 2.5556 - val_loss: 0.1144 - val_auc: 0.9894 - val_accuracy: 0.9694 - val_cost: 3.7533\n",
            "Epoch 140/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0662 - auc: 0.9956 - accuracy: 0.9802 - cost: 2.5378 - val_loss: 0.1177 - val_auc: 0.9893 - val_accuracy: 0.9701 - val_cost: 3.7103\n",
            "Epoch 141/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0659 - auc: 0.9956 - accuracy: 0.9801 - cost: 2.5382 - val_loss: 0.1153 - val_auc: 0.9895 - val_accuracy: 0.9694 - val_cost: 3.8095\n",
            "Epoch 142/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0658 - auc: 0.9956 - accuracy: 0.9801 - cost: 2.5478 - val_loss: 0.1149 - val_auc: 0.9897 - val_accuracy: 0.9694 - val_cost: 3.8790\n",
            "Epoch 143/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0659 - auc: 0.9955 - accuracy: 0.9804 - cost: 2.5166 - val_loss: 0.1145 - val_auc: 0.9897 - val_accuracy: 0.9689 - val_cost: 3.8624\n",
            "Epoch 144/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0655 - auc: 0.9956 - accuracy: 0.9806 - cost: 2.4826 - val_loss: 0.1178 - val_auc: 0.9892 - val_accuracy: 0.9681 - val_cost: 4.0542\n",
            "Epoch 145/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0648 - auc: 0.9957 - accuracy: 0.9806 - cost: 2.4877 - val_loss: 0.1180 - val_auc: 0.9895 - val_accuracy: 0.9688 - val_cost: 4.0542\n",
            "Epoch 146/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0651 - auc: 0.9957 - accuracy: 0.9805 - cost: 2.4846 - val_loss: 0.1157 - val_auc: 0.9898 - val_accuracy: 0.9703 - val_cost: 3.7202\n",
            "Epoch 147/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0650 - auc: 0.9956 - accuracy: 0.9807 - cost: 2.4761 - val_loss: 0.1164 - val_auc: 0.9894 - val_accuracy: 0.9692 - val_cost: 3.8095\n",
            "Epoch 148/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0653 - auc: 0.9956 - accuracy: 0.9806 - cost: 2.4819 - val_loss: 0.1149 - val_auc: 0.9894 - val_accuracy: 0.9702 - val_cost: 3.7599\n",
            "Epoch 149/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0659 - auc: 0.9956 - accuracy: 0.9802 - cost: 2.5332 - val_loss: 0.1157 - val_auc: 0.9894 - val_accuracy: 0.9688 - val_cost: 3.8558\n",
            "Epoch 150/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0642 - auc: 0.9958 - accuracy: 0.9805 - cost: 2.4973 - val_loss: 0.1165 - val_auc: 0.9893 - val_accuracy: 0.9691 - val_cost: 3.9120\n",
            "Epoch 151/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0651 - auc: 0.9957 - accuracy: 0.9808 - cost: 2.4626 - val_loss: 0.1181 - val_auc: 0.9896 - val_accuracy: 0.9679 - val_cost: 4.0278\n",
            "Epoch 152/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0643 - auc: 0.9958 - accuracy: 0.9807 - cost: 2.4680 - val_loss: 0.1167 - val_auc: 0.9892 - val_accuracy: 0.9691 - val_cost: 3.9616\n",
            "Epoch 153/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0637 - auc: 0.9959 - accuracy: 0.9810 - cost: 2.4433 - val_loss: 0.1174 - val_auc: 0.9894 - val_accuracy: 0.9685 - val_cost: 4.0245\n",
            "Epoch 154/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0642 - auc: 0.9957 - accuracy: 0.9808 - cost: 2.4495 - val_loss: 0.1164 - val_auc: 0.9895 - val_accuracy: 0.9689 - val_cost: 3.8492\n",
            "Epoch 155/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0636 - auc: 0.9958 - accuracy: 0.9811 - cost: 2.4078 - val_loss: 0.1166 - val_auc: 0.9894 - val_accuracy: 0.9697 - val_cost: 3.7302\n",
            "Epoch 156/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0641 - auc: 0.9958 - accuracy: 0.9815 - cost: 2.3738 - val_loss: 0.1155 - val_auc: 0.9895 - val_accuracy: 0.9693 - val_cost: 3.7765\n",
            "Epoch 157/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0648 - auc: 0.9958 - accuracy: 0.9805 - cost: 2.4961 - val_loss: 0.1169 - val_auc: 0.9896 - val_accuracy: 0.9698 - val_cost: 3.7235\n",
            "Epoch 158/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0640 - auc: 0.9958 - accuracy: 0.9808 - cost: 2.4529 - val_loss: 0.1155 - val_auc: 0.9897 - val_accuracy: 0.9694 - val_cost: 3.8492\n",
            "Epoch 159/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0643 - auc: 0.9958 - accuracy: 0.9807 - cost: 2.4691 - val_loss: 0.1159 - val_auc: 0.9894 - val_accuracy: 0.9691 - val_cost: 3.9120\n",
            "Epoch 160/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0639 - auc: 0.9958 - accuracy: 0.9808 - cost: 2.4560 - val_loss: 0.1166 - val_auc: 0.9894 - val_accuracy: 0.9692 - val_cost: 3.8790\n",
            "Epoch 161/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0633 - auc: 0.9958 - accuracy: 0.9813 - cost: 2.3858 - val_loss: 0.1171 - val_auc: 0.9895 - val_accuracy: 0.9702 - val_cost: 3.6772\n",
            "Epoch 162/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0636 - auc: 0.9958 - accuracy: 0.9811 - cost: 2.4275 - val_loss: 0.1146 - val_auc: 0.9895 - val_accuracy: 0.9691 - val_cost: 3.8294\n",
            "Epoch 163/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0639 - auc: 0.9958 - accuracy: 0.9812 - cost: 2.4097 - val_loss: 0.1175 - val_auc: 0.9894 - val_accuracy: 0.9701 - val_cost: 3.7533\n",
            "Epoch 164/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0638 - auc: 0.9958 - accuracy: 0.9809 - cost: 2.4498 - val_loss: 0.1188 - val_auc: 0.9894 - val_accuracy: 0.9690 - val_cost: 3.9253\n",
            "Epoch 165/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0632 - auc: 0.9958 - accuracy: 0.9813 - cost: 2.4039 - val_loss: 0.1184 - val_auc: 0.9891 - val_accuracy: 0.9698 - val_cost: 3.7467\n",
            "Epoch 166/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0640 - auc: 0.9958 - accuracy: 0.9807 - cost: 2.4730 - val_loss: 0.1173 - val_auc: 0.9897 - val_accuracy: 0.9686 - val_cost: 3.9914\n",
            "Epoch 167/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0634 - auc: 0.9958 - accuracy: 0.9813 - cost: 2.3931 - val_loss: 0.1171 - val_auc: 0.9895 - val_accuracy: 0.9687 - val_cost: 3.9220\n",
            "Epoch 168/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0627 - auc: 0.9959 - accuracy: 0.9811 - cost: 2.4082 - val_loss: 0.1179 - val_auc: 0.9893 - val_accuracy: 0.9701 - val_cost: 3.7302\n",
            "Epoch 169/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0632 - auc: 0.9958 - accuracy: 0.9813 - cost: 2.4012 - val_loss: 0.1190 - val_auc: 0.9892 - val_accuracy: 0.9688 - val_cost: 3.9021\n",
            "Epoch 170/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0630 - auc: 0.9959 - accuracy: 0.9812 - cost: 2.3931 - val_loss: 0.1164 - val_auc: 0.9895 - val_accuracy: 0.9701 - val_cost: 3.7103\n",
            "Epoch 171/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0629 - auc: 0.9960 - accuracy: 0.9816 - cost: 2.3665 - val_loss: 0.1174 - val_auc: 0.9895 - val_accuracy: 0.9693 - val_cost: 3.8360\n",
            "Epoch 172/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0637 - auc: 0.9957 - accuracy: 0.9813 - cost: 2.3951 - val_loss: 0.1171 - val_auc: 0.9895 - val_accuracy: 0.9694 - val_cost: 3.8426\n",
            "Epoch 173/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0624 - auc: 0.9959 - accuracy: 0.9814 - cost: 2.3731 - val_loss: 0.1175 - val_auc: 0.9892 - val_accuracy: 0.9699 - val_cost: 3.7765\n",
            "Epoch 174/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0620 - auc: 0.9960 - accuracy: 0.9815 - cost: 2.3615 - val_loss: 0.1184 - val_auc: 0.9892 - val_accuracy: 0.9704 - val_cost: 3.6739\n",
            "Epoch 175/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0613 - auc: 0.9960 - accuracy: 0.9818 - cost: 2.3299 - val_loss: 0.1198 - val_auc: 0.9890 - val_accuracy: 0.9692 - val_cost: 3.8657\n",
            "Epoch 176/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0627 - auc: 0.9959 - accuracy: 0.9813 - cost: 2.3893 - val_loss: 0.1164 - val_auc: 0.9895 - val_accuracy: 0.9704 - val_cost: 3.6739\n",
            "Epoch 177/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0620 - auc: 0.9959 - accuracy: 0.9816 - cost: 2.3461 - val_loss: 0.1165 - val_auc: 0.9898 - val_accuracy: 0.9706 - val_cost: 3.6045\n",
            "Epoch 178/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0614 - auc: 0.9959 - accuracy: 0.9819 - cost: 2.3067 - val_loss: 0.1168 - val_auc: 0.9893 - val_accuracy: 0.9706 - val_cost: 3.6607\n",
            "Epoch 179/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0626 - auc: 0.9960 - accuracy: 0.9812 - cost: 2.4078 - val_loss: 0.1194 - val_auc: 0.9891 - val_accuracy: 0.9696 - val_cost: 3.7632\n",
            "Epoch 180/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0618 - auc: 0.9960 - accuracy: 0.9818 - cost: 2.3252 - val_loss: 0.1198 - val_auc: 0.9893 - val_accuracy: 0.9699 - val_cost: 3.7302\n",
            "Epoch 181/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0619 - auc: 0.9961 - accuracy: 0.9817 - cost: 2.3414 - val_loss: 0.1182 - val_auc: 0.9892 - val_accuracy: 0.9685 - val_cost: 4.0642\n",
            "Epoch 182/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0612 - auc: 0.9960 - accuracy: 0.9820 - cost: 2.3152 - val_loss: 0.1177 - val_auc: 0.9894 - val_accuracy: 0.9701 - val_cost: 3.7335\n",
            "Epoch 183/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0620 - auc: 0.9960 - accuracy: 0.9815 - cost: 2.3731 - val_loss: 0.1194 - val_auc: 0.9891 - val_accuracy: 0.9697 - val_cost: 3.6706\n",
            "Epoch 184/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0615 - auc: 0.9960 - accuracy: 0.9816 - cost: 2.3565 - val_loss: 0.1190 - val_auc: 0.9895 - val_accuracy: 0.9694 - val_cost: 3.7401\n",
            "Epoch 185/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0620 - auc: 0.9959 - accuracy: 0.9819 - cost: 2.3075 - val_loss: 0.1195 - val_auc: 0.9891 - val_accuracy: 0.9688 - val_cost: 3.9385\n",
            "Epoch 186/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0613 - auc: 0.9960 - accuracy: 0.9822 - cost: 2.2874 - val_loss: 0.1185 - val_auc: 0.9891 - val_accuracy: 0.9701 - val_cost: 3.7368\n",
            "Epoch 187/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0617 - auc: 0.9961 - accuracy: 0.9814 - cost: 2.3715 - val_loss: 0.1182 - val_auc: 0.9890 - val_accuracy: 0.9700 - val_cost: 3.7533\n",
            "Epoch 188/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0617 - auc: 0.9961 - accuracy: 0.9816 - cost: 2.3580 - val_loss: 0.1177 - val_auc: 0.9893 - val_accuracy: 0.9699 - val_cost: 3.8128\n",
            "Epoch 189/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0615 - auc: 0.9960 - accuracy: 0.9819 - cost: 2.3187 - val_loss: 0.1192 - val_auc: 0.9891 - val_accuracy: 0.9703 - val_cost: 3.7368\n",
            "Epoch 190/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0614 - auc: 0.9960 - accuracy: 0.9817 - cost: 2.3492 - val_loss: 0.1201 - val_auc: 0.9890 - val_accuracy: 0.9703 - val_cost: 3.6144\n",
            "Epoch 191/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0616 - auc: 0.9960 - accuracy: 0.9814 - cost: 2.3773 - val_loss: 0.1193 - val_auc: 0.9892 - val_accuracy: 0.9698 - val_cost: 3.6905\n",
            "Epoch 192/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0609 - auc: 0.9961 - accuracy: 0.9820 - cost: 2.3083 - val_loss: 0.1186 - val_auc: 0.9894 - val_accuracy: 0.9703 - val_cost: 3.6640\n",
            "Epoch 193/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0610 - auc: 0.9960 - accuracy: 0.9820 - cost: 2.2928 - val_loss: 0.1185 - val_auc: 0.9893 - val_accuracy: 0.9703 - val_cost: 3.6673\n",
            "Epoch 194/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0608 - auc: 0.9961 - accuracy: 0.9821 - cost: 2.2828 - val_loss: 0.1178 - val_auc: 0.9894 - val_accuracy: 0.9695 - val_cost: 3.8823\n",
            "Epoch 195/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0607 - auc: 0.9962 - accuracy: 0.9818 - cost: 2.3333 - val_loss: 0.1175 - val_auc: 0.9892 - val_accuracy: 0.9705 - val_cost: 3.6971\n",
            "Epoch 196/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0608 - auc: 0.9961 - accuracy: 0.9819 - cost: 2.3194 - val_loss: 0.1176 - val_auc: 0.9896 - val_accuracy: 0.9700 - val_cost: 3.7599\n",
            "Epoch 197/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0602 - auc: 0.9962 - accuracy: 0.9817 - cost: 2.3345 - val_loss: 0.1181 - val_auc: 0.9895 - val_accuracy: 0.9694 - val_cost: 3.7500\n",
            "Epoch 198/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0601 - auc: 0.9960 - accuracy: 0.9819 - cost: 2.3040 - val_loss: 0.1180 - val_auc: 0.9892 - val_accuracy: 0.9699 - val_cost: 3.7798\n",
            "Epoch 199/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0614 - auc: 0.9960 - accuracy: 0.9818 - cost: 2.3341 - val_loss: 0.1185 - val_auc: 0.9890 - val_accuracy: 0.9699 - val_cost: 3.8128\n",
            "Epoch 200/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0611 - auc: 0.9960 - accuracy: 0.9818 - cost: 2.3264 - val_loss: 0.1175 - val_auc: 0.9895 - val_accuracy: 0.9706 - val_cost: 3.7467\n",
            "Epoch 201/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0605 - auc: 0.9961 - accuracy: 0.9822 - cost: 2.2878 - val_loss: 0.1180 - val_auc: 0.9893 - val_accuracy: 0.9702 - val_cost: 3.6376\n",
            "Epoch 202/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0602 - auc: 0.9962 - accuracy: 0.9823 - cost: 2.2677 - val_loss: 0.1215 - val_auc: 0.9891 - val_accuracy: 0.9693 - val_cost: 3.7401\n",
            "Epoch 203/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0600 - auc: 0.9962 - accuracy: 0.9820 - cost: 2.3071 - val_loss: 0.1197 - val_auc: 0.9893 - val_accuracy: 0.9704 - val_cost: 3.6872\n",
            "Epoch 204/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0603 - auc: 0.9961 - accuracy: 0.9820 - cost: 2.3063 - val_loss: 0.1192 - val_auc: 0.9896 - val_accuracy: 0.9699 - val_cost: 3.7566\n",
            "Epoch 205/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0600 - auc: 0.9962 - accuracy: 0.9820 - cost: 2.2986 - val_loss: 0.1187 - val_auc: 0.9891 - val_accuracy: 0.9703 - val_cost: 3.7136\n",
            "Epoch 206/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0598 - auc: 0.9962 - accuracy: 0.9824 - cost: 2.2512 - val_loss: 0.1200 - val_auc: 0.9889 - val_accuracy: 0.9697 - val_cost: 3.7864\n",
            "Epoch 207/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0600 - auc: 0.9962 - accuracy: 0.9824 - cost: 2.2542 - val_loss: 0.1206 - val_auc: 0.9891 - val_accuracy: 0.9701 - val_cost: 3.7235\n",
            "Epoch 208/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0598 - auc: 0.9962 - accuracy: 0.9822 - cost: 2.2674 - val_loss: 0.1219 - val_auc: 0.9890 - val_accuracy: 0.9697 - val_cost: 3.8790\n",
            "Epoch 209/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0598 - auc: 0.9962 - accuracy: 0.9820 - cost: 2.3098 - val_loss: 0.1205 - val_auc: 0.9889 - val_accuracy: 0.9691 - val_cost: 3.8161\n",
            "Epoch 210/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0594 - auc: 0.9963 - accuracy: 0.9827 - cost: 2.2207 - val_loss: 0.1193 - val_auc: 0.9892 - val_accuracy: 0.9692 - val_cost: 3.7930\n",
            "Epoch 211/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0590 - auc: 0.9964 - accuracy: 0.9823 - cost: 2.2566 - val_loss: 0.1195 - val_auc: 0.9893 - val_accuracy: 0.9705 - val_cost: 3.7302\n",
            "Epoch 212/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0602 - auc: 0.9962 - accuracy: 0.9821 - cost: 2.3040 - val_loss: 0.1203 - val_auc: 0.9888 - val_accuracy: 0.9704 - val_cost: 3.6640\n",
            "Epoch 213/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0597 - auc: 0.9962 - accuracy: 0.9823 - cost: 2.2647 - val_loss: 0.1210 - val_auc: 0.9890 - val_accuracy: 0.9707 - val_cost: 3.5813\n",
            "Epoch 214/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0593 - auc: 0.9963 - accuracy: 0.9824 - cost: 2.2438 - val_loss: 0.1202 - val_auc: 0.9891 - val_accuracy: 0.9691 - val_cost: 3.7831\n",
            "Epoch 215/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0594 - auc: 0.9962 - accuracy: 0.9825 - cost: 2.2404 - val_loss: 0.1221 - val_auc: 0.9889 - val_accuracy: 0.9697 - val_cost: 3.8029\n",
            "Epoch 216/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0602 - auc: 0.9962 - accuracy: 0.9823 - cost: 2.2546 - val_loss: 0.1214 - val_auc: 0.9889 - val_accuracy: 0.9690 - val_cost: 3.8426\n",
            "Epoch 217/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0596 - auc: 0.9963 - accuracy: 0.9826 - cost: 2.2361 - val_loss: 0.1217 - val_auc: 0.9890 - val_accuracy: 0.9685 - val_cost: 3.9583\n",
            "Epoch 218/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0592 - auc: 0.9963 - accuracy: 0.9824 - cost: 2.2512 - val_loss: 0.1216 - val_auc: 0.9888 - val_accuracy: 0.9694 - val_cost: 3.8327\n",
            "Epoch 219/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0595 - auc: 0.9962 - accuracy: 0.9823 - cost: 2.2677 - val_loss: 0.1235 - val_auc: 0.9887 - val_accuracy: 0.9690 - val_cost: 3.7566\n",
            "Epoch 220/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0586 - auc: 0.9963 - accuracy: 0.9831 - cost: 2.1728 - val_loss: 0.1213 - val_auc: 0.9892 - val_accuracy: 0.9697 - val_cost: 3.7434\n",
            "Epoch 221/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0587 - auc: 0.9963 - accuracy: 0.9826 - cost: 2.2323 - val_loss: 0.1210 - val_auc: 0.9892 - val_accuracy: 0.9692 - val_cost: 3.8294\n",
            "Epoch 222/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0593 - auc: 0.9963 - accuracy: 0.9826 - cost: 2.2203 - val_loss: 0.1235 - val_auc: 0.9888 - val_accuracy: 0.9686 - val_cost: 3.8591\n",
            "Epoch 223/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0591 - auc: 0.9961 - accuracy: 0.9825 - cost: 2.2473 - val_loss: 0.1209 - val_auc: 0.9889 - val_accuracy: 0.9706 - val_cost: 3.7731\n",
            "Epoch 224/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0595 - auc: 0.9962 - accuracy: 0.9822 - cost: 2.2758 - val_loss: 0.1235 - val_auc: 0.9888 - val_accuracy: 0.9694 - val_cost: 3.7731\n",
            "Epoch 225/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0584 - auc: 0.9964 - accuracy: 0.9825 - cost: 2.2380 - val_loss: 0.1212 - val_auc: 0.9891 - val_accuracy: 0.9696 - val_cost: 3.7566\n",
            "Epoch 226/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0585 - auc: 0.9962 - accuracy: 0.9826 - cost: 2.2133 - val_loss: 0.1215 - val_auc: 0.9893 - val_accuracy: 0.9699 - val_cost: 3.7103\n",
            "Epoch 227/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0583 - auc: 0.9964 - accuracy: 0.9826 - cost: 2.2419 - val_loss: 0.1221 - val_auc: 0.9891 - val_accuracy: 0.9692 - val_cost: 3.7665\n",
            "Epoch 228/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0592 - auc: 0.9962 - accuracy: 0.9822 - cost: 2.2863 - val_loss: 0.1203 - val_auc: 0.9892 - val_accuracy: 0.9699 - val_cost: 3.7798\n",
            "Epoch 229/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0588 - auc: 0.9963 - accuracy: 0.9825 - cost: 2.2388 - val_loss: 0.1214 - val_auc: 0.9892 - val_accuracy: 0.9686 - val_cost: 3.9451\n",
            "Epoch 230/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0585 - auc: 0.9964 - accuracy: 0.9826 - cost: 2.2384 - val_loss: 0.1219 - val_auc: 0.9893 - val_accuracy: 0.9693 - val_cost: 3.7302\n",
            "Epoch 231/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0576 - auc: 0.9965 - accuracy: 0.9827 - cost: 2.2157 - val_loss: 0.1226 - val_auc: 0.9890 - val_accuracy: 0.9688 - val_cost: 3.8757\n",
            "Epoch 232/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0587 - auc: 0.9964 - accuracy: 0.9826 - cost: 2.2218 - val_loss: 0.1239 - val_auc: 0.9886 - val_accuracy: 0.9694 - val_cost: 3.7963\n",
            "Epoch 233/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0583 - auc: 0.9964 - accuracy: 0.9825 - cost: 2.2404 - val_loss: 0.1222 - val_auc: 0.9890 - val_accuracy: 0.9691 - val_cost: 3.7864\n",
            "Epoch 234/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0577 - auc: 0.9964 - accuracy: 0.9829 - cost: 2.1833 - val_loss: 0.1196 - val_auc: 0.9892 - val_accuracy: 0.9700 - val_cost: 3.7202\n",
            "Epoch 235/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0582 - auc: 0.9963 - accuracy: 0.9828 - cost: 2.1995 - val_loss: 0.1218 - val_auc: 0.9892 - val_accuracy: 0.9692 - val_cost: 3.8228\n",
            "Epoch 236/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0586 - auc: 0.9963 - accuracy: 0.9824 - cost: 2.2542 - val_loss: 0.1215 - val_auc: 0.9889 - val_accuracy: 0.9693 - val_cost: 3.7599\n",
            "Epoch 237/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0578 - auc: 0.9963 - accuracy: 0.9832 - cost: 2.1439 - val_loss: 0.1200 - val_auc: 0.9892 - val_accuracy: 0.9700 - val_cost: 3.6905\n",
            "Epoch 238/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0587 - auc: 0.9963 - accuracy: 0.9825 - cost: 2.2431 - val_loss: 0.1210 - val_auc: 0.9889 - val_accuracy: 0.9694 - val_cost: 3.7765\n",
            "Epoch 239/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0583 - auc: 0.9964 - accuracy: 0.9829 - cost: 2.1802 - val_loss: 0.1224 - val_auc: 0.9888 - val_accuracy: 0.9699 - val_cost: 3.7665\n",
            "Epoch 240/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0592 - auc: 0.9962 - accuracy: 0.9825 - cost: 2.2415 - val_loss: 0.1219 - val_auc: 0.9887 - val_accuracy: 0.9697 - val_cost: 3.8029\n",
            "Epoch 241/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0580 - auc: 0.9964 - accuracy: 0.9823 - cost: 2.2758 - val_loss: 0.1242 - val_auc: 0.9887 - val_accuracy: 0.9696 - val_cost: 3.7500\n",
            "Epoch 242/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0580 - auc: 0.9965 - accuracy: 0.9824 - cost: 2.2608 - val_loss: 0.1231 - val_auc: 0.9892 - val_accuracy: 0.9694 - val_cost: 3.7566\n",
            "Epoch 243/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0580 - auc: 0.9963 - accuracy: 0.9824 - cost: 2.2465 - val_loss: 0.1244 - val_auc: 0.9890 - val_accuracy: 0.9689 - val_cost: 3.7963\n",
            "Epoch 244/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0577 - auc: 0.9964 - accuracy: 0.9827 - cost: 2.2195 - val_loss: 0.1242 - val_auc: 0.9889 - val_accuracy: 0.9697 - val_cost: 3.7500\n",
            "Epoch 245/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0571 - auc: 0.9965 - accuracy: 0.9828 - cost: 2.2022 - val_loss: 0.1220 - val_auc: 0.9890 - val_accuracy: 0.9692 - val_cost: 3.9021\n",
            "Epoch 246/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0566 - auc: 0.9965 - accuracy: 0.9828 - cost: 2.1971 - val_loss: 0.1210 - val_auc: 0.9888 - val_accuracy: 0.9694 - val_cost: 3.7930\n",
            "Epoch 247/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0570 - auc: 0.9965 - accuracy: 0.9829 - cost: 2.1933 - val_loss: 0.1239 - val_auc: 0.9891 - val_accuracy: 0.9694 - val_cost: 3.7136\n",
            "Epoch 248/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0579 - auc: 0.9964 - accuracy: 0.9827 - cost: 2.2160 - val_loss: 0.1221 - val_auc: 0.9889 - val_accuracy: 0.9695 - val_cost: 3.7599\n",
            "Epoch 249/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0575 - auc: 0.9964 - accuracy: 0.9829 - cost: 2.1763 - val_loss: 0.1219 - val_auc: 0.9888 - val_accuracy: 0.9683 - val_cost: 3.9087\n",
            "Epoch 250/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0583 - auc: 0.9964 - accuracy: 0.9826 - cost: 2.2238 - val_loss: 0.1232 - val_auc: 0.9885 - val_accuracy: 0.9694 - val_cost: 3.8228\n",
            "Epoch 251/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0579 - auc: 0.9965 - accuracy: 0.9827 - cost: 2.2037 - val_loss: 0.1248 - val_auc: 0.9888 - val_accuracy: 0.9694 - val_cost: 3.7930\n",
            "Epoch 252/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0578 - auc: 0.9965 - accuracy: 0.9827 - cost: 2.2118 - val_loss: 0.1227 - val_auc: 0.9887 - val_accuracy: 0.9696 - val_cost: 3.8261\n",
            "Epoch 253/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0580 - auc: 0.9963 - accuracy: 0.9825 - cost: 2.2319 - val_loss: 0.1230 - val_auc: 0.9889 - val_accuracy: 0.9680 - val_cost: 3.9649\n",
            "Epoch 254/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0582 - auc: 0.9964 - accuracy: 0.9826 - cost: 2.2257 - val_loss: 0.1219 - val_auc: 0.9889 - val_accuracy: 0.9699 - val_cost: 3.7533\n",
            "Epoch 255/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0580 - auc: 0.9964 - accuracy: 0.9823 - cost: 2.2589 - val_loss: 0.1250 - val_auc: 0.9887 - val_accuracy: 0.9692 - val_cost: 3.7864\n",
            "Epoch 256/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0568 - auc: 0.9966 - accuracy: 0.9828 - cost: 2.2025 - val_loss: 0.1241 - val_auc: 0.9887 - val_accuracy: 0.9694 - val_cost: 3.8790\n",
            "Epoch 257/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0579 - auc: 0.9964 - accuracy: 0.9828 - cost: 2.2052 - val_loss: 0.1265 - val_auc: 0.9886 - val_accuracy: 0.9699 - val_cost: 3.6872\n",
            "Epoch 258/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0571 - auc: 0.9964 - accuracy: 0.9831 - cost: 2.1609 - val_loss: 0.1243 - val_auc: 0.9886 - val_accuracy: 0.9699 - val_cost: 3.6739\n",
            "Epoch 259/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0576 - auc: 0.9965 - accuracy: 0.9828 - cost: 2.2010 - val_loss: 0.1213 - val_auc: 0.9890 - val_accuracy: 0.9703 - val_cost: 3.7169\n",
            "Epoch 260/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0565 - auc: 0.9965 - accuracy: 0.9832 - cost: 2.1562 - val_loss: 0.1246 - val_auc: 0.9884 - val_accuracy: 0.9695 - val_cost: 3.8757\n",
            "Epoch 261/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0577 - auc: 0.9964 - accuracy: 0.9827 - cost: 2.2253 - val_loss: 0.1240 - val_auc: 0.9885 - val_accuracy: 0.9687 - val_cost: 3.9649\n",
            "Epoch 262/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0573 - auc: 0.9964 - accuracy: 0.9830 - cost: 2.1790 - val_loss: 0.1254 - val_auc: 0.9886 - val_accuracy: 0.9697 - val_cost: 3.7996\n",
            "Epoch 263/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0571 - auc: 0.9964 - accuracy: 0.9830 - cost: 2.1628 - val_loss: 0.1243 - val_auc: 0.9886 - val_accuracy: 0.9696 - val_cost: 3.7302\n",
            "Epoch 264/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0573 - auc: 0.9965 - accuracy: 0.9827 - cost: 2.2076 - val_loss: 0.1255 - val_auc: 0.9888 - val_accuracy: 0.9695 - val_cost: 3.7500\n",
            "Epoch 265/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0560 - auc: 0.9965 - accuracy: 0.9835 - cost: 2.1046 - val_loss: 0.1266 - val_auc: 0.9886 - val_accuracy: 0.9687 - val_cost: 3.8790\n",
            "Epoch 266/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0563 - auc: 0.9966 - accuracy: 0.9831 - cost: 2.1520 - val_loss: 0.1232 - val_auc: 0.9889 - val_accuracy: 0.9698 - val_cost: 3.7599\n",
            "Epoch 267/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0569 - auc: 0.9965 - accuracy: 0.9831 - cost: 2.1655 - val_loss: 0.1252 - val_auc: 0.9889 - val_accuracy: 0.9694 - val_cost: 3.7996\n",
            "Epoch 268/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0566 - auc: 0.9965 - accuracy: 0.9827 - cost: 2.2114 - val_loss: 0.1248 - val_auc: 0.9889 - val_accuracy: 0.9693 - val_cost: 3.7996\n",
            "Epoch 269/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0566 - auc: 0.9965 - accuracy: 0.9830 - cost: 2.1798 - val_loss: 0.1242 - val_auc: 0.9886 - val_accuracy: 0.9697 - val_cost: 3.7500\n",
            "Epoch 270/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0564 - auc: 0.9965 - accuracy: 0.9831 - cost: 2.1651 - val_loss: 0.1244 - val_auc: 0.9889 - val_accuracy: 0.9690 - val_cost: 3.8492\n",
            "Epoch 271/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0570 - auc: 0.9966 - accuracy: 0.9827 - cost: 2.2052 - val_loss: 0.1235 - val_auc: 0.9885 - val_accuracy: 0.9706 - val_cost: 3.7004\n",
            "Epoch 272/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0566 - auc: 0.9965 - accuracy: 0.9828 - cost: 2.1941 - val_loss: 0.1236 - val_auc: 0.9887 - val_accuracy: 0.9695 - val_cost: 3.8128\n",
            "Epoch 273/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0564 - auc: 0.9966 - accuracy: 0.9828 - cost: 2.2014 - val_loss: 0.1250 - val_auc: 0.9888 - val_accuracy: 0.9694 - val_cost: 3.8558\n",
            "Epoch 274/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0562 - auc: 0.9966 - accuracy: 0.9834 - cost: 2.1277 - val_loss: 0.1259 - val_auc: 0.9886 - val_accuracy: 0.9697 - val_cost: 3.6905\n",
            "Epoch 275/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0567 - auc: 0.9966 - accuracy: 0.9831 - cost: 2.1613 - val_loss: 0.1245 - val_auc: 0.9888 - val_accuracy: 0.9685 - val_cost: 3.8823\n",
            "Epoch 276/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0562 - auc: 0.9966 - accuracy: 0.9832 - cost: 2.1532 - val_loss: 0.1234 - val_auc: 0.9889 - val_accuracy: 0.9704 - val_cost: 3.7169\n",
            "Epoch 277/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0558 - auc: 0.9965 - accuracy: 0.9833 - cost: 2.1339 - val_loss: 0.1231 - val_auc: 0.9890 - val_accuracy: 0.9708 - val_cost: 3.6839\n",
            "Epoch 278/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0556 - auc: 0.9967 - accuracy: 0.9832 - cost: 2.1508 - val_loss: 0.1236 - val_auc: 0.9887 - val_accuracy: 0.9699 - val_cost: 3.7665\n",
            "Epoch 279/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0563 - auc: 0.9966 - accuracy: 0.9830 - cost: 2.1790 - val_loss: 0.1234 - val_auc: 0.9886 - val_accuracy: 0.9691 - val_cost: 3.8029\n",
            "Epoch 280/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0564 - auc: 0.9966 - accuracy: 0.9831 - cost: 2.1725 - val_loss: 0.1263 - val_auc: 0.9883 - val_accuracy: 0.9692 - val_cost: 3.7897\n",
            "Epoch 281/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0563 - auc: 0.9966 - accuracy: 0.9830 - cost: 2.1678 - val_loss: 0.1228 - val_auc: 0.9886 - val_accuracy: 0.9690 - val_cost: 3.8823\n",
            "Epoch 282/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0563 - auc: 0.9966 - accuracy: 0.9833 - cost: 2.1281 - val_loss: 0.1250 - val_auc: 0.9886 - val_accuracy: 0.9692 - val_cost: 3.8128\n",
            "Epoch 283/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0563 - auc: 0.9966 - accuracy: 0.9830 - cost: 2.1759 - val_loss: 0.1249 - val_auc: 0.9883 - val_accuracy: 0.9688 - val_cost: 3.8757\n",
            "Epoch 284/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0573 - auc: 0.9966 - accuracy: 0.9826 - cost: 2.2226 - val_loss: 0.1273 - val_auc: 0.9885 - val_accuracy: 0.9692 - val_cost: 3.7632\n",
            "Epoch 285/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0565 - auc: 0.9966 - accuracy: 0.9829 - cost: 2.1887 - val_loss: 0.1252 - val_auc: 0.9886 - val_accuracy: 0.9692 - val_cost: 3.8889\n",
            "Epoch 286/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0563 - auc: 0.9966 - accuracy: 0.9832 - cost: 2.1628 - val_loss: 0.1250 - val_auc: 0.9885 - val_accuracy: 0.9692 - val_cost: 3.7765\n",
            "Epoch 287/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0555 - auc: 0.9966 - accuracy: 0.9833 - cost: 2.1397 - val_loss: 0.1245 - val_auc: 0.9889 - val_accuracy: 0.9695 - val_cost: 3.7533\n",
            "Epoch 288/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0559 - auc: 0.9966 - accuracy: 0.9833 - cost: 2.1358 - val_loss: 0.1241 - val_auc: 0.9888 - val_accuracy: 0.9694 - val_cost: 3.7599\n",
            "Epoch 289/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0564 - auc: 0.9966 - accuracy: 0.9833 - cost: 2.1335 - val_loss: 0.1264 - val_auc: 0.9890 - val_accuracy: 0.9697 - val_cost: 3.7698\n",
            "Epoch 290/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0558 - auc: 0.9966 - accuracy: 0.9832 - cost: 2.1478 - val_loss: 0.1240 - val_auc: 0.9886 - val_accuracy: 0.9704 - val_cost: 3.7269\n",
            "Epoch 291/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0552 - auc: 0.9967 - accuracy: 0.9834 - cost: 2.1262 - val_loss: 0.1272 - val_auc: 0.9881 - val_accuracy: 0.9703 - val_cost: 3.7004\n",
            "Epoch 292/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0559 - auc: 0.9967 - accuracy: 0.9829 - cost: 2.1840 - val_loss: 0.1253 - val_auc: 0.9884 - val_accuracy: 0.9697 - val_cost: 3.8327\n",
            "Epoch 293/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0568 - auc: 0.9965 - accuracy: 0.9827 - cost: 2.2072 - val_loss: 0.1240 - val_auc: 0.9889 - val_accuracy: 0.9685 - val_cost: 3.9683\n",
            "Epoch 294/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0557 - auc: 0.9966 - accuracy: 0.9832 - cost: 2.1481 - val_loss: 0.1240 - val_auc: 0.9889 - val_accuracy: 0.9699 - val_cost: 3.7698\n",
            "Epoch 295/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0559 - auc: 0.9966 - accuracy: 0.9835 - cost: 2.1088 - val_loss: 0.1276 - val_auc: 0.9883 - val_accuracy: 0.9699 - val_cost: 3.7004\n",
            "Epoch 296/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0557 - auc: 0.9967 - accuracy: 0.9832 - cost: 2.1470 - val_loss: 0.1274 - val_auc: 0.9887 - val_accuracy: 0.9694 - val_cost: 3.7930\n",
            "Epoch 297/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0561 - auc: 0.9966 - accuracy: 0.9835 - cost: 2.1169 - val_loss: 0.1260 - val_auc: 0.9884 - val_accuracy: 0.9688 - val_cost: 3.8360\n",
            "Epoch 298/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0555 - auc: 0.9968 - accuracy: 0.9836 - cost: 2.1046 - val_loss: 0.1259 - val_auc: 0.9888 - val_accuracy: 0.9684 - val_cost: 3.9352\n",
            "Epoch 299/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0555 - auc: 0.9967 - accuracy: 0.9833 - cost: 2.1323 - val_loss: 0.1259 - val_auc: 0.9887 - val_accuracy: 0.9697 - val_cost: 3.8095\n",
            "Epoch 300/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0560 - auc: 0.9966 - accuracy: 0.9831 - cost: 2.1690 - val_loss: 0.1258 - val_auc: 0.9884 - val_accuracy: 0.9696 - val_cost: 3.8029\n",
            "Epoch 301/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0559 - auc: 0.9965 - accuracy: 0.9834 - cost: 2.1242 - val_loss: 0.1270 - val_auc: 0.9885 - val_accuracy: 0.9690 - val_cost: 3.7467\n",
            "Epoch 302/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0553 - auc: 0.9967 - accuracy: 0.9838 - cost: 2.0764 - val_loss: 0.1261 - val_auc: 0.9884 - val_accuracy: 0.9688 - val_cost: 3.8525\n",
            "Epoch 303/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0557 - auc: 0.9967 - accuracy: 0.9831 - cost: 2.1570 - val_loss: 0.1299 - val_auc: 0.9887 - val_accuracy: 0.9696 - val_cost: 3.7467\n",
            "Epoch 304/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0552 - auc: 0.9967 - accuracy: 0.9834 - cost: 2.1246 - val_loss: 0.1276 - val_auc: 0.9883 - val_accuracy: 0.9695 - val_cost: 3.7731\n",
            "Epoch 305/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0553 - auc: 0.9967 - accuracy: 0.9833 - cost: 2.1431 - val_loss: 0.1286 - val_auc: 0.9884 - val_accuracy: 0.9680 - val_cost: 3.8856\n",
            "Epoch 306/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0551 - auc: 0.9967 - accuracy: 0.9833 - cost: 2.1489 - val_loss: 0.1271 - val_auc: 0.9887 - val_accuracy: 0.9689 - val_cost: 3.8029\n",
            "Epoch 307/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0549 - auc: 0.9966 - accuracy: 0.9837 - cost: 2.0930 - val_loss: 0.1257 - val_auc: 0.9888 - val_accuracy: 0.9678 - val_cost: 4.0046\n",
            "Epoch 308/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0551 - auc: 0.9967 - accuracy: 0.9836 - cost: 2.1092 - val_loss: 0.1297 - val_auc: 0.9883 - val_accuracy: 0.9685 - val_cost: 3.8360\n",
            "Epoch 309/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0550 - auc: 0.9968 - accuracy: 0.9836 - cost: 2.1038 - val_loss: 0.1252 - val_auc: 0.9886 - val_accuracy: 0.9699 - val_cost: 3.7599\n",
            "Epoch 310/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0550 - auc: 0.9968 - accuracy: 0.9832 - cost: 2.1516 - val_loss: 0.1271 - val_auc: 0.9886 - val_accuracy: 0.9687 - val_cost: 3.8657\n",
            "Epoch 311/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0554 - auc: 0.9966 - accuracy: 0.9834 - cost: 2.1300 - val_loss: 0.1265 - val_auc: 0.9886 - val_accuracy: 0.9694 - val_cost: 3.7467\n",
            "Epoch 312/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0538 - auc: 0.9969 - accuracy: 0.9835 - cost: 2.1015 - val_loss: 0.1258 - val_auc: 0.9884 - val_accuracy: 0.9683 - val_cost: 3.9286\n",
            "Epoch 313/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0559 - auc: 0.9966 - accuracy: 0.9834 - cost: 2.1346 - val_loss: 0.1278 - val_auc: 0.9883 - val_accuracy: 0.9697 - val_cost: 3.8459\n",
            "Epoch 314/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0550 - auc: 0.9967 - accuracy: 0.9839 - cost: 2.0718 - val_loss: 0.1263 - val_auc: 0.9886 - val_accuracy: 0.9692 - val_cost: 3.8459\n",
            "Epoch 315/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0551 - auc: 0.9967 - accuracy: 0.9829 - cost: 2.2014 - val_loss: 0.1270 - val_auc: 0.9886 - val_accuracy: 0.9703 - val_cost: 3.7798\n",
            "Epoch 316/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0550 - auc: 0.9969 - accuracy: 0.9832 - cost: 2.1489 - val_loss: 0.1268 - val_auc: 0.9888 - val_accuracy: 0.9693 - val_cost: 3.8492\n",
            "Epoch 317/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0549 - auc: 0.9968 - accuracy: 0.9836 - cost: 2.1049 - val_loss: 0.1304 - val_auc: 0.9883 - val_accuracy: 0.9684 - val_cost: 4.0245\n",
            "Epoch 318/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0541 - auc: 0.9968 - accuracy: 0.9841 - cost: 2.0525 - val_loss: 0.1275 - val_auc: 0.9885 - val_accuracy: 0.9686 - val_cost: 3.9484\n",
            "Epoch 319/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0542 - auc: 0.9968 - accuracy: 0.9839 - cost: 2.0602 - val_loss: 0.1253 - val_auc: 0.9888 - val_accuracy: 0.9696 - val_cost: 3.8128\n",
            "Epoch 320/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0545 - auc: 0.9968 - accuracy: 0.9834 - cost: 2.1219 - val_loss: 0.1273 - val_auc: 0.9884 - val_accuracy: 0.9690 - val_cost: 3.8558\n",
            "Epoch 321/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0554 - auc: 0.9967 - accuracy: 0.9832 - cost: 2.1516 - val_loss: 0.1259 - val_auc: 0.9888 - val_accuracy: 0.9688 - val_cost: 3.8690\n",
            "Epoch 322/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0550 - auc: 0.9966 - accuracy: 0.9835 - cost: 2.1088 - val_loss: 0.1310 - val_auc: 0.9880 - val_accuracy: 0.9683 - val_cost: 3.9616\n",
            "Epoch 323/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0544 - auc: 0.9968 - accuracy: 0.9839 - cost: 2.0621 - val_loss: 0.1290 - val_auc: 0.9884 - val_accuracy: 0.9698 - val_cost: 3.8062\n",
            "Epoch 324/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0554 - auc: 0.9967 - accuracy: 0.9832 - cost: 2.1470 - val_loss: 0.1255 - val_auc: 0.9886 - val_accuracy: 0.9699 - val_cost: 3.7765\n",
            "Epoch 325/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0542 - auc: 0.9968 - accuracy: 0.9838 - cost: 2.0764 - val_loss: 0.1279 - val_auc: 0.9883 - val_accuracy: 0.9683 - val_cost: 4.0013\n",
            "Epoch 326/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0547 - auc: 0.9969 - accuracy: 0.9834 - cost: 2.1285 - val_loss: 0.1256 - val_auc: 0.9882 - val_accuracy: 0.9698 - val_cost: 3.8690\n",
            "Epoch 327/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0540 - auc: 0.9969 - accuracy: 0.9834 - cost: 2.1242 - val_loss: 0.1266 - val_auc: 0.9886 - val_accuracy: 0.9699 - val_cost: 3.7401\n",
            "Epoch 328/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0550 - auc: 0.9967 - accuracy: 0.9838 - cost: 2.0853 - val_loss: 0.1299 - val_auc: 0.9883 - val_accuracy: 0.9677 - val_cost: 3.9881\n",
            "Epoch 329/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0553 - auc: 0.9968 - accuracy: 0.9828 - cost: 2.2022 - val_loss: 0.1291 - val_auc: 0.9884 - val_accuracy: 0.9688 - val_cost: 3.8128\n",
            "Epoch 330/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0540 - auc: 0.9969 - accuracy: 0.9840 - cost: 2.0517 - val_loss: 0.1280 - val_auc: 0.9885 - val_accuracy: 0.9700 - val_cost: 3.7335\n",
            "Epoch 331/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0541 - auc: 0.9968 - accuracy: 0.9836 - cost: 2.0856 - val_loss: 0.1280 - val_auc: 0.9885 - val_accuracy: 0.9683 - val_cost: 4.0079\n",
            "Epoch 332/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0552 - auc: 0.9966 - accuracy: 0.9837 - cost: 2.0899 - val_loss: 0.1257 - val_auc: 0.9885 - val_accuracy: 0.9698 - val_cost: 3.7897\n",
            "Epoch 333/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0539 - auc: 0.9968 - accuracy: 0.9837 - cost: 2.0826 - val_loss: 0.1272 - val_auc: 0.9887 - val_accuracy: 0.9690 - val_cost: 3.8492\n",
            "Epoch 334/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0548 - auc: 0.9968 - accuracy: 0.9833 - cost: 2.1377 - val_loss: 0.1252 - val_auc: 0.9889 - val_accuracy: 0.9696 - val_cost: 3.7864\n",
            "Epoch 335/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0545 - auc: 0.9967 - accuracy: 0.9837 - cost: 2.0910 - val_loss: 0.1262 - val_auc: 0.9889 - val_accuracy: 0.9690 - val_cost: 3.8128\n",
            "Epoch 336/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0539 - auc: 0.9968 - accuracy: 0.9836 - cost: 2.0918 - val_loss: 0.1282 - val_auc: 0.9885 - val_accuracy: 0.9684 - val_cost: 3.8690\n",
            "Epoch 337/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0551 - auc: 0.9968 - accuracy: 0.9829 - cost: 2.1979 - val_loss: 0.1306 - val_auc: 0.9878 - val_accuracy: 0.9682 - val_cost: 3.9716\n",
            "Epoch 338/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0542 - auc: 0.9968 - accuracy: 0.9838 - cost: 2.0775 - val_loss: 0.1275 - val_auc: 0.9884 - val_accuracy: 0.9700 - val_cost: 3.8062\n",
            "Epoch 339/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0548 - auc: 0.9968 - accuracy: 0.9836 - cost: 2.1092 - val_loss: 0.1289 - val_auc: 0.9882 - val_accuracy: 0.9691 - val_cost: 3.8525\n",
            "Epoch 340/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0541 - auc: 0.9968 - accuracy: 0.9835 - cost: 2.1103 - val_loss: 0.1286 - val_auc: 0.9883 - val_accuracy: 0.9700 - val_cost: 3.7269\n",
            "Epoch 341/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0547 - auc: 0.9967 - accuracy: 0.9835 - cost: 2.1088 - val_loss: 0.1277 - val_auc: 0.9886 - val_accuracy: 0.9690 - val_cost: 3.8955\n",
            "Epoch 342/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0543 - auc: 0.9967 - accuracy: 0.9835 - cost: 2.1123 - val_loss: 0.1290 - val_auc: 0.9885 - val_accuracy: 0.9694 - val_cost: 3.7798\n",
            "Epoch 343/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0540 - auc: 0.9968 - accuracy: 0.9837 - cost: 2.0768 - val_loss: 0.1302 - val_auc: 0.9881 - val_accuracy: 0.9677 - val_cost: 3.9980\n",
            "Epoch 344/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0548 - auc: 0.9968 - accuracy: 0.9835 - cost: 2.1046 - val_loss: 0.1266 - val_auc: 0.9888 - val_accuracy: 0.9696 - val_cost: 3.7599\n",
            "Epoch 345/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0538 - auc: 0.9969 - accuracy: 0.9837 - cost: 2.0918 - val_loss: 0.1279 - val_auc: 0.9883 - val_accuracy: 0.9700 - val_cost: 3.7500\n",
            "Epoch 346/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0536 - auc: 0.9968 - accuracy: 0.9842 - cost: 2.0262 - val_loss: 0.1290 - val_auc: 0.9882 - val_accuracy: 0.9701 - val_cost: 3.7467\n",
            "Epoch 347/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0537 - auc: 0.9969 - accuracy: 0.9837 - cost: 2.0907 - val_loss: 0.1282 - val_auc: 0.9886 - val_accuracy: 0.9700 - val_cost: 3.7269\n",
            "Epoch 348/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0536 - auc: 0.9968 - accuracy: 0.9840 - cost: 2.0424 - val_loss: 0.1284 - val_auc: 0.9885 - val_accuracy: 0.9702 - val_cost: 3.6971\n",
            "Epoch 349/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0535 - auc: 0.9969 - accuracy: 0.9841 - cost: 2.0351 - val_loss: 0.1293 - val_auc: 0.9881 - val_accuracy: 0.9692 - val_cost: 3.8459\n",
            "Epoch 350/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0538 - auc: 0.9969 - accuracy: 0.9837 - cost: 2.0918 - val_loss: 0.1289 - val_auc: 0.9882 - val_accuracy: 0.9684 - val_cost: 4.0079\n",
            "Epoch 351/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0546 - auc: 0.9968 - accuracy: 0.9834 - cost: 2.1200 - val_loss: 0.1278 - val_auc: 0.9882 - val_accuracy: 0.9695 - val_cost: 3.8426\n",
            "Epoch 352/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0540 - auc: 0.9969 - accuracy: 0.9834 - cost: 2.1281 - val_loss: 0.1295 - val_auc: 0.9885 - val_accuracy: 0.9688 - val_cost: 3.8823\n",
            "Epoch 353/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0537 - auc: 0.9970 - accuracy: 0.9836 - cost: 2.0934 - val_loss: 0.1288 - val_auc: 0.9887 - val_accuracy: 0.9683 - val_cost: 3.9253\n",
            "Epoch 354/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0541 - auc: 0.9968 - accuracy: 0.9834 - cost: 2.1138 - val_loss: 0.1294 - val_auc: 0.9883 - val_accuracy: 0.9690 - val_cost: 3.7963\n",
            "Epoch 355/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0539 - auc: 0.9968 - accuracy: 0.9836 - cost: 2.0872 - val_loss: 0.1302 - val_auc: 0.9885 - val_accuracy: 0.9694 - val_cost: 3.8128\n",
            "Epoch 356/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0540 - auc: 0.9969 - accuracy: 0.9834 - cost: 2.1335 - val_loss: 0.1302 - val_auc: 0.9886 - val_accuracy: 0.9692 - val_cost: 3.8360\n",
            "Epoch 357/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0538 - auc: 0.9968 - accuracy: 0.9836 - cost: 2.0907 - val_loss: 0.1313 - val_auc: 0.9885 - val_accuracy: 0.9690 - val_cost: 3.7897\n",
            "Epoch 358/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0534 - auc: 0.9968 - accuracy: 0.9838 - cost: 2.0694 - val_loss: 0.1316 - val_auc: 0.9881 - val_accuracy: 0.9692 - val_cost: 3.8261\n",
            "Epoch 359/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0533 - auc: 0.9970 - accuracy: 0.9838 - cost: 2.0745 - val_loss: 0.1334 - val_auc: 0.9880 - val_accuracy: 0.9680 - val_cost: 3.9120\n",
            "Epoch 360/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0539 - auc: 0.9969 - accuracy: 0.9837 - cost: 2.0864 - val_loss: 0.1304 - val_auc: 0.9883 - val_accuracy: 0.9695 - val_cost: 3.7169\n",
            "Epoch 361/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0531 - auc: 0.9970 - accuracy: 0.9838 - cost: 2.0806 - val_loss: 0.1315 - val_auc: 0.9881 - val_accuracy: 0.9692 - val_cost: 3.7996\n",
            "Epoch 362/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0529 - auc: 0.9969 - accuracy: 0.9841 - cost: 2.0428 - val_loss: 0.1307 - val_auc: 0.9884 - val_accuracy: 0.9690 - val_cost: 3.8294\n",
            "Epoch 363/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0530 - auc: 0.9969 - accuracy: 0.9841 - cost: 2.0313 - val_loss: 0.1302 - val_auc: 0.9885 - val_accuracy: 0.9692 - val_cost: 3.7996\n",
            "Epoch 364/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0527 - auc: 0.9970 - accuracy: 0.9841 - cost: 2.0424 - val_loss: 0.1308 - val_auc: 0.9886 - val_accuracy: 0.9688 - val_cost: 3.8492\n",
            "Epoch 365/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0536 - auc: 0.9969 - accuracy: 0.9836 - cost: 2.1022 - val_loss: 0.1318 - val_auc: 0.9885 - val_accuracy: 0.9688 - val_cost: 3.8525\n",
            "Epoch 366/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0531 - auc: 0.9969 - accuracy: 0.9838 - cost: 2.0671 - val_loss: 0.1306 - val_auc: 0.9884 - val_accuracy: 0.9688 - val_cost: 3.8790\n",
            "Epoch 367/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0532 - auc: 0.9970 - accuracy: 0.9839 - cost: 2.0532 - val_loss: 0.1320 - val_auc: 0.9879 - val_accuracy: 0.9682 - val_cost: 4.0112\n",
            "Epoch 368/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0529 - auc: 0.9969 - accuracy: 0.9839 - cost: 2.0640 - val_loss: 0.1307 - val_auc: 0.9879 - val_accuracy: 0.9695 - val_cost: 3.8591\n",
            "Epoch 369/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0534 - auc: 0.9969 - accuracy: 0.9841 - cost: 2.0405 - val_loss: 0.1345 - val_auc: 0.9882 - val_accuracy: 0.9680 - val_cost: 3.9187\n",
            "Epoch 370/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0536 - auc: 0.9969 - accuracy: 0.9839 - cost: 2.0625 - val_loss: 0.1307 - val_auc: 0.9882 - val_accuracy: 0.9688 - val_cost: 3.8988\n",
            "Epoch 371/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0530 - auc: 0.9969 - accuracy: 0.9839 - cost: 2.0610 - val_loss: 0.1301 - val_auc: 0.9888 - val_accuracy: 0.9694 - val_cost: 3.8029\n",
            "Epoch 372/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0535 - auc: 0.9969 - accuracy: 0.9839 - cost: 2.0656 - val_loss: 0.1305 - val_auc: 0.9882 - val_accuracy: 0.9694 - val_cost: 3.8459\n",
            "Epoch 373/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0533 - auc: 0.9969 - accuracy: 0.9841 - cost: 2.0467 - val_loss: 0.1290 - val_auc: 0.9886 - val_accuracy: 0.9691 - val_cost: 3.8558\n",
            "Epoch 374/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0527 - auc: 0.9970 - accuracy: 0.9839 - cost: 2.0710 - val_loss: 0.1290 - val_auc: 0.9887 - val_accuracy: 0.9692 - val_cost: 3.8459\n",
            "Epoch 375/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0531 - auc: 0.9970 - accuracy: 0.9838 - cost: 2.0768 - val_loss: 0.1317 - val_auc: 0.9883 - val_accuracy: 0.9691 - val_cost: 3.8889\n",
            "Epoch 376/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0530 - auc: 0.9970 - accuracy: 0.9838 - cost: 2.0880 - val_loss: 0.1306 - val_auc: 0.9881 - val_accuracy: 0.9681 - val_cost: 3.9716\n",
            "Epoch 377/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0539 - auc: 0.9969 - accuracy: 0.9833 - cost: 2.1343 - val_loss: 0.1316 - val_auc: 0.9885 - val_accuracy: 0.9684 - val_cost: 3.9385\n",
            "Epoch 378/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0538 - auc: 0.9969 - accuracy: 0.9836 - cost: 2.1057 - val_loss: 0.1308 - val_auc: 0.9886 - val_accuracy: 0.9697 - val_cost: 3.7963\n",
            "Epoch 379/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0538 - auc: 0.9968 - accuracy: 0.9836 - cost: 2.1019 - val_loss: 0.1332 - val_auc: 0.9888 - val_accuracy: 0.9690 - val_cost: 3.8393\n",
            "Epoch 380/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0533 - auc: 0.9968 - accuracy: 0.9841 - cost: 2.0355 - val_loss: 0.1301 - val_auc: 0.9884 - val_accuracy: 0.9686 - val_cost: 3.9782\n",
            "Epoch 381/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0525 - auc: 0.9969 - accuracy: 0.9844 - cost: 2.0000 - val_loss: 0.1310 - val_auc: 0.9885 - val_accuracy: 0.9693 - val_cost: 3.7665\n",
            "Epoch 382/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0531 - auc: 0.9969 - accuracy: 0.9836 - cost: 2.0937 - val_loss: 0.1308 - val_auc: 0.9885 - val_accuracy: 0.9692 - val_cost: 3.9054\n",
            "Epoch 383/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0532 - auc: 0.9970 - accuracy: 0.9834 - cost: 2.1250 - val_loss: 0.1321 - val_auc: 0.9882 - val_accuracy: 0.9701 - val_cost: 3.6640\n",
            "Epoch 384/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0526 - auc: 0.9970 - accuracy: 0.9839 - cost: 2.0640 - val_loss: 0.1316 - val_auc: 0.9880 - val_accuracy: 0.9688 - val_cost: 3.9087\n",
            "Epoch 385/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0518 - auc: 0.9970 - accuracy: 0.9841 - cost: 2.0351 - val_loss: 0.1331 - val_auc: 0.9880 - val_accuracy: 0.9690 - val_cost: 3.9749\n",
            "Epoch 386/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0527 - auc: 0.9970 - accuracy: 0.9836 - cost: 2.1049 - val_loss: 0.1321 - val_auc: 0.9882 - val_accuracy: 0.9691 - val_cost: 3.9021\n",
            "Epoch 387/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0523 - auc: 0.9971 - accuracy: 0.9839 - cost: 2.0621 - val_loss: 0.1336 - val_auc: 0.9884 - val_accuracy: 0.9683 - val_cost: 3.8823\n",
            "Epoch 388/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0529 - auc: 0.9969 - accuracy: 0.9840 - cost: 2.0525 - val_loss: 0.1336 - val_auc: 0.9876 - val_accuracy: 0.9695 - val_cost: 3.9187\n",
            "Epoch 389/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0539 - auc: 0.9969 - accuracy: 0.9835 - cost: 2.1088 - val_loss: 0.1315 - val_auc: 0.9880 - val_accuracy: 0.9700 - val_cost: 3.8228\n",
            "Epoch 390/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0533 - auc: 0.9969 - accuracy: 0.9841 - cost: 2.0532 - val_loss: 0.1327 - val_auc: 0.9884 - val_accuracy: 0.9696 - val_cost: 3.8161\n",
            "Epoch 391/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0538 - auc: 0.9969 - accuracy: 0.9837 - cost: 2.0833 - val_loss: 0.1307 - val_auc: 0.9886 - val_accuracy: 0.9685 - val_cost: 3.9319\n",
            "Epoch 392/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0522 - auc: 0.9970 - accuracy: 0.9844 - cost: 2.0069 - val_loss: 0.1332 - val_auc: 0.9885 - val_accuracy: 0.9685 - val_cost: 3.9087\n",
            "Epoch 393/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0525 - auc: 0.9970 - accuracy: 0.9844 - cost: 1.9988 - val_loss: 0.1319 - val_auc: 0.9880 - val_accuracy: 0.9693 - val_cost: 3.8724\n",
            "Epoch 394/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0521 - auc: 0.9970 - accuracy: 0.9840 - cost: 2.0509 - val_loss: 0.1337 - val_auc: 0.9880 - val_accuracy: 0.9684 - val_cost: 3.9451\n",
            "Epoch 395/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0531 - auc: 0.9971 - accuracy: 0.9839 - cost: 2.0633 - val_loss: 0.1324 - val_auc: 0.9883 - val_accuracy: 0.9688 - val_cost: 3.9120\n",
            "Epoch 396/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0523 - auc: 0.9970 - accuracy: 0.9843 - cost: 2.0035 - val_loss: 0.1315 - val_auc: 0.9885 - val_accuracy: 0.9689 - val_cost: 3.8856\n",
            "Epoch 397/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0529 - auc: 0.9969 - accuracy: 0.9840 - cost: 2.0525 - val_loss: 0.1317 - val_auc: 0.9884 - val_accuracy: 0.9688 - val_cost: 3.8856\n",
            "Epoch 398/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0520 - auc: 0.9971 - accuracy: 0.9844 - cost: 2.0012 - val_loss: 0.1293 - val_auc: 0.9885 - val_accuracy: 0.9694 - val_cost: 3.8558\n",
            "Epoch 399/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0523 - auc: 0.9972 - accuracy: 0.9840 - cost: 2.0513 - val_loss: 0.1335 - val_auc: 0.9883 - val_accuracy: 0.9699 - val_cost: 3.7566\n",
            "Epoch 400/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0529 - auc: 0.9969 - accuracy: 0.9840 - cost: 2.0390 - val_loss: 0.1370 - val_auc: 0.9882 - val_accuracy: 0.9678 - val_cost: 3.9716\n",
            "Epoch 401/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0528 - auc: 0.9969 - accuracy: 0.9842 - cost: 2.0293 - val_loss: 0.1335 - val_auc: 0.9884 - val_accuracy: 0.9689 - val_cost: 3.9253\n",
            "Epoch 402/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0523 - auc: 0.9970 - accuracy: 0.9841 - cost: 2.0208 - val_loss: 0.1307 - val_auc: 0.9884 - val_accuracy: 0.9688 - val_cost: 3.9914\n",
            "Epoch 403/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0526 - auc: 0.9970 - accuracy: 0.9842 - cost: 2.0270 - val_loss: 0.1337 - val_auc: 0.9878 - val_accuracy: 0.9694 - val_cost: 3.8294\n",
            "Epoch 404/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0518 - auc: 0.9970 - accuracy: 0.9841 - cost: 2.0417 - val_loss: 0.1349 - val_auc: 0.9880 - val_accuracy: 0.9685 - val_cost: 3.8955\n",
            "Epoch 405/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0530 - auc: 0.9970 - accuracy: 0.9838 - cost: 2.0818 - val_loss: 0.1324 - val_auc: 0.9886 - val_accuracy: 0.9685 - val_cost: 3.8856\n",
            "Epoch 406/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0522 - auc: 0.9970 - accuracy: 0.9839 - cost: 2.0571 - val_loss: 0.1343 - val_auc: 0.9879 - val_accuracy: 0.9692 - val_cost: 3.8690\n",
            "Epoch 407/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0522 - auc: 0.9970 - accuracy: 0.9841 - cost: 2.0451 - val_loss: 0.1317 - val_auc: 0.9885 - val_accuracy: 0.9685 - val_cost: 3.9319\n",
            "Epoch 408/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0528 - auc: 0.9971 - accuracy: 0.9834 - cost: 2.1308 - val_loss: 0.1331 - val_auc: 0.9883 - val_accuracy: 0.9681 - val_cost: 3.9947\n",
            "Epoch 409/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0525 - auc: 0.9969 - accuracy: 0.9841 - cost: 2.0367 - val_loss: 0.1317 - val_auc: 0.9884 - val_accuracy: 0.9688 - val_cost: 3.9120\n",
            "Epoch 410/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0517 - auc: 0.9971 - accuracy: 0.9842 - cost: 2.0166 - val_loss: 0.1324 - val_auc: 0.9883 - val_accuracy: 0.9676 - val_cost: 4.0112\n",
            "Epoch 411/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0526 - auc: 0.9970 - accuracy: 0.9838 - cost: 2.0687 - val_loss: 0.1334 - val_auc: 0.9883 - val_accuracy: 0.9692 - val_cost: 3.8955\n",
            "Epoch 412/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0514 - auc: 0.9971 - accuracy: 0.9846 - cost: 1.9757 - val_loss: 0.1335 - val_auc: 0.9886 - val_accuracy: 0.9693 - val_cost: 3.8426\n",
            "Epoch 413/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0518 - auc: 0.9971 - accuracy: 0.9844 - cost: 1.9988 - val_loss: 0.1324 - val_auc: 0.9876 - val_accuracy: 0.9694 - val_cost: 3.9418\n",
            "Epoch 414/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0517 - auc: 0.9971 - accuracy: 0.9841 - cost: 2.0424 - val_loss: 0.1348 - val_auc: 0.9884 - val_accuracy: 0.9688 - val_cost: 3.9220\n",
            "Epoch 415/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0519 - auc: 0.9970 - accuracy: 0.9843 - cost: 2.0085 - val_loss: 0.1375 - val_auc: 0.9883 - val_accuracy: 0.9690 - val_cost: 3.8889\n",
            "Epoch 416/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0519 - auc: 0.9972 - accuracy: 0.9845 - cost: 1.9877 - val_loss: 0.1341 - val_auc: 0.9877 - val_accuracy: 0.9689 - val_cost: 3.9848\n",
            "Epoch 417/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0516 - auc: 0.9971 - accuracy: 0.9842 - cost: 2.0270 - val_loss: 0.1330 - val_auc: 0.9883 - val_accuracy: 0.9703 - val_cost: 3.7235\n",
            "Epoch 418/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0522 - auc: 0.9971 - accuracy: 0.9844 - cost: 2.0008 - val_loss: 0.1353 - val_auc: 0.9880 - val_accuracy: 0.9695 - val_cost: 3.7996\n",
            "Epoch 419/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0515 - auc: 0.9972 - accuracy: 0.9841 - cost: 2.0355 - val_loss: 0.1339 - val_auc: 0.9881 - val_accuracy: 0.9688 - val_cost: 3.9187\n",
            "Epoch 420/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0517 - auc: 0.9971 - accuracy: 0.9843 - cost: 1.9988 - val_loss: 0.1339 - val_auc: 0.9882 - val_accuracy: 0.9679 - val_cost: 4.0774\n",
            "Epoch 421/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0514 - auc: 0.9971 - accuracy: 0.9843 - cost: 2.0015 - val_loss: 0.1301 - val_auc: 0.9887 - val_accuracy: 0.9682 - val_cost: 4.0807\n",
            "Epoch 422/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0523 - auc: 0.9969 - accuracy: 0.9843 - cost: 2.0135 - val_loss: 0.1346 - val_auc: 0.9883 - val_accuracy: 0.9690 - val_cost: 3.9087\n",
            "Epoch 423/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0521 - auc: 0.9971 - accuracy: 0.9837 - cost: 2.0845 - val_loss: 0.1338 - val_auc: 0.9880 - val_accuracy: 0.9699 - val_cost: 3.7533\n",
            "Epoch 424/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0514 - auc: 0.9971 - accuracy: 0.9844 - cost: 2.0073 - val_loss: 0.1355 - val_auc: 0.9880 - val_accuracy: 0.9687 - val_cost: 3.9286\n",
            "Epoch 425/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0513 - auc: 0.9972 - accuracy: 0.9841 - cost: 2.0417 - val_loss: 0.1331 - val_auc: 0.9881 - val_accuracy: 0.9690 - val_cost: 3.9120\n",
            "Epoch 426/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0521 - auc: 0.9971 - accuracy: 0.9843 - cost: 2.0116 - val_loss: 0.1334 - val_auc: 0.9883 - val_accuracy: 0.9681 - val_cost: 3.9583\n",
            "Epoch 427/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0517 - auc: 0.9970 - accuracy: 0.9846 - cost: 1.9699 - val_loss: 0.1342 - val_auc: 0.9882 - val_accuracy: 0.9694 - val_cost: 3.8426\n",
            "Epoch 428/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0521 - auc: 0.9970 - accuracy: 0.9838 - cost: 2.0660 - val_loss: 0.1355 - val_auc: 0.9877 - val_accuracy: 0.9676 - val_cost: 4.0939\n",
            "Epoch 429/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0526 - auc: 0.9971 - accuracy: 0.9838 - cost: 2.0795 - val_loss: 0.1343 - val_auc: 0.9876 - val_accuracy: 0.9694 - val_cost: 3.8327\n",
            "Epoch 430/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0514 - auc: 0.9971 - accuracy: 0.9845 - cost: 2.0004 - val_loss: 0.1354 - val_auc: 0.9880 - val_accuracy: 0.9702 - val_cost: 3.6971\n",
            "Epoch 431/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0512 - auc: 0.9971 - accuracy: 0.9845 - cost: 1.9861 - val_loss: 0.1351 - val_auc: 0.9883 - val_accuracy: 0.9688 - val_cost: 3.8922\n",
            "Epoch 432/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0515 - auc: 0.9971 - accuracy: 0.9842 - cost: 2.0201 - val_loss: 0.1369 - val_auc: 0.9879 - val_accuracy: 0.9688 - val_cost: 3.8988\n",
            "Epoch 433/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0517 - auc: 0.9970 - accuracy: 0.9844 - cost: 2.0023 - val_loss: 0.1365 - val_auc: 0.9879 - val_accuracy: 0.9690 - val_cost: 3.8690\n",
            "Epoch 434/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0521 - auc: 0.9971 - accuracy: 0.9841 - cost: 2.0336 - val_loss: 0.1334 - val_auc: 0.9881 - val_accuracy: 0.9690 - val_cost: 3.9286\n",
            "Epoch 435/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0517 - auc: 0.9971 - accuracy: 0.9839 - cost: 2.0575 - val_loss: 0.1326 - val_auc: 0.9884 - val_accuracy: 0.9682 - val_cost: 3.9914\n",
            "Epoch 436/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0518 - auc: 0.9971 - accuracy: 0.9842 - cost: 2.0251 - val_loss: 0.1353 - val_auc: 0.9883 - val_accuracy: 0.9690 - val_cost: 3.8757\n",
            "Epoch 437/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0515 - auc: 0.9973 - accuracy: 0.9840 - cost: 2.0532 - val_loss: 0.1353 - val_auc: 0.9881 - val_accuracy: 0.9685 - val_cost: 3.9385\n",
            "Epoch 438/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0521 - auc: 0.9970 - accuracy: 0.9842 - cost: 2.0127 - val_loss: 0.1366 - val_auc: 0.9879 - val_accuracy: 0.9687 - val_cost: 4.0013\n",
            "Epoch 439/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0525 - auc: 0.9970 - accuracy: 0.9836 - cost: 2.1022 - val_loss: 0.1362 - val_auc: 0.9883 - val_accuracy: 0.9689 - val_cost: 3.9120\n",
            "Epoch 440/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0516 - auc: 0.9971 - accuracy: 0.9845 - cost: 1.9869 - val_loss: 0.1343 - val_auc: 0.9880 - val_accuracy: 0.9691 - val_cost: 3.9352\n",
            "Epoch 441/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0512 - auc: 0.9972 - accuracy: 0.9847 - cost: 1.9633 - val_loss: 0.1373 - val_auc: 0.9880 - val_accuracy: 0.9685 - val_cost: 3.9749\n",
            "Epoch 442/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0524 - auc: 0.9971 - accuracy: 0.9838 - cost: 2.0652 - val_loss: 0.1346 - val_auc: 0.9881 - val_accuracy: 0.9694 - val_cost: 3.8657\n",
            "Epoch 443/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0511 - auc: 0.9972 - accuracy: 0.9843 - cost: 2.0100 - val_loss: 0.1324 - val_auc: 0.9881 - val_accuracy: 0.9686 - val_cost: 4.0542\n",
            "Epoch 444/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0505 - auc: 0.9973 - accuracy: 0.9844 - cost: 2.0081 - val_loss: 0.1389 - val_auc: 0.9876 - val_accuracy: 0.9685 - val_cost: 3.9385\n",
            "Epoch 445/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0516 - auc: 0.9971 - accuracy: 0.9841 - cost: 2.0367 - val_loss: 0.1333 - val_auc: 0.9884 - val_accuracy: 0.9684 - val_cost: 4.0278\n",
            "Epoch 446/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0511 - auc: 0.9971 - accuracy: 0.9847 - cost: 1.9491 - val_loss: 0.1366 - val_auc: 0.9877 - val_accuracy: 0.9688 - val_cost: 3.8690\n",
            "Epoch 447/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0513 - auc: 0.9970 - accuracy: 0.9844 - cost: 1.9853 - val_loss: 0.1345 - val_auc: 0.9881 - val_accuracy: 0.9681 - val_cost: 4.0410\n",
            "Epoch 448/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0529 - auc: 0.9970 - accuracy: 0.9837 - cost: 2.0783 - val_loss: 0.1347 - val_auc: 0.9882 - val_accuracy: 0.9692 - val_cost: 3.9319\n",
            "Epoch 449/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0511 - auc: 0.9972 - accuracy: 0.9843 - cost: 2.0135 - val_loss: 0.1364 - val_auc: 0.9879 - val_accuracy: 0.9692 - val_cost: 3.9120\n",
            "Epoch 450/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0510 - auc: 0.9971 - accuracy: 0.9841 - cost: 2.0421 - val_loss: 0.1353 - val_auc: 0.9881 - val_accuracy: 0.9685 - val_cost: 3.9087\n",
            "Epoch 451/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0508 - auc: 0.9972 - accuracy: 0.9845 - cost: 1.9919 - val_loss: 0.1388 - val_auc: 0.9879 - val_accuracy: 0.9689 - val_cost: 3.9153\n",
            "Epoch 452/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0514 - auc: 0.9971 - accuracy: 0.9845 - cost: 1.9803 - val_loss: 0.1362 - val_auc: 0.9879 - val_accuracy: 0.9685 - val_cost: 3.9848\n",
            "Epoch 453/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0504 - auc: 0.9972 - accuracy: 0.9848 - cost: 1.9387 - val_loss: 0.1348 - val_auc: 0.9882 - val_accuracy: 0.9689 - val_cost: 3.9749\n",
            "Epoch 454/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0516 - auc: 0.9971 - accuracy: 0.9841 - cost: 2.0324 - val_loss: 0.1379 - val_auc: 0.9876 - val_accuracy: 0.9686 - val_cost: 3.9187\n",
            "Epoch 455/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0509 - auc: 0.9971 - accuracy: 0.9848 - cost: 1.9556 - val_loss: 0.1340 - val_auc: 0.9885 - val_accuracy: 0.9685 - val_cost: 3.9550\n",
            "Epoch 456/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0511 - auc: 0.9972 - accuracy: 0.9842 - cost: 2.0363 - val_loss: 0.1371 - val_auc: 0.9881 - val_accuracy: 0.9688 - val_cost: 3.9319\n",
            "Epoch 457/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0511 - auc: 0.9972 - accuracy: 0.9843 - cost: 2.0031 - val_loss: 0.1372 - val_auc: 0.9877 - val_accuracy: 0.9692 - val_cost: 3.8856\n",
            "Epoch 458/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0507 - auc: 0.9972 - accuracy: 0.9846 - cost: 1.9796 - val_loss: 0.1355 - val_auc: 0.9878 - val_accuracy: 0.9682 - val_cost: 4.0840\n",
            "Epoch 459/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0523 - auc: 0.9970 - accuracy: 0.9844 - cost: 1.9927 - val_loss: 0.1343 - val_auc: 0.9882 - val_accuracy: 0.9693 - val_cost: 3.8657\n",
            "Epoch 460/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0511 - auc: 0.9971 - accuracy: 0.9843 - cost: 2.0108 - val_loss: 0.1384 - val_auc: 0.9880 - val_accuracy: 0.9681 - val_cost: 4.0212\n",
            "Epoch 461/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0515 - auc: 0.9972 - accuracy: 0.9842 - cost: 2.0305 - val_loss: 0.1363 - val_auc: 0.9881 - val_accuracy: 0.9693 - val_cost: 3.8922\n",
            "Epoch 462/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0509 - auc: 0.9972 - accuracy: 0.9846 - cost: 1.9780 - val_loss: 0.1366 - val_auc: 0.9881 - val_accuracy: 0.9690 - val_cost: 3.8591\n",
            "Epoch 463/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0502 - auc: 0.9972 - accuracy: 0.9845 - cost: 1.9869 - val_loss: 0.1351 - val_auc: 0.9882 - val_accuracy: 0.9692 - val_cost: 3.8558\n",
            "Epoch 464/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0504 - auc: 0.9973 - accuracy: 0.9842 - cost: 2.0208 - val_loss: 0.1353 - val_auc: 0.9880 - val_accuracy: 0.9685 - val_cost: 3.9815\n",
            "Epoch 465/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0501 - auc: 0.9972 - accuracy: 0.9848 - cost: 1.9452 - val_loss: 0.1381 - val_auc: 0.9883 - val_accuracy: 0.9693 - val_cost: 3.8558\n",
            "Epoch 466/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0502 - auc: 0.9972 - accuracy: 0.9844 - cost: 1.9992 - val_loss: 0.1398 - val_auc: 0.9882 - val_accuracy: 0.9684 - val_cost: 3.8889\n",
            "Epoch 467/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0516 - auc: 0.9971 - accuracy: 0.9840 - cost: 2.0486 - val_loss: 0.1416 - val_auc: 0.9881 - val_accuracy: 0.9674 - val_cost: 3.9517\n",
            "Epoch 468/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0513 - auc: 0.9972 - accuracy: 0.9847 - cost: 1.9649 - val_loss: 0.1368 - val_auc: 0.9878 - val_accuracy: 0.9699 - val_cost: 3.8294\n",
            "Epoch 469/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0494 - auc: 0.9973 - accuracy: 0.9849 - cost: 1.9325 - val_loss: 0.1356 - val_auc: 0.9881 - val_accuracy: 0.9687 - val_cost: 3.9451\n",
            "Epoch 470/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0512 - auc: 0.9972 - accuracy: 0.9843 - cost: 2.0189 - val_loss: 0.1368 - val_auc: 0.9880 - val_accuracy: 0.9686 - val_cost: 3.8525\n",
            "Epoch 471/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0500 - auc: 0.9973 - accuracy: 0.9846 - cost: 1.9726 - val_loss: 0.1360 - val_auc: 0.9886 - val_accuracy: 0.9672 - val_cost: 4.0807\n",
            "Epoch 472/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0515 - auc: 0.9971 - accuracy: 0.9843 - cost: 2.0073 - val_loss: 0.1395 - val_auc: 0.9878 - val_accuracy: 0.9677 - val_cost: 4.0642\n",
            "Epoch 473/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0502 - auc: 0.9973 - accuracy: 0.9844 - cost: 1.9861 - val_loss: 0.1372 - val_auc: 0.9877 - val_accuracy: 0.9681 - val_cost: 4.1038\n",
            "Epoch 474/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0513 - auc: 0.9970 - accuracy: 0.9847 - cost: 1.9688 - val_loss: 0.1422 - val_auc: 0.9872 - val_accuracy: 0.9680 - val_cost: 4.0079\n",
            "Epoch 475/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0513 - auc: 0.9972 - accuracy: 0.9842 - cost: 2.0258 - val_loss: 0.1386 - val_auc: 0.9883 - val_accuracy: 0.9676 - val_cost: 3.9583\n",
            "Epoch 476/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0504 - auc: 0.9972 - accuracy: 0.9846 - cost: 1.9711 - val_loss: 0.1375 - val_auc: 0.9877 - val_accuracy: 0.9688 - val_cost: 3.9616\n",
            "Epoch 477/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0507 - auc: 0.9972 - accuracy: 0.9846 - cost: 1.9695 - val_loss: 0.1385 - val_auc: 0.9877 - val_accuracy: 0.9688 - val_cost: 3.9782\n",
            "Epoch 478/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0509 - auc: 0.9972 - accuracy: 0.9845 - cost: 1.9880 - val_loss: 0.1365 - val_auc: 0.9879 - val_accuracy: 0.9678 - val_cost: 4.1832\n",
            "Epoch 479/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0513 - auc: 0.9972 - accuracy: 0.9842 - cost: 2.0332 - val_loss: 0.1351 - val_auc: 0.9879 - val_accuracy: 0.9688 - val_cost: 3.9848\n",
            "Epoch 480/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0505 - auc: 0.9973 - accuracy: 0.9844 - cost: 2.0073 - val_loss: 0.1401 - val_auc: 0.9882 - val_accuracy: 0.9693 - val_cost: 3.9021\n",
            "Epoch 481/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0505 - auc: 0.9973 - accuracy: 0.9847 - cost: 1.9568 - val_loss: 0.1376 - val_auc: 0.9876 - val_accuracy: 0.9685 - val_cost: 3.9947\n",
            "Epoch 482/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0510 - auc: 0.9971 - accuracy: 0.9845 - cost: 1.9927 - val_loss: 0.1371 - val_auc: 0.9881 - val_accuracy: 0.9686 - val_cost: 3.9749\n",
            "Epoch 483/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0501 - auc: 0.9973 - accuracy: 0.9843 - cost: 2.0166 - val_loss: 0.1364 - val_auc: 0.9881 - val_accuracy: 0.9694 - val_cost: 3.8261\n",
            "Epoch 484/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0491 - auc: 0.9974 - accuracy: 0.9850 - cost: 1.9209 - val_loss: 0.1384 - val_auc: 0.9880 - val_accuracy: 0.9683 - val_cost: 3.9418\n",
            "Epoch 485/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0501 - auc: 0.9972 - accuracy: 0.9847 - cost: 1.9668 - val_loss: 0.1386 - val_auc: 0.9878 - val_accuracy: 0.9673 - val_cost: 4.1171\n",
            "Epoch 486/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0497 - auc: 0.9973 - accuracy: 0.9847 - cost: 1.9576 - val_loss: 0.1389 - val_auc: 0.9882 - val_accuracy: 0.9682 - val_cost: 3.9451\n",
            "Epoch 487/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0501 - auc: 0.9973 - accuracy: 0.9845 - cost: 1.9892 - val_loss: 0.1385 - val_auc: 0.9875 - val_accuracy: 0.9693 - val_cost: 3.9054\n",
            "Epoch 488/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0505 - auc: 0.9971 - accuracy: 0.9847 - cost: 1.9645 - val_loss: 0.1447 - val_auc: 0.9881 - val_accuracy: 0.9685 - val_cost: 3.8591\n",
            "Epoch 489/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0505 - auc: 0.9973 - accuracy: 0.9845 - cost: 1.9965 - val_loss: 0.1428 - val_auc: 0.9879 - val_accuracy: 0.9678 - val_cost: 3.9848\n",
            "Epoch 490/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0501 - auc: 0.9973 - accuracy: 0.9845 - cost: 1.9842 - val_loss: 0.1400 - val_auc: 0.9879 - val_accuracy: 0.9679 - val_cost: 3.9550\n",
            "Epoch 491/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0501 - auc: 0.9973 - accuracy: 0.9844 - cost: 2.0023 - val_loss: 0.1415 - val_auc: 0.9877 - val_accuracy: 0.9690 - val_cost: 3.9087\n",
            "Epoch 492/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0504 - auc: 0.9972 - accuracy: 0.9848 - cost: 1.9448 - val_loss: 0.1383 - val_auc: 0.9879 - val_accuracy: 0.9674 - val_cost: 4.1534\n",
            "Epoch 493/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0508 - auc: 0.9972 - accuracy: 0.9841 - cost: 2.0405 - val_loss: 0.1399 - val_auc: 0.9880 - val_accuracy: 0.9684 - val_cost: 3.9550\n",
            "Epoch 494/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0504 - auc: 0.9973 - accuracy: 0.9843 - cost: 2.0093 - val_loss: 0.1401 - val_auc: 0.9878 - val_accuracy: 0.9686 - val_cost: 3.9153\n",
            "Epoch 495/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0504 - auc: 0.9973 - accuracy: 0.9845 - cost: 1.9927 - val_loss: 0.1383 - val_auc: 0.9881 - val_accuracy: 0.9678 - val_cost: 4.0675\n",
            "Epoch 496/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0505 - auc: 0.9973 - accuracy: 0.9845 - cost: 1.9819 - val_loss: 0.1428 - val_auc: 0.9875 - val_accuracy: 0.9690 - val_cost: 3.9220\n",
            "Epoch 497/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0506 - auc: 0.9972 - accuracy: 0.9844 - cost: 1.9931 - val_loss: 0.1399 - val_auc: 0.9880 - val_accuracy: 0.9681 - val_cost: 3.9616\n",
            "Epoch 498/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0512 - auc: 0.9971 - accuracy: 0.9847 - cost: 1.9664 - val_loss: 0.1396 - val_auc: 0.9873 - val_accuracy: 0.9684 - val_cost: 4.0046\n",
            "Epoch 499/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0501 - auc: 0.9973 - accuracy: 0.9848 - cost: 1.9371 - val_loss: 0.1383 - val_auc: 0.9877 - val_accuracy: 0.9687 - val_cost: 3.9848\n",
            "Epoch 500/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0504 - auc: 0.9973 - accuracy: 0.9843 - cost: 2.0154 - val_loss: 0.1407 - val_auc: 0.9877 - val_accuracy: 0.9679 - val_cost: 4.1435\n",
            "Epoch 501/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0500 - auc: 0.9973 - accuracy: 0.9847 - cost: 1.9610 - val_loss: 0.1416 - val_auc: 0.9876 - val_accuracy: 0.9682 - val_cost: 4.0377\n",
            "Epoch 502/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0500 - auc: 0.9973 - accuracy: 0.9846 - cost: 1.9645 - val_loss: 0.1408 - val_auc: 0.9881 - val_accuracy: 0.9678 - val_cost: 4.0079\n",
            "Epoch 503/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0499 - auc: 0.9974 - accuracy: 0.9848 - cost: 1.9479 - val_loss: 0.1399 - val_auc: 0.9875 - val_accuracy: 0.9683 - val_cost: 4.0278\n",
            "Epoch 504/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0492 - auc: 0.9974 - accuracy: 0.9846 - cost: 1.9707 - val_loss: 0.1395 - val_auc: 0.9877 - val_accuracy: 0.9696 - val_cost: 3.8161\n",
            "Epoch 505/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0499 - auc: 0.9973 - accuracy: 0.9848 - cost: 1.9460 - val_loss: 0.1387 - val_auc: 0.9878 - val_accuracy: 0.9690 - val_cost: 3.9484\n",
            "Epoch 506/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0495 - auc: 0.9974 - accuracy: 0.9848 - cost: 1.9502 - val_loss: 0.1408 - val_auc: 0.9873 - val_accuracy: 0.9685 - val_cost: 3.9848\n",
            "Epoch 507/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0499 - auc: 0.9973 - accuracy: 0.9846 - cost: 1.9657 - val_loss: 0.1412 - val_auc: 0.9875 - val_accuracy: 0.9676 - val_cost: 4.0741\n",
            "Epoch 508/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0494 - auc: 0.9974 - accuracy: 0.9847 - cost: 1.9626 - val_loss: 0.1408 - val_auc: 0.9883 - val_accuracy: 0.9690 - val_cost: 3.9947\n",
            "Epoch 509/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0497 - auc: 0.9973 - accuracy: 0.9850 - cost: 1.9171 - val_loss: 0.1405 - val_auc: 0.9879 - val_accuracy: 0.9685 - val_cost: 4.0179\n",
            "Epoch 510/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0507 - auc: 0.9973 - accuracy: 0.9843 - cost: 2.0154 - val_loss: 0.1403 - val_auc: 0.9876 - val_accuracy: 0.9687 - val_cost: 3.9120\n",
            "Epoch 511/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0507 - auc: 0.9972 - accuracy: 0.9843 - cost: 2.0150 - val_loss: 0.1385 - val_auc: 0.9878 - val_accuracy: 0.9694 - val_cost: 3.8823\n",
            "Epoch 512/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0506 - auc: 0.9973 - accuracy: 0.9844 - cost: 1.9857 - val_loss: 0.1403 - val_auc: 0.9874 - val_accuracy: 0.9683 - val_cost: 4.0146\n",
            "Epoch 513/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0495 - auc: 0.9973 - accuracy: 0.9850 - cost: 1.9275 - val_loss: 0.1378 - val_auc: 0.9880 - val_accuracy: 0.9687 - val_cost: 3.8955\n",
            "Epoch 514/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0496 - auc: 0.9973 - accuracy: 0.9848 - cost: 1.9495 - val_loss: 0.1410 - val_auc: 0.9875 - val_accuracy: 0.9683 - val_cost: 3.9914\n",
            "Epoch 515/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0499 - auc: 0.9973 - accuracy: 0.9850 - cost: 1.9221 - val_loss: 0.1385 - val_auc: 0.9876 - val_accuracy: 0.9686 - val_cost: 4.0146\n",
            "Epoch 516/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0500 - auc: 0.9973 - accuracy: 0.9847 - cost: 1.9487 - val_loss: 0.1415 - val_auc: 0.9876 - val_accuracy: 0.9694 - val_cost: 3.8194\n",
            "Epoch 517/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0500 - auc: 0.9972 - accuracy: 0.9845 - cost: 1.9780 - val_loss: 0.1405 - val_auc: 0.9877 - val_accuracy: 0.9686 - val_cost: 3.9550\n",
            "Epoch 518/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0503 - auc: 0.9972 - accuracy: 0.9846 - cost: 1.9718 - val_loss: 0.1374 - val_auc: 0.9878 - val_accuracy: 0.9679 - val_cost: 4.0377\n",
            "Epoch 519/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0490 - auc: 0.9974 - accuracy: 0.9849 - cost: 1.9302 - val_loss: 0.1391 - val_auc: 0.9878 - val_accuracy: 0.9681 - val_cost: 4.0542\n",
            "Epoch 520/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0504 - auc: 0.9971 - accuracy: 0.9848 - cost: 1.9479 - val_loss: 0.1383 - val_auc: 0.9878 - val_accuracy: 0.9681 - val_cost: 4.0278\n",
            "Epoch 521/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0495 - auc: 0.9973 - accuracy: 0.9849 - cost: 1.9379 - val_loss: 0.1405 - val_auc: 0.9875 - val_accuracy: 0.9688 - val_cost: 3.8624\n",
            "Epoch 522/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0488 - auc: 0.9974 - accuracy: 0.9851 - cost: 1.9174 - val_loss: 0.1400 - val_auc: 0.9881 - val_accuracy: 0.9685 - val_cost: 3.9220\n",
            "Epoch 523/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0495 - auc: 0.9973 - accuracy: 0.9849 - cost: 1.9406 - val_loss: 0.1449 - val_auc: 0.9882 - val_accuracy: 0.9671 - val_cost: 3.9583\n",
            "Epoch 524/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0491 - auc: 0.9974 - accuracy: 0.9846 - cost: 1.9591 - val_loss: 0.1398 - val_auc: 0.9881 - val_accuracy: 0.9683 - val_cost: 4.0410\n",
            "Epoch 525/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0496 - auc: 0.9972 - accuracy: 0.9849 - cost: 1.9429 - val_loss: 0.1433 - val_auc: 0.9875 - val_accuracy: 0.9685 - val_cost: 3.9187\n",
            "Epoch 526/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0502 - auc: 0.9973 - accuracy: 0.9846 - cost: 1.9842 - val_loss: 0.1416 - val_auc: 0.9877 - val_accuracy: 0.9684 - val_cost: 4.0212\n",
            "Epoch 527/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0500 - auc: 0.9974 - accuracy: 0.9845 - cost: 2.0019 - val_loss: 0.1420 - val_auc: 0.9879 - val_accuracy: 0.9690 - val_cost: 3.8459\n",
            "Epoch 528/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0503 - auc: 0.9973 - accuracy: 0.9839 - cost: 2.0656 - val_loss: 0.1411 - val_auc: 0.9872 - val_accuracy: 0.9680 - val_cost: 3.9848\n",
            "Epoch 529/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0497 - auc: 0.9975 - accuracy: 0.9843 - cost: 2.0108 - val_loss: 0.1404 - val_auc: 0.9877 - val_accuracy: 0.9684 - val_cost: 4.0146\n",
            "Epoch 530/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0496 - auc: 0.9974 - accuracy: 0.9842 - cost: 2.0204 - val_loss: 0.1418 - val_auc: 0.9875 - val_accuracy: 0.9684 - val_cost: 3.9054\n",
            "Epoch 531/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0493 - auc: 0.9973 - accuracy: 0.9851 - cost: 1.9070 - val_loss: 0.1427 - val_auc: 0.9877 - val_accuracy: 0.9680 - val_cost: 4.0344\n",
            "Epoch 532/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0500 - auc: 0.9973 - accuracy: 0.9845 - cost: 1.9969 - val_loss: 0.1415 - val_auc: 0.9874 - val_accuracy: 0.9693 - val_cost: 3.9087\n",
            "Epoch 533/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0500 - auc: 0.9974 - accuracy: 0.9844 - cost: 2.0108 - val_loss: 0.1436 - val_auc: 0.9873 - val_accuracy: 0.9674 - val_cost: 4.1204\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.1249 - auc: 0.9891 - accuracy: 0.9691 - cost: 3.8406\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:03:56.688440\n",
            "fold accuracy: 0.969124972820282 - fold cost: 3.840625047683716\n",
            "x_train shape: (144000, 67)\n",
            "Epoch 1/1000\n",
            "120/120 [==============================] - 2s 6ms/step - loss: 0.5305 - auc: 0.7972 - accuracy: 0.7281 - cost: 36.2566 - val_loss: 0.3996 - val_auc: 0.8989 - val_accuracy: 0.8243 - val_cost: 22.8274\n",
            "Epoch 2/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.3518 - auc: 0.9213 - accuracy: 0.8488 - cost: 19.2624 - val_loss: 0.3196 - val_auc: 0.9350 - val_accuracy: 0.8646 - val_cost: 17.2553\n",
            "Epoch 3/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.3013 - auc: 0.9425 - accuracy: 0.8748 - cost: 15.8688 - val_loss: 0.2897 - val_auc: 0.9468 - val_accuracy: 0.8792 - val_cost: 15.3274\n",
            "Epoch 4/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.2730 - auc: 0.9529 - accuracy: 0.8892 - cost: 14.0177 - val_loss: 0.2628 - val_auc: 0.9564 - val_accuracy: 0.8926 - val_cost: 13.4226\n",
            "Epoch 5/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.2497 - auc: 0.9606 - accuracy: 0.9004 - cost: 12.6003 - val_loss: 0.2428 - val_auc: 0.9627 - val_accuracy: 0.9049 - val_cost: 11.9345\n",
            "Epoch 6/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.2308 - auc: 0.9663 - accuracy: 0.9100 - cost: 11.3827 - val_loss: 0.2276 - val_auc: 0.9671 - val_accuracy: 0.9131 - val_cost: 10.9358\n",
            "Epoch 7/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.2147 - auc: 0.9708 - accuracy: 0.9165 - cost: 10.5567 - val_loss: 0.2136 - val_auc: 0.9712 - val_accuracy: 0.9205 - val_cost: 9.7784\n",
            "Epoch 8/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.2021 - auc: 0.9739 - accuracy: 0.9224 - cost: 9.7855 - val_loss: 0.2029 - val_auc: 0.9744 - val_accuracy: 0.9244 - val_cost: 9.2328\n",
            "Epoch 9/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1916 - auc: 0.9766 - accuracy: 0.9270 - cost: 9.2180 - val_loss: 0.1913 - val_auc: 0.9767 - val_accuracy: 0.9291 - val_cost: 8.8790\n",
            "Epoch 10/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1824 - auc: 0.9786 - accuracy: 0.9317 - cost: 8.6393 - val_loss: 0.1828 - val_auc: 0.9783 - val_accuracy: 0.9332 - val_cost: 8.5880\n",
            "Epoch 11/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1737 - auc: 0.9805 - accuracy: 0.9354 - cost: 8.1671 - val_loss: 0.1766 - val_auc: 0.9798 - val_accuracy: 0.9362 - val_cost: 7.9067\n",
            "Epoch 12/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1679 - auc: 0.9816 - accuracy: 0.9385 - cost: 7.7778 - val_loss: 0.1708 - val_auc: 0.9809 - val_accuracy: 0.9399 - val_cost: 7.5099\n",
            "Epoch 13/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1615 - auc: 0.9829 - accuracy: 0.9409 - cost: 7.4873 - val_loss: 0.1666 - val_auc: 0.9818 - val_accuracy: 0.9421 - val_cost: 7.1594\n",
            "Epoch 14/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1562 - auc: 0.9838 - accuracy: 0.9439 - cost: 7.1011 - val_loss: 0.1610 - val_auc: 0.9826 - val_accuracy: 0.9457 - val_cost: 6.9478\n",
            "Epoch 15/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.1529 - auc: 0.9844 - accuracy: 0.9451 - cost: 6.9529 - val_loss: 0.1577 - val_auc: 0.9834 - val_accuracy: 0.9448 - val_cost: 6.9444\n",
            "Epoch 16/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1480 - auc: 0.9853 - accuracy: 0.9470 - cost: 6.7269 - val_loss: 0.1547 - val_auc: 0.9841 - val_accuracy: 0.9465 - val_cost: 6.7163\n",
            "Epoch 17/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1460 - auc: 0.9856 - accuracy: 0.9484 - cost: 6.5498 - val_loss: 0.1540 - val_auc: 0.9841 - val_accuracy: 0.9460 - val_cost: 6.8022\n",
            "Epoch 18/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.1417 - auc: 0.9863 - accuracy: 0.9502 - cost: 6.3164 - val_loss: 0.1530 - val_auc: 0.9842 - val_accuracy: 0.9468 - val_cost: 6.7295\n",
            "Epoch 19/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1401 - auc: 0.9867 - accuracy: 0.9507 - cost: 6.2670 - val_loss: 0.1503 - val_auc: 0.9847 - val_accuracy: 0.9480 - val_cost: 6.5476\n",
            "Epoch 20/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1384 - auc: 0.9868 - accuracy: 0.9519 - cost: 6.1049 - val_loss: 0.1469 - val_auc: 0.9853 - val_accuracy: 0.9492 - val_cost: 6.5079\n",
            "Epoch 21/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1346 - auc: 0.9875 - accuracy: 0.9541 - cost: 5.8156 - val_loss: 0.1468 - val_auc: 0.9852 - val_accuracy: 0.9494 - val_cost: 6.4220\n",
            "Epoch 22/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1323 - auc: 0.9879 - accuracy: 0.9541 - cost: 5.8086 - val_loss: 0.1453 - val_auc: 0.9855 - val_accuracy: 0.9492 - val_cost: 6.5179\n",
            "Epoch 23/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1302 - auc: 0.9882 - accuracy: 0.9557 - cost: 5.6308 - val_loss: 0.1426 - val_auc: 0.9859 - val_accuracy: 0.9519 - val_cost: 6.0549\n",
            "Epoch 24/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1282 - auc: 0.9885 - accuracy: 0.9561 - cost: 5.5606 - val_loss: 0.1433 - val_auc: 0.9858 - val_accuracy: 0.9522 - val_cost: 5.9623\n",
            "Epoch 25/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1278 - auc: 0.9886 - accuracy: 0.9565 - cost: 5.5158 - val_loss: 0.1408 - val_auc: 0.9860 - val_accuracy: 0.9526 - val_cost: 6.1078\n",
            "Epoch 26/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1247 - auc: 0.9889 - accuracy: 0.9579 - cost: 5.3329 - val_loss: 0.1405 - val_auc: 0.9863 - val_accuracy: 0.9533 - val_cost: 5.8598\n",
            "Epoch 27/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1234 - auc: 0.9892 - accuracy: 0.9582 - cost: 5.2955 - val_loss: 0.1394 - val_auc: 0.9862 - val_accuracy: 0.9545 - val_cost: 5.8333\n",
            "Epoch 28/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1221 - auc: 0.9894 - accuracy: 0.9588 - cost: 5.2319 - val_loss: 0.1395 - val_auc: 0.9862 - val_accuracy: 0.9542 - val_cost: 5.8267\n",
            "Epoch 29/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1203 - auc: 0.9897 - accuracy: 0.9593 - cost: 5.1609 - val_loss: 0.1383 - val_auc: 0.9863 - val_accuracy: 0.9549 - val_cost: 5.6581\n",
            "Epoch 30/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1194 - auc: 0.9897 - accuracy: 0.9598 - cost: 5.1073 - val_loss: 0.1363 - val_auc: 0.9868 - val_accuracy: 0.9562 - val_cost: 5.4034\n",
            "Epoch 31/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1179 - auc: 0.9899 - accuracy: 0.9603 - cost: 5.0185 - val_loss: 0.1350 - val_auc: 0.9869 - val_accuracy: 0.9574 - val_cost: 5.3968\n",
            "Epoch 32/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1162 - auc: 0.9902 - accuracy: 0.9611 - cost: 4.9271 - val_loss: 0.1334 - val_auc: 0.9871 - val_accuracy: 0.9572 - val_cost: 5.4332\n",
            "Epoch 33/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1153 - auc: 0.9902 - accuracy: 0.9618 - cost: 4.8387 - val_loss: 0.1332 - val_auc: 0.9871 - val_accuracy: 0.9572 - val_cost: 5.3042\n",
            "Epoch 34/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1127 - auc: 0.9906 - accuracy: 0.9625 - cost: 4.7577 - val_loss: 0.1338 - val_auc: 0.9870 - val_accuracy: 0.9567 - val_cost: 5.5093\n",
            "Epoch 35/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1121 - auc: 0.9908 - accuracy: 0.9632 - cost: 4.6725 - val_loss: 0.1321 - val_auc: 0.9871 - val_accuracy: 0.9583 - val_cost: 5.2116\n",
            "Epoch 36/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1120 - auc: 0.9906 - accuracy: 0.9633 - cost: 4.6539 - val_loss: 0.1331 - val_auc: 0.9873 - val_accuracy: 0.9581 - val_cost: 5.1488\n",
            "Epoch 37/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1102 - auc: 0.9910 - accuracy: 0.9636 - cost: 4.6188 - val_loss: 0.1316 - val_auc: 0.9871 - val_accuracy: 0.9593 - val_cost: 5.0860\n",
            "Epoch 38/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1085 - auc: 0.9911 - accuracy: 0.9650 - cost: 4.4452 - val_loss: 0.1327 - val_auc: 0.9871 - val_accuracy: 0.9583 - val_cost: 5.1687\n",
            "Epoch 39/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1076 - auc: 0.9912 - accuracy: 0.9649 - cost: 4.4522 - val_loss: 0.1293 - val_auc: 0.9876 - val_accuracy: 0.9602 - val_cost: 5.0231\n",
            "Epoch 40/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1067 - auc: 0.9913 - accuracy: 0.9652 - cost: 4.4236 - val_loss: 0.1280 - val_auc: 0.9875 - val_accuracy: 0.9607 - val_cost: 5.0661\n",
            "Epoch 41/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1050 - auc: 0.9916 - accuracy: 0.9656 - cost: 4.3723 - val_loss: 0.1293 - val_auc: 0.9874 - val_accuracy: 0.9599 - val_cost: 4.9669\n",
            "Epoch 42/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1047 - auc: 0.9916 - accuracy: 0.9658 - cost: 4.3476 - val_loss: 0.1283 - val_auc: 0.9874 - val_accuracy: 0.9610 - val_cost: 4.8942\n",
            "Epoch 43/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1039 - auc: 0.9917 - accuracy: 0.9663 - cost: 4.2897 - val_loss: 0.1258 - val_auc: 0.9879 - val_accuracy: 0.9618 - val_cost: 4.8380\n",
            "Epoch 44/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1019 - auc: 0.9919 - accuracy: 0.9667 - cost: 4.2411 - val_loss: 0.1262 - val_auc: 0.9880 - val_accuracy: 0.9615 - val_cost: 4.8181\n",
            "Epoch 45/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1010 - auc: 0.9920 - accuracy: 0.9674 - cost: 4.1524 - val_loss: 0.1256 - val_auc: 0.9879 - val_accuracy: 0.9616 - val_cost: 4.9537\n",
            "Epoch 46/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0997 - auc: 0.9922 - accuracy: 0.9680 - cost: 4.0691 - val_loss: 0.1266 - val_auc: 0.9879 - val_accuracy: 0.9625 - val_cost: 4.5602\n",
            "Epoch 47/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0998 - auc: 0.9922 - accuracy: 0.9678 - cost: 4.1057 - val_loss: 0.1237 - val_auc: 0.9882 - val_accuracy: 0.9626 - val_cost: 4.7553\n",
            "Epoch 48/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0981 - auc: 0.9923 - accuracy: 0.9687 - cost: 3.9865 - val_loss: 0.1234 - val_auc: 0.9882 - val_accuracy: 0.9629 - val_cost: 4.5899\n",
            "Epoch 49/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0976 - auc: 0.9924 - accuracy: 0.9688 - cost: 3.9649 - val_loss: 0.1211 - val_auc: 0.9886 - val_accuracy: 0.9630 - val_cost: 4.8049\n",
            "Epoch 50/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0963 - auc: 0.9924 - accuracy: 0.9694 - cost: 3.9093 - val_loss: 0.1218 - val_auc: 0.9886 - val_accuracy: 0.9627 - val_cost: 4.6296\n",
            "Epoch 51/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0963 - auc: 0.9924 - accuracy: 0.9694 - cost: 3.8789 - val_loss: 0.1212 - val_auc: 0.9886 - val_accuracy: 0.9640 - val_cost: 4.4279\n",
            "Epoch 52/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0954 - auc: 0.9926 - accuracy: 0.9695 - cost: 3.8792 - val_loss: 0.1209 - val_auc: 0.9884 - val_accuracy: 0.9620 - val_cost: 4.9272\n",
            "Epoch 53/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0945 - auc: 0.9927 - accuracy: 0.9698 - cost: 3.8495 - val_loss: 0.1201 - val_auc: 0.9887 - val_accuracy: 0.9636 - val_cost: 4.5767\n",
            "Epoch 54/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0936 - auc: 0.9928 - accuracy: 0.9702 - cost: 3.7917 - val_loss: 0.1195 - val_auc: 0.9886 - val_accuracy: 0.9648 - val_cost: 4.4544\n",
            "Epoch 55/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0932 - auc: 0.9929 - accuracy: 0.9708 - cost: 3.7361 - val_loss: 0.1195 - val_auc: 0.9888 - val_accuracy: 0.9637 - val_cost: 4.6991\n",
            "Epoch 56/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0925 - auc: 0.9929 - accuracy: 0.9707 - cost: 3.7238 - val_loss: 0.1186 - val_auc: 0.9887 - val_accuracy: 0.9642 - val_cost: 4.4345\n",
            "Epoch 57/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0920 - auc: 0.9929 - accuracy: 0.9707 - cost: 3.7357 - val_loss: 0.1177 - val_auc: 0.9888 - val_accuracy: 0.9658 - val_cost: 4.3056\n",
            "Epoch 58/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0906 - auc: 0.9931 - accuracy: 0.9715 - cost: 3.6277 - val_loss: 0.1183 - val_auc: 0.9885 - val_accuracy: 0.9650 - val_cost: 4.3221\n",
            "Epoch 59/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0904 - auc: 0.9931 - accuracy: 0.9713 - cost: 3.6528 - val_loss: 0.1183 - val_auc: 0.9887 - val_accuracy: 0.9656 - val_cost: 4.2989\n",
            "Epoch 60/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0899 - auc: 0.9930 - accuracy: 0.9719 - cost: 3.5768 - val_loss: 0.1170 - val_auc: 0.9888 - val_accuracy: 0.9664 - val_cost: 4.2394\n",
            "Epoch 61/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0889 - auc: 0.9932 - accuracy: 0.9719 - cost: 3.5845 - val_loss: 0.1149 - val_auc: 0.9891 - val_accuracy: 0.9654 - val_cost: 4.3849\n",
            "Epoch 62/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0883 - auc: 0.9933 - accuracy: 0.9722 - cost: 3.5305 - val_loss: 0.1143 - val_auc: 0.9894 - val_accuracy: 0.9676 - val_cost: 4.0046\n",
            "Epoch 63/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0881 - auc: 0.9933 - accuracy: 0.9726 - cost: 3.4992 - val_loss: 0.1155 - val_auc: 0.9890 - val_accuracy: 0.9658 - val_cost: 4.3485\n",
            "Epoch 64/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0867 - auc: 0.9935 - accuracy: 0.9731 - cost: 3.4217 - val_loss: 0.1150 - val_auc: 0.9894 - val_accuracy: 0.9660 - val_cost: 4.2725\n",
            "Epoch 65/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0863 - auc: 0.9935 - accuracy: 0.9728 - cost: 3.4653 - val_loss: 0.1138 - val_auc: 0.9893 - val_accuracy: 0.9667 - val_cost: 4.1601\n",
            "Epoch 66/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0870 - auc: 0.9934 - accuracy: 0.9728 - cost: 3.4610 - val_loss: 0.1154 - val_auc: 0.9891 - val_accuracy: 0.9659 - val_cost: 4.2725\n",
            "Epoch 67/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0856 - auc: 0.9937 - accuracy: 0.9733 - cost: 3.4016 - val_loss: 0.1132 - val_auc: 0.9890 - val_accuracy: 0.9666 - val_cost: 4.2063\n",
            "Epoch 68/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0852 - auc: 0.9936 - accuracy: 0.9736 - cost: 3.3738 - val_loss: 0.1144 - val_auc: 0.9896 - val_accuracy: 0.9668 - val_cost: 4.1402\n",
            "Epoch 69/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0846 - auc: 0.9937 - accuracy: 0.9738 - cost: 3.3345 - val_loss: 0.1128 - val_auc: 0.9893 - val_accuracy: 0.9674 - val_cost: 4.1369\n",
            "Epoch 70/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0832 - auc: 0.9937 - accuracy: 0.9746 - cost: 3.2373 - val_loss: 0.1122 - val_auc: 0.9896 - val_accuracy: 0.9667 - val_cost: 4.1898\n",
            "Epoch 71/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0831 - auc: 0.9938 - accuracy: 0.9740 - cost: 3.2998 - val_loss: 0.1115 - val_auc: 0.9897 - val_accuracy: 0.9678 - val_cost: 3.9848\n",
            "Epoch 72/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0836 - auc: 0.9937 - accuracy: 0.9744 - cost: 3.2596 - val_loss: 0.1120 - val_auc: 0.9893 - val_accuracy: 0.9683 - val_cost: 4.0708\n",
            "Epoch 73/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0827 - auc: 0.9939 - accuracy: 0.9746 - cost: 3.2504 - val_loss: 0.1127 - val_auc: 0.9896 - val_accuracy: 0.9679 - val_cost: 3.9484\n",
            "Epoch 74/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0825 - auc: 0.9939 - accuracy: 0.9745 - cost: 3.2342 - val_loss: 0.1112 - val_auc: 0.9895 - val_accuracy: 0.9675 - val_cost: 4.1104\n",
            "Epoch 75/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0822 - auc: 0.9939 - accuracy: 0.9752 - cost: 3.1539 - val_loss: 0.1128 - val_auc: 0.9895 - val_accuracy: 0.9668 - val_cost: 4.2758\n",
            "Epoch 76/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0812 - auc: 0.9940 - accuracy: 0.9752 - cost: 3.1674 - val_loss: 0.1112 - val_auc: 0.9896 - val_accuracy: 0.9685 - val_cost: 3.9319\n",
            "Epoch 77/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0812 - auc: 0.9940 - accuracy: 0.9753 - cost: 3.1443 - val_loss: 0.1113 - val_auc: 0.9893 - val_accuracy: 0.9681 - val_cost: 4.0311\n",
            "Epoch 78/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0804 - auc: 0.9941 - accuracy: 0.9756 - cost: 3.1111 - val_loss: 0.1126 - val_auc: 0.9894 - val_accuracy: 0.9672 - val_cost: 4.1038\n",
            "Epoch 79/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0803 - auc: 0.9940 - accuracy: 0.9753 - cost: 3.1501 - val_loss: 0.1116 - val_auc: 0.9895 - val_accuracy: 0.9687 - val_cost: 3.9550\n",
            "Epoch 80/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0790 - auc: 0.9943 - accuracy: 0.9759 - cost: 3.0667 - val_loss: 0.1107 - val_auc: 0.9898 - val_accuracy: 0.9678 - val_cost: 4.0575\n",
            "Epoch 81/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0802 - auc: 0.9941 - accuracy: 0.9757 - cost: 3.1015 - val_loss: 0.1101 - val_auc: 0.9893 - val_accuracy: 0.9698 - val_cost: 3.8161\n",
            "Epoch 82/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0794 - auc: 0.9941 - accuracy: 0.9762 - cost: 3.0270 - val_loss: 0.1099 - val_auc: 0.9896 - val_accuracy: 0.9691 - val_cost: 3.8690\n",
            "Epoch 83/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0792 - auc: 0.9942 - accuracy: 0.9755 - cost: 3.1308 - val_loss: 0.1109 - val_auc: 0.9898 - val_accuracy: 0.9687 - val_cost: 3.9352\n",
            "Epoch 84/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0779 - auc: 0.9944 - accuracy: 0.9765 - cost: 2.9938 - val_loss: 0.1104 - val_auc: 0.9898 - val_accuracy: 0.9686 - val_cost: 4.0046\n",
            "Epoch 85/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0785 - auc: 0.9943 - accuracy: 0.9761 - cost: 3.0517 - val_loss: 0.1108 - val_auc: 0.9896 - val_accuracy: 0.9690 - val_cost: 3.9054\n",
            "Epoch 86/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0778 - auc: 0.9944 - accuracy: 0.9762 - cost: 3.0270 - val_loss: 0.1101 - val_auc: 0.9897 - val_accuracy: 0.9690 - val_cost: 3.9716\n",
            "Epoch 87/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0783 - auc: 0.9942 - accuracy: 0.9760 - cost: 3.0602 - val_loss: 0.1113 - val_auc: 0.9897 - val_accuracy: 0.9692 - val_cost: 3.9484\n",
            "Epoch 88/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0770 - auc: 0.9943 - accuracy: 0.9765 - cost: 2.9896 - val_loss: 0.1096 - val_auc: 0.9897 - val_accuracy: 0.9686 - val_cost: 4.0410\n",
            "Epoch 89/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0778 - auc: 0.9944 - accuracy: 0.9764 - cost: 3.0085 - val_loss: 0.1080 - val_auc: 0.9899 - val_accuracy: 0.9691 - val_cost: 3.9517\n",
            "Epoch 90/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0763 - auc: 0.9946 - accuracy: 0.9769 - cost: 2.9487 - val_loss: 0.1097 - val_auc: 0.9896 - val_accuracy: 0.9690 - val_cost: 3.9087\n",
            "Epoch 91/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0764 - auc: 0.9944 - accuracy: 0.9768 - cost: 2.9560 - val_loss: 0.1111 - val_auc: 0.9896 - val_accuracy: 0.9677 - val_cost: 4.0939\n",
            "Epoch 92/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0762 - auc: 0.9946 - accuracy: 0.9768 - cost: 2.9649 - val_loss: 0.1119 - val_auc: 0.9895 - val_accuracy: 0.9682 - val_cost: 3.8988\n",
            "Epoch 93/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0753 - auc: 0.9946 - accuracy: 0.9771 - cost: 2.9147 - val_loss: 0.1089 - val_auc: 0.9899 - val_accuracy: 0.9691 - val_cost: 3.8889\n",
            "Epoch 94/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0750 - auc: 0.9946 - accuracy: 0.9775 - cost: 2.8704 - val_loss: 0.1097 - val_auc: 0.9898 - val_accuracy: 0.9692 - val_cost: 3.7533\n",
            "Epoch 95/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0752 - auc: 0.9946 - accuracy: 0.9773 - cost: 2.8935 - val_loss: 0.1090 - val_auc: 0.9898 - val_accuracy: 0.9691 - val_cost: 3.8922\n",
            "Epoch 96/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0754 - auc: 0.9946 - accuracy: 0.9772 - cost: 2.9147 - val_loss: 0.1101 - val_auc: 0.9896 - val_accuracy: 0.9684 - val_cost: 4.0509\n",
            "Epoch 97/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0749 - auc: 0.9945 - accuracy: 0.9772 - cost: 2.9167 - val_loss: 0.1089 - val_auc: 0.9898 - val_accuracy: 0.9693 - val_cost: 3.9087\n",
            "Epoch 98/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0748 - auc: 0.9945 - accuracy: 0.9773 - cost: 2.8924 - val_loss: 0.1085 - val_auc: 0.9898 - val_accuracy: 0.9690 - val_cost: 3.9021\n",
            "Epoch 99/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0745 - auc: 0.9947 - accuracy: 0.9777 - cost: 2.8519 - val_loss: 0.1077 - val_auc: 0.9898 - val_accuracy: 0.9704 - val_cost: 3.6839\n",
            "Epoch 100/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0730 - auc: 0.9948 - accuracy: 0.9777 - cost: 2.8368 - val_loss: 0.1086 - val_auc: 0.9898 - val_accuracy: 0.9697 - val_cost: 3.8228\n",
            "Epoch 101/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0739 - auc: 0.9947 - accuracy: 0.9775 - cost: 2.8696 - val_loss: 0.1107 - val_auc: 0.9895 - val_accuracy: 0.9685 - val_cost: 3.9550\n",
            "Epoch 102/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0732 - auc: 0.9948 - accuracy: 0.9779 - cost: 2.8152 - val_loss: 0.1074 - val_auc: 0.9900 - val_accuracy: 0.9697 - val_cost: 3.8426\n",
            "Epoch 103/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0729 - auc: 0.9949 - accuracy: 0.9780 - cost: 2.8171 - val_loss: 0.1111 - val_auc: 0.9896 - val_accuracy: 0.9688 - val_cost: 3.8856\n",
            "Epoch 104/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0734 - auc: 0.9948 - accuracy: 0.9777 - cost: 2.8453 - val_loss: 0.1098 - val_auc: 0.9897 - val_accuracy: 0.9698 - val_cost: 3.7500\n",
            "Epoch 105/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0726 - auc: 0.9949 - accuracy: 0.9782 - cost: 2.7832 - val_loss: 0.1076 - val_auc: 0.9901 - val_accuracy: 0.9694 - val_cost: 3.8393\n",
            "Epoch 106/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0727 - auc: 0.9948 - accuracy: 0.9782 - cost: 2.7855 - val_loss: 0.1086 - val_auc: 0.9899 - val_accuracy: 0.9699 - val_cost: 3.7302\n",
            "Epoch 107/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0734 - auc: 0.9948 - accuracy: 0.9777 - cost: 2.8476 - val_loss: 0.1089 - val_auc: 0.9899 - val_accuracy: 0.9686 - val_cost: 3.9947\n",
            "Epoch 108/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0724 - auc: 0.9949 - accuracy: 0.9777 - cost: 2.8476 - val_loss: 0.1092 - val_auc: 0.9899 - val_accuracy: 0.9697 - val_cost: 3.8955\n",
            "Epoch 109/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0725 - auc: 0.9949 - accuracy: 0.9782 - cost: 2.7801 - val_loss: 0.1098 - val_auc: 0.9899 - val_accuracy: 0.9693 - val_cost: 3.7963\n",
            "Epoch 110/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0714 - auc: 0.9949 - accuracy: 0.9786 - cost: 2.7280 - val_loss: 0.1081 - val_auc: 0.9899 - val_accuracy: 0.9704 - val_cost: 3.6673\n",
            "Epoch 111/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0716 - auc: 0.9949 - accuracy: 0.9784 - cost: 2.7623 - val_loss: 0.1087 - val_auc: 0.9899 - val_accuracy: 0.9699 - val_cost: 3.8690\n",
            "Epoch 112/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0706 - auc: 0.9949 - accuracy: 0.9791 - cost: 2.6794 - val_loss: 0.1082 - val_auc: 0.9897 - val_accuracy: 0.9697 - val_cost: 3.8426\n",
            "Epoch 113/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0714 - auc: 0.9950 - accuracy: 0.9786 - cost: 2.7288 - val_loss: 0.1100 - val_auc: 0.9899 - val_accuracy: 0.9690 - val_cost: 3.7798\n",
            "Epoch 114/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0716 - auc: 0.9949 - accuracy: 0.9785 - cost: 2.7442 - val_loss: 0.1072 - val_auc: 0.9901 - val_accuracy: 0.9715 - val_cost: 3.6045\n",
            "Epoch 115/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0715 - auc: 0.9949 - accuracy: 0.9785 - cost: 2.7450 - val_loss: 0.1070 - val_auc: 0.9900 - val_accuracy: 0.9701 - val_cost: 3.7665\n",
            "Epoch 116/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0706 - auc: 0.9950 - accuracy: 0.9790 - cost: 2.6833 - val_loss: 0.1074 - val_auc: 0.9899 - val_accuracy: 0.9700 - val_cost: 3.8294\n",
            "Epoch 117/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0715 - auc: 0.9950 - accuracy: 0.9787 - cost: 2.7207 - val_loss: 0.1066 - val_auc: 0.9899 - val_accuracy: 0.9710 - val_cost: 3.6343\n",
            "Epoch 118/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0708 - auc: 0.9949 - accuracy: 0.9792 - cost: 2.6547 - val_loss: 0.1079 - val_auc: 0.9898 - val_accuracy: 0.9702 - val_cost: 3.6938\n",
            "Epoch 119/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0700 - auc: 0.9951 - accuracy: 0.9794 - cost: 2.6343 - val_loss: 0.1087 - val_auc: 0.9897 - val_accuracy: 0.9703 - val_cost: 3.6971\n",
            "Epoch 120/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0706 - auc: 0.9951 - accuracy: 0.9788 - cost: 2.7106 - val_loss: 0.1066 - val_auc: 0.9901 - val_accuracy: 0.9701 - val_cost: 3.8128\n",
            "Epoch 121/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0704 - auc: 0.9951 - accuracy: 0.9788 - cost: 2.7029 - val_loss: 0.1095 - val_auc: 0.9898 - val_accuracy: 0.9696 - val_cost: 3.9187\n",
            "Epoch 122/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0700 - auc: 0.9950 - accuracy: 0.9789 - cost: 2.6844 - val_loss: 0.1080 - val_auc: 0.9897 - val_accuracy: 0.9699 - val_cost: 3.7864\n",
            "Epoch 123/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0700 - auc: 0.9951 - accuracy: 0.9792 - cost: 2.6632 - val_loss: 0.1075 - val_auc: 0.9898 - val_accuracy: 0.9698 - val_cost: 3.8988\n",
            "Epoch 124/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0692 - auc: 0.9952 - accuracy: 0.9793 - cost: 2.6431 - val_loss: 0.1079 - val_auc: 0.9900 - val_accuracy: 0.9714 - val_cost: 3.7037\n",
            "Epoch 125/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0688 - auc: 0.9953 - accuracy: 0.9792 - cost: 2.6431 - val_loss: 0.1087 - val_auc: 0.9897 - val_accuracy: 0.9709 - val_cost: 3.7070\n",
            "Epoch 126/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0691 - auc: 0.9952 - accuracy: 0.9791 - cost: 2.6674 - val_loss: 0.1098 - val_auc: 0.9895 - val_accuracy: 0.9699 - val_cost: 3.7897\n",
            "Epoch 127/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0685 - auc: 0.9953 - accuracy: 0.9794 - cost: 2.6346 - val_loss: 0.1080 - val_auc: 0.9899 - val_accuracy: 0.9708 - val_cost: 3.7269\n",
            "Epoch 128/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0688 - auc: 0.9953 - accuracy: 0.9795 - cost: 2.6138 - val_loss: 0.1090 - val_auc: 0.9900 - val_accuracy: 0.9699 - val_cost: 3.7864\n",
            "Epoch 129/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0682 - auc: 0.9952 - accuracy: 0.9798 - cost: 2.5733 - val_loss: 0.1086 - val_auc: 0.9895 - val_accuracy: 0.9697 - val_cost: 3.9616\n",
            "Epoch 130/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0688 - auc: 0.9953 - accuracy: 0.9795 - cost: 2.6200 - val_loss: 0.1075 - val_auc: 0.9896 - val_accuracy: 0.9712 - val_cost: 3.6772\n",
            "Epoch 131/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0684 - auc: 0.9953 - accuracy: 0.9789 - cost: 2.6894 - val_loss: 0.1063 - val_auc: 0.9901 - val_accuracy: 0.9712 - val_cost: 3.6905\n",
            "Epoch 132/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0685 - auc: 0.9953 - accuracy: 0.9795 - cost: 2.6184 - val_loss: 0.1101 - val_auc: 0.9896 - val_accuracy: 0.9699 - val_cost: 3.7765\n",
            "Epoch 133/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0674 - auc: 0.9954 - accuracy: 0.9798 - cost: 2.5899 - val_loss: 0.1090 - val_auc: 0.9898 - val_accuracy: 0.9710 - val_cost: 3.7136\n",
            "Epoch 134/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0683 - auc: 0.9952 - accuracy: 0.9794 - cost: 2.6327 - val_loss: 0.1075 - val_auc: 0.9901 - val_accuracy: 0.9714 - val_cost: 3.5880\n",
            "Epoch 135/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0675 - auc: 0.9954 - accuracy: 0.9801 - cost: 2.5544 - val_loss: 0.1083 - val_auc: 0.9898 - val_accuracy: 0.9714 - val_cost: 3.6442\n",
            "Epoch 136/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0685 - auc: 0.9953 - accuracy: 0.9795 - cost: 2.6223 - val_loss: 0.1088 - val_auc: 0.9896 - val_accuracy: 0.9715 - val_cost: 3.7037\n",
            "Epoch 137/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0677 - auc: 0.9953 - accuracy: 0.9797 - cost: 2.5899 - val_loss: 0.1077 - val_auc: 0.9900 - val_accuracy: 0.9704 - val_cost: 3.8558\n",
            "Epoch 138/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0669 - auc: 0.9954 - accuracy: 0.9802 - cost: 2.5367 - val_loss: 0.1079 - val_auc: 0.9896 - val_accuracy: 0.9706 - val_cost: 3.7335\n",
            "Epoch 139/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0669 - auc: 0.9954 - accuracy: 0.9799 - cost: 2.5613 - val_loss: 0.1061 - val_auc: 0.9899 - val_accuracy: 0.9713 - val_cost: 3.7665\n",
            "Epoch 140/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0666 - auc: 0.9955 - accuracy: 0.9797 - cost: 2.5895 - val_loss: 0.1076 - val_auc: 0.9896 - val_accuracy: 0.9706 - val_cost: 3.7566\n",
            "Epoch 141/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0670 - auc: 0.9953 - accuracy: 0.9805 - cost: 2.4988 - val_loss: 0.1109 - val_auc: 0.9897 - val_accuracy: 0.9706 - val_cost: 3.7500\n",
            "Epoch 142/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0662 - auc: 0.9954 - accuracy: 0.9799 - cost: 2.5598 - val_loss: 0.1077 - val_auc: 0.9900 - val_accuracy: 0.9703 - val_cost: 3.8228\n",
            "Epoch 143/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0668 - auc: 0.9953 - accuracy: 0.9803 - cost: 2.5220 - val_loss: 0.1098 - val_auc: 0.9897 - val_accuracy: 0.9712 - val_cost: 3.7070\n",
            "Epoch 144/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0666 - auc: 0.9955 - accuracy: 0.9800 - cost: 2.5505 - val_loss: 0.1095 - val_auc: 0.9894 - val_accuracy: 0.9708 - val_cost: 3.7136\n",
            "Epoch 145/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0665 - auc: 0.9954 - accuracy: 0.9802 - cost: 2.5293 - val_loss: 0.1097 - val_auc: 0.9895 - val_accuracy: 0.9697 - val_cost: 3.9716\n",
            "Epoch 146/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0664 - auc: 0.9954 - accuracy: 0.9804 - cost: 2.5085 - val_loss: 0.1096 - val_auc: 0.9897 - val_accuracy: 0.9701 - val_cost: 3.8955\n",
            "Epoch 147/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0663 - auc: 0.9954 - accuracy: 0.9803 - cost: 2.5224 - val_loss: 0.1078 - val_auc: 0.9900 - val_accuracy: 0.9717 - val_cost: 3.6839\n",
            "Epoch 148/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0668 - auc: 0.9955 - accuracy: 0.9797 - cost: 2.5907 - val_loss: 0.1095 - val_auc: 0.9898 - val_accuracy: 0.9707 - val_cost: 3.7169\n",
            "Epoch 149/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0661 - auc: 0.9955 - accuracy: 0.9803 - cost: 2.5185 - val_loss: 0.1089 - val_auc: 0.9895 - val_accuracy: 0.9714 - val_cost: 3.7169\n",
            "Epoch 150/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0662 - auc: 0.9954 - accuracy: 0.9806 - cost: 2.4711 - val_loss: 0.1124 - val_auc: 0.9898 - val_accuracy: 0.9709 - val_cost: 3.6409\n",
            "Epoch 151/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0653 - auc: 0.9956 - accuracy: 0.9811 - cost: 2.4128 - val_loss: 0.1066 - val_auc: 0.9900 - val_accuracy: 0.9710 - val_cost: 3.7864\n",
            "Epoch 152/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0657 - auc: 0.9956 - accuracy: 0.9802 - cost: 2.5382 - val_loss: 0.1072 - val_auc: 0.9902 - val_accuracy: 0.9702 - val_cost: 3.7996\n",
            "Epoch 153/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0658 - auc: 0.9955 - accuracy: 0.9796 - cost: 2.6030 - val_loss: 0.1091 - val_auc: 0.9898 - val_accuracy: 0.9713 - val_cost: 3.7269\n",
            "Epoch 154/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0647 - auc: 0.9956 - accuracy: 0.9809 - cost: 2.4406 - val_loss: 0.1073 - val_auc: 0.9898 - val_accuracy: 0.9715 - val_cost: 3.6310\n",
            "Epoch 155/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0648 - auc: 0.9956 - accuracy: 0.9806 - cost: 2.4857 - val_loss: 0.1087 - val_auc: 0.9898 - val_accuracy: 0.9703 - val_cost: 3.7401\n",
            "Epoch 156/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0650 - auc: 0.9956 - accuracy: 0.9809 - cost: 2.4495 - val_loss: 0.1089 - val_auc: 0.9898 - val_accuracy: 0.9706 - val_cost: 3.7566\n",
            "Epoch 157/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0649 - auc: 0.9957 - accuracy: 0.9805 - cost: 2.5027 - val_loss: 0.1089 - val_auc: 0.9900 - val_accuracy: 0.9721 - val_cost: 3.5218\n",
            "Epoch 158/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0652 - auc: 0.9956 - accuracy: 0.9806 - cost: 2.4803 - val_loss: 0.1097 - val_auc: 0.9896 - val_accuracy: 0.9709 - val_cost: 3.7335\n",
            "Epoch 159/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0647 - auc: 0.9956 - accuracy: 0.9804 - cost: 2.5162 - val_loss: 0.1090 - val_auc: 0.9899 - val_accuracy: 0.9719 - val_cost: 3.6475\n",
            "Epoch 160/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0646 - auc: 0.9956 - accuracy: 0.9806 - cost: 2.4826 - val_loss: 0.1085 - val_auc: 0.9898 - val_accuracy: 0.9706 - val_cost: 3.8029\n",
            "Epoch 161/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0646 - auc: 0.9958 - accuracy: 0.9806 - cost: 2.4784 - val_loss: 0.1097 - val_auc: 0.9897 - val_accuracy: 0.9708 - val_cost: 3.8492\n",
            "Epoch 162/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0637 - auc: 0.9958 - accuracy: 0.9814 - cost: 2.3742 - val_loss: 0.1096 - val_auc: 0.9896 - val_accuracy: 0.9717 - val_cost: 3.6971\n",
            "Epoch 163/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0637 - auc: 0.9957 - accuracy: 0.9812 - cost: 2.4063 - val_loss: 0.1093 - val_auc: 0.9898 - val_accuracy: 0.9706 - val_cost: 3.7467\n",
            "Epoch 164/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0637 - auc: 0.9957 - accuracy: 0.9810 - cost: 2.4286 - val_loss: 0.1086 - val_auc: 0.9898 - val_accuracy: 0.9718 - val_cost: 3.6177\n",
            "Epoch 165/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0643 - auc: 0.9957 - accuracy: 0.9811 - cost: 2.4240 - val_loss: 0.1083 - val_auc: 0.9898 - val_accuracy: 0.9703 - val_cost: 3.8856\n",
            "Epoch 166/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0641 - auc: 0.9957 - accuracy: 0.9805 - cost: 2.4915 - val_loss: 0.1089 - val_auc: 0.9899 - val_accuracy: 0.9722 - val_cost: 3.6078\n",
            "Epoch 167/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0636 - auc: 0.9957 - accuracy: 0.9813 - cost: 2.3870 - val_loss: 0.1088 - val_auc: 0.9897 - val_accuracy: 0.9711 - val_cost: 3.7798\n",
            "Epoch 168/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0641 - auc: 0.9958 - accuracy: 0.9810 - cost: 2.4263 - val_loss: 0.1118 - val_auc: 0.9896 - val_accuracy: 0.9703 - val_cost: 3.7566\n",
            "Epoch 169/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0640 - auc: 0.9957 - accuracy: 0.9809 - cost: 2.4452 - val_loss: 0.1096 - val_auc: 0.9898 - val_accuracy: 0.9709 - val_cost: 3.7335\n",
            "Epoch 170/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0647 - auc: 0.9956 - accuracy: 0.9808 - cost: 2.4537 - val_loss: 0.1089 - val_auc: 0.9897 - val_accuracy: 0.9706 - val_cost: 3.8790\n",
            "Epoch 171/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0632 - auc: 0.9957 - accuracy: 0.9817 - cost: 2.3422 - val_loss: 0.1102 - val_auc: 0.9896 - val_accuracy: 0.9719 - val_cost: 3.6310\n",
            "Epoch 172/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0636 - auc: 0.9957 - accuracy: 0.9812 - cost: 2.4109 - val_loss: 0.1076 - val_auc: 0.9898 - val_accuracy: 0.9719 - val_cost: 3.6739\n",
            "Epoch 173/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0640 - auc: 0.9957 - accuracy: 0.9808 - cost: 2.4657 - val_loss: 0.1083 - val_auc: 0.9900 - val_accuracy: 0.9709 - val_cost: 3.7467\n",
            "Epoch 174/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0637 - auc: 0.9958 - accuracy: 0.9812 - cost: 2.4167 - val_loss: 0.1096 - val_auc: 0.9898 - val_accuracy: 0.9713 - val_cost: 3.6210\n",
            "Epoch 175/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0627 - auc: 0.9959 - accuracy: 0.9812 - cost: 2.3935 - val_loss: 0.1100 - val_auc: 0.9896 - val_accuracy: 0.9717 - val_cost: 3.6210\n",
            "Epoch 176/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0632 - auc: 0.9958 - accuracy: 0.9812 - cost: 2.4016 - val_loss: 0.1115 - val_auc: 0.9896 - val_accuracy: 0.9715 - val_cost: 3.7269\n",
            "Epoch 177/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0629 - auc: 0.9958 - accuracy: 0.9816 - cost: 2.3573 - val_loss: 0.1099 - val_auc: 0.9898 - val_accuracy: 0.9714 - val_cost: 3.7467\n",
            "Epoch 178/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0630 - auc: 0.9957 - accuracy: 0.9809 - cost: 2.4360 - val_loss: 0.1097 - val_auc: 0.9899 - val_accuracy: 0.9713 - val_cost: 3.6607\n",
            "Epoch 179/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0617 - auc: 0.9960 - accuracy: 0.9815 - cost: 2.3696 - val_loss: 0.1096 - val_auc: 0.9898 - val_accuracy: 0.9713 - val_cost: 3.6772\n",
            "Epoch 180/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0625 - auc: 0.9959 - accuracy: 0.9814 - cost: 2.3881 - val_loss: 0.1117 - val_auc: 0.9898 - val_accuracy: 0.9707 - val_cost: 3.8029\n",
            "Epoch 181/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0630 - auc: 0.9958 - accuracy: 0.9814 - cost: 2.3877 - val_loss: 0.1116 - val_auc: 0.9897 - val_accuracy: 0.9712 - val_cost: 3.6343\n",
            "Epoch 182/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0624 - auc: 0.9960 - accuracy: 0.9813 - cost: 2.3846 - val_loss: 0.1109 - val_auc: 0.9895 - val_accuracy: 0.9712 - val_cost: 3.7136\n",
            "Epoch 183/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0633 - auc: 0.9958 - accuracy: 0.9807 - cost: 2.4626 - val_loss: 0.1108 - val_auc: 0.9897 - val_accuracy: 0.9711 - val_cost: 3.6475\n",
            "Epoch 184/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0621 - auc: 0.9960 - accuracy: 0.9816 - cost: 2.3457 - val_loss: 0.1130 - val_auc: 0.9895 - val_accuracy: 0.9699 - val_cost: 3.8922\n",
            "Epoch 185/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0615 - auc: 0.9958 - accuracy: 0.9819 - cost: 2.3167 - val_loss: 0.1114 - val_auc: 0.9899 - val_accuracy: 0.9717 - val_cost: 3.6177\n",
            "Epoch 186/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0630 - auc: 0.9958 - accuracy: 0.9812 - cost: 2.4024 - val_loss: 0.1139 - val_auc: 0.9892 - val_accuracy: 0.9709 - val_cost: 3.6640\n",
            "Epoch 187/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0622 - auc: 0.9960 - accuracy: 0.9815 - cost: 2.3657 - val_loss: 0.1108 - val_auc: 0.9899 - val_accuracy: 0.9708 - val_cost: 3.8128\n",
            "Epoch 188/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0617 - auc: 0.9959 - accuracy: 0.9816 - cost: 2.3507 - val_loss: 0.1109 - val_auc: 0.9898 - val_accuracy: 0.9714 - val_cost: 3.7698\n",
            "Epoch 189/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0614 - auc: 0.9961 - accuracy: 0.9816 - cost: 2.3546 - val_loss: 0.1125 - val_auc: 0.9894 - val_accuracy: 0.9703 - val_cost: 3.8922\n",
            "Epoch 190/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0621 - auc: 0.9960 - accuracy: 0.9814 - cost: 2.3735 - val_loss: 0.1109 - val_auc: 0.9895 - val_accuracy: 0.9713 - val_cost: 3.6872\n",
            "Epoch 191/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0615 - auc: 0.9960 - accuracy: 0.9816 - cost: 2.3515 - val_loss: 0.1098 - val_auc: 0.9898 - val_accuracy: 0.9725 - val_cost: 3.5615\n",
            "Epoch 192/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0615 - auc: 0.9960 - accuracy: 0.9815 - cost: 2.3711 - val_loss: 0.1110 - val_auc: 0.9897 - val_accuracy: 0.9715 - val_cost: 3.6806\n",
            "Epoch 193/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0616 - auc: 0.9961 - accuracy: 0.9812 - cost: 2.4101 - val_loss: 0.1103 - val_auc: 0.9899 - val_accuracy: 0.9718 - val_cost: 3.6640\n",
            "Epoch 194/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0616 - auc: 0.9959 - accuracy: 0.9818 - cost: 2.3438 - val_loss: 0.1109 - val_auc: 0.9899 - val_accuracy: 0.9717 - val_cost: 3.5152\n",
            "Epoch 195/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0616 - auc: 0.9961 - accuracy: 0.9813 - cost: 2.3927 - val_loss: 0.1104 - val_auc: 0.9896 - val_accuracy: 0.9718 - val_cost: 3.6409\n",
            "Epoch 196/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0610 - auc: 0.9961 - accuracy: 0.9818 - cost: 2.3349 - val_loss: 0.1113 - val_auc: 0.9897 - val_accuracy: 0.9719 - val_cost: 3.5152\n",
            "Epoch 197/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0615 - auc: 0.9961 - accuracy: 0.9814 - cost: 2.3696 - val_loss: 0.1115 - val_auc: 0.9893 - val_accuracy: 0.9717 - val_cost: 3.6442\n",
            "Epoch 198/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0618 - auc: 0.9960 - accuracy: 0.9816 - cost: 2.3542 - val_loss: 0.1120 - val_auc: 0.9898 - val_accuracy: 0.9712 - val_cost: 3.7798\n",
            "Epoch 199/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0620 - auc: 0.9959 - accuracy: 0.9817 - cost: 2.3414 - val_loss: 0.1129 - val_auc: 0.9899 - val_accuracy: 0.9708 - val_cost: 3.7533\n",
            "Epoch 200/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0612 - auc: 0.9960 - accuracy: 0.9817 - cost: 2.3306 - val_loss: 0.1088 - val_auc: 0.9900 - val_accuracy: 0.9712 - val_cost: 3.8062\n",
            "Epoch 201/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0609 - auc: 0.9961 - accuracy: 0.9820 - cost: 2.3171 - val_loss: 0.1114 - val_auc: 0.9897 - val_accuracy: 0.9713 - val_cost: 3.6574\n",
            "Epoch 202/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0607 - auc: 0.9961 - accuracy: 0.9820 - cost: 2.3090 - val_loss: 0.1116 - val_auc: 0.9897 - val_accuracy: 0.9711 - val_cost: 3.7665\n",
            "Epoch 203/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0610 - auc: 0.9960 - accuracy: 0.9817 - cost: 2.3457 - val_loss: 0.1105 - val_auc: 0.9898 - val_accuracy: 0.9717 - val_cost: 3.7335\n",
            "Epoch 204/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0604 - auc: 0.9962 - accuracy: 0.9816 - cost: 2.3461 - val_loss: 0.1134 - val_auc: 0.9895 - val_accuracy: 0.9713 - val_cost: 3.7070\n",
            "Epoch 205/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0613 - auc: 0.9960 - accuracy: 0.9818 - cost: 2.3225 - val_loss: 0.1134 - val_auc: 0.9895 - val_accuracy: 0.9707 - val_cost: 3.7004\n",
            "Epoch 206/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0613 - auc: 0.9960 - accuracy: 0.9816 - cost: 2.3619 - val_loss: 0.1127 - val_auc: 0.9899 - val_accuracy: 0.9722 - val_cost: 3.5284\n",
            "Epoch 207/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0613 - auc: 0.9960 - accuracy: 0.9819 - cost: 2.3140 - val_loss: 0.1120 - val_auc: 0.9899 - val_accuracy: 0.9714 - val_cost: 3.6409\n",
            "Epoch 208/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0605 - auc: 0.9961 - accuracy: 0.9819 - cost: 2.3110 - val_loss: 0.1125 - val_auc: 0.9899 - val_accuracy: 0.9712 - val_cost: 3.7335\n",
            "Epoch 209/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0601 - auc: 0.9961 - accuracy: 0.9819 - cost: 2.3310 - val_loss: 0.1138 - val_auc: 0.9895 - val_accuracy: 0.9708 - val_cost: 3.7566\n",
            "Epoch 210/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0603 - auc: 0.9962 - accuracy: 0.9820 - cost: 2.2998 - val_loss: 0.1144 - val_auc: 0.9896 - val_accuracy: 0.9719 - val_cost: 3.5417\n",
            "Epoch 211/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0605 - auc: 0.9961 - accuracy: 0.9817 - cost: 2.3437 - val_loss: 0.1146 - val_auc: 0.9896 - val_accuracy: 0.9711 - val_cost: 3.6409\n",
            "Epoch 212/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0606 - auc: 0.9961 - accuracy: 0.9823 - cost: 2.2585 - val_loss: 0.1108 - val_auc: 0.9900 - val_accuracy: 0.9705 - val_cost: 3.8062\n",
            "Epoch 213/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0601 - auc: 0.9962 - accuracy: 0.9823 - cost: 2.2778 - val_loss: 0.1126 - val_auc: 0.9895 - val_accuracy: 0.9710 - val_cost: 3.7566\n",
            "Epoch 214/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0599 - auc: 0.9963 - accuracy: 0.9821 - cost: 2.2982 - val_loss: 0.1138 - val_auc: 0.9895 - val_accuracy: 0.9718 - val_cost: 3.6078\n",
            "Epoch 215/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0598 - auc: 0.9962 - accuracy: 0.9823 - cost: 2.2647 - val_loss: 0.1156 - val_auc: 0.9893 - val_accuracy: 0.9710 - val_cost: 3.7103\n",
            "Epoch 216/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0597 - auc: 0.9963 - accuracy: 0.9823 - cost: 2.2674 - val_loss: 0.1140 - val_auc: 0.9894 - val_accuracy: 0.9704 - val_cost: 3.8095\n",
            "Epoch 217/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0609 - auc: 0.9961 - accuracy: 0.9817 - cost: 2.3399 - val_loss: 0.1134 - val_auc: 0.9895 - val_accuracy: 0.9706 - val_cost: 3.8459\n",
            "Epoch 218/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0600 - auc: 0.9962 - accuracy: 0.9820 - cost: 2.2955 - val_loss: 0.1135 - val_auc: 0.9898 - val_accuracy: 0.9715 - val_cost: 3.6409\n",
            "Epoch 219/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0596 - auc: 0.9963 - accuracy: 0.9819 - cost: 2.3164 - val_loss: 0.1139 - val_auc: 0.9897 - val_accuracy: 0.9717 - val_cost: 3.6376\n",
            "Epoch 220/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0598 - auc: 0.9962 - accuracy: 0.9820 - cost: 2.2971 - val_loss: 0.1148 - val_auc: 0.9897 - val_accuracy: 0.9712 - val_cost: 3.7202\n",
            "Epoch 221/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0585 - auc: 0.9963 - accuracy: 0.9826 - cost: 2.2269 - val_loss: 0.1126 - val_auc: 0.9896 - val_accuracy: 0.9712 - val_cost: 3.6442\n",
            "Epoch 222/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0598 - auc: 0.9962 - accuracy: 0.9821 - cost: 2.3002 - val_loss: 0.1130 - val_auc: 0.9897 - val_accuracy: 0.9709 - val_cost: 3.6971\n",
            "Epoch 223/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0602 - auc: 0.9962 - accuracy: 0.9820 - cost: 2.3171 - val_loss: 0.1148 - val_auc: 0.9898 - val_accuracy: 0.9711 - val_cost: 3.7037\n",
            "Epoch 224/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0597 - auc: 0.9963 - accuracy: 0.9822 - cost: 2.2789 - val_loss: 0.1141 - val_auc: 0.9894 - val_accuracy: 0.9708 - val_cost: 3.7235\n",
            "Epoch 225/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0590 - auc: 0.9962 - accuracy: 0.9824 - cost: 2.2608 - val_loss: 0.1146 - val_auc: 0.9893 - val_accuracy: 0.9707 - val_cost: 3.7335\n",
            "Epoch 226/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0592 - auc: 0.9963 - accuracy: 0.9824 - cost: 2.2677 - val_loss: 0.1151 - val_auc: 0.9896 - val_accuracy: 0.9711 - val_cost: 3.6806\n",
            "Epoch 227/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0593 - auc: 0.9963 - accuracy: 0.9826 - cost: 2.2334 - val_loss: 0.1135 - val_auc: 0.9893 - val_accuracy: 0.9710 - val_cost: 3.7269\n",
            "Epoch 228/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0600 - auc: 0.9963 - accuracy: 0.9817 - cost: 2.3345 - val_loss: 0.1153 - val_auc: 0.9894 - val_accuracy: 0.9703 - val_cost: 3.9021\n",
            "Epoch 229/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0600 - auc: 0.9961 - accuracy: 0.9818 - cost: 2.3380 - val_loss: 0.1156 - val_auc: 0.9891 - val_accuracy: 0.9715 - val_cost: 3.6640\n",
            "Epoch 230/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0595 - auc: 0.9962 - accuracy: 0.9823 - cost: 2.2596 - val_loss: 0.1155 - val_auc: 0.9896 - val_accuracy: 0.9709 - val_cost: 3.7434\n",
            "Epoch 231/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0591 - auc: 0.9963 - accuracy: 0.9825 - cost: 2.2315 - val_loss: 0.1142 - val_auc: 0.9895 - val_accuracy: 0.9715 - val_cost: 3.6872\n",
            "Epoch 232/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0594 - auc: 0.9964 - accuracy: 0.9823 - cost: 2.2639 - val_loss: 0.1163 - val_auc: 0.9895 - val_accuracy: 0.9709 - val_cost: 3.7004\n",
            "Epoch 233/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0580 - auc: 0.9964 - accuracy: 0.9825 - cost: 2.2357 - val_loss: 0.1153 - val_auc: 0.9898 - val_accuracy: 0.9708 - val_cost: 3.7897\n",
            "Epoch 234/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0586 - auc: 0.9963 - accuracy: 0.9824 - cost: 2.2585 - val_loss: 0.1151 - val_auc: 0.9898 - val_accuracy: 0.9720 - val_cost: 3.5946\n",
            "Epoch 235/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0587 - auc: 0.9964 - accuracy: 0.9825 - cost: 2.2392 - val_loss: 0.1146 - val_auc: 0.9898 - val_accuracy: 0.9707 - val_cost: 3.7798\n",
            "Epoch 236/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0586 - auc: 0.9964 - accuracy: 0.9826 - cost: 2.2280 - val_loss: 0.1149 - val_auc: 0.9897 - val_accuracy: 0.9706 - val_cost: 3.8294\n",
            "Epoch 237/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0583 - auc: 0.9963 - accuracy: 0.9826 - cost: 2.2218 - val_loss: 0.1148 - val_auc: 0.9893 - val_accuracy: 0.9709 - val_cost: 3.7368\n",
            "Epoch 238/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0590 - auc: 0.9963 - accuracy: 0.9822 - cost: 2.2809 - val_loss: 0.1159 - val_auc: 0.9892 - val_accuracy: 0.9711 - val_cost: 3.7731\n",
            "Epoch 239/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0579 - auc: 0.9965 - accuracy: 0.9827 - cost: 2.2230 - val_loss: 0.1153 - val_auc: 0.9896 - val_accuracy: 0.9710 - val_cost: 3.7533\n",
            "Epoch 240/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0576 - auc: 0.9964 - accuracy: 0.9827 - cost: 2.2049 - val_loss: 0.1146 - val_auc: 0.9896 - val_accuracy: 0.9719 - val_cost: 3.7037\n",
            "Epoch 241/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0585 - auc: 0.9963 - accuracy: 0.9824 - cost: 2.2573 - val_loss: 0.1148 - val_auc: 0.9898 - val_accuracy: 0.9717 - val_cost: 3.6739\n",
            "Epoch 242/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0583 - auc: 0.9964 - accuracy: 0.9827 - cost: 2.2257 - val_loss: 0.1166 - val_auc: 0.9895 - val_accuracy: 0.9709 - val_cost: 3.7566\n",
            "Epoch 243/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0590 - auc: 0.9963 - accuracy: 0.9820 - cost: 2.3098 - val_loss: 0.1143 - val_auc: 0.9899 - val_accuracy: 0.9698 - val_cost: 3.9716\n",
            "Epoch 244/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0587 - auc: 0.9963 - accuracy: 0.9822 - cost: 2.2874 - val_loss: 0.1158 - val_auc: 0.9896 - val_accuracy: 0.9709 - val_cost: 3.7963\n",
            "Epoch 245/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0584 - auc: 0.9964 - accuracy: 0.9822 - cost: 2.2932 - val_loss: 0.1149 - val_auc: 0.9895 - val_accuracy: 0.9714 - val_cost: 3.7235\n",
            "Epoch 246/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0588 - auc: 0.9964 - accuracy: 0.9824 - cost: 2.2577 - val_loss: 0.1155 - val_auc: 0.9897 - val_accuracy: 0.9704 - val_cost: 3.8261\n",
            "Epoch 247/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0591 - auc: 0.9963 - accuracy: 0.9824 - cost: 2.2558 - val_loss: 0.1158 - val_auc: 0.9898 - val_accuracy: 0.9713 - val_cost: 3.7665\n",
            "Epoch 248/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0589 - auc: 0.9963 - accuracy: 0.9824 - cost: 2.2589 - val_loss: 0.1151 - val_auc: 0.9896 - val_accuracy: 0.9703 - val_cost: 3.8294\n",
            "Epoch 249/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0578 - auc: 0.9964 - accuracy: 0.9828 - cost: 2.2079 - val_loss: 0.1157 - val_auc: 0.9895 - val_accuracy: 0.9708 - val_cost: 3.7963\n",
            "Epoch 250/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0583 - auc: 0.9964 - accuracy: 0.9823 - cost: 2.2635 - val_loss: 0.1151 - val_auc: 0.9900 - val_accuracy: 0.9708 - val_cost: 3.8128\n",
            "Epoch 251/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0575 - auc: 0.9965 - accuracy: 0.9829 - cost: 2.1944 - val_loss: 0.1168 - val_auc: 0.9898 - val_accuracy: 0.9707 - val_cost: 3.7368\n",
            "Epoch 252/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0581 - auc: 0.9965 - accuracy: 0.9826 - cost: 2.2280 - val_loss: 0.1163 - val_auc: 0.9895 - val_accuracy: 0.9714 - val_cost: 3.6839\n",
            "Epoch 253/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0577 - auc: 0.9964 - accuracy: 0.9825 - cost: 2.2431 - val_loss: 0.1181 - val_auc: 0.9896 - val_accuracy: 0.9715 - val_cost: 3.7202\n",
            "Epoch 254/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0581 - auc: 0.9964 - accuracy: 0.9822 - cost: 2.2867 - val_loss: 0.1158 - val_auc: 0.9899 - val_accuracy: 0.9710 - val_cost: 3.6872\n",
            "Epoch 255/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0578 - auc: 0.9965 - accuracy: 0.9825 - cost: 2.2458 - val_loss: 0.1160 - val_auc: 0.9894 - val_accuracy: 0.9722 - val_cost: 3.5251\n",
            "Epoch 256/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0587 - auc: 0.9963 - accuracy: 0.9822 - cost: 2.2843 - val_loss: 0.1172 - val_auc: 0.9898 - val_accuracy: 0.9708 - val_cost: 3.7798\n",
            "Epoch 257/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0580 - auc: 0.9964 - accuracy: 0.9828 - cost: 2.2083 - val_loss: 0.1174 - val_auc: 0.9893 - val_accuracy: 0.9710 - val_cost: 3.7831\n",
            "Epoch 258/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0576 - auc: 0.9964 - accuracy: 0.9825 - cost: 2.2442 - val_loss: 0.1146 - val_auc: 0.9897 - val_accuracy: 0.9709 - val_cost: 3.7368\n",
            "Epoch 259/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0576 - auc: 0.9964 - accuracy: 0.9825 - cost: 2.2400 - val_loss: 0.1157 - val_auc: 0.9897 - val_accuracy: 0.9709 - val_cost: 3.7235\n",
            "Epoch 260/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0582 - auc: 0.9965 - accuracy: 0.9825 - cost: 2.2485 - val_loss: 0.1200 - val_auc: 0.9894 - val_accuracy: 0.9703 - val_cost: 3.8360\n",
            "Epoch 261/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0578 - auc: 0.9965 - accuracy: 0.9825 - cost: 2.2427 - val_loss: 0.1163 - val_auc: 0.9895 - val_accuracy: 0.9713 - val_cost: 3.7599\n",
            "Epoch 262/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0567 - auc: 0.9965 - accuracy: 0.9830 - cost: 2.1725 - val_loss: 0.1160 - val_auc: 0.9898 - val_accuracy: 0.9713 - val_cost: 3.6839\n",
            "Epoch 263/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0575 - auc: 0.9966 - accuracy: 0.9826 - cost: 2.2323 - val_loss: 0.1164 - val_auc: 0.9896 - val_accuracy: 0.9718 - val_cost: 3.6177\n",
            "Epoch 264/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0574 - auc: 0.9964 - accuracy: 0.9830 - cost: 2.1821 - val_loss: 0.1174 - val_auc: 0.9896 - val_accuracy: 0.9708 - val_cost: 3.6872\n",
            "Epoch 265/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0565 - auc: 0.9967 - accuracy: 0.9831 - cost: 2.1559 - val_loss: 0.1181 - val_auc: 0.9894 - val_accuracy: 0.9701 - val_cost: 3.7335\n",
            "Epoch 266/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0569 - auc: 0.9965 - accuracy: 0.9831 - cost: 2.1782 - val_loss: 0.1157 - val_auc: 0.9897 - val_accuracy: 0.9714 - val_cost: 3.6673\n",
            "Epoch 267/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0568 - auc: 0.9966 - accuracy: 0.9828 - cost: 2.2014 - val_loss: 0.1185 - val_auc: 0.9895 - val_accuracy: 0.9705 - val_cost: 3.8261\n",
            "Epoch 268/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0572 - auc: 0.9964 - accuracy: 0.9828 - cost: 2.2010 - val_loss: 0.1174 - val_auc: 0.9895 - val_accuracy: 0.9709 - val_cost: 3.8426\n",
            "Epoch 269/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0565 - auc: 0.9965 - accuracy: 0.9832 - cost: 2.1617 - val_loss: 0.1179 - val_auc: 0.9895 - val_accuracy: 0.9697 - val_cost: 3.8492\n",
            "Epoch 270/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0564 - auc: 0.9965 - accuracy: 0.9832 - cost: 2.1609 - val_loss: 0.1206 - val_auc: 0.9892 - val_accuracy: 0.9708 - val_cost: 3.6640\n",
            "Epoch 271/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0562 - auc: 0.9966 - accuracy: 0.9829 - cost: 2.1898 - val_loss: 0.1192 - val_auc: 0.9893 - val_accuracy: 0.9708 - val_cost: 3.7136\n",
            "Epoch 272/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0568 - auc: 0.9966 - accuracy: 0.9829 - cost: 2.1844 - val_loss: 0.1194 - val_auc: 0.9897 - val_accuracy: 0.9703 - val_cost: 3.9716\n",
            "Epoch 273/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0564 - auc: 0.9966 - accuracy: 0.9833 - cost: 2.1497 - val_loss: 0.1185 - val_auc: 0.9894 - val_accuracy: 0.9720 - val_cost: 3.4987\n",
            "Epoch 274/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0567 - auc: 0.9966 - accuracy: 0.9829 - cost: 2.1971 - val_loss: 0.1192 - val_auc: 0.9893 - val_accuracy: 0.9706 - val_cost: 3.8161\n",
            "Epoch 275/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0568 - auc: 0.9965 - accuracy: 0.9830 - cost: 2.1782 - val_loss: 0.1183 - val_auc: 0.9894 - val_accuracy: 0.9709 - val_cost: 3.7831\n",
            "Epoch 276/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0572 - auc: 0.9965 - accuracy: 0.9828 - cost: 2.2041 - val_loss: 0.1187 - val_auc: 0.9896 - val_accuracy: 0.9714 - val_cost: 3.6442\n",
            "Epoch 277/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0573 - auc: 0.9965 - accuracy: 0.9830 - cost: 2.1779 - val_loss: 0.1164 - val_auc: 0.9898 - val_accuracy: 0.9699 - val_cost: 3.7864\n",
            "Epoch 278/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0582 - auc: 0.9964 - accuracy: 0.9825 - cost: 2.2288 - val_loss: 0.1175 - val_auc: 0.9897 - val_accuracy: 0.9720 - val_cost: 3.6078\n",
            "Epoch 279/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0564 - auc: 0.9966 - accuracy: 0.9829 - cost: 2.1948 - val_loss: 0.1165 - val_auc: 0.9896 - val_accuracy: 0.9724 - val_cost: 3.5615\n",
            "Epoch 280/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0571 - auc: 0.9965 - accuracy: 0.9830 - cost: 2.1860 - val_loss: 0.1169 - val_auc: 0.9897 - val_accuracy: 0.9714 - val_cost: 3.6673\n",
            "Epoch 281/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0577 - auc: 0.9964 - accuracy: 0.9827 - cost: 2.2218 - val_loss: 0.1171 - val_auc: 0.9897 - val_accuracy: 0.9718 - val_cost: 3.5913\n",
            "Epoch 282/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0563 - auc: 0.9965 - accuracy: 0.9833 - cost: 2.1358 - val_loss: 0.1181 - val_auc: 0.9896 - val_accuracy: 0.9717 - val_cost: 3.6839\n",
            "Epoch 283/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0572 - auc: 0.9966 - accuracy: 0.9826 - cost: 2.2369 - val_loss: 0.1186 - val_auc: 0.9897 - val_accuracy: 0.9706 - val_cost: 3.7831\n",
            "Epoch 284/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0561 - auc: 0.9965 - accuracy: 0.9832 - cost: 2.1555 - val_loss: 0.1177 - val_auc: 0.9895 - val_accuracy: 0.9703 - val_cost: 3.8558\n",
            "Epoch 285/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0561 - auc: 0.9966 - accuracy: 0.9831 - cost: 2.1713 - val_loss: 0.1203 - val_auc: 0.9896 - val_accuracy: 0.9721 - val_cost: 3.5020\n",
            "Epoch 286/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0558 - auc: 0.9965 - accuracy: 0.9833 - cost: 2.1420 - val_loss: 0.1203 - val_auc: 0.9895 - val_accuracy: 0.9717 - val_cost: 3.5648\n",
            "Epoch 287/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0573 - auc: 0.9965 - accuracy: 0.9823 - cost: 2.2712 - val_loss: 0.1177 - val_auc: 0.9896 - val_accuracy: 0.9714 - val_cost: 3.7665\n",
            "Epoch 288/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0571 - auc: 0.9966 - accuracy: 0.9827 - cost: 2.2242 - val_loss: 0.1189 - val_auc: 0.9894 - val_accuracy: 0.9714 - val_cost: 3.8095\n",
            "Epoch 289/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0562 - auc: 0.9967 - accuracy: 0.9830 - cost: 2.1701 - val_loss: 0.1185 - val_auc: 0.9894 - val_accuracy: 0.9711 - val_cost: 3.7864\n",
            "Epoch 290/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0568 - auc: 0.9966 - accuracy: 0.9833 - cost: 2.1505 - val_loss: 0.1188 - val_auc: 0.9893 - val_accuracy: 0.9715 - val_cost: 3.6343\n",
            "Epoch 291/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0558 - auc: 0.9967 - accuracy: 0.9831 - cost: 2.1636 - val_loss: 0.1197 - val_auc: 0.9895 - val_accuracy: 0.9701 - val_cost: 3.8724\n",
            "Epoch 292/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0558 - auc: 0.9966 - accuracy: 0.9832 - cost: 2.1478 - val_loss: 0.1185 - val_auc: 0.9896 - val_accuracy: 0.9709 - val_cost: 3.7401\n",
            "Epoch 293/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0555 - auc: 0.9967 - accuracy: 0.9831 - cost: 2.1663 - val_loss: 0.1171 - val_auc: 0.9894 - val_accuracy: 0.9708 - val_cost: 3.7401\n",
            "Epoch 294/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0564 - auc: 0.9966 - accuracy: 0.9834 - cost: 2.1273 - val_loss: 0.1191 - val_auc: 0.9892 - val_accuracy: 0.9698 - val_cost: 3.9649\n",
            "Epoch 295/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0558 - auc: 0.9966 - accuracy: 0.9828 - cost: 2.2083 - val_loss: 0.1214 - val_auc: 0.9894 - val_accuracy: 0.9707 - val_cost: 3.7632\n",
            "Epoch 296/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0553 - auc: 0.9967 - accuracy: 0.9831 - cost: 2.1547 - val_loss: 0.1189 - val_auc: 0.9893 - val_accuracy: 0.9703 - val_cost: 3.8459\n",
            "Epoch 297/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0565 - auc: 0.9966 - accuracy: 0.9831 - cost: 2.1632 - val_loss: 0.1200 - val_auc: 0.9894 - val_accuracy: 0.9705 - val_cost: 3.8261\n",
            "Epoch 298/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0559 - auc: 0.9966 - accuracy: 0.9833 - cost: 2.1431 - val_loss: 0.1206 - val_auc: 0.9893 - val_accuracy: 0.9706 - val_cost: 3.7103\n",
            "Epoch 299/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0568 - auc: 0.9966 - accuracy: 0.9830 - cost: 2.1790 - val_loss: 0.1189 - val_auc: 0.9897 - val_accuracy: 0.9711 - val_cost: 3.6806\n",
            "Epoch 300/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0554 - auc: 0.9967 - accuracy: 0.9835 - cost: 2.1134 - val_loss: 0.1204 - val_auc: 0.9894 - val_accuracy: 0.9708 - val_cost: 3.7004\n",
            "Epoch 301/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0559 - auc: 0.9966 - accuracy: 0.9833 - cost: 2.1389 - val_loss: 0.1195 - val_auc: 0.9891 - val_accuracy: 0.9719 - val_cost: 3.6210\n",
            "Epoch 302/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0565 - auc: 0.9966 - accuracy: 0.9830 - cost: 2.1779 - val_loss: 0.1189 - val_auc: 0.9896 - val_accuracy: 0.9712 - val_cost: 3.6310\n",
            "Epoch 303/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0562 - auc: 0.9966 - accuracy: 0.9828 - cost: 2.2079 - val_loss: 0.1184 - val_auc: 0.9899 - val_accuracy: 0.9710 - val_cost: 3.7599\n",
            "Epoch 304/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0562 - auc: 0.9965 - accuracy: 0.9833 - cost: 2.1350 - val_loss: 0.1194 - val_auc: 0.9896 - val_accuracy: 0.9706 - val_cost: 3.7533\n",
            "Epoch 305/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0557 - auc: 0.9967 - accuracy: 0.9831 - cost: 2.1671 - val_loss: 0.1197 - val_auc: 0.9892 - val_accuracy: 0.9710 - val_cost: 3.6772\n",
            "Epoch 306/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0561 - auc: 0.9965 - accuracy: 0.9834 - cost: 2.1319 - val_loss: 0.1202 - val_auc: 0.9893 - val_accuracy: 0.9713 - val_cost: 3.6574\n",
            "Epoch 307/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0561 - auc: 0.9967 - accuracy: 0.9829 - cost: 2.1887 - val_loss: 0.1183 - val_auc: 0.9894 - val_accuracy: 0.9716 - val_cost: 3.6574\n",
            "Epoch 308/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0546 - auc: 0.9968 - accuracy: 0.9835 - cost: 2.1107 - val_loss: 0.1195 - val_auc: 0.9893 - val_accuracy: 0.9705 - val_cost: 3.7897\n",
            "Epoch 309/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0547 - auc: 0.9967 - accuracy: 0.9838 - cost: 2.0806 - val_loss: 0.1205 - val_auc: 0.9892 - val_accuracy: 0.9711 - val_cost: 3.7004\n",
            "Epoch 310/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0567 - auc: 0.9964 - accuracy: 0.9831 - cost: 2.1647 - val_loss: 0.1199 - val_auc: 0.9891 - val_accuracy: 0.9710 - val_cost: 3.6409\n",
            "Epoch 311/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0548 - auc: 0.9966 - accuracy: 0.9835 - cost: 2.1196 - val_loss: 0.1194 - val_auc: 0.9892 - val_accuracy: 0.9701 - val_cost: 3.8161\n",
            "Epoch 312/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0551 - auc: 0.9967 - accuracy: 0.9838 - cost: 2.0826 - val_loss: 0.1197 - val_auc: 0.9894 - val_accuracy: 0.9710 - val_cost: 3.7269\n",
            "Epoch 313/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0562 - auc: 0.9966 - accuracy: 0.9830 - cost: 2.1840 - val_loss: 0.1180 - val_auc: 0.9895 - val_accuracy: 0.9709 - val_cost: 3.8194\n",
            "Epoch 314/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0558 - auc: 0.9966 - accuracy: 0.9831 - cost: 2.1644 - val_loss: 0.1206 - val_auc: 0.9892 - val_accuracy: 0.9713 - val_cost: 3.6243\n",
            "Epoch 315/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0554 - auc: 0.9967 - accuracy: 0.9836 - cost: 2.1069 - val_loss: 0.1201 - val_auc: 0.9895 - val_accuracy: 0.9715 - val_cost: 3.6739\n",
            "Epoch 316/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0557 - auc: 0.9966 - accuracy: 0.9833 - cost: 2.1370 - val_loss: 0.1227 - val_auc: 0.9895 - val_accuracy: 0.9706 - val_cost: 3.5979\n",
            "Epoch 317/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0551 - auc: 0.9967 - accuracy: 0.9832 - cost: 2.1497 - val_loss: 0.1196 - val_auc: 0.9896 - val_accuracy: 0.9704 - val_cost: 3.9683\n",
            "Epoch 318/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0557 - auc: 0.9967 - accuracy: 0.9834 - cost: 2.1323 - val_loss: 0.1191 - val_auc: 0.9894 - val_accuracy: 0.9697 - val_cost: 3.8294\n",
            "Epoch 319/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0551 - auc: 0.9967 - accuracy: 0.9834 - cost: 2.1254 - val_loss: 0.1191 - val_auc: 0.9894 - val_accuracy: 0.9697 - val_cost: 3.9616\n",
            "Epoch 320/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0547 - auc: 0.9967 - accuracy: 0.9836 - cost: 2.0999 - val_loss: 0.1210 - val_auc: 0.9896 - val_accuracy: 0.9707 - val_cost: 3.8327\n",
            "Epoch 321/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0562 - auc: 0.9966 - accuracy: 0.9830 - cost: 2.1759 - val_loss: 0.1201 - val_auc: 0.9892 - val_accuracy: 0.9707 - val_cost: 3.7434\n",
            "Epoch 322/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0551 - auc: 0.9967 - accuracy: 0.9836 - cost: 2.0968 - val_loss: 0.1236 - val_auc: 0.9893 - val_accuracy: 0.9702 - val_cost: 3.8525\n",
            "Epoch 323/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0557 - auc: 0.9968 - accuracy: 0.9830 - cost: 2.1802 - val_loss: 0.1213 - val_auc: 0.9888 - val_accuracy: 0.9705 - val_cost: 3.8492\n",
            "Epoch 324/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0552 - auc: 0.9967 - accuracy: 0.9834 - cost: 2.1296 - val_loss: 0.1223 - val_auc: 0.9890 - val_accuracy: 0.9715 - val_cost: 3.6541\n",
            "Epoch 325/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0558 - auc: 0.9966 - accuracy: 0.9835 - cost: 2.1181 - val_loss: 0.1210 - val_auc: 0.9893 - val_accuracy: 0.9708 - val_cost: 3.7368\n",
            "Epoch 326/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0549 - auc: 0.9967 - accuracy: 0.9834 - cost: 2.1115 - val_loss: 0.1230 - val_auc: 0.9890 - val_accuracy: 0.9704 - val_cost: 3.8591\n",
            "Epoch 327/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0542 - auc: 0.9968 - accuracy: 0.9838 - cost: 2.0714 - val_loss: 0.1219 - val_auc: 0.9895 - val_accuracy: 0.9713 - val_cost: 3.6872\n",
            "Epoch 328/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0549 - auc: 0.9967 - accuracy: 0.9837 - cost: 2.0887 - val_loss: 0.1208 - val_auc: 0.9892 - val_accuracy: 0.9716 - val_cost: 3.6971\n",
            "Epoch 329/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0558 - auc: 0.9967 - accuracy: 0.9829 - cost: 2.1890 - val_loss: 0.1236 - val_auc: 0.9890 - val_accuracy: 0.9702 - val_cost: 3.6475\n",
            "Epoch 330/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0559 - auc: 0.9967 - accuracy: 0.9830 - cost: 2.1744 - val_loss: 0.1213 - val_auc: 0.9896 - val_accuracy: 0.9710 - val_cost: 3.6144\n",
            "Epoch 331/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0554 - auc: 0.9967 - accuracy: 0.9835 - cost: 2.1061 - val_loss: 0.1216 - val_auc: 0.9894 - val_accuracy: 0.9706 - val_cost: 3.7996\n",
            "Epoch 332/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0555 - auc: 0.9968 - accuracy: 0.9832 - cost: 2.1620 - val_loss: 0.1204 - val_auc: 0.9891 - val_accuracy: 0.9695 - val_cost: 3.9153\n",
            "Epoch 333/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0538 - auc: 0.9968 - accuracy: 0.9838 - cost: 2.0710 - val_loss: 0.1220 - val_auc: 0.9894 - val_accuracy: 0.9701 - val_cost: 3.7467\n",
            "Epoch 334/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0541 - auc: 0.9969 - accuracy: 0.9836 - cost: 2.0999 - val_loss: 0.1231 - val_auc: 0.9888 - val_accuracy: 0.9699 - val_cost: 3.8889\n",
            "Epoch 335/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0555 - auc: 0.9967 - accuracy: 0.9831 - cost: 2.1705 - val_loss: 0.1223 - val_auc: 0.9890 - val_accuracy: 0.9715 - val_cost: 3.5946\n",
            "Epoch 336/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0549 - auc: 0.9967 - accuracy: 0.9837 - cost: 2.0810 - val_loss: 0.1225 - val_auc: 0.9891 - val_accuracy: 0.9703 - val_cost: 3.7467\n",
            "Epoch 337/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0546 - auc: 0.9968 - accuracy: 0.9837 - cost: 2.0860 - val_loss: 0.1215 - val_auc: 0.9891 - val_accuracy: 0.9705 - val_cost: 3.7335\n",
            "Epoch 338/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0549 - auc: 0.9967 - accuracy: 0.9834 - cost: 2.1323 - val_loss: 0.1213 - val_auc: 0.9892 - val_accuracy: 0.9703 - val_cost: 3.7269\n",
            "Epoch 339/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0548 - auc: 0.9967 - accuracy: 0.9836 - cost: 2.1003 - val_loss: 0.1233 - val_auc: 0.9892 - val_accuracy: 0.9703 - val_cost: 3.6607\n",
            "Epoch 340/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0548 - auc: 0.9967 - accuracy: 0.9834 - cost: 2.1331 - val_loss: 0.1234 - val_auc: 0.9893 - val_accuracy: 0.9703 - val_cost: 3.7963\n",
            "Epoch 341/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0540 - auc: 0.9968 - accuracy: 0.9838 - cost: 2.0602 - val_loss: 0.1218 - val_auc: 0.9891 - val_accuracy: 0.9706 - val_cost: 3.7831\n",
            "Epoch 342/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0540 - auc: 0.9968 - accuracy: 0.9838 - cost: 2.0841 - val_loss: 0.1226 - val_auc: 0.9890 - val_accuracy: 0.9703 - val_cost: 3.7930\n",
            "Epoch 343/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0547 - auc: 0.9968 - accuracy: 0.9836 - cost: 2.0995 - val_loss: 0.1211 - val_auc: 0.9894 - val_accuracy: 0.9710 - val_cost: 3.6839\n",
            "Epoch 344/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0544 - auc: 0.9968 - accuracy: 0.9836 - cost: 2.1022 - val_loss: 0.1254 - val_auc: 0.9888 - val_accuracy: 0.9701 - val_cost: 3.7665\n",
            "Epoch 345/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0543 - auc: 0.9969 - accuracy: 0.9837 - cost: 2.0853 - val_loss: 0.1237 - val_auc: 0.9891 - val_accuracy: 0.9699 - val_cost: 3.8228\n",
            "Epoch 346/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0545 - auc: 0.9968 - accuracy: 0.9835 - cost: 2.1057 - val_loss: 0.1219 - val_auc: 0.9893 - val_accuracy: 0.9705 - val_cost: 3.7698\n",
            "Epoch 347/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0550 - auc: 0.9966 - accuracy: 0.9835 - cost: 2.1223 - val_loss: 0.1241 - val_auc: 0.9890 - val_accuracy: 0.9683 - val_cost: 4.0410\n",
            "Epoch 348/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0542 - auc: 0.9968 - accuracy: 0.9837 - cost: 2.0876 - val_loss: 0.1244 - val_auc: 0.9889 - val_accuracy: 0.9701 - val_cost: 3.8161\n",
            "Epoch 349/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0538 - auc: 0.9968 - accuracy: 0.9839 - cost: 2.0718 - val_loss: 0.1244 - val_auc: 0.9889 - val_accuracy: 0.9701 - val_cost: 3.8757\n",
            "Epoch 350/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0542 - auc: 0.9968 - accuracy: 0.9835 - cost: 2.1181 - val_loss: 0.1231 - val_auc: 0.9892 - val_accuracy: 0.9703 - val_cost: 3.7103\n",
            "Epoch 351/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0538 - auc: 0.9969 - accuracy: 0.9839 - cost: 2.0675 - val_loss: 0.1251 - val_auc: 0.9890 - val_accuracy: 0.9699 - val_cost: 3.7963\n",
            "Epoch 352/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0539 - auc: 0.9968 - accuracy: 0.9837 - cost: 2.0883 - val_loss: 0.1231 - val_auc: 0.9891 - val_accuracy: 0.9706 - val_cost: 3.8228\n",
            "Epoch 353/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0543 - auc: 0.9968 - accuracy: 0.9835 - cost: 2.1107 - val_loss: 0.1225 - val_auc: 0.9893 - val_accuracy: 0.9709 - val_cost: 3.7202\n",
            "Epoch 354/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0547 - auc: 0.9968 - accuracy: 0.9834 - cost: 2.1389 - val_loss: 0.1249 - val_auc: 0.9891 - val_accuracy: 0.9698 - val_cost: 3.7698\n",
            "Epoch 355/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0535 - auc: 0.9969 - accuracy: 0.9839 - cost: 2.0683 - val_loss: 0.1252 - val_auc: 0.9888 - val_accuracy: 0.9695 - val_cost: 4.0079\n",
            "Epoch 356/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0543 - auc: 0.9968 - accuracy: 0.9836 - cost: 2.1061 - val_loss: 0.1240 - val_auc: 0.9892 - val_accuracy: 0.9696 - val_cost: 3.7765\n",
            "Epoch 357/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0541 - auc: 0.9970 - accuracy: 0.9836 - cost: 2.1038 - val_loss: 0.1240 - val_auc: 0.9892 - val_accuracy: 0.9705 - val_cost: 3.7996\n",
            "Epoch 358/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0544 - auc: 0.9968 - accuracy: 0.9834 - cost: 2.1215 - val_loss: 0.1239 - val_auc: 0.9890 - val_accuracy: 0.9703 - val_cost: 3.7202\n",
            "Epoch 359/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0543 - auc: 0.9968 - accuracy: 0.9834 - cost: 2.1397 - val_loss: 0.1255 - val_auc: 0.9891 - val_accuracy: 0.9702 - val_cost: 3.7368\n",
            "Epoch 360/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0542 - auc: 0.9968 - accuracy: 0.9837 - cost: 2.0995 - val_loss: 0.1233 - val_auc: 0.9891 - val_accuracy: 0.9694 - val_cost: 3.9782\n",
            "Epoch 361/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0534 - auc: 0.9969 - accuracy: 0.9837 - cost: 2.0984 - val_loss: 0.1228 - val_auc: 0.9894 - val_accuracy: 0.9703 - val_cost: 3.7930\n",
            "Epoch 362/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0539 - auc: 0.9969 - accuracy: 0.9835 - cost: 2.1092 - val_loss: 0.1267 - val_auc: 0.9886 - val_accuracy: 0.9694 - val_cost: 3.8360\n",
            "Epoch 363/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0541 - auc: 0.9967 - accuracy: 0.9842 - cost: 2.0251 - val_loss: 0.1252 - val_auc: 0.9888 - val_accuracy: 0.9697 - val_cost: 3.8988\n",
            "Epoch 364/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0532 - auc: 0.9970 - accuracy: 0.9839 - cost: 2.0660 - val_loss: 0.1246 - val_auc: 0.9893 - val_accuracy: 0.9707 - val_cost: 3.7202\n",
            "Epoch 365/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0537 - auc: 0.9970 - accuracy: 0.9840 - cost: 2.0498 - val_loss: 0.1262 - val_auc: 0.9892 - val_accuracy: 0.9708 - val_cost: 3.6409\n",
            "Epoch 366/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0531 - auc: 0.9969 - accuracy: 0.9838 - cost: 2.0853 - val_loss: 0.1263 - val_auc: 0.9888 - val_accuracy: 0.9692 - val_cost: 3.8856\n",
            "Epoch 367/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0537 - auc: 0.9969 - accuracy: 0.9839 - cost: 2.0772 - val_loss: 0.1237 - val_auc: 0.9890 - val_accuracy: 0.9699 - val_cost: 3.8426\n",
            "Epoch 368/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0536 - auc: 0.9968 - accuracy: 0.9837 - cost: 2.1096 - val_loss: 0.1273 - val_auc: 0.9889 - val_accuracy: 0.9705 - val_cost: 3.7070\n",
            "Epoch 369/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0543 - auc: 0.9969 - accuracy: 0.9833 - cost: 2.1366 - val_loss: 0.1247 - val_auc: 0.9890 - val_accuracy: 0.9706 - val_cost: 3.7202\n",
            "Epoch 370/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0539 - auc: 0.9968 - accuracy: 0.9842 - cost: 2.0258 - val_loss: 0.1251 - val_auc: 0.9886 - val_accuracy: 0.9699 - val_cost: 3.8459\n",
            "Epoch 371/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0536 - auc: 0.9968 - accuracy: 0.9839 - cost: 2.0710 - val_loss: 0.1263 - val_auc: 0.9886 - val_accuracy: 0.9696 - val_cost: 3.8988\n",
            "Epoch 372/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0552 - auc: 0.9967 - accuracy: 0.9831 - cost: 2.1667 - val_loss: 0.1237 - val_auc: 0.9889 - val_accuracy: 0.9708 - val_cost: 3.6475\n",
            "Epoch 373/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0539 - auc: 0.9968 - accuracy: 0.9836 - cost: 2.1046 - val_loss: 0.1259 - val_auc: 0.9889 - val_accuracy: 0.9699 - val_cost: 3.8823\n",
            "Epoch 374/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0532 - auc: 0.9970 - accuracy: 0.9840 - cost: 2.0486 - val_loss: 0.1246 - val_auc: 0.9893 - val_accuracy: 0.9706 - val_cost: 3.7996\n",
            "Epoch 375/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0539 - auc: 0.9968 - accuracy: 0.9837 - cost: 2.0988 - val_loss: 0.1268 - val_auc: 0.9888 - val_accuracy: 0.9694 - val_cost: 3.8757\n",
            "Epoch 376/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0539 - auc: 0.9968 - accuracy: 0.9839 - cost: 2.0745 - val_loss: 0.1242 - val_auc: 0.9893 - val_accuracy: 0.9694 - val_cost: 3.8624\n",
            "Epoch 377/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0534 - auc: 0.9969 - accuracy: 0.9837 - cost: 2.0887 - val_loss: 0.1254 - val_auc: 0.9890 - val_accuracy: 0.9699 - val_cost: 3.8095\n",
            "Epoch 378/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0529 - auc: 0.9970 - accuracy: 0.9843 - cost: 2.0143 - val_loss: 0.1258 - val_auc: 0.9888 - val_accuracy: 0.9691 - val_cost: 3.9616\n",
            "Epoch 379/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0536 - auc: 0.9969 - accuracy: 0.9841 - cost: 2.0513 - val_loss: 0.1261 - val_auc: 0.9891 - val_accuracy: 0.9694 - val_cost: 3.8889\n",
            "Epoch 380/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0534 - auc: 0.9970 - accuracy: 0.9836 - cost: 2.1030 - val_loss: 0.1261 - val_auc: 0.9890 - val_accuracy: 0.9703 - val_cost: 3.7335\n",
            "Epoch 381/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0534 - auc: 0.9969 - accuracy: 0.9839 - cost: 2.0606 - val_loss: 0.1275 - val_auc: 0.9887 - val_accuracy: 0.9698 - val_cost: 3.9187\n",
            "Epoch 382/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0544 - auc: 0.9968 - accuracy: 0.9837 - cost: 2.0829 - val_loss: 0.1228 - val_auc: 0.9890 - val_accuracy: 0.9701 - val_cost: 3.8459\n",
            "Epoch 383/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0535 - auc: 0.9969 - accuracy: 0.9838 - cost: 2.0787 - val_loss: 0.1279 - val_auc: 0.9889 - val_accuracy: 0.9696 - val_cost: 3.8261\n",
            "Epoch 384/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0527 - auc: 0.9969 - accuracy: 0.9841 - cost: 2.0336 - val_loss: 0.1273 - val_auc: 0.9886 - val_accuracy: 0.9699 - val_cost: 3.8790\n",
            "Epoch 385/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0529 - auc: 0.9969 - accuracy: 0.9839 - cost: 2.0791 - val_loss: 0.1240 - val_auc: 0.9890 - val_accuracy: 0.9703 - val_cost: 3.7831\n",
            "Epoch 386/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0530 - auc: 0.9969 - accuracy: 0.9840 - cost: 2.0559 - val_loss: 0.1278 - val_auc: 0.9886 - val_accuracy: 0.9699 - val_cost: 3.8624\n",
            "Epoch 387/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0527 - auc: 0.9970 - accuracy: 0.9841 - cost: 2.0405 - val_loss: 0.1262 - val_auc: 0.9887 - val_accuracy: 0.9707 - val_cost: 3.7235\n",
            "Epoch 388/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0526 - auc: 0.9970 - accuracy: 0.9841 - cost: 2.0436 - val_loss: 0.1242 - val_auc: 0.9891 - val_accuracy: 0.9705 - val_cost: 3.7202\n",
            "Epoch 389/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0527 - auc: 0.9969 - accuracy: 0.9840 - cost: 2.0513 - val_loss: 0.1273 - val_auc: 0.9887 - val_accuracy: 0.9701 - val_cost: 3.6739\n",
            "Epoch 390/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0539 - auc: 0.9969 - accuracy: 0.9837 - cost: 2.0837 - val_loss: 0.1274 - val_auc: 0.9887 - val_accuracy: 0.9701 - val_cost: 3.7070\n",
            "Epoch 391/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0528 - auc: 0.9970 - accuracy: 0.9841 - cost: 2.0347 - val_loss: 0.1266 - val_auc: 0.9888 - val_accuracy: 0.9707 - val_cost: 3.7665\n",
            "Epoch 392/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0540 - auc: 0.9969 - accuracy: 0.9838 - cost: 2.0837 - val_loss: 0.1263 - val_auc: 0.9886 - val_accuracy: 0.9709 - val_cost: 3.7897\n",
            "Epoch 393/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0524 - auc: 0.9970 - accuracy: 0.9845 - cost: 1.9792 - val_loss: 0.1267 - val_auc: 0.9889 - val_accuracy: 0.9708 - val_cost: 3.7765\n",
            "Epoch 394/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0527 - auc: 0.9970 - accuracy: 0.9841 - cost: 2.0490 - val_loss: 0.1270 - val_auc: 0.9886 - val_accuracy: 0.9706 - val_cost: 3.8062\n",
            "Epoch 395/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0530 - auc: 0.9970 - accuracy: 0.9840 - cost: 2.0455 - val_loss: 0.1263 - val_auc: 0.9884 - val_accuracy: 0.9702 - val_cost: 3.8459\n",
            "Epoch 396/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0529 - auc: 0.9970 - accuracy: 0.9838 - cost: 2.0833 - val_loss: 0.1264 - val_auc: 0.9887 - val_accuracy: 0.9704 - val_cost: 3.7368\n",
            "Epoch 397/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0533 - auc: 0.9970 - accuracy: 0.9837 - cost: 2.0910 - val_loss: 0.1279 - val_auc: 0.9886 - val_accuracy: 0.9692 - val_cost: 3.8889\n",
            "Epoch 398/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0527 - auc: 0.9970 - accuracy: 0.9840 - cost: 2.0536 - val_loss: 0.1268 - val_auc: 0.9888 - val_accuracy: 0.9697 - val_cost: 3.8856\n",
            "Epoch 399/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0528 - auc: 0.9970 - accuracy: 0.9838 - cost: 2.0760 - val_loss: 0.1274 - val_auc: 0.9890 - val_accuracy: 0.9695 - val_cost: 3.7864\n",
            "Epoch 400/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0531 - auc: 0.9969 - accuracy: 0.9840 - cost: 2.0590 - val_loss: 0.1282 - val_auc: 0.9887 - val_accuracy: 0.9695 - val_cost: 3.7434\n",
            "Epoch 401/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0529 - auc: 0.9969 - accuracy: 0.9843 - cost: 2.0154 - val_loss: 0.1277 - val_auc: 0.9887 - val_accuracy: 0.9708 - val_cost: 3.6938\n",
            "Epoch 402/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0537 - auc: 0.9969 - accuracy: 0.9840 - cost: 2.0509 - val_loss: 0.1254 - val_auc: 0.9889 - val_accuracy: 0.9703 - val_cost: 3.8095\n",
            "Epoch 403/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0527 - auc: 0.9970 - accuracy: 0.9843 - cost: 2.0143 - val_loss: 0.1253 - val_auc: 0.9887 - val_accuracy: 0.9706 - val_cost: 3.7136\n",
            "Epoch 404/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0527 - auc: 0.9970 - accuracy: 0.9840 - cost: 2.0502 - val_loss: 0.1274 - val_auc: 0.9886 - val_accuracy: 0.9701 - val_cost: 3.7335\n",
            "Epoch 405/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0522 - auc: 0.9971 - accuracy: 0.9845 - cost: 1.9834 - val_loss: 0.1286 - val_auc: 0.9885 - val_accuracy: 0.9703 - val_cost: 3.8095\n",
            "Epoch 406/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0537 - auc: 0.9969 - accuracy: 0.9836 - cost: 2.0922 - val_loss: 0.1286 - val_auc: 0.9884 - val_accuracy: 0.9702 - val_cost: 3.8393\n",
            "Epoch 407/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0528 - auc: 0.9970 - accuracy: 0.9840 - cost: 2.0440 - val_loss: 0.1286 - val_auc: 0.9882 - val_accuracy: 0.9703 - val_cost: 3.7434\n",
            "Epoch 408/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0532 - auc: 0.9970 - accuracy: 0.9839 - cost: 2.0621 - val_loss: 0.1257 - val_auc: 0.9889 - val_accuracy: 0.9709 - val_cost: 3.7566\n",
            "Epoch 409/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0525 - auc: 0.9970 - accuracy: 0.9844 - cost: 1.9965 - val_loss: 0.1297 - val_auc: 0.9883 - val_accuracy: 0.9699 - val_cost: 3.7698\n",
            "Epoch 410/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0522 - auc: 0.9970 - accuracy: 0.9843 - cost: 2.0197 - val_loss: 0.1291 - val_auc: 0.9888 - val_accuracy: 0.9701 - val_cost: 3.8327\n",
            "Epoch 411/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0524 - auc: 0.9970 - accuracy: 0.9840 - cost: 2.0463 - val_loss: 0.1277 - val_auc: 0.9887 - val_accuracy: 0.9703 - val_cost: 3.7632\n",
            "Epoch 412/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0530 - auc: 0.9969 - accuracy: 0.9841 - cost: 2.0382 - val_loss: 0.1277 - val_auc: 0.9883 - val_accuracy: 0.9694 - val_cost: 3.9286\n",
            "Epoch 413/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0531 - auc: 0.9970 - accuracy: 0.9841 - cost: 2.0390 - val_loss: 0.1281 - val_auc: 0.9890 - val_accuracy: 0.9693 - val_cost: 3.8360\n",
            "Epoch 414/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0521 - auc: 0.9971 - accuracy: 0.9843 - cost: 2.0120 - val_loss: 0.1275 - val_auc: 0.9889 - val_accuracy: 0.9694 - val_cost: 3.8624\n",
            "Epoch 415/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0516 - auc: 0.9971 - accuracy: 0.9843 - cost: 2.0147 - val_loss: 0.1306 - val_auc: 0.9886 - val_accuracy: 0.9689 - val_cost: 3.9319\n",
            "Epoch 416/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0520 - auc: 0.9971 - accuracy: 0.9844 - cost: 2.0012 - val_loss: 0.1289 - val_auc: 0.9888 - val_accuracy: 0.9696 - val_cost: 3.8889\n",
            "Epoch 417/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0527 - auc: 0.9970 - accuracy: 0.9839 - cost: 2.0683 - val_loss: 0.1268 - val_auc: 0.9885 - val_accuracy: 0.9704 - val_cost: 3.7500\n",
            "Epoch 418/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0523 - auc: 0.9970 - accuracy: 0.9842 - cost: 2.0316 - val_loss: 0.1261 - val_auc: 0.9889 - val_accuracy: 0.9702 - val_cost: 3.7665\n",
            "Epoch 419/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0523 - auc: 0.9970 - accuracy: 0.9845 - cost: 1.9873 - val_loss: 0.1296 - val_auc: 0.9886 - val_accuracy: 0.9703 - val_cost: 3.7731\n",
            "Epoch 420/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0523 - auc: 0.9971 - accuracy: 0.9842 - cost: 2.0185 - val_loss: 0.1291 - val_auc: 0.9890 - val_accuracy: 0.9704 - val_cost: 3.7136\n",
            "Epoch 421/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0515 - auc: 0.9971 - accuracy: 0.9844 - cost: 1.9981 - val_loss: 0.1349 - val_auc: 0.9886 - val_accuracy: 0.9701 - val_cost: 3.6772\n",
            "Epoch 422/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0516 - auc: 0.9971 - accuracy: 0.9844 - cost: 1.9973 - val_loss: 0.1288 - val_auc: 0.9884 - val_accuracy: 0.9707 - val_cost: 3.7235\n",
            "Epoch 423/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0524 - auc: 0.9971 - accuracy: 0.9839 - cost: 2.0529 - val_loss: 0.1307 - val_auc: 0.9887 - val_accuracy: 0.9700 - val_cost: 3.8525\n",
            "Epoch 424/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0528 - auc: 0.9969 - accuracy: 0.9840 - cost: 2.0536 - val_loss: 0.1272 - val_auc: 0.9890 - val_accuracy: 0.9706 - val_cost: 3.7533\n",
            "Epoch 425/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0520 - auc: 0.9969 - accuracy: 0.9847 - cost: 1.9583 - val_loss: 0.1268 - val_auc: 0.9889 - val_accuracy: 0.9708 - val_cost: 3.7302\n",
            "Epoch 426/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0517 - auc: 0.9971 - accuracy: 0.9842 - cost: 2.0208 - val_loss: 0.1295 - val_auc: 0.9887 - val_accuracy: 0.9696 - val_cost: 3.9451\n",
            "Epoch 427/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0520 - auc: 0.9970 - accuracy: 0.9843 - cost: 2.0258 - val_loss: 0.1286 - val_auc: 0.9889 - val_accuracy: 0.9697 - val_cost: 3.7632\n",
            "Epoch 428/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0526 - auc: 0.9971 - accuracy: 0.9836 - cost: 2.1038 - val_loss: 0.1288 - val_auc: 0.9892 - val_accuracy: 0.9704 - val_cost: 3.7037\n",
            "Epoch 429/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0520 - auc: 0.9970 - accuracy: 0.9843 - cost: 2.0185 - val_loss: 0.1298 - val_auc: 0.9887 - val_accuracy: 0.9702 - val_cost: 3.7434\n",
            "Epoch 430/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0529 - auc: 0.9970 - accuracy: 0.9839 - cost: 2.0521 - val_loss: 0.1290 - val_auc: 0.9885 - val_accuracy: 0.9703 - val_cost: 3.7731\n",
            "Epoch 431/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0519 - auc: 0.9971 - accuracy: 0.9844 - cost: 2.0004 - val_loss: 0.1284 - val_auc: 0.9884 - val_accuracy: 0.9694 - val_cost: 3.8823\n",
            "Epoch 432/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0529 - auc: 0.9970 - accuracy: 0.9838 - cost: 2.0833 - val_loss: 0.1285 - val_auc: 0.9887 - val_accuracy: 0.9683 - val_cost: 4.0642\n",
            "Epoch 433/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0530 - auc: 0.9970 - accuracy: 0.9840 - cost: 2.0532 - val_loss: 0.1289 - val_auc: 0.9888 - val_accuracy: 0.9701 - val_cost: 3.7037\n",
            "Epoch 434/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0525 - auc: 0.9970 - accuracy: 0.9840 - cost: 2.0552 - val_loss: 0.1304 - val_auc: 0.9887 - val_accuracy: 0.9708 - val_cost: 3.6343\n",
            "Epoch 435/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0524 - auc: 0.9970 - accuracy: 0.9844 - cost: 2.0012 - val_loss: 0.1314 - val_auc: 0.9882 - val_accuracy: 0.9707 - val_cost: 3.7566\n",
            "Epoch 436/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0521 - auc: 0.9970 - accuracy: 0.9844 - cost: 2.0066 - val_loss: 0.1308 - val_auc: 0.9884 - val_accuracy: 0.9690 - val_cost: 3.8955\n",
            "Epoch 437/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0524 - auc: 0.9969 - accuracy: 0.9841 - cost: 2.0428 - val_loss: 0.1298 - val_auc: 0.9885 - val_accuracy: 0.9697 - val_cost: 3.8459\n",
            "Epoch 438/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0519 - auc: 0.9970 - accuracy: 0.9845 - cost: 1.9838 - val_loss: 0.1316 - val_auc: 0.9882 - val_accuracy: 0.9691 - val_cost: 3.9616\n",
            "Epoch 439/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0512 - auc: 0.9970 - accuracy: 0.9845 - cost: 1.9961 - val_loss: 0.1309 - val_auc: 0.9885 - val_accuracy: 0.9706 - val_cost: 3.6706\n",
            "Epoch 440/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0520 - auc: 0.9970 - accuracy: 0.9845 - cost: 1.9927 - val_loss: 0.1321 - val_auc: 0.9883 - val_accuracy: 0.9700 - val_cost: 3.7269\n",
            "Epoch 441/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0523 - auc: 0.9970 - accuracy: 0.9842 - cost: 2.0255 - val_loss: 0.1302 - val_auc: 0.9881 - val_accuracy: 0.9702 - val_cost: 3.8194\n",
            "Epoch 442/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0530 - auc: 0.9969 - accuracy: 0.9837 - cost: 2.0814 - val_loss: 0.1304 - val_auc: 0.9884 - val_accuracy: 0.9701 - val_cost: 3.7599\n",
            "Epoch 443/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0518 - auc: 0.9970 - accuracy: 0.9841 - cost: 2.0374 - val_loss: 0.1273 - val_auc: 0.9887 - val_accuracy: 0.9701 - val_cost: 3.6971\n",
            "Epoch 444/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0521 - auc: 0.9970 - accuracy: 0.9843 - cost: 2.0235 - val_loss: 0.1277 - val_auc: 0.9888 - val_accuracy: 0.9703 - val_cost: 3.7632\n",
            "Epoch 445/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0514 - auc: 0.9972 - accuracy: 0.9842 - cost: 2.0343 - val_loss: 0.1320 - val_auc: 0.9884 - val_accuracy: 0.9700 - val_cost: 3.7467\n",
            "Epoch 446/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0524 - auc: 0.9970 - accuracy: 0.9840 - cost: 2.0401 - val_loss: 0.1315 - val_auc: 0.9885 - val_accuracy: 0.9699 - val_cost: 3.7335\n",
            "Epoch 447/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0516 - auc: 0.9971 - accuracy: 0.9842 - cost: 2.0201 - val_loss: 0.1290 - val_auc: 0.9885 - val_accuracy: 0.9699 - val_cost: 3.7632\n",
            "Epoch 448/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0507 - auc: 0.9972 - accuracy: 0.9847 - cost: 1.9587 - val_loss: 0.1287 - val_auc: 0.9887 - val_accuracy: 0.9708 - val_cost: 3.7335\n",
            "Epoch 449/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0518 - auc: 0.9971 - accuracy: 0.9843 - cost: 2.0162 - val_loss: 0.1287 - val_auc: 0.9885 - val_accuracy: 0.9712 - val_cost: 3.6905\n",
            "Epoch 450/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0516 - auc: 0.9971 - accuracy: 0.9841 - cost: 2.0390 - val_loss: 0.1338 - val_auc: 0.9883 - val_accuracy: 0.9704 - val_cost: 3.6938\n",
            "Epoch 451/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0510 - auc: 0.9971 - accuracy: 0.9844 - cost: 2.0012 - val_loss: 0.1295 - val_auc: 0.9886 - val_accuracy: 0.9698 - val_cost: 3.7434\n",
            "Epoch 452/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0518 - auc: 0.9971 - accuracy: 0.9845 - cost: 1.9911 - val_loss: 0.1302 - val_auc: 0.9886 - val_accuracy: 0.9692 - val_cost: 3.8492\n",
            "Epoch 453/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0512 - auc: 0.9972 - accuracy: 0.9841 - cost: 2.0370 - val_loss: 0.1289 - val_auc: 0.9885 - val_accuracy: 0.9694 - val_cost: 3.9583\n",
            "Epoch 454/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0516 - auc: 0.9970 - accuracy: 0.9844 - cost: 2.0058 - val_loss: 0.1301 - val_auc: 0.9885 - val_accuracy: 0.9703 - val_cost: 3.7004\n",
            "Epoch 455/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0516 - auc: 0.9971 - accuracy: 0.9844 - cost: 2.0027 - val_loss: 0.1321 - val_auc: 0.9884 - val_accuracy: 0.9699 - val_cost: 3.7566\n",
            "Epoch 456/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0506 - auc: 0.9972 - accuracy: 0.9846 - cost: 1.9695 - val_loss: 0.1302 - val_auc: 0.9887 - val_accuracy: 0.9708 - val_cost: 3.7037\n",
            "Epoch 457/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0514 - auc: 0.9970 - accuracy: 0.9845 - cost: 1.9819 - val_loss: 0.1311 - val_auc: 0.9884 - val_accuracy: 0.9697 - val_cost: 3.8790\n",
            "Epoch 458/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0515 - auc: 0.9971 - accuracy: 0.9845 - cost: 1.9857 - val_loss: 0.1292 - val_auc: 0.9889 - val_accuracy: 0.9704 - val_cost: 3.6574\n",
            "Epoch 459/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0527 - auc: 0.9970 - accuracy: 0.9844 - cost: 2.0058 - val_loss: 0.1300 - val_auc: 0.9887 - val_accuracy: 0.9695 - val_cost: 3.9187\n",
            "Epoch 460/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0524 - auc: 0.9970 - accuracy: 0.9841 - cost: 2.0490 - val_loss: 0.1306 - val_auc: 0.9886 - val_accuracy: 0.9709 - val_cost: 3.6111\n",
            "Epoch 461/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0511 - auc: 0.9971 - accuracy: 0.9845 - cost: 1.9946 - val_loss: 0.1325 - val_auc: 0.9886 - val_accuracy: 0.9701 - val_cost: 3.7731\n",
            "Epoch 462/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0509 - auc: 0.9971 - accuracy: 0.9847 - cost: 1.9599 - val_loss: 0.1333 - val_auc: 0.9885 - val_accuracy: 0.9703 - val_cost: 3.7169\n",
            "Epoch 463/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0518 - auc: 0.9971 - accuracy: 0.9842 - cost: 2.0193 - val_loss: 0.1325 - val_auc: 0.9887 - val_accuracy: 0.9708 - val_cost: 3.6243\n",
            "Epoch 464/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0520 - auc: 0.9971 - accuracy: 0.9844 - cost: 1.9950 - val_loss: 0.1288 - val_auc: 0.9885 - val_accuracy: 0.9703 - val_cost: 3.7434\n",
            "Epoch 465/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0512 - auc: 0.9972 - accuracy: 0.9846 - cost: 1.9788 - val_loss: 0.1343 - val_auc: 0.9884 - val_accuracy: 0.9700 - val_cost: 3.7665\n",
            "Epoch 466/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0515 - auc: 0.9971 - accuracy: 0.9843 - cost: 2.0131 - val_loss: 0.1292 - val_auc: 0.9886 - val_accuracy: 0.9697 - val_cost: 3.8393\n",
            "Epoch 467/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0522 - auc: 0.9970 - accuracy: 0.9840 - cost: 2.0544 - val_loss: 0.1309 - val_auc: 0.9888 - val_accuracy: 0.9705 - val_cost: 3.7136\n",
            "Epoch 468/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0519 - auc: 0.9971 - accuracy: 0.9841 - cost: 2.0394 - val_loss: 0.1312 - val_auc: 0.9887 - val_accuracy: 0.9698 - val_cost: 3.8095\n",
            "Epoch 469/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0518 - auc: 0.9971 - accuracy: 0.9841 - cost: 2.0428 - val_loss: 0.1320 - val_auc: 0.9888 - val_accuracy: 0.9705 - val_cost: 3.6673\n",
            "Epoch 470/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0518 - auc: 0.9971 - accuracy: 0.9840 - cost: 2.0532 - val_loss: 0.1305 - val_auc: 0.9883 - val_accuracy: 0.9710 - val_cost: 3.6310\n",
            "Epoch 471/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0518 - auc: 0.9971 - accuracy: 0.9842 - cost: 2.0177 - val_loss: 0.1328 - val_auc: 0.9881 - val_accuracy: 0.9701 - val_cost: 3.6971\n",
            "Epoch 472/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0516 - auc: 0.9972 - accuracy: 0.9843 - cost: 2.0174 - val_loss: 0.1328 - val_auc: 0.9885 - val_accuracy: 0.9710 - val_cost: 3.6276\n",
            "Epoch 473/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0512 - auc: 0.9972 - accuracy: 0.9844 - cost: 1.9965 - val_loss: 0.1329 - val_auc: 0.9883 - val_accuracy: 0.9691 - val_cost: 3.8393\n",
            "Epoch 474/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0506 - auc: 0.9973 - accuracy: 0.9847 - cost: 1.9591 - val_loss: 0.1318 - val_auc: 0.9886 - val_accuracy: 0.9703 - val_cost: 3.7566\n",
            "Epoch 475/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0519 - auc: 0.9970 - accuracy: 0.9844 - cost: 2.0147 - val_loss: 0.1314 - val_auc: 0.9885 - val_accuracy: 0.9702 - val_cost: 3.7434\n",
            "Epoch 476/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0510 - auc: 0.9971 - accuracy: 0.9848 - cost: 1.9560 - val_loss: 0.1341 - val_auc: 0.9883 - val_accuracy: 0.9699 - val_cost: 3.6905\n",
            "Epoch 477/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0513 - auc: 0.9971 - accuracy: 0.9843 - cost: 2.0062 - val_loss: 0.1308 - val_auc: 0.9883 - val_accuracy: 0.9697 - val_cost: 3.9120\n",
            "Epoch 478/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0503 - auc: 0.9972 - accuracy: 0.9849 - cost: 1.9518 - val_loss: 0.1337 - val_auc: 0.9885 - val_accuracy: 0.9698 - val_cost: 3.8591\n",
            "Epoch 479/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0509 - auc: 0.9971 - accuracy: 0.9847 - cost: 1.9545 - val_loss: 0.1324 - val_auc: 0.9887 - val_accuracy: 0.9695 - val_cost: 3.8228\n",
            "Epoch 480/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0515 - auc: 0.9972 - accuracy: 0.9841 - cost: 2.0436 - val_loss: 0.1308 - val_auc: 0.9885 - val_accuracy: 0.9703 - val_cost: 3.7665\n",
            "Epoch 481/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0510 - auc: 0.9972 - accuracy: 0.9846 - cost: 1.9742 - val_loss: 0.1315 - val_auc: 0.9886 - val_accuracy: 0.9699 - val_cost: 3.8327\n",
            "Epoch 482/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0516 - auc: 0.9972 - accuracy: 0.9841 - cost: 2.0409 - val_loss: 0.1325 - val_auc: 0.9883 - val_accuracy: 0.9703 - val_cost: 3.6640\n",
            "Epoch 483/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0509 - auc: 0.9972 - accuracy: 0.9845 - cost: 1.9811 - val_loss: 0.1333 - val_auc: 0.9885 - val_accuracy: 0.9710 - val_cost: 3.5747\n",
            "Epoch 484/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0499 - auc: 0.9972 - accuracy: 0.9850 - cost: 1.9263 - val_loss: 0.1313 - val_auc: 0.9884 - val_accuracy: 0.9702 - val_cost: 3.7731\n",
            "Epoch 485/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0512 - auc: 0.9970 - accuracy: 0.9845 - cost: 1.9919 - val_loss: 0.1307 - val_auc: 0.9884 - val_accuracy: 0.9690 - val_cost: 3.8790\n",
            "Epoch 486/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0508 - auc: 0.9971 - accuracy: 0.9845 - cost: 1.9919 - val_loss: 0.1308 - val_auc: 0.9886 - val_accuracy: 0.9699 - val_cost: 3.8062\n",
            "Epoch 487/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0511 - auc: 0.9971 - accuracy: 0.9848 - cost: 1.9460 - val_loss: 0.1311 - val_auc: 0.9885 - val_accuracy: 0.9710 - val_cost: 3.6839\n",
            "Epoch 488/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0517 - auc: 0.9971 - accuracy: 0.9844 - cost: 2.0062 - val_loss: 0.1322 - val_auc: 0.9885 - val_accuracy: 0.9701 - val_cost: 3.7963\n",
            "Epoch 489/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0514 - auc: 0.9972 - accuracy: 0.9844 - cost: 2.0058 - val_loss: 0.1313 - val_auc: 0.9884 - val_accuracy: 0.9709 - val_cost: 3.7037\n",
            "Epoch 490/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0508 - auc: 0.9972 - accuracy: 0.9842 - cost: 2.0189 - val_loss: 0.1330 - val_auc: 0.9885 - val_accuracy: 0.9707 - val_cost: 3.6938\n",
            "Epoch 491/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0507 - auc: 0.9972 - accuracy: 0.9846 - cost: 1.9765 - val_loss: 0.1305 - val_auc: 0.9887 - val_accuracy: 0.9708 - val_cost: 3.6839\n",
            "Epoch 492/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0513 - auc: 0.9971 - accuracy: 0.9845 - cost: 1.9911 - val_loss: 0.1341 - val_auc: 0.9884 - val_accuracy: 0.9697 - val_cost: 3.7897\n",
            "Epoch 493/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0516 - auc: 0.9972 - accuracy: 0.9846 - cost: 1.9811 - val_loss: 0.1315 - val_auc: 0.9886 - val_accuracy: 0.9697 - val_cost: 3.7335\n",
            "Epoch 494/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0515 - auc: 0.9971 - accuracy: 0.9847 - cost: 1.9464 - val_loss: 0.1351 - val_auc: 0.9884 - val_accuracy: 0.9698 - val_cost: 3.8823\n",
            "Epoch 495/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0506 - auc: 0.9972 - accuracy: 0.9843 - cost: 2.0243 - val_loss: 0.1347 - val_auc: 0.9881 - val_accuracy: 0.9699 - val_cost: 3.7434\n",
            "Epoch 496/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0500 - auc: 0.9972 - accuracy: 0.9848 - cost: 1.9471 - val_loss: 0.1350 - val_auc: 0.9886 - val_accuracy: 0.9704 - val_cost: 3.6640\n",
            "Epoch 497/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0506 - auc: 0.9972 - accuracy: 0.9845 - cost: 1.9815 - val_loss: 0.1291 - val_auc: 0.9886 - val_accuracy: 0.9708 - val_cost: 3.7599\n",
            "Epoch 498/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0505 - auc: 0.9972 - accuracy: 0.9848 - cost: 1.9622 - val_loss: 0.1352 - val_auc: 0.9882 - val_accuracy: 0.9706 - val_cost: 3.6905\n",
            "Epoch 499/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0512 - auc: 0.9971 - accuracy: 0.9847 - cost: 1.9545 - val_loss: 0.1335 - val_auc: 0.9885 - val_accuracy: 0.9708 - val_cost: 3.7169\n",
            "Epoch 500/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0507 - auc: 0.9973 - accuracy: 0.9848 - cost: 1.9510 - val_loss: 0.1323 - val_auc: 0.9885 - val_accuracy: 0.9712 - val_cost: 3.6574\n",
            "Epoch 501/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0512 - auc: 0.9971 - accuracy: 0.9843 - cost: 2.0174 - val_loss: 0.1323 - val_auc: 0.9882 - val_accuracy: 0.9709 - val_cost: 3.6607\n",
            "Epoch 502/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0510 - auc: 0.9971 - accuracy: 0.9843 - cost: 2.0066 - val_loss: 0.1325 - val_auc: 0.9884 - val_accuracy: 0.9702 - val_cost: 3.7401\n",
            "Epoch 503/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0511 - auc: 0.9972 - accuracy: 0.9845 - cost: 1.9877 - val_loss: 0.1307 - val_auc: 0.9883 - val_accuracy: 0.9703 - val_cost: 3.7136\n",
            "Epoch 504/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0501 - auc: 0.9972 - accuracy: 0.9845 - cost: 1.9950 - val_loss: 0.1324 - val_auc: 0.9885 - val_accuracy: 0.9699 - val_cost: 3.8624\n",
            "Epoch 505/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0506 - auc: 0.9972 - accuracy: 0.9845 - cost: 1.9884 - val_loss: 0.1355 - val_auc: 0.9885 - val_accuracy: 0.9700 - val_cost: 3.7798\n",
            "Epoch 506/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0515 - auc: 0.9971 - accuracy: 0.9844 - cost: 2.0004 - val_loss: 0.1315 - val_auc: 0.9887 - val_accuracy: 0.9712 - val_cost: 3.6111\n",
            "Epoch 507/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0509 - auc: 0.9972 - accuracy: 0.9845 - cost: 1.9753 - val_loss: 0.1348 - val_auc: 0.9881 - val_accuracy: 0.9699 - val_cost: 3.8360\n",
            "Epoch 508/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0512 - auc: 0.9971 - accuracy: 0.9846 - cost: 1.9784 - val_loss: 0.1336 - val_auc: 0.9887 - val_accuracy: 0.9707 - val_cost: 3.7037\n",
            "Epoch 509/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0501 - auc: 0.9972 - accuracy: 0.9846 - cost: 1.9707 - val_loss: 0.1328 - val_auc: 0.9884 - val_accuracy: 0.9709 - val_cost: 3.6177\n",
            "Epoch 510/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0498 - auc: 0.9973 - accuracy: 0.9850 - cost: 1.9205 - val_loss: 0.1347 - val_auc: 0.9887 - val_accuracy: 0.9694 - val_cost: 3.7963\n",
            "Epoch 511/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0506 - auc: 0.9972 - accuracy: 0.9844 - cost: 2.0093 - val_loss: 0.1323 - val_auc: 0.9883 - val_accuracy: 0.9714 - val_cost: 3.5780\n",
            "Epoch 512/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0505 - auc: 0.9972 - accuracy: 0.9844 - cost: 1.9954 - val_loss: 0.1365 - val_auc: 0.9883 - val_accuracy: 0.9699 - val_cost: 3.6971\n",
            "Epoch 513/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0503 - auc: 0.9972 - accuracy: 0.9847 - cost: 1.9622 - val_loss: 0.1313 - val_auc: 0.9885 - val_accuracy: 0.9695 - val_cost: 3.8724\n",
            "Epoch 514/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0510 - auc: 0.9972 - accuracy: 0.9845 - cost: 1.9853 - val_loss: 0.1348 - val_auc: 0.9885 - val_accuracy: 0.9710 - val_cost: 3.6276\n",
            "Epoch 515/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0508 - auc: 0.9972 - accuracy: 0.9844 - cost: 1.9931 - val_loss: 0.1314 - val_auc: 0.9887 - val_accuracy: 0.9702 - val_cost: 3.7632\n",
            "Epoch 516/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0513 - auc: 0.9972 - accuracy: 0.9844 - cost: 1.9996 - val_loss: 0.1316 - val_auc: 0.9886 - val_accuracy: 0.9697 - val_cost: 3.8426\n",
            "Epoch 517/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0514 - auc: 0.9971 - accuracy: 0.9845 - cost: 1.9819 - val_loss: 0.1314 - val_auc: 0.9891 - val_accuracy: 0.9695 - val_cost: 3.9550\n",
            "Epoch 518/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0495 - auc: 0.9974 - accuracy: 0.9852 - cost: 1.9043 - val_loss: 0.1350 - val_auc: 0.9884 - val_accuracy: 0.9702 - val_cost: 3.7930\n",
            "Epoch 519/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0506 - auc: 0.9972 - accuracy: 0.9846 - cost: 1.9718 - val_loss: 0.1308 - val_auc: 0.9886 - val_accuracy: 0.9699 - val_cost: 3.7963\n",
            "Epoch 520/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0514 - auc: 0.9971 - accuracy: 0.9842 - cost: 2.0313 - val_loss: 0.1322 - val_auc: 0.9887 - val_accuracy: 0.9703 - val_cost: 3.7731\n",
            "Epoch 521/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0514 - auc: 0.9971 - accuracy: 0.9841 - cost: 2.0351 - val_loss: 0.1329 - val_auc: 0.9885 - val_accuracy: 0.9701 - val_cost: 3.7665\n",
            "Epoch 522/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0504 - auc: 0.9973 - accuracy: 0.9849 - cost: 1.9414 - val_loss: 0.1311 - val_auc: 0.9885 - val_accuracy: 0.9706 - val_cost: 3.6872\n",
            "Epoch 523/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0504 - auc: 0.9972 - accuracy: 0.9849 - cost: 1.9406 - val_loss: 0.1323 - val_auc: 0.9885 - val_accuracy: 0.9708 - val_cost: 3.7169\n",
            "Epoch 524/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0505 - auc: 0.9972 - accuracy: 0.9845 - cost: 1.9888 - val_loss: 0.1334 - val_auc: 0.9885 - val_accuracy: 0.9711 - val_cost: 3.5847\n",
            "Epoch 525/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0499 - auc: 0.9973 - accuracy: 0.9850 - cost: 1.9267 - val_loss: 0.1367 - val_auc: 0.9884 - val_accuracy: 0.9708 - val_cost: 3.6276\n",
            "Epoch 526/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0513 - auc: 0.9971 - accuracy: 0.9844 - cost: 2.0050 - val_loss: 0.1350 - val_auc: 0.9885 - val_accuracy: 0.9704 - val_cost: 3.6673\n",
            "Epoch 527/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0508 - auc: 0.9972 - accuracy: 0.9848 - cost: 1.9552 - val_loss: 0.1325 - val_auc: 0.9885 - val_accuracy: 0.9695 - val_cost: 3.8558\n",
            "Epoch 528/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0508 - auc: 0.9972 - accuracy: 0.9848 - cost: 1.9595 - val_loss: 0.1321 - val_auc: 0.9888 - val_accuracy: 0.9708 - val_cost: 3.6673\n",
            "Epoch 529/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0509 - auc: 0.9972 - accuracy: 0.9843 - cost: 2.0158 - val_loss: 0.1346 - val_auc: 0.9885 - val_accuracy: 0.9710 - val_cost: 3.6806\n",
            "Epoch 530/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0496 - auc: 0.9973 - accuracy: 0.9849 - cost: 1.9414 - val_loss: 0.1317 - val_auc: 0.9882 - val_accuracy: 0.9703 - val_cost: 3.7698\n",
            "Epoch 531/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0506 - auc: 0.9972 - accuracy: 0.9844 - cost: 2.0093 - val_loss: 0.1337 - val_auc: 0.9884 - val_accuracy: 0.9713 - val_cost: 3.4987\n",
            "Epoch 532/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0504 - auc: 0.9972 - accuracy: 0.9845 - cost: 1.9788 - val_loss: 0.1351 - val_auc: 0.9883 - val_accuracy: 0.9705 - val_cost: 3.7533\n",
            "Epoch 533/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0501 - auc: 0.9973 - accuracy: 0.9841 - cost: 2.0359 - val_loss: 0.1332 - val_auc: 0.9885 - val_accuracy: 0.9706 - val_cost: 3.6872\n",
            "Epoch 534/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0504 - auc: 0.9971 - accuracy: 0.9850 - cost: 1.9309 - val_loss: 0.1349 - val_auc: 0.9882 - val_accuracy: 0.9703 - val_cost: 3.7269\n",
            "Epoch 535/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0502 - auc: 0.9971 - accuracy: 0.9846 - cost: 1.9703 - val_loss: 0.1356 - val_auc: 0.9882 - val_accuracy: 0.9696 - val_cost: 3.8558\n",
            "Epoch 536/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0511 - auc: 0.9973 - accuracy: 0.9842 - cost: 2.0212 - val_loss: 0.1358 - val_auc: 0.9885 - val_accuracy: 0.9704 - val_cost: 3.8194\n",
            "Epoch 537/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0497 - auc: 0.9973 - accuracy: 0.9847 - cost: 1.9726 - val_loss: 0.1356 - val_auc: 0.9884 - val_accuracy: 0.9701 - val_cost: 3.6607\n",
            "Epoch 538/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0501 - auc: 0.9972 - accuracy: 0.9846 - cost: 1.9834 - val_loss: 0.1366 - val_auc: 0.9883 - val_accuracy: 0.9701 - val_cost: 3.6772\n",
            "Epoch 539/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0497 - auc: 0.9973 - accuracy: 0.9850 - cost: 1.9259 - val_loss: 0.1339 - val_auc: 0.9883 - val_accuracy: 0.9706 - val_cost: 3.7897\n",
            "Epoch 540/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0500 - auc: 0.9973 - accuracy: 0.9851 - cost: 1.9144 - val_loss: 0.1373 - val_auc: 0.9886 - val_accuracy: 0.9704 - val_cost: 3.7302\n",
            "Epoch 541/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0504 - auc: 0.9972 - accuracy: 0.9845 - cost: 1.9985 - val_loss: 0.1348 - val_auc: 0.9883 - val_accuracy: 0.9702 - val_cost: 3.8624\n",
            "Epoch 542/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0503 - auc: 0.9972 - accuracy: 0.9851 - cost: 1.9124 - val_loss: 0.1363 - val_auc: 0.9882 - val_accuracy: 0.9706 - val_cost: 3.7269\n",
            "Epoch 543/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0496 - auc: 0.9973 - accuracy: 0.9851 - cost: 1.9101 - val_loss: 0.1356 - val_auc: 0.9885 - val_accuracy: 0.9705 - val_cost: 3.7103\n",
            "Epoch 544/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0505 - auc: 0.9973 - accuracy: 0.9841 - cost: 2.0343 - val_loss: 0.1328 - val_auc: 0.9887 - val_accuracy: 0.9705 - val_cost: 3.7368\n",
            "Epoch 545/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0504 - auc: 0.9973 - accuracy: 0.9844 - cost: 2.0100 - val_loss: 0.1336 - val_auc: 0.9887 - val_accuracy: 0.9708 - val_cost: 3.6475\n",
            "Epoch 546/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0503 - auc: 0.9972 - accuracy: 0.9849 - cost: 1.9363 - val_loss: 0.1379 - val_auc: 0.9885 - val_accuracy: 0.9706 - val_cost: 3.6673\n",
            "Epoch 547/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0501 - auc: 0.9972 - accuracy: 0.9846 - cost: 1.9749 - val_loss: 0.1320 - val_auc: 0.9886 - val_accuracy: 0.9712 - val_cost: 3.6905\n",
            "Epoch 548/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0501 - auc: 0.9973 - accuracy: 0.9848 - cost: 1.9487 - val_loss: 0.1343 - val_auc: 0.9887 - val_accuracy: 0.9700 - val_cost: 3.7632\n",
            "Epoch 549/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0506 - auc: 0.9971 - accuracy: 0.9849 - cost: 1.9514 - val_loss: 0.1353 - val_auc: 0.9883 - val_accuracy: 0.9703 - val_cost: 3.7235\n",
            "Epoch 550/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0511 - auc: 0.9973 - accuracy: 0.9843 - cost: 2.0220 - val_loss: 0.1324 - val_auc: 0.9886 - val_accuracy: 0.9705 - val_cost: 3.7202\n",
            "Epoch 551/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0496 - auc: 0.9973 - accuracy: 0.9848 - cost: 1.9495 - val_loss: 0.1340 - val_auc: 0.9887 - val_accuracy: 0.9711 - val_cost: 3.6607\n",
            "Epoch 552/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0494 - auc: 0.9974 - accuracy: 0.9850 - cost: 1.9290 - val_loss: 0.1341 - val_auc: 0.9887 - val_accuracy: 0.9704 - val_cost: 3.7698\n",
            "Epoch 553/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0502 - auc: 0.9972 - accuracy: 0.9849 - cost: 1.9429 - val_loss: 0.1339 - val_auc: 0.9886 - val_accuracy: 0.9710 - val_cost: 3.6012\n",
            "Epoch 554/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0485 - auc: 0.9973 - accuracy: 0.9854 - cost: 1.8704 - val_loss: 0.1352 - val_auc: 0.9884 - val_accuracy: 0.9701 - val_cost: 3.7864\n",
            "Epoch 555/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0497 - auc: 0.9973 - accuracy: 0.9846 - cost: 1.9761 - val_loss: 0.1360 - val_auc: 0.9885 - val_accuracy: 0.9710 - val_cost: 3.7004\n",
            "Epoch 556/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0497 - auc: 0.9973 - accuracy: 0.9849 - cost: 1.9344 - val_loss: 0.1343 - val_auc: 0.9885 - val_accuracy: 0.9701 - val_cost: 3.7599\n",
            "Epoch 557/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0502 - auc: 0.9973 - accuracy: 0.9850 - cost: 1.9209 - val_loss: 0.1363 - val_auc: 0.9884 - val_accuracy: 0.9706 - val_cost: 3.7037\n",
            "Epoch 558/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0509 - auc: 0.9972 - accuracy: 0.9845 - cost: 1.9865 - val_loss: 0.1325 - val_auc: 0.9886 - val_accuracy: 0.9709 - val_cost: 3.6607\n",
            "Epoch 559/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0503 - auc: 0.9972 - accuracy: 0.9847 - cost: 1.9514 - val_loss: 0.1341 - val_auc: 0.9883 - val_accuracy: 0.9700 - val_cost: 3.9484\n",
            "Epoch 560/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0494 - auc: 0.9974 - accuracy: 0.9848 - cost: 1.9541 - val_loss: 0.1339 - val_auc: 0.9887 - val_accuracy: 0.9700 - val_cost: 3.7698\n",
            "Epoch 561/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0496 - auc: 0.9974 - accuracy: 0.9844 - cost: 2.0042 - val_loss: 0.1337 - val_auc: 0.9886 - val_accuracy: 0.9694 - val_cost: 3.8790\n",
            "Epoch 562/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0495 - auc: 0.9973 - accuracy: 0.9847 - cost: 1.9637 - val_loss: 0.1365 - val_auc: 0.9883 - val_accuracy: 0.9711 - val_cost: 3.6541\n",
            "Epoch 563/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0488 - auc: 0.9974 - accuracy: 0.9849 - cost: 1.9406 - val_loss: 0.1355 - val_auc: 0.9884 - val_accuracy: 0.9711 - val_cost: 3.6706\n",
            "Epoch 564/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0497 - auc: 0.9973 - accuracy: 0.9848 - cost: 1.9514 - val_loss: 0.1363 - val_auc: 0.9883 - val_accuracy: 0.9697 - val_cost: 3.8790\n",
            "Epoch 565/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0497 - auc: 0.9972 - accuracy: 0.9849 - cost: 1.9340 - val_loss: 0.1335 - val_auc: 0.9885 - val_accuracy: 0.9712 - val_cost: 3.6442\n",
            "Epoch 566/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0503 - auc: 0.9972 - accuracy: 0.9847 - cost: 1.9633 - val_loss: 0.1373 - val_auc: 0.9882 - val_accuracy: 0.9704 - val_cost: 3.8261\n",
            "Epoch 567/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0494 - auc: 0.9973 - accuracy: 0.9852 - cost: 1.8900 - val_loss: 0.1350 - val_auc: 0.9882 - val_accuracy: 0.9701 - val_cost: 3.7765\n",
            "Epoch 568/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0509 - auc: 0.9971 - accuracy: 0.9847 - cost: 1.9637 - val_loss: 0.1370 - val_auc: 0.9882 - val_accuracy: 0.9696 - val_cost: 3.7632\n",
            "Epoch 569/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0501 - auc: 0.9972 - accuracy: 0.9848 - cost: 1.9579 - val_loss: 0.1360 - val_auc: 0.9882 - val_accuracy: 0.9703 - val_cost: 3.7368\n",
            "Epoch 570/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0500 - auc: 0.9972 - accuracy: 0.9844 - cost: 2.0066 - val_loss: 0.1351 - val_auc: 0.9881 - val_accuracy: 0.9702 - val_cost: 3.7401\n",
            "Epoch 571/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0497 - auc: 0.9973 - accuracy: 0.9849 - cost: 1.9225 - val_loss: 0.1362 - val_auc: 0.9883 - val_accuracy: 0.9706 - val_cost: 3.7136\n",
            "Epoch 572/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0492 - auc: 0.9974 - accuracy: 0.9849 - cost: 1.9294 - val_loss: 0.1333 - val_auc: 0.9884 - val_accuracy: 0.9708 - val_cost: 3.7467\n",
            "Epoch 573/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0494 - auc: 0.9974 - accuracy: 0.9846 - cost: 1.9792 - val_loss: 0.1351 - val_auc: 0.9883 - val_accuracy: 0.9713 - val_cost: 3.6343\n",
            "Epoch 574/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0494 - auc: 0.9973 - accuracy: 0.9848 - cost: 1.9483 - val_loss: 0.1357 - val_auc: 0.9884 - val_accuracy: 0.9706 - val_cost: 3.7235\n",
            "Epoch 575/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0498 - auc: 0.9973 - accuracy: 0.9849 - cost: 1.9390 - val_loss: 0.1340 - val_auc: 0.9885 - val_accuracy: 0.9717 - val_cost: 3.5615\n",
            "Epoch 576/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0496 - auc: 0.9973 - accuracy: 0.9847 - cost: 1.9649 - val_loss: 0.1329 - val_auc: 0.9883 - val_accuracy: 0.9697 - val_cost: 3.8360\n",
            "Epoch 577/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0495 - auc: 0.9974 - accuracy: 0.9846 - cost: 1.9857 - val_loss: 0.1360 - val_auc: 0.9886 - val_accuracy: 0.9706 - val_cost: 3.7202\n",
            "Epoch 578/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0489 - auc: 0.9973 - accuracy: 0.9850 - cost: 1.9329 - val_loss: 0.1382 - val_auc: 0.9883 - val_accuracy: 0.9693 - val_cost: 3.8591\n",
            "Epoch 579/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0504 - auc: 0.9972 - accuracy: 0.9845 - cost: 1.9869 - val_loss: 0.1360 - val_auc: 0.9883 - val_accuracy: 0.9697 - val_cost: 3.8724\n",
            "Epoch 580/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0504 - auc: 0.9973 - accuracy: 0.9845 - cost: 1.9888 - val_loss: 0.1356 - val_auc: 0.9885 - val_accuracy: 0.9707 - val_cost: 3.7665\n",
            "Epoch 581/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0493 - auc: 0.9974 - accuracy: 0.9847 - cost: 1.9796 - val_loss: 0.1367 - val_auc: 0.9885 - val_accuracy: 0.9706 - val_cost: 3.7930\n",
            "Epoch 582/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0501 - auc: 0.9972 - accuracy: 0.9844 - cost: 1.9873 - val_loss: 0.1364 - val_auc: 0.9881 - val_accuracy: 0.9712 - val_cost: 3.6177\n",
            "Epoch 583/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0500 - auc: 0.9972 - accuracy: 0.9850 - cost: 1.9240 - val_loss: 0.1365 - val_auc: 0.9886 - val_accuracy: 0.9702 - val_cost: 3.8525\n",
            "Epoch 584/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0485 - auc: 0.9973 - accuracy: 0.9853 - cost: 1.8839 - val_loss: 0.1378 - val_auc: 0.9882 - val_accuracy: 0.9701 - val_cost: 3.6971\n",
            "Epoch 585/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0490 - auc: 0.9974 - accuracy: 0.9847 - cost: 1.9572 - val_loss: 0.1353 - val_auc: 0.9884 - val_accuracy: 0.9707 - val_cost: 3.6971\n",
            "Epoch 586/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0495 - auc: 0.9973 - accuracy: 0.9851 - cost: 1.9159 - val_loss: 0.1357 - val_auc: 0.9884 - val_accuracy: 0.9706 - val_cost: 3.7831\n",
            "Epoch 587/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0499 - auc: 0.9973 - accuracy: 0.9846 - cost: 1.9765 - val_loss: 0.1370 - val_auc: 0.9882 - val_accuracy: 0.9702 - val_cost: 3.7665\n",
            "Epoch 588/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0500 - auc: 0.9972 - accuracy: 0.9849 - cost: 1.9444 - val_loss: 0.1384 - val_auc: 0.9883 - val_accuracy: 0.9710 - val_cost: 3.6806\n",
            "Epoch 589/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0491 - auc: 0.9973 - accuracy: 0.9851 - cost: 1.9047 - val_loss: 0.1320 - val_auc: 0.9887 - val_accuracy: 0.9709 - val_cost: 3.6276\n",
            "Epoch 590/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0498 - auc: 0.9972 - accuracy: 0.9850 - cost: 1.9259 - val_loss: 0.1374 - val_auc: 0.9886 - val_accuracy: 0.9702 - val_cost: 3.7434\n",
            "Epoch 591/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0492 - auc: 0.9973 - accuracy: 0.9845 - cost: 1.9857 - val_loss: 0.1381 - val_auc: 0.9880 - val_accuracy: 0.9701 - val_cost: 3.6806\n",
            "Epoch 592/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0491 - auc: 0.9974 - accuracy: 0.9851 - cost: 1.9151 - val_loss: 0.1372 - val_auc: 0.9883 - val_accuracy: 0.9703 - val_cost: 3.7864\n",
            "Epoch 593/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0497 - auc: 0.9973 - accuracy: 0.9850 - cost: 1.9194 - val_loss: 0.1357 - val_auc: 0.9880 - val_accuracy: 0.9709 - val_cost: 3.7302\n",
            "Epoch 594/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0490 - auc: 0.9973 - accuracy: 0.9851 - cost: 1.9178 - val_loss: 0.1372 - val_auc: 0.9881 - val_accuracy: 0.9698 - val_cost: 3.7731\n",
            "Epoch 595/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0494 - auc: 0.9974 - accuracy: 0.9849 - cost: 1.9367 - val_loss: 0.1346 - val_auc: 0.9881 - val_accuracy: 0.9701 - val_cost: 3.7665\n",
            "Epoch 596/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0496 - auc: 0.9973 - accuracy: 0.9847 - cost: 1.9579 - val_loss: 0.1371 - val_auc: 0.9884 - val_accuracy: 0.9702 - val_cost: 3.7500\n",
            "Epoch 597/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0489 - auc: 0.9973 - accuracy: 0.9855 - cost: 1.8584 - val_loss: 0.1374 - val_auc: 0.9880 - val_accuracy: 0.9706 - val_cost: 3.6640\n",
            "Epoch 598/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0502 - auc: 0.9972 - accuracy: 0.9845 - cost: 1.9834 - val_loss: 0.1364 - val_auc: 0.9881 - val_accuracy: 0.9706 - val_cost: 3.8194\n",
            "Epoch 599/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0493 - auc: 0.9973 - accuracy: 0.9848 - cost: 1.9475 - val_loss: 0.1364 - val_auc: 0.9879 - val_accuracy: 0.9702 - val_cost: 3.7269\n",
            "Epoch 600/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0488 - auc: 0.9974 - accuracy: 0.9852 - cost: 1.8993 - val_loss: 0.1337 - val_auc: 0.9883 - val_accuracy: 0.9706 - val_cost: 3.7037\n",
            "Epoch 601/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0499 - auc: 0.9972 - accuracy: 0.9846 - cost: 1.9842 - val_loss: 0.1387 - val_auc: 0.9879 - val_accuracy: 0.9706 - val_cost: 3.7004\n",
            "Epoch 602/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0488 - auc: 0.9974 - accuracy: 0.9852 - cost: 1.9039 - val_loss: 0.1345 - val_auc: 0.9882 - val_accuracy: 0.9706 - val_cost: 3.7136\n",
            "Epoch 603/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0495 - auc: 0.9973 - accuracy: 0.9847 - cost: 1.9618 - val_loss: 0.1374 - val_auc: 0.9881 - val_accuracy: 0.9711 - val_cost: 3.7004\n",
            "Epoch 604/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0489 - auc: 0.9974 - accuracy: 0.9851 - cost: 1.9155 - val_loss: 0.1378 - val_auc: 0.9877 - val_accuracy: 0.9701 - val_cost: 3.7500\n",
            "Epoch 605/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0489 - auc: 0.9974 - accuracy: 0.9849 - cost: 1.9363 - val_loss: 0.1378 - val_auc: 0.9882 - val_accuracy: 0.9705 - val_cost: 3.7765\n",
            "Epoch 606/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0490 - auc: 0.9973 - accuracy: 0.9852 - cost: 1.9020 - val_loss: 0.1366 - val_auc: 0.9881 - val_accuracy: 0.9710 - val_cost: 3.6442\n",
            "Epoch 607/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0496 - auc: 0.9973 - accuracy: 0.9849 - cost: 1.9448 - val_loss: 0.1406 - val_auc: 0.9883 - val_accuracy: 0.9710 - val_cost: 3.6475\n",
            "Epoch 608/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0493 - auc: 0.9974 - accuracy: 0.9849 - cost: 1.9344 - val_loss: 0.1376 - val_auc: 0.9881 - val_accuracy: 0.9709 - val_cost: 3.6905\n",
            "Epoch 609/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0487 - auc: 0.9974 - accuracy: 0.9852 - cost: 1.9066 - val_loss: 0.1366 - val_auc: 0.9885 - val_accuracy: 0.9715 - val_cost: 3.5747\n",
            "Epoch 610/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0491 - auc: 0.9973 - accuracy: 0.9850 - cost: 1.9313 - val_loss: 0.1356 - val_auc: 0.9882 - val_accuracy: 0.9710 - val_cost: 3.7136\n",
            "Epoch 611/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0493 - auc: 0.9973 - accuracy: 0.9853 - cost: 1.8981 - val_loss: 0.1375 - val_auc: 0.9883 - val_accuracy: 0.9701 - val_cost: 3.7831\n",
            "Epoch 612/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0484 - auc: 0.9974 - accuracy: 0.9853 - cost: 1.8789 - val_loss: 0.1380 - val_auc: 0.9881 - val_accuracy: 0.9709 - val_cost: 3.7037\n",
            "Epoch 613/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0491 - auc: 0.9974 - accuracy: 0.9846 - cost: 1.9722 - val_loss: 0.1382 - val_auc: 0.9878 - val_accuracy: 0.9704 - val_cost: 3.7401\n",
            "Epoch 614/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0494 - auc: 0.9973 - accuracy: 0.9851 - cost: 1.9082 - val_loss: 0.1357 - val_auc: 0.9881 - val_accuracy: 0.9696 - val_cost: 3.9385\n",
            "Epoch 615/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0500 - auc: 0.9973 - accuracy: 0.9847 - cost: 1.9691 - val_loss: 0.1414 - val_auc: 0.9879 - val_accuracy: 0.9694 - val_cost: 3.9087\n",
            "Epoch 616/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0495 - auc: 0.9973 - accuracy: 0.9848 - cost: 1.9591 - val_loss: 0.1380 - val_auc: 0.9882 - val_accuracy: 0.9713 - val_cost: 3.6872\n",
            "Epoch 617/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0487 - auc: 0.9974 - accuracy: 0.9849 - cost: 1.9398 - val_loss: 0.1345 - val_auc: 0.9886 - val_accuracy: 0.9703 - val_cost: 3.7731\n",
            "Epoch 618/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0490 - auc: 0.9974 - accuracy: 0.9850 - cost: 1.9259 - val_loss: 0.1364 - val_auc: 0.9882 - val_accuracy: 0.9708 - val_cost: 3.7235\n",
            "Epoch 619/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0497 - auc: 0.9973 - accuracy: 0.9848 - cost: 1.9475 - val_loss: 0.1382 - val_auc: 0.9880 - val_accuracy: 0.9701 - val_cost: 3.7169\n",
            "Epoch 620/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0486 - auc: 0.9974 - accuracy: 0.9850 - cost: 1.9201 - val_loss: 0.1377 - val_auc: 0.9881 - val_accuracy: 0.9708 - val_cost: 3.6111\n",
            "Epoch 621/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0498 - auc: 0.9974 - accuracy: 0.9850 - cost: 1.9159 - val_loss: 0.1361 - val_auc: 0.9881 - val_accuracy: 0.9699 - val_cost: 3.7368\n",
            "Epoch 622/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0488 - auc: 0.9974 - accuracy: 0.9854 - cost: 1.8762 - val_loss: 0.1402 - val_auc: 0.9878 - val_accuracy: 0.9712 - val_cost: 3.6243\n",
            "Epoch 623/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0485 - auc: 0.9974 - accuracy: 0.9853 - cost: 1.8889 - val_loss: 0.1378 - val_auc: 0.9880 - val_accuracy: 0.9705 - val_cost: 3.8029\n",
            "Epoch 624/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0490 - auc: 0.9974 - accuracy: 0.9849 - cost: 1.9402 - val_loss: 0.1361 - val_auc: 0.9878 - val_accuracy: 0.9705 - val_cost: 3.7136\n",
            "Epoch 625/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0487 - auc: 0.9974 - accuracy: 0.9851 - cost: 1.9151 - val_loss: 0.1393 - val_auc: 0.9880 - val_accuracy: 0.9700 - val_cost: 3.6905\n",
            "Epoch 626/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0483 - auc: 0.9974 - accuracy: 0.9852 - cost: 1.9020 - val_loss: 0.1382 - val_auc: 0.9880 - val_accuracy: 0.9717 - val_cost: 3.5185\n",
            "Epoch 627/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0489 - auc: 0.9974 - accuracy: 0.9852 - cost: 1.8974 - val_loss: 0.1411 - val_auc: 0.9879 - val_accuracy: 0.9714 - val_cost: 3.5714\n",
            "Epoch 628/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0495 - auc: 0.9974 - accuracy: 0.9847 - cost: 1.9541 - val_loss: 0.1376 - val_auc: 0.9878 - val_accuracy: 0.9695 - val_cost: 3.7632\n",
            "Epoch 629/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0489 - auc: 0.9974 - accuracy: 0.9846 - cost: 1.9734 - val_loss: 0.1388 - val_auc: 0.9882 - val_accuracy: 0.9713 - val_cost: 3.5747\n",
            "Epoch 630/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0493 - auc: 0.9974 - accuracy: 0.9849 - cost: 1.9356 - val_loss: 0.1379 - val_auc: 0.9883 - val_accuracy: 0.9705 - val_cost: 3.7103\n",
            "Epoch 631/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0491 - auc: 0.9973 - accuracy: 0.9849 - cost: 1.9275 - val_loss: 0.1363 - val_auc: 0.9885 - val_accuracy: 0.9711 - val_cost: 3.6177\n",
            "Epoch 632/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0492 - auc: 0.9974 - accuracy: 0.9847 - cost: 1.9572 - val_loss: 0.1395 - val_auc: 0.9879 - val_accuracy: 0.9701 - val_cost: 3.7798\n",
            "Epoch 633/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0485 - auc: 0.9973 - accuracy: 0.9852 - cost: 1.8985 - val_loss: 0.1385 - val_auc: 0.9885 - val_accuracy: 0.9706 - val_cost: 3.7202\n",
            "Epoch 634/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0488 - auc: 0.9974 - accuracy: 0.9851 - cost: 1.9140 - val_loss: 0.1387 - val_auc: 0.9877 - val_accuracy: 0.9694 - val_cost: 3.8492\n",
            "Epoch 635/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0484 - auc: 0.9975 - accuracy: 0.9852 - cost: 1.8981 - val_loss: 0.1394 - val_auc: 0.9880 - val_accuracy: 0.9703 - val_cost: 3.7698\n",
            "Epoch 636/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0483 - auc: 0.9974 - accuracy: 0.9851 - cost: 1.9147 - val_loss: 0.1366 - val_auc: 0.9885 - val_accuracy: 0.9703 - val_cost: 3.7235\n",
            "Epoch 637/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0480 - auc: 0.9974 - accuracy: 0.9855 - cost: 1.8642 - val_loss: 0.1398 - val_auc: 0.9881 - val_accuracy: 0.9710 - val_cost: 3.6541\n",
            "Epoch 638/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0488 - auc: 0.9973 - accuracy: 0.9851 - cost: 1.9066 - val_loss: 0.1365 - val_auc: 0.9884 - val_accuracy: 0.9704 - val_cost: 3.7269\n",
            "Epoch 639/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0487 - auc: 0.9974 - accuracy: 0.9853 - cost: 1.8835 - val_loss: 0.1383 - val_auc: 0.9881 - val_accuracy: 0.9708 - val_cost: 3.6508\n",
            "Epoch 640/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0479 - auc: 0.9974 - accuracy: 0.9852 - cost: 1.9062 - val_loss: 0.1381 - val_auc: 0.9883 - val_accuracy: 0.9707 - val_cost: 3.6839\n",
            "Epoch 641/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0493 - auc: 0.9974 - accuracy: 0.9849 - cost: 1.9367 - val_loss: 0.1384 - val_auc: 0.9882 - val_accuracy: 0.9719 - val_cost: 3.5218\n",
            "Epoch 642/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0489 - auc: 0.9974 - accuracy: 0.9850 - cost: 1.9174 - val_loss: 0.1374 - val_auc: 0.9883 - val_accuracy: 0.9710 - val_cost: 3.6772\n",
            "Epoch 643/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0488 - auc: 0.9974 - accuracy: 0.9851 - cost: 1.9182 - val_loss: 0.1417 - val_auc: 0.9881 - val_accuracy: 0.9719 - val_cost: 3.5251\n",
            "Epoch 644/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0475 - auc: 0.9975 - accuracy: 0.9853 - cost: 1.8773 - val_loss: 0.1356 - val_auc: 0.9886 - val_accuracy: 0.9706 - val_cost: 3.7434\n",
            "Epoch 645/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0494 - auc: 0.9974 - accuracy: 0.9847 - cost: 1.9552 - val_loss: 0.1385 - val_auc: 0.9883 - val_accuracy: 0.9703 - val_cost: 3.7897\n",
            "Epoch 646/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0487 - auc: 0.9974 - accuracy: 0.9850 - cost: 1.9217 - val_loss: 0.1380 - val_auc: 0.9883 - val_accuracy: 0.9710 - val_cost: 3.7004\n",
            "Epoch 647/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0489 - auc: 0.9974 - accuracy: 0.9849 - cost: 1.9333 - val_loss: 0.1360 - val_auc: 0.9884 - val_accuracy: 0.9710 - val_cost: 3.6872\n",
            "Epoch 648/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0490 - auc: 0.9973 - accuracy: 0.9851 - cost: 1.9155 - val_loss: 0.1349 - val_auc: 0.9887 - val_accuracy: 0.9701 - val_cost: 3.8294\n",
            "Epoch 649/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0490 - auc: 0.9974 - accuracy: 0.9846 - cost: 1.9722 - val_loss: 0.1388 - val_auc: 0.9882 - val_accuracy: 0.9703 - val_cost: 3.6574\n",
            "Epoch 650/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0489 - auc: 0.9975 - accuracy: 0.9849 - cost: 1.9352 - val_loss: 0.1382 - val_auc: 0.9885 - val_accuracy: 0.9706 - val_cost: 3.7103\n",
            "Epoch 651/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0488 - auc: 0.9974 - accuracy: 0.9848 - cost: 1.9468 - val_loss: 0.1415 - val_auc: 0.9883 - val_accuracy: 0.9703 - val_cost: 3.7566\n",
            "Epoch 652/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0488 - auc: 0.9974 - accuracy: 0.9854 - cost: 1.8823 - val_loss: 0.1395 - val_auc: 0.9882 - val_accuracy: 0.9688 - val_cost: 3.9153\n",
            "Epoch 653/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0486 - auc: 0.9974 - accuracy: 0.9851 - cost: 1.9028 - val_loss: 0.1405 - val_auc: 0.9882 - val_accuracy: 0.9695 - val_cost: 3.7930\n",
            "Epoch 654/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0479 - auc: 0.9975 - accuracy: 0.9854 - cost: 1.8646 - val_loss: 0.1407 - val_auc: 0.9877 - val_accuracy: 0.9706 - val_cost: 3.7500\n",
            "Epoch 655/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0476 - auc: 0.9974 - accuracy: 0.9856 - cost: 1.8465 - val_loss: 0.1359 - val_auc: 0.9886 - val_accuracy: 0.9710 - val_cost: 3.6243\n",
            "Epoch 656/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0485 - auc: 0.9974 - accuracy: 0.9850 - cost: 1.9259 - val_loss: 0.1390 - val_auc: 0.9881 - val_accuracy: 0.9698 - val_cost: 3.7897\n",
            "Epoch 657/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0490 - auc: 0.9974 - accuracy: 0.9848 - cost: 1.9533 - val_loss: 0.1406 - val_auc: 0.9875 - val_accuracy: 0.9693 - val_cost: 3.9418\n",
            "Epoch 658/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0486 - auc: 0.9975 - accuracy: 0.9851 - cost: 1.9221 - val_loss: 0.1385 - val_auc: 0.9881 - val_accuracy: 0.9709 - val_cost: 3.6508\n",
            "Epoch 659/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0489 - auc: 0.9974 - accuracy: 0.9850 - cost: 1.9290 - val_loss: 0.1415 - val_auc: 0.9881 - val_accuracy: 0.9714 - val_cost: 3.6310\n",
            "Epoch 660/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0490 - auc: 0.9973 - accuracy: 0.9849 - cost: 1.9290 - val_loss: 0.1386 - val_auc: 0.9882 - val_accuracy: 0.9703 - val_cost: 3.7103\n",
            "Epoch 661/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0486 - auc: 0.9974 - accuracy: 0.9852 - cost: 1.8989 - val_loss: 0.1370 - val_auc: 0.9880 - val_accuracy: 0.9696 - val_cost: 3.8988\n",
            "Epoch 662/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0485 - auc: 0.9974 - accuracy: 0.9848 - cost: 1.9583 - val_loss: 0.1406 - val_auc: 0.9879 - val_accuracy: 0.9699 - val_cost: 3.7864\n",
            "Epoch 663/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0485 - auc: 0.9974 - accuracy: 0.9851 - cost: 1.9171 - val_loss: 0.1378 - val_auc: 0.9884 - val_accuracy: 0.9709 - val_cost: 3.6673\n",
            "Epoch 664/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0488 - auc: 0.9974 - accuracy: 0.9848 - cost: 1.9541 - val_loss: 0.1448 - val_auc: 0.9875 - val_accuracy: 0.9690 - val_cost: 3.8922\n",
            "Epoch 665/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0487 - auc: 0.9974 - accuracy: 0.9847 - cost: 1.9568 - val_loss: 0.1417 - val_auc: 0.9880 - val_accuracy: 0.9698 - val_cost: 3.8261\n",
            "Epoch 666/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0486 - auc: 0.9974 - accuracy: 0.9850 - cost: 1.9190 - val_loss: 0.1407 - val_auc: 0.9880 - val_accuracy: 0.9703 - val_cost: 3.7103\n",
            "Epoch 667/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0484 - auc: 0.9974 - accuracy: 0.9853 - cost: 1.8873 - val_loss: 0.1402 - val_auc: 0.9879 - val_accuracy: 0.9703 - val_cost: 3.7731\n",
            "Epoch 668/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0473 - auc: 0.9975 - accuracy: 0.9856 - cost: 1.8515 - val_loss: 0.1397 - val_auc: 0.9879 - val_accuracy: 0.9701 - val_cost: 3.7566\n",
            "Epoch 669/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0478 - auc: 0.9975 - accuracy: 0.9853 - cost: 1.8831 - val_loss: 0.1409 - val_auc: 0.9878 - val_accuracy: 0.9708 - val_cost: 3.7103\n",
            "Epoch 670/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0476 - auc: 0.9975 - accuracy: 0.9853 - cost: 1.8893 - val_loss: 0.1431 - val_auc: 0.9878 - val_accuracy: 0.9707 - val_cost: 3.6806\n",
            "Epoch 671/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0488 - auc: 0.9975 - accuracy: 0.9847 - cost: 1.9610 - val_loss: 0.1398 - val_auc: 0.9880 - val_accuracy: 0.9705 - val_cost: 3.8095\n",
            "Epoch 672/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0488 - auc: 0.9975 - accuracy: 0.9849 - cost: 1.9390 - val_loss: 0.1395 - val_auc: 0.9879 - val_accuracy: 0.9702 - val_cost: 3.7368\n",
            "Epoch 673/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0482 - auc: 0.9975 - accuracy: 0.9851 - cost: 1.9147 - val_loss: 0.1410 - val_auc: 0.9881 - val_accuracy: 0.9702 - val_cost: 3.7897\n",
            "Epoch 674/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0488 - auc: 0.9974 - accuracy: 0.9848 - cost: 1.9506 - val_loss: 0.1406 - val_auc: 0.9880 - val_accuracy: 0.9706 - val_cost: 3.6607\n",
            "Epoch 675/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0488 - auc: 0.9974 - accuracy: 0.9852 - cost: 1.8916 - val_loss: 0.1416 - val_auc: 0.9877 - val_accuracy: 0.9702 - val_cost: 3.7302\n",
            "Epoch 676/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0486 - auc: 0.9974 - accuracy: 0.9853 - cost: 1.8885 - val_loss: 0.1419 - val_auc: 0.9881 - val_accuracy: 0.9701 - val_cost: 3.7335\n",
            "Epoch 677/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0477 - auc: 0.9975 - accuracy: 0.9855 - cost: 1.8522 - val_loss: 0.1430 - val_auc: 0.9879 - val_accuracy: 0.9703 - val_cost: 3.7037\n",
            "Epoch 678/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0480 - auc: 0.9975 - accuracy: 0.9858 - cost: 1.8283 - val_loss: 0.1428 - val_auc: 0.9880 - val_accuracy: 0.9717 - val_cost: 3.5880\n",
            "Epoch 679/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0485 - auc: 0.9975 - accuracy: 0.9849 - cost: 1.9313 - val_loss: 0.1427 - val_auc: 0.9877 - val_accuracy: 0.9701 - val_cost: 3.7632\n",
            "Epoch 680/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0483 - auc: 0.9974 - accuracy: 0.9850 - cost: 1.9329 - val_loss: 0.1424 - val_auc: 0.9876 - val_accuracy: 0.9694 - val_cost: 3.8029\n",
            "Epoch 681/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0483 - auc: 0.9976 - accuracy: 0.9850 - cost: 1.9182 - val_loss: 0.1401 - val_auc: 0.9881 - val_accuracy: 0.9708 - val_cost: 3.7269\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.1333 - auc: 0.9882 - accuracy: 0.9707 - cost: 3.6844\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:04:59.588025\n",
            "fold accuracy: 0.9706875085830688 - fold cost: 3.684375047683716\n",
            "x_train shape: (144000, 67)\n",
            "Epoch 1/1000\n",
            "120/120 [==============================] - 2s 5ms/step - loss: 0.5329 - auc: 0.7947 - accuracy: 0.7258 - cost: 36.5664 - val_loss: 0.4023 - val_auc: 0.8973 - val_accuracy: 0.8249 - val_cost: 22.0403\n",
            "Epoch 2/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.3524 - auc: 0.9209 - accuracy: 0.8481 - cost: 19.3711 - val_loss: 0.3195 - val_auc: 0.9355 - val_accuracy: 0.8640 - val_cost: 16.6567\n",
            "Epoch 3/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.3027 - auc: 0.9420 - accuracy: 0.8746 - cost: 15.8654 - val_loss: 0.2882 - val_auc: 0.9476 - val_accuracy: 0.8817 - val_cost: 14.7751\n",
            "Epoch 4/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.2740 - auc: 0.9526 - accuracy: 0.8887 - cost: 14.0911 - val_loss: 0.2632 - val_auc: 0.9565 - val_accuracy: 0.8944 - val_cost: 12.9464\n",
            "Epoch 5/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.2511 - auc: 0.9603 - accuracy: 0.8995 - cost: 12.7141 - val_loss: 0.2438 - val_auc: 0.9626 - val_accuracy: 0.9023 - val_cost: 12.1925\n",
            "Epoch 6/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.2322 - auc: 0.9659 - accuracy: 0.9084 - cost: 11.5783 - val_loss: 0.2264 - val_auc: 0.9675 - val_accuracy: 0.9135 - val_cost: 10.7341\n",
            "Epoch 7/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2152 - auc: 0.9707 - accuracy: 0.9166 - cost: 10.5475 - val_loss: 0.2126 - val_auc: 0.9716 - val_accuracy: 0.9208 - val_cost: 9.6693\n",
            "Epoch 8/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.2027 - auc: 0.9739 - accuracy: 0.9221 - cost: 9.8333 - val_loss: 0.1988 - val_auc: 0.9748 - val_accuracy: 0.9271 - val_cost: 9.0675\n",
            "Epoch 9/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1901 - auc: 0.9768 - accuracy: 0.9279 - cost: 9.1134 - val_loss: 0.1908 - val_auc: 0.9766 - val_accuracy: 0.9303 - val_cost: 8.6607\n",
            "Epoch 10/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1815 - auc: 0.9788 - accuracy: 0.9323 - cost: 8.5505 - val_loss: 0.1829 - val_auc: 0.9782 - val_accuracy: 0.9342 - val_cost: 8.1878\n",
            "Epoch 11/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1730 - auc: 0.9806 - accuracy: 0.9365 - cost: 8.0324 - val_loss: 0.1758 - val_auc: 0.9797 - val_accuracy: 0.9381 - val_cost: 7.6455\n",
            "Epoch 12/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1670 - auc: 0.9818 - accuracy: 0.9385 - cost: 7.7944 - val_loss: 0.1698 - val_auc: 0.9809 - val_accuracy: 0.9400 - val_cost: 7.5397\n",
            "Epoch 13/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1615 - auc: 0.9828 - accuracy: 0.9410 - cost: 7.4691 - val_loss: 0.1671 - val_auc: 0.9815 - val_accuracy: 0.9418 - val_cost: 7.4735\n",
            "Epoch 14/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1571 - auc: 0.9836 - accuracy: 0.9435 - cost: 7.1570 - val_loss: 0.1628 - val_auc: 0.9823 - val_accuracy: 0.9435 - val_cost: 6.9213\n",
            "Epoch 15/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.1531 - auc: 0.9843 - accuracy: 0.9451 - cost: 6.9460 - val_loss: 0.1581 - val_auc: 0.9831 - val_accuracy: 0.9448 - val_cost: 6.9444\n",
            "Epoch 16/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.1492 - auc: 0.9851 - accuracy: 0.9469 - cost: 6.7130 - val_loss: 0.1575 - val_auc: 0.9833 - val_accuracy: 0.9459 - val_cost: 6.6435\n",
            "Epoch 17/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1457 - auc: 0.9857 - accuracy: 0.9488 - cost: 6.4823 - val_loss: 0.1530 - val_auc: 0.9841 - val_accuracy: 0.9474 - val_cost: 6.5774\n",
            "Epoch 18/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1424 - auc: 0.9863 - accuracy: 0.9500 - cost: 6.3225 - val_loss: 0.1520 - val_auc: 0.9842 - val_accuracy: 0.9480 - val_cost: 6.5377\n",
            "Epoch 19/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.1396 - auc: 0.9867 - accuracy: 0.9514 - cost: 6.1667 - val_loss: 0.1493 - val_auc: 0.9847 - val_accuracy: 0.9509 - val_cost: 6.2302\n",
            "Epoch 20/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1371 - auc: 0.9871 - accuracy: 0.9525 - cost: 6.0374 - val_loss: 0.1485 - val_auc: 0.9847 - val_accuracy: 0.9510 - val_cost: 6.1640\n",
            "Epoch 21/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1354 - auc: 0.9873 - accuracy: 0.9534 - cost: 5.9005 - val_loss: 0.1468 - val_auc: 0.9850 - val_accuracy: 0.9524 - val_cost: 5.9358\n",
            "Epoch 22/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.1335 - auc: 0.9877 - accuracy: 0.9540 - cost: 5.8407 - val_loss: 0.1467 - val_auc: 0.9853 - val_accuracy: 0.9514 - val_cost: 5.9325\n",
            "Epoch 23/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1298 - auc: 0.9883 - accuracy: 0.9552 - cost: 5.6863 - val_loss: 0.1454 - val_auc: 0.9856 - val_accuracy: 0.9517 - val_cost: 5.8532\n",
            "Epoch 24/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1286 - auc: 0.9885 - accuracy: 0.9559 - cost: 5.5914 - val_loss: 0.1437 - val_auc: 0.9857 - val_accuracy: 0.9525 - val_cost: 5.8333\n",
            "Epoch 25/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1275 - auc: 0.9885 - accuracy: 0.9565 - cost: 5.5162 - val_loss: 0.1446 - val_auc: 0.9855 - val_accuracy: 0.9538 - val_cost: 5.5622\n",
            "Epoch 26/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.1256 - auc: 0.9888 - accuracy: 0.9570 - cost: 5.4703 - val_loss: 0.1411 - val_auc: 0.9858 - val_accuracy: 0.9550 - val_cost: 5.5886\n",
            "Epoch 27/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.1241 - auc: 0.9891 - accuracy: 0.9579 - cost: 5.3603 - val_loss: 0.1389 - val_auc: 0.9862 - val_accuracy: 0.9562 - val_cost: 5.5126\n",
            "Epoch 28/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1220 - auc: 0.9894 - accuracy: 0.9586 - cost: 5.2654 - val_loss: 0.1392 - val_auc: 0.9861 - val_accuracy: 0.9556 - val_cost: 5.5919\n",
            "Epoch 29/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1209 - auc: 0.9895 - accuracy: 0.9594 - cost: 5.1937 - val_loss: 0.1392 - val_auc: 0.9863 - val_accuracy: 0.9554 - val_cost: 5.3869\n",
            "Epoch 30/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1196 - auc: 0.9897 - accuracy: 0.9596 - cost: 5.1304 - val_loss: 0.1379 - val_auc: 0.9861 - val_accuracy: 0.9569 - val_cost: 5.2745\n",
            "Epoch 31/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1180 - auc: 0.9899 - accuracy: 0.9602 - cost: 5.0687 - val_loss: 0.1368 - val_auc: 0.9864 - val_accuracy: 0.9569 - val_cost: 5.3869\n",
            "Epoch 32/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1164 - auc: 0.9901 - accuracy: 0.9611 - cost: 4.9572 - val_loss: 0.1373 - val_auc: 0.9864 - val_accuracy: 0.9567 - val_cost: 5.3770\n",
            "Epoch 33/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1160 - auc: 0.9902 - accuracy: 0.9611 - cost: 4.9417 - val_loss: 0.1354 - val_auc: 0.9865 - val_accuracy: 0.9584 - val_cost: 5.1554\n",
            "Epoch 34/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1138 - auc: 0.9905 - accuracy: 0.9624 - cost: 4.7758 - val_loss: 0.1358 - val_auc: 0.9866 - val_accuracy: 0.9575 - val_cost: 5.2249\n",
            "Epoch 35/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1136 - auc: 0.9904 - accuracy: 0.9624 - cost: 4.7901 - val_loss: 0.1331 - val_auc: 0.9868 - val_accuracy: 0.9587 - val_cost: 5.1389\n",
            "Epoch 36/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1127 - auc: 0.9905 - accuracy: 0.9628 - cost: 4.7392 - val_loss: 0.1331 - val_auc: 0.9869 - val_accuracy: 0.9585 - val_cost: 5.2050\n",
            "Epoch 37/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.1115 - auc: 0.9907 - accuracy: 0.9632 - cost: 4.6817 - val_loss: 0.1325 - val_auc: 0.9870 - val_accuracy: 0.9604 - val_cost: 4.8975\n",
            "Epoch 38/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.1104 - auc: 0.9909 - accuracy: 0.9638 - cost: 4.6042 - val_loss: 0.1316 - val_auc: 0.9870 - val_accuracy: 0.9602 - val_cost: 4.9835\n",
            "Epoch 39/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1088 - auc: 0.9910 - accuracy: 0.9640 - cost: 4.5833 - val_loss: 0.1317 - val_auc: 0.9869 - val_accuracy: 0.9601 - val_cost: 5.0198\n",
            "Epoch 40/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1077 - auc: 0.9912 - accuracy: 0.9649 - cost: 4.4745 - val_loss: 0.1317 - val_auc: 0.9869 - val_accuracy: 0.9603 - val_cost: 4.9239\n",
            "Epoch 41/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1066 - auc: 0.9913 - accuracy: 0.9652 - cost: 4.4325 - val_loss: 0.1304 - val_auc: 0.9873 - val_accuracy: 0.9604 - val_cost: 4.9074\n",
            "Epoch 42/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1056 - auc: 0.9915 - accuracy: 0.9655 - cost: 4.3939 - val_loss: 0.1301 - val_auc: 0.9872 - val_accuracy: 0.9597 - val_cost: 5.0529\n",
            "Epoch 43/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1057 - auc: 0.9914 - accuracy: 0.9654 - cost: 4.4113 - val_loss: 0.1289 - val_auc: 0.9873 - val_accuracy: 0.9619 - val_cost: 4.6197\n",
            "Epoch 44/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1048 - auc: 0.9915 - accuracy: 0.9658 - cost: 4.3546 - val_loss: 0.1279 - val_auc: 0.9877 - val_accuracy: 0.9621 - val_cost: 4.6263\n",
            "Epoch 45/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.1035 - auc: 0.9917 - accuracy: 0.9666 - cost: 4.2554 - val_loss: 0.1269 - val_auc: 0.9877 - val_accuracy: 0.9621 - val_cost: 4.6362\n",
            "Epoch 46/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1037 - auc: 0.9917 - accuracy: 0.9663 - cost: 4.2909 - val_loss: 0.1278 - val_auc: 0.9874 - val_accuracy: 0.9625 - val_cost: 4.6958\n",
            "Epoch 47/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1029 - auc: 0.9918 - accuracy: 0.9667 - cost: 4.2500 - val_loss: 0.1283 - val_auc: 0.9875 - val_accuracy: 0.9620 - val_cost: 4.7288\n",
            "Epoch 48/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1026 - auc: 0.9919 - accuracy: 0.9664 - cost: 4.2913 - val_loss: 0.1270 - val_auc: 0.9875 - val_accuracy: 0.9619 - val_cost: 4.7156\n",
            "Epoch 49/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1006 - auc: 0.9921 - accuracy: 0.9672 - cost: 4.1717 - val_loss: 0.1260 - val_auc: 0.9877 - val_accuracy: 0.9626 - val_cost: 4.5734\n",
            "Epoch 50/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0990 - auc: 0.9922 - accuracy: 0.9682 - cost: 4.0467 - val_loss: 0.1267 - val_auc: 0.9876 - val_accuracy: 0.9619 - val_cost: 4.8743\n",
            "Epoch 51/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0996 - auc: 0.9921 - accuracy: 0.9679 - cost: 4.0957 - val_loss: 0.1250 - val_auc: 0.9879 - val_accuracy: 0.9620 - val_cost: 4.7851\n",
            "Epoch 52/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0991 - auc: 0.9922 - accuracy: 0.9681 - cost: 4.0644 - val_loss: 0.1254 - val_auc: 0.9879 - val_accuracy: 0.9626 - val_cost: 4.6065\n",
            "Epoch 53/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0973 - auc: 0.9925 - accuracy: 0.9688 - cost: 3.9888 - val_loss: 0.1237 - val_auc: 0.9880 - val_accuracy: 0.9642 - val_cost: 4.3750\n",
            "Epoch 54/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0978 - auc: 0.9923 - accuracy: 0.9686 - cost: 4.0093 - val_loss: 0.1233 - val_auc: 0.9880 - val_accuracy: 0.9638 - val_cost: 4.4974\n",
            "Epoch 55/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0963 - auc: 0.9924 - accuracy: 0.9690 - cost: 3.9568 - val_loss: 0.1227 - val_auc: 0.9881 - val_accuracy: 0.9629 - val_cost: 4.6462\n",
            "Epoch 56/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0956 - auc: 0.9926 - accuracy: 0.9692 - cost: 3.9271 - val_loss: 0.1212 - val_auc: 0.9883 - val_accuracy: 0.9635 - val_cost: 4.5602\n",
            "Epoch 57/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0949 - auc: 0.9926 - accuracy: 0.9697 - cost: 3.8673 - val_loss: 0.1231 - val_auc: 0.9882 - val_accuracy: 0.9629 - val_cost: 4.6759\n",
            "Epoch 58/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0945 - auc: 0.9927 - accuracy: 0.9701 - cost: 3.8225 - val_loss: 0.1220 - val_auc: 0.9883 - val_accuracy: 0.9648 - val_cost: 4.3188\n",
            "Epoch 59/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0939 - auc: 0.9928 - accuracy: 0.9696 - cost: 3.8746 - val_loss: 0.1225 - val_auc: 0.9882 - val_accuracy: 0.9644 - val_cost: 4.4180\n",
            "Epoch 60/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0938 - auc: 0.9928 - accuracy: 0.9698 - cost: 3.8538 - val_loss: 0.1213 - val_auc: 0.9884 - val_accuracy: 0.9640 - val_cost: 4.4742\n",
            "Epoch 61/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0922 - auc: 0.9930 - accuracy: 0.9709 - cost: 3.7191 - val_loss: 0.1209 - val_auc: 0.9883 - val_accuracy: 0.9642 - val_cost: 4.4742\n",
            "Epoch 62/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0916 - auc: 0.9931 - accuracy: 0.9708 - cost: 3.7207 - val_loss: 0.1209 - val_auc: 0.9887 - val_accuracy: 0.9649 - val_cost: 4.2493\n",
            "Epoch 63/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0924 - auc: 0.9929 - accuracy: 0.9705 - cost: 3.7778 - val_loss: 0.1202 - val_auc: 0.9885 - val_accuracy: 0.9651 - val_cost: 4.3485\n",
            "Epoch 64/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0907 - auc: 0.9930 - accuracy: 0.9717 - cost: 3.6242 - val_loss: 0.1204 - val_auc: 0.9886 - val_accuracy: 0.9649 - val_cost: 4.3287\n",
            "Epoch 65/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0903 - auc: 0.9931 - accuracy: 0.9714 - cost: 3.6547 - val_loss: 0.1199 - val_auc: 0.9886 - val_accuracy: 0.9669 - val_cost: 4.0708\n",
            "Epoch 66/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0895 - auc: 0.9932 - accuracy: 0.9718 - cost: 3.5988 - val_loss: 0.1210 - val_auc: 0.9887 - val_accuracy: 0.9657 - val_cost: 4.2725\n",
            "Epoch 67/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0894 - auc: 0.9932 - accuracy: 0.9718 - cost: 3.5934 - val_loss: 0.1207 - val_auc: 0.9886 - val_accuracy: 0.9647 - val_cost: 4.2593\n",
            "Epoch 68/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0891 - auc: 0.9933 - accuracy: 0.9718 - cost: 3.6088 - val_loss: 0.1200 - val_auc: 0.9886 - val_accuracy: 0.9650 - val_cost: 4.2460\n",
            "Epoch 69/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0890 - auc: 0.9932 - accuracy: 0.9722 - cost: 3.5733 - val_loss: 0.1186 - val_auc: 0.9888 - val_accuracy: 0.9662 - val_cost: 4.1534\n",
            "Epoch 70/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0878 - auc: 0.9934 - accuracy: 0.9732 - cost: 3.4383 - val_loss: 0.1196 - val_auc: 0.9886 - val_accuracy: 0.9658 - val_cost: 4.2626\n",
            "Epoch 71/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0873 - auc: 0.9934 - accuracy: 0.9727 - cost: 3.4919 - val_loss: 0.1192 - val_auc: 0.9886 - val_accuracy: 0.9667 - val_cost: 4.1534\n",
            "Epoch 72/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0870 - auc: 0.9935 - accuracy: 0.9731 - cost: 3.4421 - val_loss: 0.1189 - val_auc: 0.9888 - val_accuracy: 0.9657 - val_cost: 4.2262\n",
            "Epoch 73/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0871 - auc: 0.9934 - accuracy: 0.9724 - cost: 3.5359 - val_loss: 0.1175 - val_auc: 0.9887 - val_accuracy: 0.9667 - val_cost: 4.1303\n",
            "Epoch 74/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0861 - auc: 0.9936 - accuracy: 0.9731 - cost: 3.4475 - val_loss: 0.1179 - val_auc: 0.9889 - val_accuracy: 0.9674 - val_cost: 4.0079\n",
            "Epoch 75/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0852 - auc: 0.9936 - accuracy: 0.9739 - cost: 3.3438 - val_loss: 0.1176 - val_auc: 0.9888 - val_accuracy: 0.9663 - val_cost: 4.1369\n",
            "Epoch 76/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0850 - auc: 0.9937 - accuracy: 0.9732 - cost: 3.4271 - val_loss: 0.1187 - val_auc: 0.9889 - val_accuracy: 0.9658 - val_cost: 4.2196\n",
            "Epoch 77/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0837 - auc: 0.9938 - accuracy: 0.9740 - cost: 3.3218 - val_loss: 0.1190 - val_auc: 0.9886 - val_accuracy: 0.9658 - val_cost: 4.2725\n",
            "Epoch 78/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0841 - auc: 0.9938 - accuracy: 0.9737 - cost: 3.3839 - val_loss: 0.1176 - val_auc: 0.9890 - val_accuracy: 0.9670 - val_cost: 4.0575\n",
            "Epoch 79/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0839 - auc: 0.9938 - accuracy: 0.9741 - cost: 3.3233 - val_loss: 0.1181 - val_auc: 0.9889 - val_accuracy: 0.9669 - val_cost: 4.1138\n",
            "Epoch 80/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0830 - auc: 0.9939 - accuracy: 0.9743 - cost: 3.2878 - val_loss: 0.1174 - val_auc: 0.9889 - val_accuracy: 0.9667 - val_cost: 4.1204\n",
            "Epoch 81/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0826 - auc: 0.9939 - accuracy: 0.9746 - cost: 3.2596 - val_loss: 0.1156 - val_auc: 0.9891 - val_accuracy: 0.9667 - val_cost: 4.1435\n",
            "Epoch 82/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0823 - auc: 0.9939 - accuracy: 0.9746 - cost: 3.2523 - val_loss: 0.1166 - val_auc: 0.9891 - val_accuracy: 0.9656 - val_cost: 4.3155\n",
            "Epoch 83/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0824 - auc: 0.9939 - accuracy: 0.9747 - cost: 3.2446 - val_loss: 0.1174 - val_auc: 0.9890 - val_accuracy: 0.9669 - val_cost: 4.1733\n",
            "Epoch 84/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0829 - auc: 0.9938 - accuracy: 0.9749 - cost: 3.2269 - val_loss: 0.1183 - val_auc: 0.9890 - val_accuracy: 0.9658 - val_cost: 4.2460\n",
            "Epoch 85/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0812 - auc: 0.9940 - accuracy: 0.9753 - cost: 3.1682 - val_loss: 0.1175 - val_auc: 0.9889 - val_accuracy: 0.9671 - val_cost: 4.1303\n",
            "Epoch 86/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0815 - auc: 0.9940 - accuracy: 0.9750 - cost: 3.2029 - val_loss: 0.1177 - val_auc: 0.9890 - val_accuracy: 0.9669 - val_cost: 4.0344\n",
            "Epoch 87/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0801 - auc: 0.9941 - accuracy: 0.9757 - cost: 3.1073 - val_loss: 0.1190 - val_auc: 0.9887 - val_accuracy: 0.9658 - val_cost: 4.2725\n",
            "Epoch 88/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0801 - auc: 0.9941 - accuracy: 0.9756 - cost: 3.1273 - val_loss: 0.1186 - val_auc: 0.9888 - val_accuracy: 0.9669 - val_cost: 4.0840\n",
            "Epoch 89/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0798 - auc: 0.9942 - accuracy: 0.9753 - cost: 3.1694 - val_loss: 0.1169 - val_auc: 0.9889 - val_accuracy: 0.9666 - val_cost: 4.1369\n",
            "Epoch 90/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0802 - auc: 0.9941 - accuracy: 0.9754 - cost: 3.1543 - val_loss: 0.1186 - val_auc: 0.9888 - val_accuracy: 0.9669 - val_cost: 4.2758\n",
            "Epoch 91/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0798 - auc: 0.9941 - accuracy: 0.9755 - cost: 3.1485 - val_loss: 0.1180 - val_auc: 0.9886 - val_accuracy: 0.9663 - val_cost: 4.2493\n",
            "Epoch 92/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0798 - auc: 0.9940 - accuracy: 0.9758 - cost: 3.1003 - val_loss: 0.1171 - val_auc: 0.9889 - val_accuracy: 0.9668 - val_cost: 4.1071\n",
            "Epoch 93/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0797 - auc: 0.9941 - accuracy: 0.9755 - cost: 3.1408 - val_loss: 0.1188 - val_auc: 0.9885 - val_accuracy: 0.9665 - val_cost: 4.1832\n",
            "Epoch 94/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0791 - auc: 0.9942 - accuracy: 0.9759 - cost: 3.0887 - val_loss: 0.1167 - val_auc: 0.9892 - val_accuracy: 0.9674 - val_cost: 4.0046\n",
            "Epoch 95/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0797 - auc: 0.9942 - accuracy: 0.9756 - cost: 3.1100 - val_loss: 0.1168 - val_auc: 0.9889 - val_accuracy: 0.9679 - val_cost: 4.0840\n",
            "Epoch 96/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0778 - auc: 0.9944 - accuracy: 0.9764 - cost: 3.0297 - val_loss: 0.1179 - val_auc: 0.9890 - val_accuracy: 0.9673 - val_cost: 4.1501\n",
            "Epoch 97/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0779 - auc: 0.9942 - accuracy: 0.9765 - cost: 3.0170 - val_loss: 0.1177 - val_auc: 0.9887 - val_accuracy: 0.9673 - val_cost: 4.1667\n",
            "Epoch 98/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0772 - auc: 0.9943 - accuracy: 0.9762 - cost: 3.0529 - val_loss: 0.1192 - val_auc: 0.9887 - val_accuracy: 0.9670 - val_cost: 4.0873\n",
            "Epoch 99/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0771 - auc: 0.9944 - accuracy: 0.9766 - cost: 2.9988 - val_loss: 0.1177 - val_auc: 0.9888 - val_accuracy: 0.9688 - val_cost: 3.9087\n",
            "Epoch 100/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0772 - auc: 0.9944 - accuracy: 0.9767 - cost: 2.9850 - val_loss: 0.1195 - val_auc: 0.9888 - val_accuracy: 0.9667 - val_cost: 4.1270\n",
            "Epoch 101/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0769 - auc: 0.9944 - accuracy: 0.9764 - cost: 3.0247 - val_loss: 0.1180 - val_auc: 0.9889 - val_accuracy: 0.9680 - val_cost: 3.9021\n",
            "Epoch 102/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0771 - auc: 0.9944 - accuracy: 0.9766 - cost: 2.9977 - val_loss: 0.1204 - val_auc: 0.9885 - val_accuracy: 0.9669 - val_cost: 3.9947\n",
            "Epoch 103/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0762 - auc: 0.9945 - accuracy: 0.9767 - cost: 2.9823 - val_loss: 0.1179 - val_auc: 0.9891 - val_accuracy: 0.9673 - val_cost: 4.1667\n",
            "Epoch 104/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0756 - auc: 0.9946 - accuracy: 0.9772 - cost: 2.9286 - val_loss: 0.1168 - val_auc: 0.9888 - val_accuracy: 0.9678 - val_cost: 4.0675\n",
            "Epoch 105/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0760 - auc: 0.9945 - accuracy: 0.9769 - cost: 2.9479 - val_loss: 0.1171 - val_auc: 0.9892 - val_accuracy: 0.9678 - val_cost: 4.0509\n",
            "Epoch 106/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0754 - auc: 0.9946 - accuracy: 0.9769 - cost: 2.9533 - val_loss: 0.1212 - val_auc: 0.9888 - val_accuracy: 0.9669 - val_cost: 4.0443\n",
            "Epoch 107/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0754 - auc: 0.9947 - accuracy: 0.9771 - cost: 2.9290 - val_loss: 0.1209 - val_auc: 0.9888 - val_accuracy: 0.9672 - val_cost: 4.1270\n",
            "Epoch 108/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0763 - auc: 0.9944 - accuracy: 0.9770 - cost: 2.9506 - val_loss: 0.1176 - val_auc: 0.9890 - val_accuracy: 0.9666 - val_cost: 4.1766\n",
            "Epoch 109/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0752 - auc: 0.9946 - accuracy: 0.9770 - cost: 2.9429 - val_loss: 0.1196 - val_auc: 0.9889 - val_accuracy: 0.9678 - val_cost: 3.9683\n",
            "Epoch 110/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0743 - auc: 0.9948 - accuracy: 0.9774 - cost: 2.9012 - val_loss: 0.1207 - val_auc: 0.9887 - val_accuracy: 0.9676 - val_cost: 3.9947\n",
            "Epoch 111/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0749 - auc: 0.9947 - accuracy: 0.9772 - cost: 2.9190 - val_loss: 0.1193 - val_auc: 0.9890 - val_accuracy: 0.9673 - val_cost: 4.0774\n",
            "Epoch 112/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0746 - auc: 0.9946 - accuracy: 0.9773 - cost: 2.9051 - val_loss: 0.1172 - val_auc: 0.9891 - val_accuracy: 0.9678 - val_cost: 4.1402\n",
            "Epoch 113/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0735 - auc: 0.9948 - accuracy: 0.9779 - cost: 2.8229 - val_loss: 0.1187 - val_auc: 0.9892 - val_accuracy: 0.9672 - val_cost: 4.0344\n",
            "Epoch 114/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0742 - auc: 0.9947 - accuracy: 0.9779 - cost: 2.8465 - val_loss: 0.1201 - val_auc: 0.9888 - val_accuracy: 0.9663 - val_cost: 4.3089\n",
            "Epoch 115/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0754 - auc: 0.9946 - accuracy: 0.9769 - cost: 2.9552 - val_loss: 0.1198 - val_auc: 0.9890 - val_accuracy: 0.9677 - val_cost: 4.0079\n",
            "Epoch 116/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0742 - auc: 0.9946 - accuracy: 0.9773 - cost: 2.9147 - val_loss: 0.1211 - val_auc: 0.9886 - val_accuracy: 0.9679 - val_cost: 3.8624\n",
            "Epoch 117/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0738 - auc: 0.9947 - accuracy: 0.9779 - cost: 2.8318 - val_loss: 0.1184 - val_auc: 0.9890 - val_accuracy: 0.9676 - val_cost: 4.0509\n",
            "Epoch 118/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0737 - auc: 0.9948 - accuracy: 0.9776 - cost: 2.8681 - val_loss: 0.1189 - val_auc: 0.9889 - val_accuracy: 0.9683 - val_cost: 3.9220\n",
            "Epoch 119/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0729 - auc: 0.9948 - accuracy: 0.9779 - cost: 2.8368 - val_loss: 0.1204 - val_auc: 0.9886 - val_accuracy: 0.9679 - val_cost: 3.9220\n",
            "Epoch 120/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0735 - auc: 0.9948 - accuracy: 0.9774 - cost: 2.8951 - val_loss: 0.1207 - val_auc: 0.9888 - val_accuracy: 0.9681 - val_cost: 3.9352\n",
            "Epoch 121/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0729 - auc: 0.9948 - accuracy: 0.9782 - cost: 2.7998 - val_loss: 0.1184 - val_auc: 0.9890 - val_accuracy: 0.9676 - val_cost: 4.0807\n",
            "Epoch 122/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0722 - auc: 0.9949 - accuracy: 0.9782 - cost: 2.7932 - val_loss: 0.1200 - val_auc: 0.9888 - val_accuracy: 0.9674 - val_cost: 4.0410\n",
            "Epoch 123/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0726 - auc: 0.9949 - accuracy: 0.9780 - cost: 2.8237 - val_loss: 0.1191 - val_auc: 0.9887 - val_accuracy: 0.9671 - val_cost: 4.1237\n",
            "Epoch 124/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0721 - auc: 0.9950 - accuracy: 0.9783 - cost: 2.7766 - val_loss: 0.1192 - val_auc: 0.9891 - val_accuracy: 0.9678 - val_cost: 4.0179\n",
            "Epoch 125/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0718 - auc: 0.9950 - accuracy: 0.9782 - cost: 2.7967 - val_loss: 0.1204 - val_auc: 0.9888 - val_accuracy: 0.9667 - val_cost: 4.1898\n",
            "Epoch 126/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0717 - auc: 0.9950 - accuracy: 0.9781 - cost: 2.8117 - val_loss: 0.1182 - val_auc: 0.9890 - val_accuracy: 0.9675 - val_cost: 4.0939\n",
            "Epoch 127/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0719 - auc: 0.9948 - accuracy: 0.9781 - cost: 2.8021 - val_loss: 0.1198 - val_auc: 0.9890 - val_accuracy: 0.9672 - val_cost: 4.0873\n",
            "Epoch 128/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0716 - auc: 0.9950 - accuracy: 0.9782 - cost: 2.7921 - val_loss: 0.1207 - val_auc: 0.9882 - val_accuracy: 0.9672 - val_cost: 4.1468\n",
            "Epoch 129/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0716 - auc: 0.9949 - accuracy: 0.9787 - cost: 2.7299 - val_loss: 0.1185 - val_auc: 0.9887 - val_accuracy: 0.9678 - val_cost: 4.0939\n",
            "Epoch 130/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0718 - auc: 0.9949 - accuracy: 0.9785 - cost: 2.7608 - val_loss: 0.1223 - val_auc: 0.9885 - val_accuracy: 0.9673 - val_cost: 4.0575\n",
            "Epoch 131/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0714 - auc: 0.9950 - accuracy: 0.9785 - cost: 2.7566 - val_loss: 0.1184 - val_auc: 0.9892 - val_accuracy: 0.9676 - val_cost: 4.0708\n",
            "Epoch 132/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0705 - auc: 0.9951 - accuracy: 0.9788 - cost: 2.7087 - val_loss: 0.1205 - val_auc: 0.9889 - val_accuracy: 0.9676 - val_cost: 4.0146\n",
            "Epoch 133/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0709 - auc: 0.9950 - accuracy: 0.9786 - cost: 2.7527 - val_loss: 0.1204 - val_auc: 0.9887 - val_accuracy: 0.9671 - val_cost: 4.1402\n",
            "Epoch 134/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0704 - auc: 0.9951 - accuracy: 0.9788 - cost: 2.7176 - val_loss: 0.1198 - val_auc: 0.9889 - val_accuracy: 0.9676 - val_cost: 4.0774\n",
            "Epoch 135/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0710 - auc: 0.9950 - accuracy: 0.9786 - cost: 2.7380 - val_loss: 0.1218 - val_auc: 0.9889 - val_accuracy: 0.9663 - val_cost: 4.1435\n",
            "Epoch 136/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0705 - auc: 0.9950 - accuracy: 0.9786 - cost: 2.7450 - val_loss: 0.1188 - val_auc: 0.9887 - val_accuracy: 0.9689 - val_cost: 3.8889\n",
            "Epoch 137/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0699 - auc: 0.9952 - accuracy: 0.9791 - cost: 2.6663 - val_loss: 0.1171 - val_auc: 0.9892 - val_accuracy: 0.9689 - val_cost: 4.0112\n",
            "Epoch 138/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0697 - auc: 0.9951 - accuracy: 0.9792 - cost: 2.6759 - val_loss: 0.1215 - val_auc: 0.9888 - val_accuracy: 0.9674 - val_cost: 4.0708\n",
            "Epoch 139/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0697 - auc: 0.9951 - accuracy: 0.9791 - cost: 2.6624 - val_loss: 0.1204 - val_auc: 0.9887 - val_accuracy: 0.9676 - val_cost: 4.1237\n",
            "Epoch 140/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0705 - auc: 0.9950 - accuracy: 0.9788 - cost: 2.7164 - val_loss: 0.1187 - val_auc: 0.9893 - val_accuracy: 0.9681 - val_cost: 4.0741\n",
            "Epoch 141/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0700 - auc: 0.9951 - accuracy: 0.9790 - cost: 2.6917 - val_loss: 0.1185 - val_auc: 0.9889 - val_accuracy: 0.9690 - val_cost: 3.8724\n",
            "Epoch 142/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0688 - auc: 0.9952 - accuracy: 0.9789 - cost: 2.6998 - val_loss: 0.1221 - val_auc: 0.9888 - val_accuracy: 0.9674 - val_cost: 3.9253\n",
            "Epoch 143/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0696 - auc: 0.9951 - accuracy: 0.9791 - cost: 2.6825 - val_loss: 0.1207 - val_auc: 0.9885 - val_accuracy: 0.9678 - val_cost: 4.0377\n",
            "Epoch 144/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0698 - auc: 0.9951 - accuracy: 0.9789 - cost: 2.7103 - val_loss: 0.1197 - val_auc: 0.9888 - val_accuracy: 0.9690 - val_cost: 3.8856\n",
            "Epoch 145/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0685 - auc: 0.9952 - accuracy: 0.9796 - cost: 2.6235 - val_loss: 0.1207 - val_auc: 0.9889 - val_accuracy: 0.9676 - val_cost: 4.0807\n",
            "Epoch 146/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0693 - auc: 0.9952 - accuracy: 0.9795 - cost: 2.6362 - val_loss: 0.1205 - val_auc: 0.9888 - val_accuracy: 0.9692 - val_cost: 3.8459\n",
            "Epoch 147/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0689 - auc: 0.9952 - accuracy: 0.9796 - cost: 2.6169 - val_loss: 0.1190 - val_auc: 0.9888 - val_accuracy: 0.9681 - val_cost: 4.0642\n",
            "Epoch 148/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0687 - auc: 0.9952 - accuracy: 0.9796 - cost: 2.6134 - val_loss: 0.1215 - val_auc: 0.9886 - val_accuracy: 0.9683 - val_cost: 3.9649\n",
            "Epoch 149/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0686 - auc: 0.9953 - accuracy: 0.9795 - cost: 2.6312 - val_loss: 0.1217 - val_auc: 0.9887 - val_accuracy: 0.9656 - val_cost: 4.2328\n",
            "Epoch 150/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0689 - auc: 0.9952 - accuracy: 0.9793 - cost: 2.6404 - val_loss: 0.1221 - val_auc: 0.9884 - val_accuracy: 0.9678 - val_cost: 4.1171\n",
            "Epoch 151/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0685 - auc: 0.9952 - accuracy: 0.9794 - cost: 2.6393 - val_loss: 0.1233 - val_auc: 0.9885 - val_accuracy: 0.9670 - val_cost: 4.0774\n",
            "Epoch 152/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0679 - auc: 0.9953 - accuracy: 0.9798 - cost: 2.5818 - val_loss: 0.1215 - val_auc: 0.9889 - val_accuracy: 0.9682 - val_cost: 4.0873\n",
            "Epoch 153/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0680 - auc: 0.9953 - accuracy: 0.9796 - cost: 2.6088 - val_loss: 0.1218 - val_auc: 0.9890 - val_accuracy: 0.9671 - val_cost: 4.0840\n",
            "Epoch 154/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0689 - auc: 0.9952 - accuracy: 0.9795 - cost: 2.6312 - val_loss: 0.1215 - val_auc: 0.9886 - val_accuracy: 0.9673 - val_cost: 4.1336\n",
            "Epoch 155/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0680 - auc: 0.9953 - accuracy: 0.9797 - cost: 2.6065 - val_loss: 0.1208 - val_auc: 0.9887 - val_accuracy: 0.9679 - val_cost: 4.0179\n",
            "Epoch 156/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0681 - auc: 0.9953 - accuracy: 0.9798 - cost: 2.5829 - val_loss: 0.1229 - val_auc: 0.9889 - val_accuracy: 0.9682 - val_cost: 3.9782\n",
            "Epoch 157/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0670 - auc: 0.9954 - accuracy: 0.9800 - cost: 2.5640 - val_loss: 0.1229 - val_auc: 0.9884 - val_accuracy: 0.9682 - val_cost: 4.0410\n",
            "Epoch 158/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0678 - auc: 0.9955 - accuracy: 0.9798 - cost: 2.5976 - val_loss: 0.1218 - val_auc: 0.9885 - val_accuracy: 0.9683 - val_cost: 3.9749\n",
            "Epoch 159/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0670 - auc: 0.9954 - accuracy: 0.9801 - cost: 2.5536 - val_loss: 0.1215 - val_auc: 0.9887 - val_accuracy: 0.9676 - val_cost: 4.0013\n",
            "Epoch 160/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0677 - auc: 0.9954 - accuracy: 0.9796 - cost: 2.6181 - val_loss: 0.1219 - val_auc: 0.9889 - val_accuracy: 0.9681 - val_cost: 4.0509\n",
            "Epoch 161/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0677 - auc: 0.9952 - accuracy: 0.9796 - cost: 2.6161 - val_loss: 0.1199 - val_auc: 0.9890 - val_accuracy: 0.9687 - val_cost: 3.9352\n",
            "Epoch 162/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0684 - auc: 0.9953 - accuracy: 0.9794 - cost: 2.6393 - val_loss: 0.1225 - val_auc: 0.9886 - val_accuracy: 0.9664 - val_cost: 4.2229\n",
            "Epoch 163/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0668 - auc: 0.9955 - accuracy: 0.9798 - cost: 2.6003 - val_loss: 0.1231 - val_auc: 0.9886 - val_accuracy: 0.9677 - val_cost: 4.0179\n",
            "Epoch 164/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0673 - auc: 0.9953 - accuracy: 0.9799 - cost: 2.5795 - val_loss: 0.1212 - val_auc: 0.9888 - val_accuracy: 0.9683 - val_cost: 3.9848\n",
            "Epoch 165/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0668 - auc: 0.9954 - accuracy: 0.9804 - cost: 2.5247 - val_loss: 0.1205 - val_auc: 0.9886 - val_accuracy: 0.9685 - val_cost: 4.0145\n",
            "Epoch 166/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0658 - auc: 0.9955 - accuracy: 0.9806 - cost: 2.4927 - val_loss: 0.1218 - val_auc: 0.9882 - val_accuracy: 0.9677 - val_cost: 4.0344\n",
            "Epoch 167/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0668 - auc: 0.9955 - accuracy: 0.9802 - cost: 2.5417 - val_loss: 0.1232 - val_auc: 0.9886 - val_accuracy: 0.9668 - val_cost: 4.1104\n",
            "Epoch 168/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0667 - auc: 0.9954 - accuracy: 0.9801 - cost: 2.5598 - val_loss: 0.1217 - val_auc: 0.9886 - val_accuracy: 0.9681 - val_cost: 3.9517\n",
            "Epoch 169/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0673 - auc: 0.9954 - accuracy: 0.9799 - cost: 2.5795 - val_loss: 0.1214 - val_auc: 0.9889 - val_accuracy: 0.9676 - val_cost: 4.0410\n",
            "Epoch 170/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0664 - auc: 0.9954 - accuracy: 0.9799 - cost: 2.5652 - val_loss: 0.1230 - val_auc: 0.9883 - val_accuracy: 0.9683 - val_cost: 3.9815\n",
            "Epoch 171/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0675 - auc: 0.9953 - accuracy: 0.9801 - cost: 2.5610 - val_loss: 0.1223 - val_auc: 0.9886 - val_accuracy: 0.9681 - val_cost: 3.9616\n",
            "Epoch 172/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0666 - auc: 0.9955 - accuracy: 0.9801 - cost: 2.5532 - val_loss: 0.1243 - val_auc: 0.9887 - val_accuracy: 0.9676 - val_cost: 4.1369\n",
            "Epoch 173/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0664 - auc: 0.9954 - accuracy: 0.9803 - cost: 2.5278 - val_loss: 0.1235 - val_auc: 0.9884 - val_accuracy: 0.9679 - val_cost: 4.0377\n",
            "Epoch 174/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0659 - auc: 0.9955 - accuracy: 0.9809 - cost: 2.4502 - val_loss: 0.1238 - val_auc: 0.9889 - val_accuracy: 0.9677 - val_cost: 3.9749\n",
            "Epoch 175/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0659 - auc: 0.9954 - accuracy: 0.9802 - cost: 2.5316 - val_loss: 0.1247 - val_auc: 0.9886 - val_accuracy: 0.9664 - val_cost: 4.1898\n",
            "Epoch 176/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0654 - auc: 0.9955 - accuracy: 0.9805 - cost: 2.5012 - val_loss: 0.1230 - val_auc: 0.9884 - val_accuracy: 0.9686 - val_cost: 3.9352\n",
            "Epoch 177/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0657 - auc: 0.9955 - accuracy: 0.9801 - cost: 2.5637 - val_loss: 0.1237 - val_auc: 0.9886 - val_accuracy: 0.9676 - val_cost: 4.0972\n",
            "Epoch 178/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0668 - auc: 0.9955 - accuracy: 0.9798 - cost: 2.5891 - val_loss: 0.1277 - val_auc: 0.9880 - val_accuracy: 0.9675 - val_cost: 3.9914\n",
            "Epoch 179/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0664 - auc: 0.9954 - accuracy: 0.9805 - cost: 2.4938 - val_loss: 0.1227 - val_auc: 0.9890 - val_accuracy: 0.9678 - val_cost: 4.0179\n",
            "Epoch 180/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0652 - auc: 0.9955 - accuracy: 0.9806 - cost: 2.4765 - val_loss: 0.1215 - val_auc: 0.9889 - val_accuracy: 0.9669 - val_cost: 4.1468\n",
            "Epoch 181/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0647 - auc: 0.9956 - accuracy: 0.9806 - cost: 2.4811 - val_loss: 0.1221 - val_auc: 0.9887 - val_accuracy: 0.9679 - val_cost: 4.0179\n",
            "Epoch 182/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0644 - auc: 0.9957 - accuracy: 0.9807 - cost: 2.4722 - val_loss: 0.1250 - val_auc: 0.9885 - val_accuracy: 0.9683 - val_cost: 3.9782\n",
            "Epoch 183/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0662 - auc: 0.9956 - accuracy: 0.9801 - cost: 2.5494 - val_loss: 0.1229 - val_auc: 0.9887 - val_accuracy: 0.9676 - val_cost: 3.9980\n",
            "Epoch 184/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0655 - auc: 0.9956 - accuracy: 0.9804 - cost: 2.5154 - val_loss: 0.1248 - val_auc: 0.9885 - val_accuracy: 0.9672 - val_cost: 4.1766\n",
            "Epoch 185/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0652 - auc: 0.9957 - accuracy: 0.9803 - cost: 2.5201 - val_loss: 0.1235 - val_auc: 0.9887 - val_accuracy: 0.9683 - val_cost: 4.0443\n",
            "Epoch 186/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0648 - auc: 0.9957 - accuracy: 0.9802 - cost: 2.5374 - val_loss: 0.1257 - val_auc: 0.9887 - val_accuracy: 0.9688 - val_cost: 3.9220\n",
            "Epoch 187/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0652 - auc: 0.9956 - accuracy: 0.9807 - cost: 2.4792 - val_loss: 0.1226 - val_auc: 0.9885 - val_accuracy: 0.9669 - val_cost: 4.1898\n",
            "Epoch 188/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0653 - auc: 0.9956 - accuracy: 0.9802 - cost: 2.5297 - val_loss: 0.1240 - val_auc: 0.9886 - val_accuracy: 0.9678 - val_cost: 3.9815\n",
            "Epoch 189/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0653 - auc: 0.9955 - accuracy: 0.9804 - cost: 2.5316 - val_loss: 0.1228 - val_auc: 0.9885 - val_accuracy: 0.9676 - val_cost: 4.0344\n",
            "Epoch 190/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0648 - auc: 0.9957 - accuracy: 0.9804 - cost: 2.5073 - val_loss: 0.1239 - val_auc: 0.9883 - val_accuracy: 0.9665 - val_cost: 4.2229\n",
            "Epoch 191/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0644 - auc: 0.9956 - accuracy: 0.9811 - cost: 2.4194 - val_loss: 0.1252 - val_auc: 0.9885 - val_accuracy: 0.9675 - val_cost: 4.0608\n",
            "Epoch 192/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0647 - auc: 0.9957 - accuracy: 0.9806 - cost: 2.4950 - val_loss: 0.1242 - val_auc: 0.9884 - val_accuracy: 0.9679 - val_cost: 4.1204\n",
            "Epoch 193/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0648 - auc: 0.9957 - accuracy: 0.9804 - cost: 2.5116 - val_loss: 0.1251 - val_auc: 0.9885 - val_accuracy: 0.9677 - val_cost: 4.1138\n",
            "Epoch 194/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0653 - auc: 0.9957 - accuracy: 0.9806 - cost: 2.4877 - val_loss: 0.1247 - val_auc: 0.9887 - val_accuracy: 0.9678 - val_cost: 3.9815\n",
            "Epoch 195/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0642 - auc: 0.9956 - accuracy: 0.9809 - cost: 2.4444 - val_loss: 0.1232 - val_auc: 0.9887 - val_accuracy: 0.9676 - val_cost: 4.0708\n",
            "Epoch 196/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0645 - auc: 0.9958 - accuracy: 0.9802 - cost: 2.5340 - val_loss: 0.1264 - val_auc: 0.9881 - val_accuracy: 0.9678 - val_cost: 4.0608\n",
            "Epoch 197/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0650 - auc: 0.9957 - accuracy: 0.9806 - cost: 2.4950 - val_loss: 0.1244 - val_auc: 0.9884 - val_accuracy: 0.9679 - val_cost: 3.9683\n",
            "Epoch 198/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0645 - auc: 0.9958 - accuracy: 0.9808 - cost: 2.4626 - val_loss: 0.1252 - val_auc: 0.9883 - val_accuracy: 0.9676 - val_cost: 4.1435\n",
            "Epoch 199/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0638 - auc: 0.9958 - accuracy: 0.9807 - cost: 2.4819 - val_loss: 0.1266 - val_auc: 0.9882 - val_accuracy: 0.9676 - val_cost: 4.0013\n",
            "Epoch 200/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0639 - auc: 0.9957 - accuracy: 0.9810 - cost: 2.4329 - val_loss: 0.1263 - val_auc: 0.9883 - val_accuracy: 0.9672 - val_cost: 4.2262\n",
            "Epoch 201/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0637 - auc: 0.9957 - accuracy: 0.9809 - cost: 2.4460 - val_loss: 0.1257 - val_auc: 0.9884 - val_accuracy: 0.9666 - val_cost: 4.1832\n",
            "Epoch 202/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0646 - auc: 0.9957 - accuracy: 0.9807 - cost: 2.4838 - val_loss: 0.1266 - val_auc: 0.9884 - val_accuracy: 0.9681 - val_cost: 3.8657\n",
            "Epoch 203/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0633 - auc: 0.9958 - accuracy: 0.9813 - cost: 2.4001 - val_loss: 0.1262 - val_auc: 0.9886 - val_accuracy: 0.9676 - val_cost: 4.0013\n",
            "Epoch 204/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0634 - auc: 0.9958 - accuracy: 0.9812 - cost: 2.4209 - val_loss: 0.1251 - val_auc: 0.9882 - val_accuracy: 0.9679 - val_cost: 3.9782\n",
            "Epoch 205/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0642 - auc: 0.9957 - accuracy: 0.9811 - cost: 2.4159 - val_loss: 0.1260 - val_auc: 0.9885 - val_accuracy: 0.9681 - val_cost: 4.0046\n",
            "Epoch 206/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0638 - auc: 0.9959 - accuracy: 0.9809 - cost: 2.4456 - val_loss: 0.1272 - val_auc: 0.9881 - val_accuracy: 0.9669 - val_cost: 4.1005\n",
            "Epoch 207/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0634 - auc: 0.9957 - accuracy: 0.9810 - cost: 2.4321 - val_loss: 0.1254 - val_auc: 0.9882 - val_accuracy: 0.9681 - val_cost: 4.0212\n",
            "Epoch 208/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0629 - auc: 0.9959 - accuracy: 0.9816 - cost: 2.3646 - val_loss: 0.1262 - val_auc: 0.9883 - val_accuracy: 0.9683 - val_cost: 3.9782\n",
            "Epoch 209/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0633 - auc: 0.9959 - accuracy: 0.9810 - cost: 2.4336 - val_loss: 0.1249 - val_auc: 0.9885 - val_accuracy: 0.9674 - val_cost: 4.0344\n",
            "Epoch 210/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0626 - auc: 0.9958 - accuracy: 0.9815 - cost: 2.3765 - val_loss: 0.1268 - val_auc: 0.9881 - val_accuracy: 0.9674 - val_cost: 4.1171\n",
            "Epoch 211/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0634 - auc: 0.9957 - accuracy: 0.9812 - cost: 2.4201 - val_loss: 0.1258 - val_auc: 0.9881 - val_accuracy: 0.9667 - val_cost: 4.2526\n",
            "Epoch 212/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0641 - auc: 0.9957 - accuracy: 0.9808 - cost: 2.4688 - val_loss: 0.1261 - val_auc: 0.9885 - val_accuracy: 0.9673 - val_cost: 4.1171\n",
            "Epoch 213/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0634 - auc: 0.9958 - accuracy: 0.9810 - cost: 2.4433 - val_loss: 0.1261 - val_auc: 0.9886 - val_accuracy: 0.9676 - val_cost: 4.0046\n",
            "Epoch 214/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0628 - auc: 0.9958 - accuracy: 0.9808 - cost: 2.4668 - val_loss: 0.1260 - val_auc: 0.9881 - val_accuracy: 0.9676 - val_cost: 4.1402\n",
            "Epoch 215/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0618 - auc: 0.9960 - accuracy: 0.9816 - cost: 2.3638 - val_loss: 0.1265 - val_auc: 0.9884 - val_accuracy: 0.9670 - val_cost: 4.2560\n",
            "Epoch 216/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0640 - auc: 0.9957 - accuracy: 0.9807 - cost: 2.4745 - val_loss: 0.1249 - val_auc: 0.9886 - val_accuracy: 0.9686 - val_cost: 3.9616\n",
            "Epoch 217/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0636 - auc: 0.9957 - accuracy: 0.9811 - cost: 2.4201 - val_loss: 0.1259 - val_auc: 0.9884 - val_accuracy: 0.9676 - val_cost: 4.1005\n",
            "Epoch 218/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0627 - auc: 0.9958 - accuracy: 0.9816 - cost: 2.3654 - val_loss: 0.1271 - val_auc: 0.9883 - val_accuracy: 0.9678 - val_cost: 3.9947\n",
            "Epoch 219/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0622 - auc: 0.9959 - accuracy: 0.9812 - cost: 2.4039 - val_loss: 0.1267 - val_auc: 0.9883 - val_accuracy: 0.9677 - val_cost: 4.0575\n",
            "Epoch 220/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0618 - auc: 0.9959 - accuracy: 0.9815 - cost: 2.3808 - val_loss: 0.1279 - val_auc: 0.9881 - val_accuracy: 0.9673 - val_cost: 4.1634\n",
            "Epoch 221/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0630 - auc: 0.9959 - accuracy: 0.9810 - cost: 2.4302 - val_loss: 0.1269 - val_auc: 0.9882 - val_accuracy: 0.9677 - val_cost: 4.0608\n",
            "Epoch 222/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0626 - auc: 0.9959 - accuracy: 0.9815 - cost: 2.3754 - val_loss: 0.1250 - val_auc: 0.9887 - val_accuracy: 0.9669 - val_cost: 4.1534\n",
            "Epoch 223/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0622 - auc: 0.9959 - accuracy: 0.9815 - cost: 2.3846 - val_loss: 0.1279 - val_auc: 0.9882 - val_accuracy: 0.9671 - val_cost: 4.0873\n",
            "Epoch 224/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0621 - auc: 0.9960 - accuracy: 0.9815 - cost: 2.3769 - val_loss: 0.1271 - val_auc: 0.9878 - val_accuracy: 0.9668 - val_cost: 4.1567\n",
            "Epoch 225/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0619 - auc: 0.9961 - accuracy: 0.9814 - cost: 2.4001 - val_loss: 0.1271 - val_auc: 0.9885 - val_accuracy: 0.9669 - val_cost: 4.1369\n",
            "Epoch 226/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0624 - auc: 0.9958 - accuracy: 0.9815 - cost: 2.3677 - val_loss: 0.1295 - val_auc: 0.9881 - val_accuracy: 0.9674 - val_cost: 4.0972\n",
            "Epoch 227/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0621 - auc: 0.9959 - accuracy: 0.9816 - cost: 2.3642 - val_loss: 0.1261 - val_auc: 0.9885 - val_accuracy: 0.9667 - val_cost: 4.1534\n",
            "Epoch 228/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0619 - auc: 0.9960 - accuracy: 0.9814 - cost: 2.3889 - val_loss: 0.1299 - val_auc: 0.9880 - val_accuracy: 0.9675 - val_cost: 4.0542\n",
            "Epoch 229/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0624 - auc: 0.9958 - accuracy: 0.9815 - cost: 2.3754 - val_loss: 0.1272 - val_auc: 0.9884 - val_accuracy: 0.9677 - val_cost: 4.0443\n",
            "Epoch 230/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0622 - auc: 0.9959 - accuracy: 0.9808 - cost: 2.4672 - val_loss: 0.1267 - val_auc: 0.9883 - val_accuracy: 0.9677 - val_cost: 4.0642\n",
            "Epoch 231/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0616 - auc: 0.9960 - accuracy: 0.9816 - cost: 2.3750 - val_loss: 0.1288 - val_auc: 0.9882 - val_accuracy: 0.9678 - val_cost: 3.9319\n",
            "Epoch 232/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0622 - auc: 0.9960 - accuracy: 0.9811 - cost: 2.4290 - val_loss: 0.1280 - val_auc: 0.9879 - val_accuracy: 0.9676 - val_cost: 3.9980\n",
            "Epoch 233/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0618 - auc: 0.9959 - accuracy: 0.9813 - cost: 2.4028 - val_loss: 0.1300 - val_auc: 0.9882 - val_accuracy: 0.9675 - val_cost: 3.9782\n",
            "Epoch 234/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0620 - auc: 0.9959 - accuracy: 0.9815 - cost: 2.3688 - val_loss: 0.1299 - val_auc: 0.9879 - val_accuracy: 0.9676 - val_cost: 3.9451\n",
            "Epoch 235/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0611 - auc: 0.9960 - accuracy: 0.9818 - cost: 2.3245 - val_loss: 0.1289 - val_auc: 0.9887 - val_accuracy: 0.9681 - val_cost: 3.9550\n",
            "Epoch 236/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0616 - auc: 0.9959 - accuracy: 0.9811 - cost: 2.4344 - val_loss: 0.1285 - val_auc: 0.9883 - val_accuracy: 0.9665 - val_cost: 4.1435\n",
            "Epoch 237/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0605 - auc: 0.9961 - accuracy: 0.9816 - cost: 2.3619 - val_loss: 0.1282 - val_auc: 0.9882 - val_accuracy: 0.9681 - val_cost: 3.9517\n",
            "Epoch 238/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0623 - auc: 0.9959 - accuracy: 0.9814 - cost: 2.3970 - val_loss: 0.1284 - val_auc: 0.9881 - val_accuracy: 0.9672 - val_cost: 4.1005\n",
            "Epoch 239/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0610 - auc: 0.9960 - accuracy: 0.9817 - cost: 2.3480 - val_loss: 0.1282 - val_auc: 0.9879 - val_accuracy: 0.9679 - val_cost: 4.0675\n",
            "Epoch 240/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0613 - auc: 0.9960 - accuracy: 0.9814 - cost: 2.3777 - val_loss: 0.1299 - val_auc: 0.9880 - val_accuracy: 0.9672 - val_cost: 3.9716\n",
            "Epoch 241/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0619 - auc: 0.9961 - accuracy: 0.9811 - cost: 2.4252 - val_loss: 0.1306 - val_auc: 0.9881 - val_accuracy: 0.9669 - val_cost: 4.0542\n",
            "Epoch 242/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0618 - auc: 0.9959 - accuracy: 0.9813 - cost: 2.4032 - val_loss: 0.1306 - val_auc: 0.9881 - val_accuracy: 0.9673 - val_cost: 4.1303\n",
            "Epoch 243/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0607 - auc: 0.9961 - accuracy: 0.9815 - cost: 2.3800 - val_loss: 0.1297 - val_auc: 0.9880 - val_accuracy: 0.9675 - val_cost: 4.0344\n",
            "Epoch 244/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0607 - auc: 0.9961 - accuracy: 0.9823 - cost: 2.2708 - val_loss: 0.1296 - val_auc: 0.9879 - val_accuracy: 0.9687 - val_cost: 3.9616\n",
            "Epoch 245/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0613 - auc: 0.9961 - accuracy: 0.9811 - cost: 2.4182 - val_loss: 0.1305 - val_auc: 0.9882 - val_accuracy: 0.9667 - val_cost: 4.1700\n",
            "Epoch 246/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0609 - auc: 0.9960 - accuracy: 0.9820 - cost: 2.3067 - val_loss: 0.1284 - val_auc: 0.9883 - val_accuracy: 0.9683 - val_cost: 3.9980\n",
            "Epoch 247/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0610 - auc: 0.9961 - accuracy: 0.9816 - cost: 2.3688 - val_loss: 0.1294 - val_auc: 0.9882 - val_accuracy: 0.9683 - val_cost: 3.9683\n",
            "Epoch 248/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0611 - auc: 0.9960 - accuracy: 0.9814 - cost: 2.3943 - val_loss: 0.1279 - val_auc: 0.9884 - val_accuracy: 0.9679 - val_cost: 4.0575\n",
            "Epoch 249/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0613 - auc: 0.9959 - accuracy: 0.9820 - cost: 2.3017 - val_loss: 0.1309 - val_auc: 0.9880 - val_accuracy: 0.9673 - val_cost: 4.1105\n",
            "Epoch 250/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0609 - auc: 0.9960 - accuracy: 0.9818 - cost: 2.3453 - val_loss: 0.1300 - val_auc: 0.9878 - val_accuracy: 0.9676 - val_cost: 4.0443\n",
            "Epoch 251/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0608 - auc: 0.9960 - accuracy: 0.9818 - cost: 2.3430 - val_loss: 0.1293 - val_auc: 0.9882 - val_accuracy: 0.9680 - val_cost: 4.0575\n",
            "Epoch 252/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0611 - auc: 0.9961 - accuracy: 0.9815 - cost: 2.3677 - val_loss: 0.1309 - val_auc: 0.9882 - val_accuracy: 0.9674 - val_cost: 4.0807\n",
            "Epoch 253/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0606 - auc: 0.9961 - accuracy: 0.9819 - cost: 2.3260 - val_loss: 0.1307 - val_auc: 0.9880 - val_accuracy: 0.9669 - val_cost: 4.1138\n",
            "Epoch 254/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0604 - auc: 0.9961 - accuracy: 0.9818 - cost: 2.3449 - val_loss: 0.1288 - val_auc: 0.9883 - val_accuracy: 0.9688 - val_cost: 3.8922\n",
            "Epoch 255/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0603 - auc: 0.9962 - accuracy: 0.9822 - cost: 2.2870 - val_loss: 0.1302 - val_auc: 0.9883 - val_accuracy: 0.9677 - val_cost: 4.0873\n",
            "Epoch 256/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0603 - auc: 0.9961 - accuracy: 0.9820 - cost: 2.3171 - val_loss: 0.1285 - val_auc: 0.9881 - val_accuracy: 0.9676 - val_cost: 4.0807\n",
            "Epoch 257/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0599 - auc: 0.9961 - accuracy: 0.9819 - cost: 2.3314 - val_loss: 0.1295 - val_auc: 0.9882 - val_accuracy: 0.9683 - val_cost: 3.9649\n",
            "Epoch 258/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0606 - auc: 0.9960 - accuracy: 0.9821 - cost: 2.2944 - val_loss: 0.1293 - val_auc: 0.9880 - val_accuracy: 0.9688 - val_cost: 3.9881\n",
            "Epoch 259/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0600 - auc: 0.9962 - accuracy: 0.9822 - cost: 2.2948 - val_loss: 0.1308 - val_auc: 0.9880 - val_accuracy: 0.9669 - val_cost: 4.1204\n",
            "Epoch 260/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0601 - auc: 0.9961 - accuracy: 0.9822 - cost: 2.2932 - val_loss: 0.1320 - val_auc: 0.9879 - val_accuracy: 0.9676 - val_cost: 4.0774\n",
            "Epoch 261/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0608 - auc: 0.9961 - accuracy: 0.9820 - cost: 2.3241 - val_loss: 0.1309 - val_auc: 0.9882 - val_accuracy: 0.9672 - val_cost: 4.0840\n",
            "Epoch 262/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0609 - auc: 0.9961 - accuracy: 0.9818 - cost: 2.3360 - val_loss: 0.1288 - val_auc: 0.9881 - val_accuracy: 0.9682 - val_cost: 4.0840\n",
            "Epoch 263/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0612 - auc: 0.9960 - accuracy: 0.9818 - cost: 2.3395 - val_loss: 0.1331 - val_auc: 0.9877 - val_accuracy: 0.9680 - val_cost: 3.8823\n",
            "Epoch 264/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0610 - auc: 0.9960 - accuracy: 0.9816 - cost: 2.3661 - val_loss: 0.1279 - val_auc: 0.9882 - val_accuracy: 0.9685 - val_cost: 4.0079\n",
            "Epoch 265/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0606 - auc: 0.9960 - accuracy: 0.9818 - cost: 2.3360 - val_loss: 0.1307 - val_auc: 0.9882 - val_accuracy: 0.9668 - val_cost: 3.9848\n",
            "Epoch 266/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0602 - auc: 0.9963 - accuracy: 0.9820 - cost: 2.3125 - val_loss: 0.1299 - val_auc: 0.9880 - val_accuracy: 0.9671 - val_cost: 4.0245\n",
            "Epoch 267/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0609 - auc: 0.9961 - accuracy: 0.9820 - cost: 2.2998 - val_loss: 0.1286 - val_auc: 0.9884 - val_accuracy: 0.9669 - val_cost: 4.1997\n",
            "Epoch 268/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0602 - auc: 0.9960 - accuracy: 0.9821 - cost: 2.3013 - val_loss: 0.1296 - val_auc: 0.9883 - val_accuracy: 0.9685 - val_cost: 3.8955\n",
            "Epoch 269/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0597 - auc: 0.9962 - accuracy: 0.9820 - cost: 2.3191 - val_loss: 0.1304 - val_auc: 0.9880 - val_accuracy: 0.9685 - val_cost: 4.0046\n",
            "Epoch 270/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0591 - auc: 0.9962 - accuracy: 0.9824 - cost: 2.2685 - val_loss: 0.1315 - val_auc: 0.9878 - val_accuracy: 0.9676 - val_cost: 4.0344\n",
            "Epoch 271/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0600 - auc: 0.9962 - accuracy: 0.9823 - cost: 2.2716 - val_loss: 0.1281 - val_auc: 0.9880 - val_accuracy: 0.9677 - val_cost: 4.0013\n",
            "Epoch 272/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0604 - auc: 0.9961 - accuracy: 0.9817 - cost: 2.3534 - val_loss: 0.1317 - val_auc: 0.9878 - val_accuracy: 0.9681 - val_cost: 3.9352\n",
            "Epoch 273/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0597 - auc: 0.9962 - accuracy: 0.9820 - cost: 2.3191 - val_loss: 0.1290 - val_auc: 0.9882 - val_accuracy: 0.9678 - val_cost: 4.0344\n",
            "Epoch 274/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0595 - auc: 0.9962 - accuracy: 0.9820 - cost: 2.3121 - val_loss: 0.1303 - val_auc: 0.9879 - val_accuracy: 0.9678 - val_cost: 4.0509\n",
            "Epoch 275/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0592 - auc: 0.9962 - accuracy: 0.9824 - cost: 2.2550 - val_loss: 0.1295 - val_auc: 0.9882 - val_accuracy: 0.9678 - val_cost: 4.0873\n",
            "Epoch 276/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0596 - auc: 0.9963 - accuracy: 0.9821 - cost: 2.2994 - val_loss: 0.1305 - val_auc: 0.9883 - val_accuracy: 0.9671 - val_cost: 4.0675\n",
            "Epoch 277/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0602 - auc: 0.9962 - accuracy: 0.9820 - cost: 2.3156 - val_loss: 0.1330 - val_auc: 0.9879 - val_accuracy: 0.9680 - val_cost: 3.9418\n",
            "Epoch 278/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0593 - auc: 0.9961 - accuracy: 0.9825 - cost: 2.2535 - val_loss: 0.1334 - val_auc: 0.9878 - val_accuracy: 0.9677 - val_cost: 3.9550\n",
            "Epoch 279/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0591 - auc: 0.9961 - accuracy: 0.9825 - cost: 2.2465 - val_loss: 0.1327 - val_auc: 0.9879 - val_accuracy: 0.9673 - val_cost: 3.9815\n",
            "Epoch 280/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0603 - auc: 0.9961 - accuracy: 0.9823 - cost: 2.2704 - val_loss: 0.1339 - val_auc: 0.9880 - val_accuracy: 0.9682 - val_cost: 3.9187\n",
            "Epoch 281/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0603 - auc: 0.9962 - accuracy: 0.9819 - cost: 2.3295 - val_loss: 0.1324 - val_auc: 0.9879 - val_accuracy: 0.9669 - val_cost: 4.1501\n",
            "Epoch 282/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0594 - auc: 0.9962 - accuracy: 0.9824 - cost: 2.2658 - val_loss: 0.1334 - val_auc: 0.9878 - val_accuracy: 0.9678 - val_cost: 4.0179\n",
            "Epoch 283/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0598 - auc: 0.9962 - accuracy: 0.9820 - cost: 2.3140 - val_loss: 0.1334 - val_auc: 0.9878 - val_accuracy: 0.9675 - val_cost: 4.1071\n",
            "Epoch 284/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0586 - auc: 0.9963 - accuracy: 0.9825 - cost: 2.2492 - val_loss: 0.1307 - val_auc: 0.9882 - val_accuracy: 0.9684 - val_cost: 3.8856\n",
            "Epoch 285/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0605 - auc: 0.9961 - accuracy: 0.9821 - cost: 2.3032 - val_loss: 0.1315 - val_auc: 0.9877 - val_accuracy: 0.9688 - val_cost: 3.8988\n",
            "Epoch 286/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0593 - auc: 0.9963 - accuracy: 0.9826 - cost: 2.2338 - val_loss: 0.1336 - val_auc: 0.9879 - val_accuracy: 0.9682 - val_cost: 3.9815\n",
            "Epoch 287/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0588 - auc: 0.9964 - accuracy: 0.9821 - cost: 2.3044 - val_loss: 0.1317 - val_auc: 0.9878 - val_accuracy: 0.9683 - val_cost: 3.9616\n",
            "Epoch 288/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0587 - auc: 0.9961 - accuracy: 0.9828 - cost: 2.2010 - val_loss: 0.1339 - val_auc: 0.9878 - val_accuracy: 0.9678 - val_cost: 3.8459\n",
            "Epoch 289/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0583 - auc: 0.9964 - accuracy: 0.9827 - cost: 2.2184 - val_loss: 0.1311 - val_auc: 0.9880 - val_accuracy: 0.9684 - val_cost: 3.9319\n",
            "Epoch 290/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0588 - auc: 0.9964 - accuracy: 0.9822 - cost: 2.2840 - val_loss: 0.1326 - val_auc: 0.9880 - val_accuracy: 0.9685 - val_cost: 3.9220\n",
            "Epoch 291/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0601 - auc: 0.9961 - accuracy: 0.9816 - cost: 2.3465 - val_loss: 0.1337 - val_auc: 0.9880 - val_accuracy: 0.9687 - val_cost: 3.9187\n",
            "Epoch 292/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0594 - auc: 0.9962 - accuracy: 0.9819 - cost: 2.3283 - val_loss: 0.1340 - val_auc: 0.9880 - val_accuracy: 0.9686 - val_cost: 3.9120\n",
            "Epoch 293/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0592 - auc: 0.9962 - accuracy: 0.9823 - cost: 2.2728 - val_loss: 0.1333 - val_auc: 0.9877 - val_accuracy: 0.9675 - val_cost: 4.0344\n",
            "Epoch 294/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0594 - auc: 0.9962 - accuracy: 0.9820 - cost: 2.3140 - val_loss: 0.1365 - val_auc: 0.9876 - val_accuracy: 0.9665 - val_cost: 4.0807\n",
            "Epoch 295/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0588 - auc: 0.9964 - accuracy: 0.9821 - cost: 2.3056 - val_loss: 0.1351 - val_auc: 0.9877 - val_accuracy: 0.9676 - val_cost: 4.0245\n",
            "Epoch 296/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0590 - auc: 0.9964 - accuracy: 0.9819 - cost: 2.3252 - val_loss: 0.1331 - val_auc: 0.9877 - val_accuracy: 0.9678 - val_cost: 3.9253\n",
            "Epoch 297/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0588 - auc: 0.9963 - accuracy: 0.9824 - cost: 2.2639 - val_loss: 0.1329 - val_auc: 0.9877 - val_accuracy: 0.9683 - val_cost: 3.9418\n",
            "Epoch 298/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0590 - auc: 0.9963 - accuracy: 0.9825 - cost: 2.2365 - val_loss: 0.1337 - val_auc: 0.9876 - val_accuracy: 0.9674 - val_cost: 4.0939\n",
            "Epoch 299/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0586 - auc: 0.9964 - accuracy: 0.9821 - cost: 2.2978 - val_loss: 0.1330 - val_auc: 0.9876 - val_accuracy: 0.9686 - val_cost: 3.9716\n",
            "Epoch 300/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0593 - auc: 0.9963 - accuracy: 0.9824 - cost: 2.2731 - val_loss: 0.1358 - val_auc: 0.9876 - val_accuracy: 0.9681 - val_cost: 3.8492\n",
            "Epoch 301/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0595 - auc: 0.9963 - accuracy: 0.9819 - cost: 2.3148 - val_loss: 0.1331 - val_auc: 0.9882 - val_accuracy: 0.9670 - val_cost: 4.1534\n",
            "Epoch 302/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0583 - auc: 0.9962 - accuracy: 0.9831 - cost: 2.1659 - val_loss: 0.1318 - val_auc: 0.9879 - val_accuracy: 0.9678 - val_cost: 3.9484\n",
            "Epoch 303/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0590 - auc: 0.9963 - accuracy: 0.9827 - cost: 2.2184 - val_loss: 0.1319 - val_auc: 0.9879 - val_accuracy: 0.9677 - val_cost: 4.0212\n",
            "Epoch 304/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0581 - auc: 0.9963 - accuracy: 0.9828 - cost: 2.2099 - val_loss: 0.1323 - val_auc: 0.9876 - val_accuracy: 0.9685 - val_cost: 3.9484\n",
            "Epoch 305/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0585 - auc: 0.9963 - accuracy: 0.9823 - cost: 2.2805 - val_loss: 0.1343 - val_auc: 0.9879 - val_accuracy: 0.9684 - val_cost: 3.9583\n",
            "Epoch 306/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0590 - auc: 0.9962 - accuracy: 0.9824 - cost: 2.2542 - val_loss: 0.1347 - val_auc: 0.9878 - val_accuracy: 0.9683 - val_cost: 3.9683\n",
            "Epoch 307/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0581 - auc: 0.9963 - accuracy: 0.9822 - cost: 2.2816 - val_loss: 0.1318 - val_auc: 0.9880 - val_accuracy: 0.9678 - val_cost: 4.0873\n",
            "Epoch 308/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0580 - auc: 0.9964 - accuracy: 0.9826 - cost: 2.2431 - val_loss: 0.1373 - val_auc: 0.9875 - val_accuracy: 0.9678 - val_cost: 3.9319\n",
            "Epoch 309/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0579 - auc: 0.9963 - accuracy: 0.9829 - cost: 2.2099 - val_loss: 0.1340 - val_auc: 0.9876 - val_accuracy: 0.9684 - val_cost: 3.9286\n",
            "Epoch 310/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0588 - auc: 0.9962 - accuracy: 0.9825 - cost: 2.2600 - val_loss: 0.1346 - val_auc: 0.9876 - val_accuracy: 0.9681 - val_cost: 4.0013\n",
            "Epoch 311/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0582 - auc: 0.9964 - accuracy: 0.9826 - cost: 2.2211 - val_loss: 0.1353 - val_auc: 0.9875 - val_accuracy: 0.9678 - val_cost: 4.0112\n",
            "Epoch 312/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0592 - auc: 0.9962 - accuracy: 0.9820 - cost: 2.3137 - val_loss: 0.1343 - val_auc: 0.9877 - val_accuracy: 0.9690 - val_cost: 3.8823\n",
            "Epoch 313/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0582 - auc: 0.9965 - accuracy: 0.9824 - cost: 2.2639 - val_loss: 0.1342 - val_auc: 0.9874 - val_accuracy: 0.9681 - val_cost: 4.1071\n",
            "Epoch 314/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0579 - auc: 0.9963 - accuracy: 0.9825 - cost: 2.2465 - val_loss: 0.1336 - val_auc: 0.9873 - val_accuracy: 0.9683 - val_cost: 3.8856\n",
            "Epoch 315/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0584 - auc: 0.9964 - accuracy: 0.9825 - cost: 2.2639 - val_loss: 0.1351 - val_auc: 0.9874 - val_accuracy: 0.9684 - val_cost: 3.9418\n",
            "Epoch 316/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0575 - auc: 0.9964 - accuracy: 0.9827 - cost: 2.2315 - val_loss: 0.1335 - val_auc: 0.9879 - val_accuracy: 0.9693 - val_cost: 3.8393\n",
            "Epoch 317/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0580 - auc: 0.9964 - accuracy: 0.9827 - cost: 2.2180 - val_loss: 0.1354 - val_auc: 0.9875 - val_accuracy: 0.9670 - val_cost: 4.2890\n",
            "Epoch 318/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0577 - auc: 0.9964 - accuracy: 0.9828 - cost: 2.2245 - val_loss: 0.1336 - val_auc: 0.9876 - val_accuracy: 0.9688 - val_cost: 3.8889\n",
            "Epoch 319/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0575 - auc: 0.9965 - accuracy: 0.9824 - cost: 2.2616 - val_loss: 0.1341 - val_auc: 0.9880 - val_accuracy: 0.9679 - val_cost: 3.9749\n",
            "Epoch 320/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0577 - auc: 0.9963 - accuracy: 0.9827 - cost: 2.2215 - val_loss: 0.1355 - val_auc: 0.9879 - val_accuracy: 0.9692 - val_cost: 3.8393\n",
            "Epoch 321/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0573 - auc: 0.9965 - accuracy: 0.9828 - cost: 2.2245 - val_loss: 0.1356 - val_auc: 0.9878 - val_accuracy: 0.9685 - val_cost: 3.8790\n",
            "Epoch 322/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0575 - auc: 0.9964 - accuracy: 0.9829 - cost: 2.1917 - val_loss: 0.1358 - val_auc: 0.9874 - val_accuracy: 0.9685 - val_cost: 3.9517\n",
            "Epoch 323/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0569 - auc: 0.9965 - accuracy: 0.9828 - cost: 2.2118 - val_loss: 0.1371 - val_auc: 0.9875 - val_accuracy: 0.9683 - val_cost: 3.9385\n",
            "Epoch 324/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0578 - auc: 0.9964 - accuracy: 0.9824 - cost: 2.2596 - val_loss: 0.1338 - val_auc: 0.9881 - val_accuracy: 0.9682 - val_cost: 3.9683\n",
            "Epoch 325/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0571 - auc: 0.9965 - accuracy: 0.9827 - cost: 2.2180 - val_loss: 0.1333 - val_auc: 0.9877 - val_accuracy: 0.9687 - val_cost: 3.8525\n",
            "Epoch 326/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0577 - auc: 0.9965 - accuracy: 0.9826 - cost: 2.2438 - val_loss: 0.1363 - val_auc: 0.9876 - val_accuracy: 0.9696 - val_cost: 3.8095\n",
            "Epoch 327/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0577 - auc: 0.9965 - accuracy: 0.9821 - cost: 2.2890 - val_loss: 0.1338 - val_auc: 0.9877 - val_accuracy: 0.9681 - val_cost: 3.9980\n",
            "Epoch 328/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0575 - auc: 0.9965 - accuracy: 0.9829 - cost: 2.2118 - val_loss: 0.1364 - val_auc: 0.9877 - val_accuracy: 0.9685 - val_cost: 3.8922\n",
            "Epoch 329/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0579 - auc: 0.9964 - accuracy: 0.9823 - cost: 2.2735 - val_loss: 0.1337 - val_auc: 0.9878 - val_accuracy: 0.9683 - val_cost: 3.9683\n",
            "Epoch 330/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0565 - auc: 0.9965 - accuracy: 0.9829 - cost: 2.1875 - val_loss: 0.1358 - val_auc: 0.9875 - val_accuracy: 0.9682 - val_cost: 3.9782\n",
            "Epoch 331/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0568 - auc: 0.9965 - accuracy: 0.9828 - cost: 2.2068 - val_loss: 0.1348 - val_auc: 0.9875 - val_accuracy: 0.9682 - val_cost: 4.0179\n",
            "Epoch 332/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0579 - auc: 0.9963 - accuracy: 0.9826 - cost: 2.2384 - val_loss: 0.1372 - val_auc: 0.9869 - val_accuracy: 0.9681 - val_cost: 3.9484\n",
            "Epoch 333/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0578 - auc: 0.9964 - accuracy: 0.9823 - cost: 2.2677 - val_loss: 0.1360 - val_auc: 0.9874 - val_accuracy: 0.9697 - val_cost: 3.8360\n",
            "Epoch 334/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0575 - auc: 0.9965 - accuracy: 0.9824 - cost: 2.2596 - val_loss: 0.1369 - val_auc: 0.9876 - val_accuracy: 0.9688 - val_cost: 3.7765\n",
            "Epoch 335/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0574 - auc: 0.9964 - accuracy: 0.9827 - cost: 2.2296 - val_loss: 0.1360 - val_auc: 0.9873 - val_accuracy: 0.9673 - val_cost: 4.0146\n",
            "Epoch 336/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0572 - auc: 0.9964 - accuracy: 0.9828 - cost: 2.2006 - val_loss: 0.1345 - val_auc: 0.9875 - val_accuracy: 0.9678 - val_cost: 4.0046\n",
            "Epoch 337/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0568 - auc: 0.9965 - accuracy: 0.9830 - cost: 2.1863 - val_loss: 0.1344 - val_auc: 0.9876 - val_accuracy: 0.9686 - val_cost: 3.8757\n",
            "Epoch 338/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0565 - auc: 0.9966 - accuracy: 0.9831 - cost: 2.1736 - val_loss: 0.1354 - val_auc: 0.9875 - val_accuracy: 0.9676 - val_cost: 4.0476\n",
            "Epoch 339/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0566 - auc: 0.9964 - accuracy: 0.9831 - cost: 2.1620 - val_loss: 0.1359 - val_auc: 0.9876 - val_accuracy: 0.9677 - val_cost: 4.0575\n",
            "Epoch 340/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0574 - auc: 0.9965 - accuracy: 0.9830 - cost: 2.1867 - val_loss: 0.1366 - val_auc: 0.9877 - val_accuracy: 0.9685 - val_cost: 3.8062\n",
            "Epoch 341/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0572 - auc: 0.9965 - accuracy: 0.9826 - cost: 2.2350 - val_loss: 0.1340 - val_auc: 0.9876 - val_accuracy: 0.9679 - val_cost: 4.0575\n",
            "Epoch 342/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0566 - auc: 0.9966 - accuracy: 0.9829 - cost: 2.1979 - val_loss: 0.1368 - val_auc: 0.9875 - val_accuracy: 0.9690 - val_cost: 3.8724\n",
            "Epoch 343/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0574 - auc: 0.9964 - accuracy: 0.9827 - cost: 2.2346 - val_loss: 0.1327 - val_auc: 0.9877 - val_accuracy: 0.9685 - val_cost: 3.9881\n",
            "Epoch 344/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0565 - auc: 0.9966 - accuracy: 0.9830 - cost: 2.1975 - val_loss: 0.1370 - val_auc: 0.9867 - val_accuracy: 0.9688 - val_cost: 3.8724\n",
            "Epoch 345/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0565 - auc: 0.9966 - accuracy: 0.9828 - cost: 2.2157 - val_loss: 0.1342 - val_auc: 0.9879 - val_accuracy: 0.9681 - val_cost: 4.0410\n",
            "Epoch 346/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0564 - auc: 0.9965 - accuracy: 0.9834 - cost: 2.1420 - val_loss: 0.1347 - val_auc: 0.9877 - val_accuracy: 0.9686 - val_cost: 3.9947\n",
            "Epoch 347/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0562 - auc: 0.9966 - accuracy: 0.9833 - cost: 2.1462 - val_loss: 0.1350 - val_auc: 0.9875 - val_accuracy: 0.9681 - val_cost: 4.0509\n",
            "Epoch 348/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0570 - auc: 0.9965 - accuracy: 0.9828 - cost: 2.2180 - val_loss: 0.1378 - val_auc: 0.9876 - val_accuracy: 0.9681 - val_cost: 3.9120\n",
            "Epoch 349/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0565 - auc: 0.9966 - accuracy: 0.9831 - cost: 2.1763 - val_loss: 0.1378 - val_auc: 0.9877 - val_accuracy: 0.9674 - val_cost: 4.1038\n",
            "Epoch 350/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0563 - auc: 0.9966 - accuracy: 0.9829 - cost: 2.2118 - val_loss: 0.1362 - val_auc: 0.9874 - val_accuracy: 0.9679 - val_cost: 3.9947\n",
            "Epoch 351/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0567 - auc: 0.9965 - accuracy: 0.9831 - cost: 2.1694 - val_loss: 0.1396 - val_auc: 0.9873 - val_accuracy: 0.9687 - val_cost: 3.8955\n",
            "Epoch 352/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0570 - auc: 0.9965 - accuracy: 0.9828 - cost: 2.2160 - val_loss: 0.1364 - val_auc: 0.9878 - val_accuracy: 0.9674 - val_cost: 4.0245\n",
            "Epoch 353/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0568 - auc: 0.9965 - accuracy: 0.9831 - cost: 2.1624 - val_loss: 0.1371 - val_auc: 0.9879 - val_accuracy: 0.9681 - val_cost: 3.9649\n",
            "Epoch 354/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0565 - auc: 0.9966 - accuracy: 0.9831 - cost: 2.1744 - val_loss: 0.1381 - val_auc: 0.9871 - val_accuracy: 0.9681 - val_cost: 4.0608\n",
            "Epoch 355/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0569 - auc: 0.9966 - accuracy: 0.9828 - cost: 2.2029 - val_loss: 0.1390 - val_auc: 0.9872 - val_accuracy: 0.9680 - val_cost: 4.0013\n",
            "Epoch 356/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0563 - auc: 0.9965 - accuracy: 0.9830 - cost: 2.1875 - val_loss: 0.1385 - val_auc: 0.9874 - val_accuracy: 0.9681 - val_cost: 3.9087\n",
            "Epoch 357/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0565 - auc: 0.9965 - accuracy: 0.9829 - cost: 2.2052 - val_loss: 0.1375 - val_auc: 0.9873 - val_accuracy: 0.9690 - val_cost: 3.7731\n",
            "Epoch 358/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0564 - auc: 0.9965 - accuracy: 0.9830 - cost: 2.1829 - val_loss: 0.1375 - val_auc: 0.9874 - val_accuracy: 0.9683 - val_cost: 3.9749\n",
            "Epoch 359/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0566 - auc: 0.9966 - accuracy: 0.9833 - cost: 2.1489 - val_loss: 0.1377 - val_auc: 0.9872 - val_accuracy: 0.9689 - val_cost: 3.8327\n",
            "Epoch 360/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0562 - auc: 0.9965 - accuracy: 0.9833 - cost: 2.1412 - val_loss: 0.1367 - val_auc: 0.9875 - val_accuracy: 0.9683 - val_cost: 3.9253\n",
            "Epoch 361/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0565 - auc: 0.9965 - accuracy: 0.9832 - cost: 2.1605 - val_loss: 0.1387 - val_auc: 0.9875 - val_accuracy: 0.9683 - val_cost: 3.8955\n",
            "Epoch 362/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0558 - auc: 0.9966 - accuracy: 0.9833 - cost: 2.1451 - val_loss: 0.1376 - val_auc: 0.9871 - val_accuracy: 0.9682 - val_cost: 4.0146\n",
            "Epoch 363/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0570 - auc: 0.9965 - accuracy: 0.9827 - cost: 2.2292 - val_loss: 0.1372 - val_auc: 0.9875 - val_accuracy: 0.9681 - val_cost: 3.9484\n",
            "Epoch 364/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0557 - auc: 0.9966 - accuracy: 0.9831 - cost: 2.1682 - val_loss: 0.1383 - val_auc: 0.9875 - val_accuracy: 0.9678 - val_cost: 4.0708\n",
            "Epoch 365/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0554 - auc: 0.9966 - accuracy: 0.9831 - cost: 2.1717 - val_loss: 0.1375 - val_auc: 0.9875 - val_accuracy: 0.9682 - val_cost: 3.9947\n",
            "Epoch 366/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0566 - auc: 0.9965 - accuracy: 0.9833 - cost: 2.1470 - val_loss: 0.1393 - val_auc: 0.9871 - val_accuracy: 0.9681 - val_cost: 3.9683\n",
            "Epoch 367/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0569 - auc: 0.9965 - accuracy: 0.9827 - cost: 2.2226 - val_loss: 0.1386 - val_auc: 0.9869 - val_accuracy: 0.9686 - val_cost: 3.9848\n",
            "Epoch 368/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0565 - auc: 0.9966 - accuracy: 0.9830 - cost: 2.1763 - val_loss: 0.1385 - val_auc: 0.9873 - val_accuracy: 0.9682 - val_cost: 3.9253\n",
            "Epoch 369/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0563 - auc: 0.9966 - accuracy: 0.9832 - cost: 2.1717 - val_loss: 0.1383 - val_auc: 0.9871 - val_accuracy: 0.9683 - val_cost: 3.9947\n",
            "Epoch 370/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0557 - auc: 0.9966 - accuracy: 0.9831 - cost: 2.1686 - val_loss: 0.1391 - val_auc: 0.9870 - val_accuracy: 0.9680 - val_cost: 3.8922\n",
            "Epoch 371/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0564 - auc: 0.9966 - accuracy: 0.9831 - cost: 2.1698 - val_loss: 0.1411 - val_auc: 0.9874 - val_accuracy: 0.9676 - val_cost: 3.9583\n",
            "Epoch 372/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0553 - auc: 0.9967 - accuracy: 0.9835 - cost: 2.1265 - val_loss: 0.1367 - val_auc: 0.9876 - val_accuracy: 0.9678 - val_cost: 3.9947\n",
            "Epoch 373/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0552 - auc: 0.9967 - accuracy: 0.9835 - cost: 2.1181 - val_loss: 0.1377 - val_auc: 0.9874 - val_accuracy: 0.9689 - val_cost: 3.8889\n",
            "Epoch 374/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0563 - auc: 0.9966 - accuracy: 0.9832 - cost: 2.1605 - val_loss: 0.1392 - val_auc: 0.9875 - val_accuracy: 0.9674 - val_cost: 4.0278\n",
            "Epoch 375/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0555 - auc: 0.9967 - accuracy: 0.9833 - cost: 2.1439 - val_loss: 0.1396 - val_auc: 0.9872 - val_accuracy: 0.9684 - val_cost: 3.9451\n",
            "Epoch 376/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0562 - auc: 0.9967 - accuracy: 0.9831 - cost: 2.1786 - val_loss: 0.1364 - val_auc: 0.9876 - val_accuracy: 0.9685 - val_cost: 3.9385\n",
            "Epoch 377/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0560 - auc: 0.9967 - accuracy: 0.9831 - cost: 2.1802 - val_loss: 0.1379 - val_auc: 0.9876 - val_accuracy: 0.9674 - val_cost: 4.1270\n",
            "Epoch 378/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0552 - auc: 0.9967 - accuracy: 0.9830 - cost: 2.1825 - val_loss: 0.1389 - val_auc: 0.9874 - val_accuracy: 0.9683 - val_cost: 3.9881\n",
            "Epoch 379/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0553 - auc: 0.9967 - accuracy: 0.9830 - cost: 2.1813 - val_loss: 0.1391 - val_auc: 0.9873 - val_accuracy: 0.9681 - val_cost: 3.9054\n",
            "Epoch 380/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0553 - auc: 0.9967 - accuracy: 0.9833 - cost: 2.1424 - val_loss: 0.1412 - val_auc: 0.9871 - val_accuracy: 0.9681 - val_cost: 3.9187\n",
            "Epoch 381/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0549 - auc: 0.9967 - accuracy: 0.9836 - cost: 2.1100 - val_loss: 0.1383 - val_auc: 0.9873 - val_accuracy: 0.9676 - val_cost: 4.0046\n",
            "Epoch 382/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0553 - auc: 0.9968 - accuracy: 0.9830 - cost: 2.1933 - val_loss: 0.1389 - val_auc: 0.9874 - val_accuracy: 0.9672 - val_cost: 4.1964\n",
            "Epoch 383/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0559 - auc: 0.9967 - accuracy: 0.9831 - cost: 2.1725 - val_loss: 0.1406 - val_auc: 0.9874 - val_accuracy: 0.9670 - val_cost: 4.1005\n",
            "Epoch 384/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0553 - auc: 0.9967 - accuracy: 0.9834 - cost: 2.1258 - val_loss: 0.1418 - val_auc: 0.9876 - val_accuracy: 0.9689 - val_cost: 3.8228\n",
            "Epoch 385/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0560 - auc: 0.9967 - accuracy: 0.9830 - cost: 2.1840 - val_loss: 0.1427 - val_auc: 0.9871 - val_accuracy: 0.9663 - val_cost: 4.1964\n",
            "Epoch 386/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0562 - auc: 0.9965 - accuracy: 0.9831 - cost: 2.1786 - val_loss: 0.1382 - val_auc: 0.9875 - val_accuracy: 0.9673 - val_cost: 3.9881\n",
            "Epoch 387/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0560 - auc: 0.9965 - accuracy: 0.9835 - cost: 2.1235 - val_loss: 0.1404 - val_auc: 0.9873 - val_accuracy: 0.9675 - val_cost: 4.0509\n",
            "Epoch 388/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0548 - auc: 0.9967 - accuracy: 0.9835 - cost: 2.1150 - val_loss: 0.1388 - val_auc: 0.9876 - val_accuracy: 0.9676 - val_cost: 3.9683\n",
            "Epoch 389/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0563 - auc: 0.9966 - accuracy: 0.9832 - cost: 2.1613 - val_loss: 0.1390 - val_auc: 0.9875 - val_accuracy: 0.9683 - val_cost: 3.9980\n",
            "Epoch 390/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0542 - auc: 0.9968 - accuracy: 0.9837 - cost: 2.0972 - val_loss: 0.1406 - val_auc: 0.9877 - val_accuracy: 0.9688 - val_cost: 3.8690\n",
            "Epoch 391/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0552 - auc: 0.9968 - accuracy: 0.9834 - cost: 2.1281 - val_loss: 0.1418 - val_auc: 0.9874 - val_accuracy: 0.9679 - val_cost: 3.9782\n",
            "Epoch 392/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0550 - auc: 0.9968 - accuracy: 0.9834 - cost: 2.1439 - val_loss: 0.1453 - val_auc: 0.9874 - val_accuracy: 0.9688 - val_cost: 3.7897\n",
            "Epoch 393/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0553 - auc: 0.9968 - accuracy: 0.9833 - cost: 2.1431 - val_loss: 0.1409 - val_auc: 0.9874 - val_accuracy: 0.9684 - val_cost: 3.9550\n",
            "Epoch 394/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0557 - auc: 0.9966 - accuracy: 0.9833 - cost: 2.1528 - val_loss: 0.1410 - val_auc: 0.9874 - val_accuracy: 0.9672 - val_cost: 4.0509\n",
            "Epoch 395/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0558 - auc: 0.9966 - accuracy: 0.9831 - cost: 2.1709 - val_loss: 0.1383 - val_auc: 0.9877 - val_accuracy: 0.9685 - val_cost: 3.9087\n",
            "Epoch 396/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0552 - auc: 0.9967 - accuracy: 0.9834 - cost: 2.1385 - val_loss: 0.1406 - val_auc: 0.9878 - val_accuracy: 0.9679 - val_cost: 3.9352\n",
            "Epoch 397/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0546 - auc: 0.9969 - accuracy: 0.9831 - cost: 2.1721 - val_loss: 0.1392 - val_auc: 0.9874 - val_accuracy: 0.9679 - val_cost: 4.0939\n",
            "Epoch 398/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0551 - auc: 0.9968 - accuracy: 0.9831 - cost: 2.1640 - val_loss: 0.1423 - val_auc: 0.9872 - val_accuracy: 0.9683 - val_cost: 3.9616\n",
            "Epoch 399/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0560 - auc: 0.9965 - accuracy: 0.9834 - cost: 2.1312 - val_loss: 0.1403 - val_auc: 0.9869 - val_accuracy: 0.9678 - val_cost: 4.0675\n",
            "Epoch 400/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0556 - auc: 0.9967 - accuracy: 0.9832 - cost: 2.1578 - val_loss: 0.1392 - val_auc: 0.9873 - val_accuracy: 0.9691 - val_cost: 3.8955\n",
            "Epoch 401/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0549 - auc: 0.9968 - accuracy: 0.9833 - cost: 2.1501 - val_loss: 0.1421 - val_auc: 0.9871 - val_accuracy: 0.9667 - val_cost: 4.1270\n",
            "Epoch 402/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0557 - auc: 0.9967 - accuracy: 0.9830 - cost: 2.1840 - val_loss: 0.1428 - val_auc: 0.9868 - val_accuracy: 0.9681 - val_cost: 3.9947\n",
            "Epoch 403/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0555 - auc: 0.9966 - accuracy: 0.9834 - cost: 2.1424 - val_loss: 0.1409 - val_auc: 0.9876 - val_accuracy: 0.9690 - val_cost: 3.9153\n",
            "Epoch 404/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0553 - auc: 0.9966 - accuracy: 0.9838 - cost: 2.0883 - val_loss: 0.1416 - val_auc: 0.9870 - val_accuracy: 0.9673 - val_cost: 3.9947\n",
            "Epoch 405/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0547 - auc: 0.9969 - accuracy: 0.9832 - cost: 2.1613 - val_loss: 0.1420 - val_auc: 0.9872 - val_accuracy: 0.9675 - val_cost: 4.0675\n",
            "Epoch 406/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0548 - auc: 0.9968 - accuracy: 0.9836 - cost: 2.1019 - val_loss: 0.1405 - val_auc: 0.9873 - val_accuracy: 0.9685 - val_cost: 3.9881\n",
            "Epoch 407/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0545 - auc: 0.9968 - accuracy: 0.9834 - cost: 2.1269 - val_loss: 0.1417 - val_auc: 0.9872 - val_accuracy: 0.9684 - val_cost: 3.9914\n",
            "Epoch 408/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0548 - auc: 0.9968 - accuracy: 0.9836 - cost: 2.1096 - val_loss: 0.1431 - val_auc: 0.9873 - val_accuracy: 0.9672 - val_cost: 4.1336\n",
            "Epoch 409/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0550 - auc: 0.9968 - accuracy: 0.9830 - cost: 2.1875 - val_loss: 0.1416 - val_auc: 0.9873 - val_accuracy: 0.9681 - val_cost: 4.0013\n",
            "Epoch 410/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0548 - auc: 0.9968 - accuracy: 0.9831 - cost: 2.1840 - val_loss: 0.1428 - val_auc: 0.9872 - val_accuracy: 0.9690 - val_cost: 3.8856\n",
            "Epoch 411/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0549 - auc: 0.9968 - accuracy: 0.9832 - cost: 2.1559 - val_loss: 0.1429 - val_auc: 0.9873 - val_accuracy: 0.9678 - val_cost: 3.9418\n",
            "Epoch 412/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0549 - auc: 0.9967 - accuracy: 0.9837 - cost: 2.1042 - val_loss: 0.1425 - val_auc: 0.9869 - val_accuracy: 0.9675 - val_cost: 3.9914\n",
            "Epoch 413/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0549 - auc: 0.9967 - accuracy: 0.9835 - cost: 2.1323 - val_loss: 0.1428 - val_auc: 0.9870 - val_accuracy: 0.9667 - val_cost: 4.1138\n",
            "Epoch 414/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0545 - auc: 0.9969 - accuracy: 0.9836 - cost: 2.1115 - val_loss: 0.1415 - val_auc: 0.9869 - val_accuracy: 0.9678 - val_cost: 4.0939\n",
            "Epoch 415/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0556 - auc: 0.9967 - accuracy: 0.9833 - cost: 2.1489 - val_loss: 0.1431 - val_auc: 0.9871 - val_accuracy: 0.9670 - val_cost: 4.0344\n",
            "Epoch 416/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0555 - auc: 0.9967 - accuracy: 0.9832 - cost: 2.1574 - val_loss: 0.1414 - val_auc: 0.9871 - val_accuracy: 0.9683 - val_cost: 3.9550\n",
            "Epoch 417/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0551 - auc: 0.9968 - accuracy: 0.9832 - cost: 2.1605 - val_loss: 0.1425 - val_auc: 0.9873 - val_accuracy: 0.9674 - val_cost: 4.0311\n",
            "Epoch 418/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0548 - auc: 0.9968 - accuracy: 0.9837 - cost: 2.0949 - val_loss: 0.1455 - val_auc: 0.9873 - val_accuracy: 0.9666 - val_cost: 4.0807\n",
            "Epoch 419/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0536 - auc: 0.9969 - accuracy: 0.9842 - cost: 2.0401 - val_loss: 0.1450 - val_auc: 0.9877 - val_accuracy: 0.9674 - val_cost: 3.9418\n",
            "Epoch 420/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0553 - auc: 0.9968 - accuracy: 0.9832 - cost: 2.1578 - val_loss: 0.1431 - val_auc: 0.9875 - val_accuracy: 0.9681 - val_cost: 3.9848\n",
            "Epoch 421/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0547 - auc: 0.9969 - accuracy: 0.9835 - cost: 2.1316 - val_loss: 0.1456 - val_auc: 0.9873 - val_accuracy: 0.9676 - val_cost: 4.0245\n",
            "Epoch 422/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0555 - auc: 0.9968 - accuracy: 0.9835 - cost: 2.1300 - val_loss: 0.1402 - val_auc: 0.9873 - val_accuracy: 0.9678 - val_cost: 3.9683\n",
            "Epoch 423/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0553 - auc: 0.9968 - accuracy: 0.9833 - cost: 2.1535 - val_loss: 0.1444 - val_auc: 0.9874 - val_accuracy: 0.9679 - val_cost: 3.9220\n",
            "Epoch 424/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0543 - auc: 0.9968 - accuracy: 0.9836 - cost: 2.1046 - val_loss: 0.1435 - val_auc: 0.9873 - val_accuracy: 0.9680 - val_cost: 4.0476\n",
            "Epoch 425/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0543 - auc: 0.9968 - accuracy: 0.9830 - cost: 2.1836 - val_loss: 0.1448 - val_auc: 0.9871 - val_accuracy: 0.9678 - val_cost: 4.0675\n",
            "Epoch 426/1000\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 0.0545 - auc: 0.9967 - accuracy: 0.9836 - cost: 2.1192 - val_loss: 0.1438 - val_auc: 0.9872 - val_accuracy: 0.9675 - val_cost: 4.0278\n",
            "Epoch 427/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0543 - auc: 0.9968 - accuracy: 0.9837 - cost: 2.1057 - val_loss: 0.1421 - val_auc: 0.9871 - val_accuracy: 0.9689 - val_cost: 3.9451\n",
            "Epoch 428/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0538 - auc: 0.9968 - accuracy: 0.9838 - cost: 2.0868 - val_loss: 0.1463 - val_auc: 0.9871 - val_accuracy: 0.9668 - val_cost: 4.0410\n",
            "Epoch 429/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0542 - auc: 0.9969 - accuracy: 0.9837 - cost: 2.1053 - val_loss: 0.1457 - val_auc: 0.9872 - val_accuracy: 0.9669 - val_cost: 4.0741\n",
            "Epoch 430/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0543 - auc: 0.9968 - accuracy: 0.9835 - cost: 2.1231 - val_loss: 0.1453 - val_auc: 0.9873 - val_accuracy: 0.9678 - val_cost: 4.0443\n",
            "Epoch 431/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0535 - auc: 0.9969 - accuracy: 0.9840 - cost: 2.0625 - val_loss: 0.1454 - val_auc: 0.9872 - val_accuracy: 0.9678 - val_cost: 4.0443\n",
            "Epoch 432/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0545 - auc: 0.9968 - accuracy: 0.9834 - cost: 2.1366 - val_loss: 0.1438 - val_auc: 0.9871 - val_accuracy: 0.9681 - val_cost: 3.9914\n",
            "Epoch 433/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0545 - auc: 0.9968 - accuracy: 0.9837 - cost: 2.1007 - val_loss: 0.1477 - val_auc: 0.9869 - val_accuracy: 0.9676 - val_cost: 3.9517\n",
            "Epoch 434/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0550 - auc: 0.9968 - accuracy: 0.9834 - cost: 2.1354 - val_loss: 0.1459 - val_auc: 0.9872 - val_accuracy: 0.9676 - val_cost: 4.0046\n",
            "Epoch 435/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0533 - auc: 0.9970 - accuracy: 0.9836 - cost: 2.1057 - val_loss: 0.1427 - val_auc: 0.9873 - val_accuracy: 0.9687 - val_cost: 4.0013\n",
            "Epoch 436/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0531 - auc: 0.9969 - accuracy: 0.9839 - cost: 2.0679 - val_loss: 0.1434 - val_auc: 0.9871 - val_accuracy: 0.9679 - val_cost: 4.0476\n",
            "Epoch 437/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0547 - auc: 0.9968 - accuracy: 0.9831 - cost: 2.1694 - val_loss: 0.1449 - val_auc: 0.9871 - val_accuracy: 0.9678 - val_cost: 4.0146\n",
            "Epoch 438/1000\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 0.0546 - auc: 0.9968 - accuracy: 0.9837 - cost: 2.1034 - val_loss: 0.1445 - val_auc: 0.9867 - val_accuracy: 0.9687 - val_cost: 3.9881\n",
            "Epoch 439/1000\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 0.0542 - auc: 0.9968 - accuracy: 0.9836 - cost: 2.1084 - val_loss: 0.1454 - val_auc: 0.9873 - val_accuracy: 0.9678 - val_cost: 3.9947\n",
            "Epoch 440/1000\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 0.0546 - auc: 0.9968 - accuracy: 0.9834 - cost: 2.1370 - val_loss: 0.1428 - val_auc: 0.9870 - val_accuracy: 0.9685 - val_cost: 3.9749\n",
            "Epoch 441/1000\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 0.0545 - auc: 0.9968 - accuracy: 0.9831 - cost: 2.1601 - val_loss: 0.1449 - val_auc: 0.9874 - val_accuracy: 0.9676 - val_cost: 4.0476\n",
            "Epoch 442/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0535 - auc: 0.9969 - accuracy: 0.9836 - cost: 2.1111 - val_loss: 0.1437 - val_auc: 0.9873 - val_accuracy: 0.9676 - val_cost: 4.0278\n",
            "Epoch 443/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0539 - auc: 0.9969 - accuracy: 0.9837 - cost: 2.1019 - val_loss: 0.1448 - val_auc: 0.9873 - val_accuracy: 0.9680 - val_cost: 3.9550\n",
            "Epoch 444/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0534 - auc: 0.9970 - accuracy: 0.9835 - cost: 2.1200 - val_loss: 0.1477 - val_auc: 0.9869 - val_accuracy: 0.9674 - val_cost: 4.0013\n",
            "Epoch 445/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0536 - auc: 0.9970 - accuracy: 0.9837 - cost: 2.0922 - val_loss: 0.1447 - val_auc: 0.9871 - val_accuracy: 0.9678 - val_cost: 3.9319\n",
            "Epoch 446/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0537 - auc: 0.9968 - accuracy: 0.9837 - cost: 2.1042 - val_loss: 0.1476 - val_auc: 0.9866 - val_accuracy: 0.9672 - val_cost: 4.0575\n",
            "Epoch 447/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0539 - auc: 0.9969 - accuracy: 0.9833 - cost: 2.1474 - val_loss: 0.1445 - val_auc: 0.9874 - val_accuracy: 0.9685 - val_cost: 3.9253\n",
            "Epoch 448/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0539 - auc: 0.9969 - accuracy: 0.9836 - cost: 2.1100 - val_loss: 0.1453 - val_auc: 0.9873 - val_accuracy: 0.9687 - val_cost: 3.9286\n",
            "Epoch 449/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0541 - auc: 0.9969 - accuracy: 0.9838 - cost: 2.0826 - val_loss: 0.1420 - val_auc: 0.9871 - val_accuracy: 0.9693 - val_cost: 3.9187\n",
            "Epoch 450/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0533 - auc: 0.9969 - accuracy: 0.9838 - cost: 2.0837 - val_loss: 0.1486 - val_auc: 0.9868 - val_accuracy: 0.9679 - val_cost: 3.9683\n",
            "Epoch 451/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0535 - auc: 0.9969 - accuracy: 0.9838 - cost: 2.0829 - val_loss: 0.1475 - val_auc: 0.9869 - val_accuracy: 0.9683 - val_cost: 3.9980\n",
            "Epoch 452/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0543 - auc: 0.9968 - accuracy: 0.9837 - cost: 2.0961 - val_loss: 0.1463 - val_auc: 0.9871 - val_accuracy: 0.9681 - val_cost: 3.9914\n",
            "Epoch 453/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0541 - auc: 0.9969 - accuracy: 0.9837 - cost: 2.0810 - val_loss: 0.1477 - val_auc: 0.9871 - val_accuracy: 0.9675 - val_cost: 4.0708\n",
            "Epoch 454/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0551 - auc: 0.9967 - accuracy: 0.9834 - cost: 2.1362 - val_loss: 0.1445 - val_auc: 0.9873 - val_accuracy: 0.9676 - val_cost: 4.0311\n",
            "Epoch 455/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0528 - auc: 0.9969 - accuracy: 0.9841 - cost: 2.0544 - val_loss: 0.1450 - val_auc: 0.9870 - val_accuracy: 0.9685 - val_cost: 3.9352\n",
            "Epoch 456/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0536 - auc: 0.9969 - accuracy: 0.9837 - cost: 2.1003 - val_loss: 0.1469 - val_auc: 0.9868 - val_accuracy: 0.9681 - val_cost: 3.9451\n",
            "Epoch 457/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0540 - auc: 0.9969 - accuracy: 0.9836 - cost: 2.1154 - val_loss: 0.1466 - val_auc: 0.9870 - val_accuracy: 0.9678 - val_cost: 3.9583\n",
            "Epoch 458/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0529 - auc: 0.9969 - accuracy: 0.9841 - cost: 2.0490 - val_loss: 0.1463 - val_auc: 0.9869 - val_accuracy: 0.9685 - val_cost: 3.9352\n",
            "Epoch 459/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0546 - auc: 0.9968 - accuracy: 0.9834 - cost: 2.1420 - val_loss: 0.1445 - val_auc: 0.9870 - val_accuracy: 0.9681 - val_cost: 3.9749\n",
            "Epoch 460/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0536 - auc: 0.9969 - accuracy: 0.9835 - cost: 2.1269 - val_loss: 0.1468 - val_auc: 0.9869 - val_accuracy: 0.9687 - val_cost: 3.8790\n",
            "Epoch 461/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0525 - auc: 0.9970 - accuracy: 0.9841 - cost: 2.0394 - val_loss: 0.1463 - val_auc: 0.9872 - val_accuracy: 0.9685 - val_cost: 3.8889\n",
            "Epoch 462/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0536 - auc: 0.9968 - accuracy: 0.9839 - cost: 2.0721 - val_loss: 0.1451 - val_auc: 0.9870 - val_accuracy: 0.9679 - val_cost: 4.0476\n",
            "Epoch 463/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0538 - auc: 0.9969 - accuracy: 0.9839 - cost: 2.0687 - val_loss: 0.1483 - val_auc: 0.9868 - val_accuracy: 0.9675 - val_cost: 3.9418\n",
            "Epoch 464/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0536 - auc: 0.9969 - accuracy: 0.9835 - cost: 2.1258 - val_loss: 0.1470 - val_auc: 0.9868 - val_accuracy: 0.9682 - val_cost: 3.9649\n",
            "Epoch 465/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0536 - auc: 0.9970 - accuracy: 0.9836 - cost: 2.1107 - val_loss: 0.1464 - val_auc: 0.9872 - val_accuracy: 0.9688 - val_cost: 3.8856\n",
            "Epoch 466/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0532 - auc: 0.9970 - accuracy: 0.9835 - cost: 2.1331 - val_loss: 0.1474 - val_auc: 0.9871 - val_accuracy: 0.9682 - val_cost: 3.9286\n",
            "Epoch 467/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0529 - auc: 0.9969 - accuracy: 0.9840 - cost: 2.0617 - val_loss: 0.1459 - val_auc: 0.9872 - val_accuracy: 0.9674 - val_cost: 4.0972\n",
            "Epoch 468/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0530 - auc: 0.9969 - accuracy: 0.9834 - cost: 2.1235 - val_loss: 0.1497 - val_auc: 0.9870 - val_accuracy: 0.9679 - val_cost: 3.8624\n",
            "Epoch 469/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0533 - auc: 0.9969 - accuracy: 0.9842 - cost: 2.0309 - val_loss: 0.1447 - val_auc: 0.9873 - val_accuracy: 0.9683 - val_cost: 3.9881\n",
            "Epoch 470/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0539 - auc: 0.9970 - accuracy: 0.9832 - cost: 2.1636 - val_loss: 0.1472 - val_auc: 0.9871 - val_accuracy: 0.9666 - val_cost: 4.1435\n",
            "Epoch 471/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0538 - auc: 0.9969 - accuracy: 0.9838 - cost: 2.0833 - val_loss: 0.1502 - val_auc: 0.9871 - val_accuracy: 0.9668 - val_cost: 4.0311\n",
            "Epoch 472/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0533 - auc: 0.9969 - accuracy: 0.9839 - cost: 2.0610 - val_loss: 0.1465 - val_auc: 0.9872 - val_accuracy: 0.9680 - val_cost: 3.9253\n",
            "Epoch 473/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0526 - auc: 0.9971 - accuracy: 0.9837 - cost: 2.0938 - val_loss: 0.1467 - val_auc: 0.9872 - val_accuracy: 0.9678 - val_cost: 4.0542\n",
            "Epoch 474/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0529 - auc: 0.9970 - accuracy: 0.9838 - cost: 2.0941 - val_loss: 0.1481 - val_auc: 0.9870 - val_accuracy: 0.9680 - val_cost: 4.0013\n",
            "Epoch 475/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0531 - auc: 0.9970 - accuracy: 0.9839 - cost: 2.0667 - val_loss: 0.1486 - val_auc: 0.9868 - val_accuracy: 0.9679 - val_cost: 4.1005\n",
            "Epoch 476/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0535 - auc: 0.9970 - accuracy: 0.9835 - cost: 2.1308 - val_loss: 0.1476 - val_auc: 0.9869 - val_accuracy: 0.9672 - val_cost: 4.1534\n",
            "Epoch 477/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0530 - auc: 0.9969 - accuracy: 0.9838 - cost: 2.0791 - val_loss: 0.1465 - val_auc: 0.9874 - val_accuracy: 0.9687 - val_cost: 3.8889\n",
            "Epoch 478/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0539 - auc: 0.9969 - accuracy: 0.9837 - cost: 2.1011 - val_loss: 0.1455 - val_auc: 0.9874 - val_accuracy: 0.9678 - val_cost: 4.0245\n",
            "Epoch 479/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0532 - auc: 0.9969 - accuracy: 0.9842 - cost: 2.0394 - val_loss: 0.1473 - val_auc: 0.9867 - val_accuracy: 0.9678 - val_cost: 4.0112\n",
            "Epoch 480/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0526 - auc: 0.9970 - accuracy: 0.9839 - cost: 2.0687 - val_loss: 0.1482 - val_auc: 0.9874 - val_accuracy: 0.9688 - val_cost: 3.9120\n",
            "Epoch 481/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0533 - auc: 0.9969 - accuracy: 0.9841 - cost: 2.0424 - val_loss: 0.1479 - val_auc: 0.9870 - val_accuracy: 0.9677 - val_cost: 3.9881\n",
            "Epoch 482/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0540 - auc: 0.9969 - accuracy: 0.9836 - cost: 2.1111 - val_loss: 0.1478 - val_auc: 0.9865 - val_accuracy: 0.9675 - val_cost: 4.0013\n",
            "Epoch 483/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0528 - auc: 0.9971 - accuracy: 0.9839 - cost: 2.0756 - val_loss: 0.1467 - val_auc: 0.9871 - val_accuracy: 0.9685 - val_cost: 3.8889\n",
            "Epoch 484/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0525 - auc: 0.9971 - accuracy: 0.9841 - cost: 2.0459 - val_loss: 0.1489 - val_auc: 0.9871 - val_accuracy: 0.9665 - val_cost: 4.1964\n",
            "Epoch 485/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0533 - auc: 0.9969 - accuracy: 0.9839 - cost: 2.0837 - val_loss: 0.1477 - val_auc: 0.9872 - val_accuracy: 0.9674 - val_cost: 4.0245\n",
            "Epoch 486/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0522 - auc: 0.9971 - accuracy: 0.9842 - cost: 2.0258 - val_loss: 0.1476 - val_auc: 0.9872 - val_accuracy: 0.9679 - val_cost: 3.9616\n",
            "Epoch 487/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0527 - auc: 0.9970 - accuracy: 0.9839 - cost: 2.0810 - val_loss: 0.1485 - val_auc: 0.9871 - val_accuracy: 0.9678 - val_cost: 3.9418\n",
            "Epoch 488/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0532 - auc: 0.9970 - accuracy: 0.9838 - cost: 2.0926 - val_loss: 0.1500 - val_auc: 0.9869 - val_accuracy: 0.9682 - val_cost: 3.9550\n",
            "Epoch 489/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0530 - auc: 0.9970 - accuracy: 0.9837 - cost: 2.0910 - val_loss: 0.1487 - val_auc: 0.9873 - val_accuracy: 0.9689 - val_cost: 3.8889\n",
            "Epoch 490/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0531 - auc: 0.9969 - accuracy: 0.9841 - cost: 2.0455 - val_loss: 0.1485 - val_auc: 0.9869 - val_accuracy: 0.9679 - val_cost: 4.0443\n",
            "Epoch 491/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0530 - auc: 0.9971 - accuracy: 0.9838 - cost: 2.0883 - val_loss: 0.1497 - val_auc: 0.9869 - val_accuracy: 0.9690 - val_cost: 3.8558\n",
            "Epoch 492/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0527 - auc: 0.9970 - accuracy: 0.9840 - cost: 2.0567 - val_loss: 0.1469 - val_auc: 0.9867 - val_accuracy: 0.9681 - val_cost: 4.0675\n",
            "Epoch 493/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0530 - auc: 0.9969 - accuracy: 0.9839 - cost: 2.0764 - val_loss: 0.1491 - val_auc: 0.9873 - val_accuracy: 0.9673 - val_cost: 4.0575\n",
            "Epoch 494/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0530 - auc: 0.9970 - accuracy: 0.9838 - cost: 2.0806 - val_loss: 0.1485 - val_auc: 0.9875 - val_accuracy: 0.9683 - val_cost: 4.0112\n",
            "Epoch 495/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0532 - auc: 0.9970 - accuracy: 0.9833 - cost: 2.1458 - val_loss: 0.1488 - val_auc: 0.9869 - val_accuracy: 0.9674 - val_cost: 4.0972\n",
            "Epoch 496/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0533 - auc: 0.9970 - accuracy: 0.9839 - cost: 2.0775 - val_loss: 0.1476 - val_auc: 0.9872 - val_accuracy: 0.9685 - val_cost: 3.9153\n",
            "Epoch 497/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0522 - auc: 0.9971 - accuracy: 0.9842 - cost: 2.0397 - val_loss: 0.1497 - val_auc: 0.9871 - val_accuracy: 0.9682 - val_cost: 3.9881\n",
            "Epoch 498/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0526 - auc: 0.9969 - accuracy: 0.9844 - cost: 2.0193 - val_loss: 0.1502 - val_auc: 0.9872 - val_accuracy: 0.9674 - val_cost: 3.9120\n",
            "Epoch 499/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0532 - auc: 0.9970 - accuracy: 0.9839 - cost: 2.0710 - val_loss: 0.1474 - val_auc: 0.9869 - val_accuracy: 0.9683 - val_cost: 3.9649\n",
            "Epoch 500/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0524 - auc: 0.9969 - accuracy: 0.9843 - cost: 2.0228 - val_loss: 0.1458 - val_auc: 0.9874 - val_accuracy: 0.9682 - val_cost: 3.9980\n",
            "Epoch 501/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0531 - auc: 0.9970 - accuracy: 0.9835 - cost: 2.1358 - val_loss: 0.1479 - val_auc: 0.9872 - val_accuracy: 0.9684 - val_cost: 3.9253\n",
            "Epoch 502/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0523 - auc: 0.9970 - accuracy: 0.9840 - cost: 2.0594 - val_loss: 0.1502 - val_auc: 0.9867 - val_accuracy: 0.9683 - val_cost: 3.9649\n",
            "Epoch 503/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0523 - auc: 0.9970 - accuracy: 0.9842 - cost: 2.0297 - val_loss: 0.1487 - val_auc: 0.9868 - val_accuracy: 0.9684 - val_cost: 4.0112\n",
            "Epoch 504/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0534 - auc: 0.9970 - accuracy: 0.9836 - cost: 2.1073 - val_loss: 0.1525 - val_auc: 0.9866 - val_accuracy: 0.9674 - val_cost: 4.1171\n",
            "Epoch 505/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0526 - auc: 0.9971 - accuracy: 0.9840 - cost: 2.0633 - val_loss: 0.1525 - val_auc: 0.9871 - val_accuracy: 0.9673 - val_cost: 3.9980\n",
            "Epoch 506/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0528 - auc: 0.9970 - accuracy: 0.9840 - cost: 2.0548 - val_loss: 0.1512 - val_auc: 0.9869 - val_accuracy: 0.9685 - val_cost: 3.8327\n",
            "Epoch 507/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0522 - auc: 0.9971 - accuracy: 0.9844 - cost: 2.0077 - val_loss: 0.1505 - val_auc: 0.9868 - val_accuracy: 0.9676 - val_cost: 4.0179\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.1249 - auc: 0.9890 - accuracy: 0.9691 - cost: 3.8375\n",
            "500/500 [==============================] - 1s 975us/step\n",
            "fold train/predict time: 0:03:46.497810\n",
            "fold accuracy: 0.9690625071525574 - fold cost: 3.8375000953674316\n",
            "x_train shape: (144000, 67)\n",
            "Epoch 1/1000\n",
            "120/120 [==============================] - 2s 6ms/step - loss: 0.5296 - auc: 0.7983 - accuracy: 0.7292 - cost: 36.1084 - val_loss: 0.3988 - val_auc: 0.9005 - val_accuracy: 0.8260 - val_cost: 21.8419\n",
            "Epoch 2/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.3523 - auc: 0.9210 - accuracy: 0.8489 - cost: 19.2531 - val_loss: 0.3143 - val_auc: 0.9375 - val_accuracy: 0.8659 - val_cost: 16.6766\n",
            "Epoch 3/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.3026 - auc: 0.9419 - accuracy: 0.8743 - cost: 15.9460 - val_loss: 0.2848 - val_auc: 0.9486 - val_accuracy: 0.8802 - val_cost: 15.0529\n",
            "Epoch 4/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.2744 - auc: 0.9524 - accuracy: 0.8888 - cost: 14.0617 - val_loss: 0.2588 - val_auc: 0.9579 - val_accuracy: 0.8958 - val_cost: 13.1184\n",
            "Epoch 5/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.2511 - auc: 0.9602 - accuracy: 0.8993 - cost: 12.7492 - val_loss: 0.2395 - val_auc: 0.9636 - val_accuracy: 0.9041 - val_cost: 12.0007\n",
            "Epoch 6/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.2326 - auc: 0.9658 - accuracy: 0.9085 - cost: 11.5679 - val_loss: 0.2229 - val_auc: 0.9686 - val_accuracy: 0.9122 - val_cost: 10.8565\n",
            "Epoch 7/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.2170 - auc: 0.9702 - accuracy: 0.9158 - cost: 10.6115 - val_loss: 0.2096 - val_auc: 0.9723 - val_accuracy: 0.9210 - val_cost: 9.7586\n",
            "Epoch 8/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2036 - auc: 0.9737 - accuracy: 0.9220 - cost: 9.8684 - val_loss: 0.1977 - val_auc: 0.9753 - val_accuracy: 0.9250 - val_cost: 9.1501\n",
            "Epoch 9/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1929 - auc: 0.9761 - accuracy: 0.9277 - cost: 9.1393 - val_loss: 0.1870 - val_auc: 0.9774 - val_accuracy: 0.9313 - val_cost: 8.6144\n",
            "Epoch 10/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1824 - auc: 0.9786 - accuracy: 0.9320 - cost: 8.6073 - val_loss: 0.1805 - val_auc: 0.9789 - val_accuracy: 0.9336 - val_cost: 8.4425\n",
            "Epoch 11/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1754 - auc: 0.9801 - accuracy: 0.9347 - cost: 8.2724 - val_loss: 0.1723 - val_auc: 0.9805 - val_accuracy: 0.9388 - val_cost: 7.7183\n",
            "Epoch 12/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1690 - auc: 0.9814 - accuracy: 0.9380 - cost: 7.8526 - val_loss: 0.1669 - val_auc: 0.9817 - val_accuracy: 0.9393 - val_cost: 7.5298\n",
            "Epoch 13/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1626 - auc: 0.9827 - accuracy: 0.9411 - cost: 7.4695 - val_loss: 0.1618 - val_auc: 0.9827 - val_accuracy: 0.9419 - val_cost: 7.3016\n",
            "Epoch 14/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1578 - auc: 0.9835 - accuracy: 0.9435 - cost: 7.1809 - val_loss: 0.1618 - val_auc: 0.9831 - val_accuracy: 0.9433 - val_cost: 6.7361\n",
            "Epoch 15/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1529 - auc: 0.9844 - accuracy: 0.9453 - cost: 6.9317 - val_loss: 0.1559 - val_auc: 0.9836 - val_accuracy: 0.9444 - val_cost: 6.9610\n",
            "Epoch 16/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1489 - auc: 0.9852 - accuracy: 0.9475 - cost: 6.6539 - val_loss: 0.1520 - val_auc: 0.9845 - val_accuracy: 0.9467 - val_cost: 6.4980\n",
            "Epoch 17/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1450 - auc: 0.9858 - accuracy: 0.9484 - cost: 6.5505 - val_loss: 0.1496 - val_auc: 0.9848 - val_accuracy: 0.9481 - val_cost: 6.3724\n",
            "Epoch 18/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1428 - auc: 0.9861 - accuracy: 0.9496 - cost: 6.3781 - val_loss: 0.1456 - val_auc: 0.9855 - val_accuracy: 0.9486 - val_cost: 6.4021\n",
            "Epoch 19/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1382 - auc: 0.9869 - accuracy: 0.9511 - cost: 6.1941 - val_loss: 0.1439 - val_auc: 0.9859 - val_accuracy: 0.9505 - val_cost: 6.1012\n",
            "Epoch 20/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1363 - auc: 0.9872 - accuracy: 0.9532 - cost: 5.9479 - val_loss: 0.1423 - val_auc: 0.9859 - val_accuracy: 0.9506 - val_cost: 6.1607\n",
            "Epoch 21/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1332 - auc: 0.9878 - accuracy: 0.9539 - cost: 5.8414 - val_loss: 0.1408 - val_auc: 0.9862 - val_accuracy: 0.9521 - val_cost: 5.9788\n",
            "Epoch 22/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1312 - auc: 0.9880 - accuracy: 0.9549 - cost: 5.7323 - val_loss: 0.1385 - val_auc: 0.9865 - val_accuracy: 0.9526 - val_cost: 5.9259\n",
            "Epoch 23/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1288 - auc: 0.9884 - accuracy: 0.9562 - cost: 5.5490 - val_loss: 0.1350 - val_auc: 0.9870 - val_accuracy: 0.9555 - val_cost: 5.6151\n",
            "Epoch 24/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1255 - auc: 0.9889 - accuracy: 0.9566 - cost: 5.5058 - val_loss: 0.1351 - val_auc: 0.9871 - val_accuracy: 0.9538 - val_cost: 5.8399\n",
            "Epoch 25/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1238 - auc: 0.9892 - accuracy: 0.9578 - cost: 5.3534 - val_loss: 0.1329 - val_auc: 0.9873 - val_accuracy: 0.9556 - val_cost: 5.6085\n",
            "Epoch 26/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1228 - auc: 0.9892 - accuracy: 0.9583 - cost: 5.2994 - val_loss: 0.1336 - val_auc: 0.9874 - val_accuracy: 0.9557 - val_cost: 5.3439\n",
            "Epoch 27/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1200 - auc: 0.9897 - accuracy: 0.9599 - cost: 5.0926 - val_loss: 0.1319 - val_auc: 0.9874 - val_accuracy: 0.9569 - val_cost: 5.5522\n",
            "Epoch 28/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1176 - auc: 0.9899 - accuracy: 0.9603 - cost: 5.0509 - val_loss: 0.1298 - val_auc: 0.9876 - val_accuracy: 0.9574 - val_cost: 5.3241\n",
            "Epoch 29/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1167 - auc: 0.9900 - accuracy: 0.9608 - cost: 4.9830 - val_loss: 0.1287 - val_auc: 0.9877 - val_accuracy: 0.9583 - val_cost: 5.1753\n",
            "Epoch 30/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1142 - auc: 0.9904 - accuracy: 0.9620 - cost: 4.8434 - val_loss: 0.1279 - val_auc: 0.9879 - val_accuracy: 0.9595 - val_cost: 4.9603\n",
            "Epoch 31/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1131 - auc: 0.9904 - accuracy: 0.9624 - cost: 4.7859 - val_loss: 0.1262 - val_auc: 0.9881 - val_accuracy: 0.9599 - val_cost: 5.0430\n",
            "Epoch 32/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1114 - auc: 0.9908 - accuracy: 0.9633 - cost: 4.6609 - val_loss: 0.1269 - val_auc: 0.9879 - val_accuracy: 0.9590 - val_cost: 5.0959\n",
            "Epoch 33/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1095 - auc: 0.9910 - accuracy: 0.9640 - cost: 4.5775 - val_loss: 0.1262 - val_auc: 0.9881 - val_accuracy: 0.9589 - val_cost: 5.2216\n",
            "Epoch 34/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1092 - auc: 0.9910 - accuracy: 0.9645 - cost: 4.5235 - val_loss: 0.1249 - val_auc: 0.9883 - val_accuracy: 0.9604 - val_cost: 4.8479\n",
            "Epoch 35/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1072 - auc: 0.9913 - accuracy: 0.9652 - cost: 4.4282 - val_loss: 0.1253 - val_auc: 0.9885 - val_accuracy: 0.9606 - val_cost: 4.7189\n",
            "Epoch 36/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1059 - auc: 0.9914 - accuracy: 0.9655 - cost: 4.3823 - val_loss: 0.1228 - val_auc: 0.9884 - val_accuracy: 0.9606 - val_cost: 4.8909\n",
            "Epoch 37/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1043 - auc: 0.9915 - accuracy: 0.9657 - cost: 4.3692 - val_loss: 0.1219 - val_auc: 0.9886 - val_accuracy: 0.9612 - val_cost: 4.7487\n",
            "Epoch 38/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1032 - auc: 0.9917 - accuracy: 0.9666 - cost: 4.2323 - val_loss: 0.1225 - val_auc: 0.9885 - val_accuracy: 0.9606 - val_cost: 4.8611\n",
            "Epoch 39/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1028 - auc: 0.9917 - accuracy: 0.9668 - cost: 4.2272 - val_loss: 0.1229 - val_auc: 0.9886 - val_accuracy: 0.9617 - val_cost: 4.5635\n",
            "Epoch 40/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1022 - auc: 0.9917 - accuracy: 0.9673 - cost: 4.1570 - val_loss: 0.1198 - val_auc: 0.9888 - val_accuracy: 0.9635 - val_cost: 4.6065\n",
            "Epoch 41/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1012 - auc: 0.9919 - accuracy: 0.9670 - cost: 4.2137 - val_loss: 0.1206 - val_auc: 0.9888 - val_accuracy: 0.9625 - val_cost: 4.5470\n",
            "Epoch 42/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1001 - auc: 0.9920 - accuracy: 0.9676 - cost: 4.1127 - val_loss: 0.1184 - val_auc: 0.9888 - val_accuracy: 0.9641 - val_cost: 4.5205\n",
            "Epoch 43/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0986 - auc: 0.9923 - accuracy: 0.9683 - cost: 4.0309 - val_loss: 0.1184 - val_auc: 0.9890 - val_accuracy: 0.9638 - val_cost: 4.5536\n",
            "Epoch 44/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0975 - auc: 0.9922 - accuracy: 0.9691 - cost: 3.9460 - val_loss: 0.1179 - val_auc: 0.9890 - val_accuracy: 0.9640 - val_cost: 4.3750\n",
            "Epoch 45/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0969 - auc: 0.9924 - accuracy: 0.9694 - cost: 3.8939 - val_loss: 0.1167 - val_auc: 0.9894 - val_accuracy: 0.9651 - val_cost: 4.2295\n",
            "Epoch 46/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0955 - auc: 0.9925 - accuracy: 0.9695 - cost: 3.8904 - val_loss: 0.1166 - val_auc: 0.9891 - val_accuracy: 0.9652 - val_cost: 4.3419\n",
            "Epoch 47/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0955 - auc: 0.9926 - accuracy: 0.9697 - cost: 3.8611 - val_loss: 0.1172 - val_auc: 0.9893 - val_accuracy: 0.9645 - val_cost: 4.2890\n",
            "Epoch 48/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0947 - auc: 0.9926 - accuracy: 0.9699 - cost: 3.8295 - val_loss: 0.1159 - val_auc: 0.9895 - val_accuracy: 0.9656 - val_cost: 4.2956\n",
            "Epoch 49/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0938 - auc: 0.9927 - accuracy: 0.9707 - cost: 3.7407 - val_loss: 0.1150 - val_auc: 0.9895 - val_accuracy: 0.9656 - val_cost: 4.3221\n",
            "Epoch 50/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0925 - auc: 0.9928 - accuracy: 0.9711 - cost: 3.6786 - val_loss: 0.1148 - val_auc: 0.9894 - val_accuracy: 0.9663 - val_cost: 4.3089\n",
            "Epoch 51/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0920 - auc: 0.9928 - accuracy: 0.9707 - cost: 3.7427 - val_loss: 0.1136 - val_auc: 0.9895 - val_accuracy: 0.9660 - val_cost: 4.2361\n",
            "Epoch 52/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0906 - auc: 0.9930 - accuracy: 0.9715 - cost: 3.6493 - val_loss: 0.1133 - val_auc: 0.9896 - val_accuracy: 0.9656 - val_cost: 4.2229\n",
            "Epoch 53/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0906 - auc: 0.9930 - accuracy: 0.9714 - cost: 3.6474 - val_loss: 0.1135 - val_auc: 0.9897 - val_accuracy: 0.9658 - val_cost: 4.1634\n",
            "Epoch 54/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0898 - auc: 0.9930 - accuracy: 0.9724 - cost: 3.5204 - val_loss: 0.1134 - val_auc: 0.9895 - val_accuracy: 0.9656 - val_cost: 4.2262\n",
            "Epoch 55/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0892 - auc: 0.9932 - accuracy: 0.9725 - cost: 3.5123 - val_loss: 0.1140 - val_auc: 0.9898 - val_accuracy: 0.9669 - val_cost: 4.1634\n",
            "Epoch 56/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0879 - auc: 0.9933 - accuracy: 0.9723 - cost: 3.5421 - val_loss: 0.1123 - val_auc: 0.9899 - val_accuracy: 0.9672 - val_cost: 3.9848\n",
            "Epoch 57/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0883 - auc: 0.9933 - accuracy: 0.9723 - cost: 3.5378 - val_loss: 0.1114 - val_auc: 0.9901 - val_accuracy: 0.9672 - val_cost: 4.1369\n",
            "Epoch 58/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0873 - auc: 0.9934 - accuracy: 0.9728 - cost: 3.4803 - val_loss: 0.1112 - val_auc: 0.9898 - val_accuracy: 0.9674 - val_cost: 4.0542\n",
            "Epoch 59/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0873 - auc: 0.9932 - accuracy: 0.9730 - cost: 3.4549 - val_loss: 0.1120 - val_auc: 0.9896 - val_accuracy: 0.9676 - val_cost: 4.0179\n",
            "Epoch 60/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0864 - auc: 0.9933 - accuracy: 0.9735 - cost: 3.3904 - val_loss: 0.1124 - val_auc: 0.9897 - val_accuracy: 0.9666 - val_cost: 4.3188\n",
            "Epoch 61/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0859 - auc: 0.9935 - accuracy: 0.9732 - cost: 3.4217 - val_loss: 0.1112 - val_auc: 0.9899 - val_accuracy: 0.9681 - val_cost: 3.9385\n",
            "Epoch 62/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0846 - auc: 0.9937 - accuracy: 0.9736 - cost: 3.3704 - val_loss: 0.1110 - val_auc: 0.9897 - val_accuracy: 0.9678 - val_cost: 3.9782\n",
            "Epoch 63/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0841 - auc: 0.9938 - accuracy: 0.9739 - cost: 3.3256 - val_loss: 0.1113 - val_auc: 0.9900 - val_accuracy: 0.9670 - val_cost: 4.2626\n",
            "Epoch 64/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0839 - auc: 0.9937 - accuracy: 0.9743 - cost: 3.2778 - val_loss: 0.1099 - val_auc: 0.9901 - val_accuracy: 0.9677 - val_cost: 3.9749\n",
            "Epoch 65/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0836 - auc: 0.9937 - accuracy: 0.9747 - cost: 3.2357 - val_loss: 0.1100 - val_auc: 0.9900 - val_accuracy: 0.9685 - val_cost: 3.9517\n",
            "Epoch 66/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0840 - auc: 0.9937 - accuracy: 0.9740 - cost: 3.3264 - val_loss: 0.1106 - val_auc: 0.9900 - val_accuracy: 0.9687 - val_cost: 3.8955\n",
            "Epoch 67/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0828 - auc: 0.9938 - accuracy: 0.9743 - cost: 3.2758 - val_loss: 0.1095 - val_auc: 0.9900 - val_accuracy: 0.9682 - val_cost: 3.9716\n",
            "Epoch 68/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0828 - auc: 0.9939 - accuracy: 0.9749 - cost: 3.2068 - val_loss: 0.1101 - val_auc: 0.9900 - val_accuracy: 0.9697 - val_cost: 3.7335\n",
            "Epoch 69/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0810 - auc: 0.9941 - accuracy: 0.9747 - cost: 3.2357 - val_loss: 0.1103 - val_auc: 0.9901 - val_accuracy: 0.9687 - val_cost: 3.9286\n",
            "Epoch 70/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0822 - auc: 0.9939 - accuracy: 0.9744 - cost: 3.2620 - val_loss: 0.1119 - val_auc: 0.9899 - val_accuracy: 0.9672 - val_cost: 4.1700\n",
            "Epoch 71/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0821 - auc: 0.9938 - accuracy: 0.9748 - cost: 3.2257 - val_loss: 0.1099 - val_auc: 0.9903 - val_accuracy: 0.9683 - val_cost: 3.9550\n",
            "Epoch 72/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0802 - auc: 0.9941 - accuracy: 0.9752 - cost: 3.1771 - val_loss: 0.1105 - val_auc: 0.9900 - val_accuracy: 0.9695 - val_cost: 3.7467\n",
            "Epoch 73/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0799 - auc: 0.9941 - accuracy: 0.9753 - cost: 3.1640 - val_loss: 0.1114 - val_auc: 0.9899 - val_accuracy: 0.9688 - val_cost: 3.7533\n",
            "Epoch 74/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0803 - auc: 0.9940 - accuracy: 0.9754 - cost: 3.1262 - val_loss: 0.1088 - val_auc: 0.9900 - val_accuracy: 0.9699 - val_cost: 3.7566\n",
            "Epoch 75/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0787 - auc: 0.9942 - accuracy: 0.9757 - cost: 3.0961 - val_loss: 0.1118 - val_auc: 0.9901 - val_accuracy: 0.9680 - val_cost: 4.0774\n",
            "Epoch 76/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0794 - auc: 0.9941 - accuracy: 0.9758 - cost: 3.0891 - val_loss: 0.1090 - val_auc: 0.9902 - val_accuracy: 0.9693 - val_cost: 3.8095\n",
            "Epoch 77/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0792 - auc: 0.9941 - accuracy: 0.9760 - cost: 3.0625 - val_loss: 0.1106 - val_auc: 0.9902 - val_accuracy: 0.9689 - val_cost: 3.8095\n",
            "Epoch 78/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0782 - auc: 0.9943 - accuracy: 0.9760 - cost: 3.0664 - val_loss: 0.1104 - val_auc: 0.9903 - val_accuracy: 0.9684 - val_cost: 3.9451\n",
            "Epoch 79/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0787 - auc: 0.9942 - accuracy: 0.9758 - cost: 3.0895 - val_loss: 0.1110 - val_auc: 0.9901 - val_accuracy: 0.9687 - val_cost: 3.9947\n",
            "Epoch 80/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0778 - auc: 0.9943 - accuracy: 0.9767 - cost: 2.9842 - val_loss: 0.1127 - val_auc: 0.9898 - val_accuracy: 0.9674 - val_cost: 4.0509\n",
            "Epoch 81/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0779 - auc: 0.9943 - accuracy: 0.9761 - cost: 3.0667 - val_loss: 0.1116 - val_auc: 0.9899 - val_accuracy: 0.9685 - val_cost: 4.0079\n",
            "Epoch 82/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0784 - auc: 0.9942 - accuracy: 0.9763 - cost: 3.0363 - val_loss: 0.1103 - val_auc: 0.9901 - val_accuracy: 0.9690 - val_cost: 3.8459\n",
            "Epoch 83/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0771 - auc: 0.9945 - accuracy: 0.9766 - cost: 2.9985 - val_loss: 0.1101 - val_auc: 0.9902 - val_accuracy: 0.9695 - val_cost: 3.9054\n",
            "Epoch 84/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0765 - auc: 0.9945 - accuracy: 0.9769 - cost: 2.9672 - val_loss: 0.1116 - val_auc: 0.9899 - val_accuracy: 0.9678 - val_cost: 3.9385\n",
            "Epoch 85/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0762 - auc: 0.9945 - accuracy: 0.9772 - cost: 2.9240 - val_loss: 0.1105 - val_auc: 0.9900 - val_accuracy: 0.9699 - val_cost: 3.7599\n",
            "Epoch 86/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0758 - auc: 0.9946 - accuracy: 0.9770 - cost: 2.9417 - val_loss: 0.1117 - val_auc: 0.9900 - val_accuracy: 0.9690 - val_cost: 3.6574\n",
            "Epoch 87/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0765 - auc: 0.9944 - accuracy: 0.9768 - cost: 2.9606 - val_loss: 0.1098 - val_auc: 0.9901 - val_accuracy: 0.9691 - val_cost: 3.8558\n",
            "Epoch 88/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0754 - auc: 0.9945 - accuracy: 0.9770 - cost: 2.9456 - val_loss: 0.1092 - val_auc: 0.9904 - val_accuracy: 0.9700 - val_cost: 3.7599\n",
            "Epoch 89/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0755 - auc: 0.9945 - accuracy: 0.9772 - cost: 2.9163 - val_loss: 0.1093 - val_auc: 0.9901 - val_accuracy: 0.9684 - val_cost: 3.9914\n",
            "Epoch 90/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0741 - auc: 0.9947 - accuracy: 0.9777 - cost: 2.8511 - val_loss: 0.1115 - val_auc: 0.9901 - val_accuracy: 0.9679 - val_cost: 4.0509\n",
            "Epoch 91/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0739 - auc: 0.9947 - accuracy: 0.9779 - cost: 2.8252 - val_loss: 0.1114 - val_auc: 0.9900 - val_accuracy: 0.9697 - val_cost: 3.6640\n",
            "Epoch 92/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0744 - auc: 0.9947 - accuracy: 0.9782 - cost: 2.7978 - val_loss: 0.1118 - val_auc: 0.9899 - val_accuracy: 0.9686 - val_cost: 3.9517\n",
            "Epoch 93/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0746 - auc: 0.9947 - accuracy: 0.9775 - cost: 2.8862 - val_loss: 0.1096 - val_auc: 0.9899 - val_accuracy: 0.9696 - val_cost: 3.8591\n",
            "Epoch 94/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0739 - auc: 0.9947 - accuracy: 0.9780 - cost: 2.8198 - val_loss: 0.1103 - val_auc: 0.9901 - val_accuracy: 0.9686 - val_cost: 3.9881\n",
            "Epoch 95/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0730 - auc: 0.9947 - accuracy: 0.9782 - cost: 2.7809 - val_loss: 0.1123 - val_auc: 0.9900 - val_accuracy: 0.9685 - val_cost: 3.9749\n",
            "Epoch 96/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0743 - auc: 0.9946 - accuracy: 0.9778 - cost: 2.8376 - val_loss: 0.1096 - val_auc: 0.9902 - val_accuracy: 0.9705 - val_cost: 3.6508\n",
            "Epoch 97/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0737 - auc: 0.9947 - accuracy: 0.9777 - cost: 2.8519 - val_loss: 0.1111 - val_auc: 0.9900 - val_accuracy: 0.9693 - val_cost: 3.9286\n",
            "Epoch 98/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0725 - auc: 0.9948 - accuracy: 0.9781 - cost: 2.8121 - val_loss: 0.1115 - val_auc: 0.9900 - val_accuracy: 0.9689 - val_cost: 3.8327\n",
            "Epoch 99/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0726 - auc: 0.9950 - accuracy: 0.9779 - cost: 2.8291 - val_loss: 0.1105 - val_auc: 0.9901 - val_accuracy: 0.9690 - val_cost: 3.9914\n",
            "Epoch 100/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0727 - auc: 0.9948 - accuracy: 0.9782 - cost: 2.7905 - val_loss: 0.1144 - val_auc: 0.9899 - val_accuracy: 0.9695 - val_cost: 3.6706\n",
            "Epoch 101/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0730 - auc: 0.9949 - accuracy: 0.9783 - cost: 2.7932 - val_loss: 0.1132 - val_auc: 0.9900 - val_accuracy: 0.9680 - val_cost: 4.0642\n",
            "Epoch 102/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0728 - auc: 0.9947 - accuracy: 0.9780 - cost: 2.8221 - val_loss: 0.1110 - val_auc: 0.9900 - val_accuracy: 0.9699 - val_cost: 3.7302\n",
            "Epoch 103/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0720 - auc: 0.9950 - accuracy: 0.9783 - cost: 2.7739 - val_loss: 0.1111 - val_auc: 0.9901 - val_accuracy: 0.9708 - val_cost: 3.5880\n",
            "Epoch 104/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0720 - auc: 0.9949 - accuracy: 0.9782 - cost: 2.7986 - val_loss: 0.1104 - val_auc: 0.9902 - val_accuracy: 0.9699 - val_cost: 3.7996\n",
            "Epoch 105/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0709 - auc: 0.9950 - accuracy: 0.9786 - cost: 2.7469 - val_loss: 0.1106 - val_auc: 0.9902 - val_accuracy: 0.9695 - val_cost: 3.7963\n",
            "Epoch 106/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0718 - auc: 0.9949 - accuracy: 0.9785 - cost: 2.7523 - val_loss: 0.1116 - val_auc: 0.9900 - val_accuracy: 0.9701 - val_cost: 3.7368\n",
            "Epoch 107/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0710 - auc: 0.9951 - accuracy: 0.9787 - cost: 2.7350 - val_loss: 0.1135 - val_auc: 0.9898 - val_accuracy: 0.9690 - val_cost: 3.9484\n",
            "Epoch 108/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0713 - auc: 0.9950 - accuracy: 0.9787 - cost: 2.7361 - val_loss: 0.1111 - val_auc: 0.9902 - val_accuracy: 0.9699 - val_cost: 3.7368\n",
            "Epoch 109/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0715 - auc: 0.9949 - accuracy: 0.9791 - cost: 2.6651 - val_loss: 0.1108 - val_auc: 0.9903 - val_accuracy: 0.9697 - val_cost: 3.8261\n",
            "Epoch 110/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0710 - auc: 0.9950 - accuracy: 0.9788 - cost: 2.7164 - val_loss: 0.1108 - val_auc: 0.9901 - val_accuracy: 0.9694 - val_cost: 3.8459\n",
            "Epoch 111/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0718 - auc: 0.9949 - accuracy: 0.9784 - cost: 2.7620 - val_loss: 0.1111 - val_auc: 0.9903 - val_accuracy: 0.9699 - val_cost: 3.7235\n",
            "Epoch 112/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0696 - auc: 0.9951 - accuracy: 0.9790 - cost: 2.6883 - val_loss: 0.1140 - val_auc: 0.9902 - val_accuracy: 0.9700 - val_cost: 3.6078\n",
            "Epoch 113/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0706 - auc: 0.9950 - accuracy: 0.9790 - cost: 2.6860 - val_loss: 0.1111 - val_auc: 0.9900 - val_accuracy: 0.9699 - val_cost: 3.7269\n",
            "Epoch 114/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0700 - auc: 0.9951 - accuracy: 0.9792 - cost: 2.6655 - val_loss: 0.1111 - val_auc: 0.9902 - val_accuracy: 0.9701 - val_cost: 3.7004\n",
            "Epoch 115/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0705 - auc: 0.9951 - accuracy: 0.9790 - cost: 2.6987 - val_loss: 0.1125 - val_auc: 0.9900 - val_accuracy: 0.9694 - val_cost: 3.8426\n",
            "Epoch 116/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0694 - auc: 0.9952 - accuracy: 0.9795 - cost: 2.6269 - val_loss: 0.1124 - val_auc: 0.9899 - val_accuracy: 0.9701 - val_cost: 3.6706\n",
            "Epoch 117/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0696 - auc: 0.9951 - accuracy: 0.9797 - cost: 2.5953 - val_loss: 0.1132 - val_auc: 0.9901 - val_accuracy: 0.9694 - val_cost: 3.7963\n",
            "Epoch 118/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0700 - auc: 0.9950 - accuracy: 0.9792 - cost: 2.6728 - val_loss: 0.1111 - val_auc: 0.9902 - val_accuracy: 0.9697 - val_cost: 3.8558\n",
            "Epoch 119/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0692 - auc: 0.9953 - accuracy: 0.9792 - cost: 2.6682 - val_loss: 0.1134 - val_auc: 0.9897 - val_accuracy: 0.9692 - val_cost: 3.7864\n",
            "Epoch 120/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0696 - auc: 0.9951 - accuracy: 0.9794 - cost: 2.6400 - val_loss: 0.1108 - val_auc: 0.9901 - val_accuracy: 0.9700 - val_cost: 3.7599\n",
            "Epoch 121/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0687 - auc: 0.9952 - accuracy: 0.9799 - cost: 2.5860 - val_loss: 0.1129 - val_auc: 0.9901 - val_accuracy: 0.9715 - val_cost: 3.4358\n",
            "Epoch 122/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0686 - auc: 0.9952 - accuracy: 0.9793 - cost: 2.6481 - val_loss: 0.1132 - val_auc: 0.9898 - val_accuracy: 0.9692 - val_cost: 3.7269\n",
            "Epoch 123/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0680 - auc: 0.9953 - accuracy: 0.9797 - cost: 2.6084 - val_loss: 0.1142 - val_auc: 0.9897 - val_accuracy: 0.9697 - val_cost: 3.6905\n",
            "Epoch 124/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0690 - auc: 0.9952 - accuracy: 0.9793 - cost: 2.6474 - val_loss: 0.1131 - val_auc: 0.9899 - val_accuracy: 0.9697 - val_cost: 3.8591\n",
            "Epoch 125/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0683 - auc: 0.9952 - accuracy: 0.9798 - cost: 2.5961 - val_loss: 0.1115 - val_auc: 0.9900 - val_accuracy: 0.9710 - val_cost: 3.5880\n",
            "Epoch 126/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0674 - auc: 0.9953 - accuracy: 0.9799 - cost: 2.5617 - val_loss: 0.1138 - val_auc: 0.9901 - val_accuracy: 0.9712 - val_cost: 3.5351\n",
            "Epoch 127/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0679 - auc: 0.9952 - accuracy: 0.9801 - cost: 2.5509 - val_loss: 0.1145 - val_auc: 0.9898 - val_accuracy: 0.9690 - val_cost: 3.9980\n",
            "Epoch 128/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0683 - auc: 0.9953 - accuracy: 0.9797 - cost: 2.6049 - val_loss: 0.1139 - val_auc: 0.9902 - val_accuracy: 0.9691 - val_cost: 3.8988\n",
            "Epoch 129/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0679 - auc: 0.9952 - accuracy: 0.9800 - cost: 2.5648 - val_loss: 0.1145 - val_auc: 0.9898 - val_accuracy: 0.9702 - val_cost: 3.6971\n",
            "Epoch 130/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0684 - auc: 0.9953 - accuracy: 0.9799 - cost: 2.5856 - val_loss: 0.1135 - val_auc: 0.9897 - val_accuracy: 0.9711 - val_cost: 3.6144\n",
            "Epoch 131/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0683 - auc: 0.9952 - accuracy: 0.9798 - cost: 2.5818 - val_loss: 0.1133 - val_auc: 0.9898 - val_accuracy: 0.9700 - val_cost: 3.7864\n",
            "Epoch 132/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0681 - auc: 0.9952 - accuracy: 0.9798 - cost: 2.5968 - val_loss: 0.1118 - val_auc: 0.9902 - val_accuracy: 0.9698 - val_cost: 3.6772\n",
            "Epoch 133/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0675 - auc: 0.9954 - accuracy: 0.9801 - cost: 2.5463 - val_loss: 0.1150 - val_auc: 0.9900 - val_accuracy: 0.9704 - val_cost: 3.5582\n",
            "Epoch 134/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0674 - auc: 0.9953 - accuracy: 0.9799 - cost: 2.5849 - val_loss: 0.1140 - val_auc: 0.9898 - val_accuracy: 0.9704 - val_cost: 3.6442\n",
            "Epoch 135/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0670 - auc: 0.9953 - accuracy: 0.9802 - cost: 2.5448 - val_loss: 0.1169 - val_auc: 0.9896 - val_accuracy: 0.9706 - val_cost: 3.6210\n",
            "Epoch 136/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0675 - auc: 0.9954 - accuracy: 0.9800 - cost: 2.5586 - val_loss: 0.1116 - val_auc: 0.9898 - val_accuracy: 0.9708 - val_cost: 3.6409\n",
            "Epoch 137/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0665 - auc: 0.9955 - accuracy: 0.9806 - cost: 2.4815 - val_loss: 0.1150 - val_auc: 0.9895 - val_accuracy: 0.9710 - val_cost: 3.5780\n",
            "Epoch 138/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0679 - auc: 0.9953 - accuracy: 0.9796 - cost: 2.6254 - val_loss: 0.1125 - val_auc: 0.9899 - val_accuracy: 0.9706 - val_cost: 3.7765\n",
            "Epoch 139/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0672 - auc: 0.9954 - accuracy: 0.9799 - cost: 2.5818 - val_loss: 0.1133 - val_auc: 0.9897 - val_accuracy: 0.9702 - val_cost: 3.7368\n",
            "Epoch 140/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0671 - auc: 0.9954 - accuracy: 0.9800 - cost: 2.5710 - val_loss: 0.1133 - val_auc: 0.9898 - val_accuracy: 0.9702 - val_cost: 3.7599\n",
            "Epoch 141/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0667 - auc: 0.9954 - accuracy: 0.9799 - cost: 2.5733 - val_loss: 0.1152 - val_auc: 0.9896 - val_accuracy: 0.9703 - val_cost: 3.6541\n",
            "Epoch 142/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0656 - auc: 0.9955 - accuracy: 0.9806 - cost: 2.4919 - val_loss: 0.1148 - val_auc: 0.9900 - val_accuracy: 0.9706 - val_cost: 3.5516\n",
            "Epoch 143/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0661 - auc: 0.9954 - accuracy: 0.9803 - cost: 2.5204 - val_loss: 0.1137 - val_auc: 0.9897 - val_accuracy: 0.9704 - val_cost: 3.6607\n",
            "Epoch 144/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0665 - auc: 0.9954 - accuracy: 0.9800 - cost: 2.5675 - val_loss: 0.1129 - val_auc: 0.9899 - val_accuracy: 0.9713 - val_cost: 3.5582\n",
            "Epoch 145/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0664 - auc: 0.9955 - accuracy: 0.9805 - cost: 2.4985 - val_loss: 0.1124 - val_auc: 0.9901 - val_accuracy: 0.9708 - val_cost: 3.6772\n",
            "Epoch 146/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0657 - auc: 0.9956 - accuracy: 0.9804 - cost: 2.5150 - val_loss: 0.1159 - val_auc: 0.9899 - val_accuracy: 0.9698 - val_cost: 3.6475\n",
            "Epoch 147/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0660 - auc: 0.9954 - accuracy: 0.9805 - cost: 2.5062 - val_loss: 0.1139 - val_auc: 0.9900 - val_accuracy: 0.9712 - val_cost: 3.5317\n",
            "Epoch 148/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0662 - auc: 0.9954 - accuracy: 0.9805 - cost: 2.5050 - val_loss: 0.1142 - val_auc: 0.9900 - val_accuracy: 0.9710 - val_cost: 3.5582\n",
            "Epoch 149/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0665 - auc: 0.9954 - accuracy: 0.9806 - cost: 2.4884 - val_loss: 0.1137 - val_auc: 0.9896 - val_accuracy: 0.9719 - val_cost: 3.5086\n",
            "Epoch 150/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0658 - auc: 0.9955 - accuracy: 0.9806 - cost: 2.4834 - val_loss: 0.1141 - val_auc: 0.9898 - val_accuracy: 0.9710 - val_cost: 3.5780\n",
            "Epoch 151/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0653 - auc: 0.9956 - accuracy: 0.9804 - cost: 2.5220 - val_loss: 0.1130 - val_auc: 0.9899 - val_accuracy: 0.9712 - val_cost: 3.5946\n",
            "Epoch 152/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0654 - auc: 0.9955 - accuracy: 0.9807 - cost: 2.4726 - val_loss: 0.1133 - val_auc: 0.9901 - val_accuracy: 0.9705 - val_cost: 3.6111\n",
            "Epoch 153/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0648 - auc: 0.9956 - accuracy: 0.9806 - cost: 2.4896 - val_loss: 0.1131 - val_auc: 0.9902 - val_accuracy: 0.9715 - val_cost: 3.5284\n",
            "Epoch 154/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0654 - auc: 0.9955 - accuracy: 0.9811 - cost: 2.4302 - val_loss: 0.1159 - val_auc: 0.9897 - val_accuracy: 0.9707 - val_cost: 3.6343\n",
            "Epoch 155/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0652 - auc: 0.9956 - accuracy: 0.9805 - cost: 2.4896 - val_loss: 0.1154 - val_auc: 0.9898 - val_accuracy: 0.9699 - val_cost: 3.8228\n",
            "Epoch 156/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0651 - auc: 0.9956 - accuracy: 0.9808 - cost: 2.4572 - val_loss: 0.1138 - val_auc: 0.9898 - val_accuracy: 0.9706 - val_cost: 3.6772\n",
            "Epoch 157/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0646 - auc: 0.9956 - accuracy: 0.9807 - cost: 2.4753 - val_loss: 0.1151 - val_auc: 0.9898 - val_accuracy: 0.9708 - val_cost: 3.5913\n",
            "Epoch 158/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0656 - auc: 0.9955 - accuracy: 0.9805 - cost: 2.5050 - val_loss: 0.1146 - val_auc: 0.9898 - val_accuracy: 0.9707 - val_cost: 3.6343\n",
            "Epoch 159/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0651 - auc: 0.9956 - accuracy: 0.9809 - cost: 2.4587 - val_loss: 0.1145 - val_auc: 0.9899 - val_accuracy: 0.9712 - val_cost: 3.5615\n",
            "Epoch 160/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0645 - auc: 0.9957 - accuracy: 0.9808 - cost: 2.4522 - val_loss: 0.1142 - val_auc: 0.9896 - val_accuracy: 0.9711 - val_cost: 3.5913\n",
            "Epoch 161/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0647 - auc: 0.9956 - accuracy: 0.9810 - cost: 2.4510 - val_loss: 0.1155 - val_auc: 0.9897 - val_accuracy: 0.9710 - val_cost: 3.5549\n",
            "Epoch 162/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0639 - auc: 0.9957 - accuracy: 0.9810 - cost: 2.4441 - val_loss: 0.1146 - val_auc: 0.9898 - val_accuracy: 0.9709 - val_cost: 3.5615\n",
            "Epoch 163/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0645 - auc: 0.9957 - accuracy: 0.9807 - cost: 2.4680 - val_loss: 0.1148 - val_auc: 0.9898 - val_accuracy: 0.9708 - val_cost: 3.6376\n",
            "Epoch 164/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0653 - auc: 0.9956 - accuracy: 0.9807 - cost: 2.4742 - val_loss: 0.1153 - val_auc: 0.9896 - val_accuracy: 0.9717 - val_cost: 3.5417\n",
            "Epoch 165/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0646 - auc: 0.9957 - accuracy: 0.9812 - cost: 2.4140 - val_loss: 0.1173 - val_auc: 0.9894 - val_accuracy: 0.9714 - val_cost: 3.6177\n",
            "Epoch 166/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0644 - auc: 0.9956 - accuracy: 0.9812 - cost: 2.4055 - val_loss: 0.1135 - val_auc: 0.9899 - val_accuracy: 0.9719 - val_cost: 3.4888\n",
            "Epoch 167/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0639 - auc: 0.9957 - accuracy: 0.9812 - cost: 2.4097 - val_loss: 0.1165 - val_auc: 0.9898 - val_accuracy: 0.9706 - val_cost: 3.6442\n",
            "Epoch 168/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0638 - auc: 0.9958 - accuracy: 0.9808 - cost: 2.4622 - val_loss: 0.1156 - val_auc: 0.9898 - val_accuracy: 0.9712 - val_cost: 3.5516\n",
            "Epoch 169/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0633 - auc: 0.9958 - accuracy: 0.9809 - cost: 2.4464 - val_loss: 0.1164 - val_auc: 0.9896 - val_accuracy: 0.9712 - val_cost: 3.5152\n",
            "Epoch 170/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0640 - auc: 0.9955 - accuracy: 0.9810 - cost: 2.4352 - val_loss: 0.1154 - val_auc: 0.9895 - val_accuracy: 0.9709 - val_cost: 3.7037\n",
            "Epoch 171/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0639 - auc: 0.9957 - accuracy: 0.9810 - cost: 2.4425 - val_loss: 0.1157 - val_auc: 0.9895 - val_accuracy: 0.9710 - val_cost: 3.6806\n",
            "Epoch 172/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0636 - auc: 0.9958 - accuracy: 0.9813 - cost: 2.4097 - val_loss: 0.1161 - val_auc: 0.9898 - val_accuracy: 0.9706 - val_cost: 3.6607\n",
            "Epoch 173/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0639 - auc: 0.9957 - accuracy: 0.9810 - cost: 2.4348 - val_loss: 0.1152 - val_auc: 0.9897 - val_accuracy: 0.9703 - val_cost: 3.7500\n",
            "Epoch 174/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0640 - auc: 0.9956 - accuracy: 0.9809 - cost: 2.4541 - val_loss: 0.1144 - val_auc: 0.9899 - val_accuracy: 0.9712 - val_cost: 3.5549\n",
            "Epoch 175/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0641 - auc: 0.9957 - accuracy: 0.9811 - cost: 2.4329 - val_loss: 0.1153 - val_auc: 0.9899 - val_accuracy: 0.9717 - val_cost: 3.4656\n",
            "Epoch 176/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0637 - auc: 0.9958 - accuracy: 0.9811 - cost: 2.4309 - val_loss: 0.1156 - val_auc: 0.9900 - val_accuracy: 0.9705 - val_cost: 3.7897\n",
            "Epoch 177/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0634 - auc: 0.9956 - accuracy: 0.9812 - cost: 2.4120 - val_loss: 0.1164 - val_auc: 0.9898 - val_accuracy: 0.9711 - val_cost: 3.5384\n",
            "Epoch 178/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0628 - auc: 0.9958 - accuracy: 0.9818 - cost: 2.3434 - val_loss: 0.1154 - val_auc: 0.9897 - val_accuracy: 0.9702 - val_cost: 3.7566\n",
            "Epoch 179/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0642 - auc: 0.9957 - accuracy: 0.9812 - cost: 2.4221 - val_loss: 0.1140 - val_auc: 0.9897 - val_accuracy: 0.9717 - val_cost: 3.5847\n",
            "Epoch 180/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0634 - auc: 0.9958 - accuracy: 0.9810 - cost: 2.4371 - val_loss: 0.1160 - val_auc: 0.9899 - val_accuracy: 0.9712 - val_cost: 3.6276\n",
            "Epoch 181/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0629 - auc: 0.9957 - accuracy: 0.9812 - cost: 2.4062 - val_loss: 0.1157 - val_auc: 0.9896 - val_accuracy: 0.9702 - val_cost: 3.7831\n",
            "Epoch 182/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0631 - auc: 0.9958 - accuracy: 0.9811 - cost: 2.4309 - val_loss: 0.1169 - val_auc: 0.9892 - val_accuracy: 0.9703 - val_cost: 3.7269\n",
            "Epoch 183/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0631 - auc: 0.9958 - accuracy: 0.9815 - cost: 2.3711 - val_loss: 0.1174 - val_auc: 0.9897 - val_accuracy: 0.9710 - val_cost: 3.6508\n",
            "Epoch 184/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0623 - auc: 0.9959 - accuracy: 0.9818 - cost: 2.3333 - val_loss: 0.1165 - val_auc: 0.9893 - val_accuracy: 0.9705 - val_cost: 3.7500\n",
            "Epoch 185/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0628 - auc: 0.9958 - accuracy: 0.9812 - cost: 2.4151 - val_loss: 0.1170 - val_auc: 0.9895 - val_accuracy: 0.9697 - val_cost: 3.7169\n",
            "Epoch 186/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0628 - auc: 0.9959 - accuracy: 0.9816 - cost: 2.3661 - val_loss: 0.1159 - val_auc: 0.9893 - val_accuracy: 0.9710 - val_cost: 3.6111\n",
            "Epoch 187/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0617 - auc: 0.9959 - accuracy: 0.9818 - cost: 2.3465 - val_loss: 0.1183 - val_auc: 0.9897 - val_accuracy: 0.9708 - val_cost: 3.5714\n",
            "Epoch 188/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0626 - auc: 0.9958 - accuracy: 0.9814 - cost: 2.3900 - val_loss: 0.1166 - val_auc: 0.9898 - val_accuracy: 0.9706 - val_cost: 3.6177\n",
            "Epoch 189/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0631 - auc: 0.9958 - accuracy: 0.9814 - cost: 2.3858 - val_loss: 0.1161 - val_auc: 0.9897 - val_accuracy: 0.9713 - val_cost: 3.5516\n",
            "Epoch 190/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0629 - auc: 0.9958 - accuracy: 0.9813 - cost: 2.4120 - val_loss: 0.1183 - val_auc: 0.9896 - val_accuracy: 0.9708 - val_cost: 3.6409\n",
            "Epoch 191/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0627 - auc: 0.9959 - accuracy: 0.9815 - cost: 2.3750 - val_loss: 0.1164 - val_auc: 0.9898 - val_accuracy: 0.9708 - val_cost: 3.5450\n",
            "Epoch 192/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0622 - auc: 0.9958 - accuracy: 0.9820 - cost: 2.3164 - val_loss: 0.1172 - val_auc: 0.9897 - val_accuracy: 0.9708 - val_cost: 3.6111\n",
            "Epoch 193/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0620 - auc: 0.9959 - accuracy: 0.9817 - cost: 2.3538 - val_loss: 0.1178 - val_auc: 0.9894 - val_accuracy: 0.9710 - val_cost: 3.6012\n",
            "Epoch 194/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0625 - auc: 0.9959 - accuracy: 0.9815 - cost: 2.3708 - val_loss: 0.1178 - val_auc: 0.9891 - val_accuracy: 0.9712 - val_cost: 3.6640\n",
            "Epoch 195/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0624 - auc: 0.9959 - accuracy: 0.9812 - cost: 2.4144 - val_loss: 0.1172 - val_auc: 0.9895 - val_accuracy: 0.9698 - val_cost: 3.7731\n",
            "Epoch 196/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0620 - auc: 0.9960 - accuracy: 0.9817 - cost: 2.3453 - val_loss: 0.1166 - val_auc: 0.9897 - val_accuracy: 0.9709 - val_cost: 3.5747\n",
            "Epoch 197/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0616 - auc: 0.9961 - accuracy: 0.9813 - cost: 2.3989 - val_loss: 0.1173 - val_auc: 0.9895 - val_accuracy: 0.9707 - val_cost: 3.5847\n",
            "Epoch 198/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0616 - auc: 0.9959 - accuracy: 0.9821 - cost: 2.3059 - val_loss: 0.1162 - val_auc: 0.9897 - val_accuracy: 0.9719 - val_cost: 3.4854\n",
            "Epoch 199/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0607 - auc: 0.9960 - accuracy: 0.9823 - cost: 2.2708 - val_loss: 0.1195 - val_auc: 0.9893 - val_accuracy: 0.9701 - val_cost: 3.7963\n",
            "Epoch 200/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0623 - auc: 0.9958 - accuracy: 0.9816 - cost: 2.3657 - val_loss: 0.1170 - val_auc: 0.9893 - val_accuracy: 0.9712 - val_cost: 3.5813\n",
            "Epoch 201/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0618 - auc: 0.9959 - accuracy: 0.9815 - cost: 2.3700 - val_loss: 0.1163 - val_auc: 0.9895 - val_accuracy: 0.9707 - val_cost: 3.6739\n",
            "Epoch 202/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0619 - auc: 0.9959 - accuracy: 0.9818 - cost: 2.3426 - val_loss: 0.1174 - val_auc: 0.9893 - val_accuracy: 0.9709 - val_cost: 3.6012\n",
            "Epoch 203/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0619 - auc: 0.9960 - accuracy: 0.9817 - cost: 2.3557 - val_loss: 0.1165 - val_auc: 0.9897 - val_accuracy: 0.9719 - val_cost: 3.5053\n",
            "Epoch 204/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0613 - auc: 0.9959 - accuracy: 0.9811 - cost: 2.4313 - val_loss: 0.1192 - val_auc: 0.9892 - val_accuracy: 0.9706 - val_cost: 3.6177\n",
            "Epoch 205/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0610 - auc: 0.9960 - accuracy: 0.9818 - cost: 2.3492 - val_loss: 0.1199 - val_auc: 0.9893 - val_accuracy: 0.9703 - val_cost: 3.6276\n",
            "Epoch 206/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0607 - auc: 0.9960 - accuracy: 0.9820 - cost: 2.3106 - val_loss: 0.1180 - val_auc: 0.9894 - val_accuracy: 0.9703 - val_cost: 3.8194\n",
            "Epoch 207/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0612 - auc: 0.9960 - accuracy: 0.9815 - cost: 2.3715 - val_loss: 0.1199 - val_auc: 0.9890 - val_accuracy: 0.9719 - val_cost: 3.4358\n",
            "Epoch 208/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0609 - auc: 0.9959 - accuracy: 0.9821 - cost: 2.3106 - val_loss: 0.1177 - val_auc: 0.9894 - val_accuracy: 0.9707 - val_cost: 3.6872\n",
            "Epoch 209/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0613 - auc: 0.9960 - accuracy: 0.9817 - cost: 2.3569 - val_loss: 0.1179 - val_auc: 0.9894 - val_accuracy: 0.9716 - val_cost: 3.5813\n",
            "Epoch 210/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0607 - auc: 0.9960 - accuracy: 0.9820 - cost: 2.3090 - val_loss: 0.1189 - val_auc: 0.9888 - val_accuracy: 0.9717 - val_cost: 3.4623\n",
            "Epoch 211/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0601 - auc: 0.9961 - accuracy: 0.9820 - cost: 2.3144 - val_loss: 0.1172 - val_auc: 0.9895 - val_accuracy: 0.9710 - val_cost: 3.6706\n",
            "Epoch 212/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0614 - auc: 0.9959 - accuracy: 0.9816 - cost: 2.3646 - val_loss: 0.1201 - val_auc: 0.9888 - val_accuracy: 0.9704 - val_cost: 3.7302\n",
            "Epoch 213/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0607 - auc: 0.9960 - accuracy: 0.9822 - cost: 2.2901 - val_loss: 0.1184 - val_auc: 0.9891 - val_accuracy: 0.9712 - val_cost: 3.6210\n",
            "Epoch 214/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0596 - auc: 0.9963 - accuracy: 0.9825 - cost: 2.2400 - val_loss: 0.1180 - val_auc: 0.9892 - val_accuracy: 0.9707 - val_cost: 3.6574\n",
            "Epoch 215/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0607 - auc: 0.9960 - accuracy: 0.9821 - cost: 2.3032 - val_loss: 0.1186 - val_auc: 0.9895 - val_accuracy: 0.9717 - val_cost: 3.5384\n",
            "Epoch 216/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0601 - auc: 0.9961 - accuracy: 0.9824 - cost: 2.2674 - val_loss: 0.1201 - val_auc: 0.9890 - val_accuracy: 0.9706 - val_cost: 3.7070\n",
            "Epoch 217/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0604 - auc: 0.9961 - accuracy: 0.9821 - cost: 2.3094 - val_loss: 0.1213 - val_auc: 0.9891 - val_accuracy: 0.9710 - val_cost: 3.5648\n",
            "Epoch 218/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0604 - auc: 0.9961 - accuracy: 0.9821 - cost: 2.3067 - val_loss: 0.1194 - val_auc: 0.9892 - val_accuracy: 0.9716 - val_cost: 3.4888\n",
            "Epoch 219/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0607 - auc: 0.9961 - accuracy: 0.9821 - cost: 2.3059 - val_loss: 0.1186 - val_auc: 0.9896 - val_accuracy: 0.9714 - val_cost: 3.5020\n",
            "Epoch 220/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0607 - auc: 0.9961 - accuracy: 0.9820 - cost: 2.3152 - val_loss: 0.1187 - val_auc: 0.9890 - val_accuracy: 0.9712 - val_cost: 3.5681\n",
            "Epoch 221/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0618 - auc: 0.9960 - accuracy: 0.9815 - cost: 2.3746 - val_loss: 0.1204 - val_auc: 0.9890 - val_accuracy: 0.9714 - val_cost: 3.5351\n",
            "Epoch 222/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0600 - auc: 0.9961 - accuracy: 0.9823 - cost: 2.2874 - val_loss: 0.1182 - val_auc: 0.9893 - val_accuracy: 0.9710 - val_cost: 3.5714\n",
            "Epoch 223/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0602 - auc: 0.9961 - accuracy: 0.9824 - cost: 2.2539 - val_loss: 0.1185 - val_auc: 0.9891 - val_accuracy: 0.9710 - val_cost: 3.6673\n",
            "Epoch 224/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0604 - auc: 0.9960 - accuracy: 0.9823 - cost: 2.2805 - val_loss: 0.1191 - val_auc: 0.9892 - val_accuracy: 0.9714 - val_cost: 3.4954\n",
            "Epoch 225/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0595 - auc: 0.9961 - accuracy: 0.9824 - cost: 2.2693 - val_loss: 0.1189 - val_auc: 0.9892 - val_accuracy: 0.9699 - val_cost: 3.8161\n",
            "Epoch 226/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0600 - auc: 0.9961 - accuracy: 0.9821 - cost: 2.2994 - val_loss: 0.1200 - val_auc: 0.9891 - val_accuracy: 0.9700 - val_cost: 3.7368\n",
            "Epoch 227/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0604 - auc: 0.9961 - accuracy: 0.9823 - cost: 2.2701 - val_loss: 0.1174 - val_auc: 0.9896 - val_accuracy: 0.9717 - val_cost: 3.4722\n",
            "Epoch 228/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0608 - auc: 0.9961 - accuracy: 0.9822 - cost: 2.2867 - val_loss: 0.1201 - val_auc: 0.9894 - val_accuracy: 0.9699 - val_cost: 3.7963\n",
            "Epoch 229/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0599 - auc: 0.9962 - accuracy: 0.9822 - cost: 2.2955 - val_loss: 0.1205 - val_auc: 0.9893 - val_accuracy: 0.9708 - val_cost: 3.5417\n",
            "Epoch 230/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0599 - auc: 0.9961 - accuracy: 0.9823 - cost: 2.2681 - val_loss: 0.1192 - val_auc: 0.9889 - val_accuracy: 0.9709 - val_cost: 3.6971\n",
            "Epoch 231/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0596 - auc: 0.9961 - accuracy: 0.9825 - cost: 2.2643 - val_loss: 0.1203 - val_auc: 0.9892 - val_accuracy: 0.9715 - val_cost: 3.6144\n",
            "Epoch 232/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0594 - auc: 0.9962 - accuracy: 0.9822 - cost: 2.2809 - val_loss: 0.1187 - val_auc: 0.9891 - val_accuracy: 0.9707 - val_cost: 3.6144\n",
            "Epoch 233/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0592 - auc: 0.9963 - accuracy: 0.9824 - cost: 2.2797 - val_loss: 0.1193 - val_auc: 0.9892 - val_accuracy: 0.9707 - val_cost: 3.6905\n",
            "Epoch 234/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0595 - auc: 0.9961 - accuracy: 0.9824 - cost: 2.2616 - val_loss: 0.1214 - val_auc: 0.9890 - val_accuracy: 0.9708 - val_cost: 3.6276\n",
            "Epoch 235/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0595 - auc: 0.9963 - accuracy: 0.9824 - cost: 2.2666 - val_loss: 0.1220 - val_auc: 0.9888 - val_accuracy: 0.9707 - val_cost: 3.6343\n",
            "Epoch 236/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0584 - auc: 0.9963 - accuracy: 0.9828 - cost: 2.2099 - val_loss: 0.1210 - val_auc: 0.9887 - val_accuracy: 0.9698 - val_cost: 3.7302\n",
            "Epoch 237/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0596 - auc: 0.9963 - accuracy: 0.9819 - cost: 2.3275 - val_loss: 0.1221 - val_auc: 0.9891 - val_accuracy: 0.9715 - val_cost: 3.5582\n",
            "Epoch 238/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0600 - auc: 0.9961 - accuracy: 0.9823 - cost: 2.2766 - val_loss: 0.1213 - val_auc: 0.9886 - val_accuracy: 0.9703 - val_cost: 3.8062\n",
            "Epoch 239/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0593 - auc: 0.9963 - accuracy: 0.9823 - cost: 2.2758 - val_loss: 0.1182 - val_auc: 0.9895 - val_accuracy: 0.9720 - val_cost: 3.4921\n",
            "Epoch 240/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0589 - auc: 0.9962 - accuracy: 0.9827 - cost: 2.2172 - val_loss: 0.1205 - val_auc: 0.9888 - val_accuracy: 0.9721 - val_cost: 3.5450\n",
            "Epoch 241/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0583 - auc: 0.9963 - accuracy: 0.9830 - cost: 2.1836 - val_loss: 0.1213 - val_auc: 0.9887 - val_accuracy: 0.9726 - val_cost: 3.3829\n",
            "Epoch 242/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0588 - auc: 0.9963 - accuracy: 0.9824 - cost: 2.2616 - val_loss: 0.1201 - val_auc: 0.9891 - val_accuracy: 0.9713 - val_cost: 3.6409\n",
            "Epoch 243/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0592 - auc: 0.9962 - accuracy: 0.9823 - cost: 2.2778 - val_loss: 0.1225 - val_auc: 0.9884 - val_accuracy: 0.9703 - val_cost: 3.7368\n",
            "Epoch 244/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0591 - auc: 0.9963 - accuracy: 0.9822 - cost: 2.2870 - val_loss: 0.1234 - val_auc: 0.9888 - val_accuracy: 0.9710 - val_cost: 3.5450\n",
            "Epoch 245/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0583 - auc: 0.9964 - accuracy: 0.9827 - cost: 2.2211 - val_loss: 0.1213 - val_auc: 0.9885 - val_accuracy: 0.9701 - val_cost: 3.8228\n",
            "Epoch 246/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0584 - auc: 0.9963 - accuracy: 0.9826 - cost: 2.2404 - val_loss: 0.1214 - val_auc: 0.9890 - val_accuracy: 0.9717 - val_cost: 3.5648\n",
            "Epoch 247/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0590 - auc: 0.9963 - accuracy: 0.9820 - cost: 2.3194 - val_loss: 0.1221 - val_auc: 0.9886 - val_accuracy: 0.9714 - val_cost: 3.5417\n",
            "Epoch 248/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0589 - auc: 0.9962 - accuracy: 0.9819 - cost: 2.3245 - val_loss: 0.1227 - val_auc: 0.9889 - val_accuracy: 0.9697 - val_cost: 3.7698\n",
            "Epoch 249/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0597 - auc: 0.9961 - accuracy: 0.9823 - cost: 2.2840 - val_loss: 0.1217 - val_auc: 0.9888 - val_accuracy: 0.9717 - val_cost: 3.4855\n",
            "Epoch 250/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0605 - auc: 0.9961 - accuracy: 0.9821 - cost: 2.3025 - val_loss: 0.1217 - val_auc: 0.9887 - val_accuracy: 0.9715 - val_cost: 3.5582\n",
            "Epoch 251/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0572 - auc: 0.9964 - accuracy: 0.9831 - cost: 2.1682 - val_loss: 0.1222 - val_auc: 0.9890 - val_accuracy: 0.9715 - val_cost: 3.5119\n",
            "Epoch 252/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0593 - auc: 0.9962 - accuracy: 0.9828 - cost: 2.2195 - val_loss: 0.1224 - val_auc: 0.9887 - val_accuracy: 0.9706 - val_cost: 3.7169\n",
            "Epoch 253/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0590 - auc: 0.9962 - accuracy: 0.9822 - cost: 2.2975 - val_loss: 0.1232 - val_auc: 0.9892 - val_accuracy: 0.9701 - val_cost: 3.7070\n",
            "Epoch 254/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0587 - auc: 0.9964 - accuracy: 0.9824 - cost: 2.2604 - val_loss: 0.1224 - val_auc: 0.9893 - val_accuracy: 0.9708 - val_cost: 3.5979\n",
            "Epoch 255/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0586 - auc: 0.9962 - accuracy: 0.9828 - cost: 2.2133 - val_loss: 0.1219 - val_auc: 0.9887 - val_accuracy: 0.9717 - val_cost: 3.4524\n",
            "Epoch 256/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0583 - auc: 0.9962 - accuracy: 0.9826 - cost: 2.2269 - val_loss: 0.1217 - val_auc: 0.9891 - val_accuracy: 0.9710 - val_cost: 3.6045\n",
            "Epoch 257/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0587 - auc: 0.9963 - accuracy: 0.9827 - cost: 2.2284 - val_loss: 0.1217 - val_auc: 0.9890 - val_accuracy: 0.9712 - val_cost: 3.5979\n",
            "Epoch 258/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0581 - auc: 0.9964 - accuracy: 0.9828 - cost: 2.2272 - val_loss: 0.1239 - val_auc: 0.9888 - val_accuracy: 0.9712 - val_cost: 3.4954\n",
            "Epoch 259/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0592 - auc: 0.9963 - accuracy: 0.9821 - cost: 2.3017 - val_loss: 0.1254 - val_auc: 0.9885 - val_accuracy: 0.9706 - val_cost: 3.5780\n",
            "Epoch 260/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0583 - auc: 0.9963 - accuracy: 0.9827 - cost: 2.2145 - val_loss: 0.1225 - val_auc: 0.9888 - val_accuracy: 0.9715 - val_cost: 3.5681\n",
            "Epoch 261/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0580 - auc: 0.9964 - accuracy: 0.9826 - cost: 2.2380 - val_loss: 0.1201 - val_auc: 0.9894 - val_accuracy: 0.9707 - val_cost: 3.5880\n",
            "Epoch 262/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0589 - auc: 0.9964 - accuracy: 0.9824 - cost: 2.2600 - val_loss: 0.1213 - val_auc: 0.9889 - val_accuracy: 0.9712 - val_cost: 3.6310\n",
            "Epoch 263/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0589 - auc: 0.9962 - accuracy: 0.9825 - cost: 2.2450 - val_loss: 0.1215 - val_auc: 0.9891 - val_accuracy: 0.9712 - val_cost: 3.5582\n",
            "Epoch 264/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0586 - auc: 0.9964 - accuracy: 0.9824 - cost: 2.2716 - val_loss: 0.1222 - val_auc: 0.9886 - val_accuracy: 0.9711 - val_cost: 3.6276\n",
            "Epoch 265/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0593 - auc: 0.9961 - accuracy: 0.9822 - cost: 2.2924 - val_loss: 0.1223 - val_auc: 0.9888 - val_accuracy: 0.9711 - val_cost: 3.6276\n",
            "Epoch 266/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0581 - auc: 0.9964 - accuracy: 0.9827 - cost: 2.2222 - val_loss: 0.1260 - val_auc: 0.9886 - val_accuracy: 0.9699 - val_cost: 3.6673\n",
            "Epoch 267/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0585 - auc: 0.9962 - accuracy: 0.9828 - cost: 2.2076 - val_loss: 0.1225 - val_auc: 0.9891 - val_accuracy: 0.9721 - val_cost: 3.4590\n",
            "Epoch 268/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0574 - auc: 0.9964 - accuracy: 0.9831 - cost: 2.1732 - val_loss: 0.1223 - val_auc: 0.9890 - val_accuracy: 0.9705 - val_cost: 3.6409\n",
            "Epoch 269/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0576 - auc: 0.9965 - accuracy: 0.9828 - cost: 2.2203 - val_loss: 0.1250 - val_auc: 0.9888 - val_accuracy: 0.9709 - val_cost: 3.5450\n",
            "Epoch 270/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0572 - auc: 0.9964 - accuracy: 0.9830 - cost: 2.1836 - val_loss: 0.1237 - val_auc: 0.9884 - val_accuracy: 0.9712 - val_cost: 3.6045\n",
            "Epoch 271/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0576 - auc: 0.9964 - accuracy: 0.9830 - cost: 2.1871 - val_loss: 0.1228 - val_auc: 0.9886 - val_accuracy: 0.9714 - val_cost: 3.5185\n",
            "Epoch 272/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0576 - auc: 0.9964 - accuracy: 0.9830 - cost: 2.1856 - val_loss: 0.1232 - val_auc: 0.9888 - val_accuracy: 0.9708 - val_cost: 3.7070\n",
            "Epoch 273/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0592 - auc: 0.9963 - accuracy: 0.9823 - cost: 2.2766 - val_loss: 0.1266 - val_auc: 0.9887 - val_accuracy: 0.9709 - val_cost: 3.6045\n",
            "Epoch 274/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0591 - auc: 0.9960 - accuracy: 0.9828 - cost: 2.2234 - val_loss: 0.1244 - val_auc: 0.9887 - val_accuracy: 0.9709 - val_cost: 3.5549\n",
            "Epoch 275/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0580 - auc: 0.9963 - accuracy: 0.9829 - cost: 2.2106 - val_loss: 0.1254 - val_auc: 0.9886 - val_accuracy: 0.9710 - val_cost: 3.5913\n",
            "Epoch 276/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0576 - auc: 0.9964 - accuracy: 0.9828 - cost: 2.2064 - val_loss: 0.1244 - val_auc: 0.9884 - val_accuracy: 0.9714 - val_cost: 3.5020\n",
            "Epoch 277/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0579 - auc: 0.9963 - accuracy: 0.9830 - cost: 2.1794 - val_loss: 0.1222 - val_auc: 0.9889 - val_accuracy: 0.9720 - val_cost: 3.4855\n",
            "Epoch 278/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0570 - auc: 0.9964 - accuracy: 0.9829 - cost: 2.1956 - val_loss: 0.1228 - val_auc: 0.9889 - val_accuracy: 0.9705 - val_cost: 3.6971\n",
            "Epoch 279/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0580 - auc: 0.9963 - accuracy: 0.9828 - cost: 2.2130 - val_loss: 0.1240 - val_auc: 0.9885 - val_accuracy: 0.9716 - val_cost: 3.5813\n",
            "Epoch 280/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0574 - auc: 0.9964 - accuracy: 0.9829 - cost: 2.1995 - val_loss: 0.1230 - val_auc: 0.9888 - val_accuracy: 0.9708 - val_cost: 3.6177\n",
            "Epoch 281/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0582 - auc: 0.9963 - accuracy: 0.9828 - cost: 2.2199 - val_loss: 0.1226 - val_auc: 0.9886 - val_accuracy: 0.9722 - val_cost: 3.4358\n",
            "Epoch 282/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0580 - auc: 0.9963 - accuracy: 0.9829 - cost: 2.2018 - val_loss: 0.1211 - val_auc: 0.9891 - val_accuracy: 0.9717 - val_cost: 3.5549\n",
            "Epoch 283/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0574 - auc: 0.9964 - accuracy: 0.9831 - cost: 2.1806 - val_loss: 0.1211 - val_auc: 0.9888 - val_accuracy: 0.9713 - val_cost: 3.6045\n",
            "Epoch 284/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0578 - auc: 0.9964 - accuracy: 0.9827 - cost: 2.2172 - val_loss: 0.1228 - val_auc: 0.9888 - val_accuracy: 0.9710 - val_cost: 3.5714\n",
            "Epoch 285/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0571 - auc: 0.9963 - accuracy: 0.9830 - cost: 2.1817 - val_loss: 0.1253 - val_auc: 0.9886 - val_accuracy: 0.9706 - val_cost: 3.6276\n",
            "Epoch 286/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0579 - auc: 0.9965 - accuracy: 0.9826 - cost: 2.2627 - val_loss: 0.1242 - val_auc: 0.9886 - val_accuracy: 0.9704 - val_cost: 3.6872\n",
            "Epoch 287/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0570 - auc: 0.9965 - accuracy: 0.9829 - cost: 2.1983 - val_loss: 0.1236 - val_auc: 0.9890 - val_accuracy: 0.9703 - val_cost: 3.6376\n",
            "Epoch 288/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0580 - auc: 0.9963 - accuracy: 0.9827 - cost: 2.2242 - val_loss: 0.1255 - val_auc: 0.9888 - val_accuracy: 0.9708 - val_cost: 3.6144\n",
            "Epoch 289/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0580 - auc: 0.9963 - accuracy: 0.9828 - cost: 2.2126 - val_loss: 0.1275 - val_auc: 0.9887 - val_accuracy: 0.9697 - val_cost: 3.7269\n",
            "Epoch 290/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0575 - auc: 0.9964 - accuracy: 0.9829 - cost: 2.2002 - val_loss: 0.1253 - val_auc: 0.9887 - val_accuracy: 0.9706 - val_cost: 3.5681\n",
            "Epoch 291/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0579 - auc: 0.9964 - accuracy: 0.9828 - cost: 2.2029 - val_loss: 0.1257 - val_auc: 0.9887 - val_accuracy: 0.9714 - val_cost: 3.5847\n",
            "Epoch 292/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0569 - auc: 0.9964 - accuracy: 0.9831 - cost: 2.1744 - val_loss: 0.1259 - val_auc: 0.9885 - val_accuracy: 0.9707 - val_cost: 3.6276\n",
            "Epoch 293/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0570 - auc: 0.9963 - accuracy: 0.9831 - cost: 2.1736 - val_loss: 0.1258 - val_auc: 0.9884 - val_accuracy: 0.9706 - val_cost: 3.6640\n",
            "Epoch 294/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0568 - auc: 0.9964 - accuracy: 0.9828 - cost: 2.2168 - val_loss: 0.1250 - val_auc: 0.9887 - val_accuracy: 0.9709 - val_cost: 3.6144\n",
            "Epoch 295/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0566 - auc: 0.9966 - accuracy: 0.9828 - cost: 2.2060 - val_loss: 0.1260 - val_auc: 0.9886 - val_accuracy: 0.9714 - val_cost: 3.5152\n",
            "Epoch 296/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0572 - auc: 0.9965 - accuracy: 0.9831 - cost: 2.1732 - val_loss: 0.1268 - val_auc: 0.9886 - val_accuracy: 0.9705 - val_cost: 3.6607\n",
            "Epoch 297/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0574 - auc: 0.9964 - accuracy: 0.9830 - cost: 2.1914 - val_loss: 0.1256 - val_auc: 0.9889 - val_accuracy: 0.9709 - val_cost: 3.6144\n",
            "Epoch 298/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0573 - auc: 0.9965 - accuracy: 0.9830 - cost: 2.1829 - val_loss: 0.1257 - val_auc: 0.9886 - val_accuracy: 0.9707 - val_cost: 3.5979\n",
            "Epoch 299/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0565 - auc: 0.9964 - accuracy: 0.9830 - cost: 2.1914 - val_loss: 0.1245 - val_auc: 0.9888 - val_accuracy: 0.9712 - val_cost: 3.5582\n",
            "Epoch 300/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0576 - auc: 0.9963 - accuracy: 0.9828 - cost: 2.2226 - val_loss: 0.1249 - val_auc: 0.9887 - val_accuracy: 0.9699 - val_cost: 3.7500\n",
            "Epoch 301/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0562 - auc: 0.9965 - accuracy: 0.9834 - cost: 2.1300 - val_loss: 0.1269 - val_auc: 0.9885 - val_accuracy: 0.9699 - val_cost: 3.8492\n",
            "Epoch 302/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0570 - auc: 0.9965 - accuracy: 0.9830 - cost: 2.1767 - val_loss: 0.1271 - val_auc: 0.9888 - val_accuracy: 0.9711 - val_cost: 3.5780\n",
            "Epoch 303/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0571 - auc: 0.9966 - accuracy: 0.9828 - cost: 2.2052 - val_loss: 0.1275 - val_auc: 0.9887 - val_accuracy: 0.9704 - val_cost: 3.7103\n",
            "Epoch 304/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0574 - auc: 0.9964 - accuracy: 0.9829 - cost: 2.1925 - val_loss: 0.1260 - val_auc: 0.9889 - val_accuracy: 0.9706 - val_cost: 3.6607\n",
            "Epoch 305/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0564 - auc: 0.9965 - accuracy: 0.9830 - cost: 2.1829 - val_loss: 0.1247 - val_auc: 0.9890 - val_accuracy: 0.9701 - val_cost: 3.7368\n",
            "Epoch 306/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0568 - auc: 0.9964 - accuracy: 0.9832 - cost: 2.1620 - val_loss: 0.1269 - val_auc: 0.9888 - val_accuracy: 0.9715 - val_cost: 3.5648\n",
            "Epoch 307/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0569 - auc: 0.9965 - accuracy: 0.9834 - cost: 2.1308 - val_loss: 0.1276 - val_auc: 0.9886 - val_accuracy: 0.9711 - val_cost: 3.6806\n",
            "Epoch 308/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0577 - auc: 0.9964 - accuracy: 0.9832 - cost: 2.1682 - val_loss: 0.1237 - val_auc: 0.9886 - val_accuracy: 0.9712 - val_cost: 3.6045\n",
            "Epoch 309/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0559 - auc: 0.9965 - accuracy: 0.9831 - cost: 2.1717 - val_loss: 0.1266 - val_auc: 0.9887 - val_accuracy: 0.9712 - val_cost: 3.5847\n",
            "Epoch 310/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0557 - auc: 0.9965 - accuracy: 0.9834 - cost: 2.1377 - val_loss: 0.1243 - val_auc: 0.9888 - val_accuracy: 0.9708 - val_cost: 3.7500\n",
            "Epoch 311/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0566 - auc: 0.9965 - accuracy: 0.9831 - cost: 2.1725 - val_loss: 0.1279 - val_auc: 0.9886 - val_accuracy: 0.9709 - val_cost: 3.5119\n",
            "Epoch 312/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0566 - auc: 0.9966 - accuracy: 0.9831 - cost: 2.1674 - val_loss: 0.1254 - val_auc: 0.9889 - val_accuracy: 0.9712 - val_cost: 3.6409\n",
            "Epoch 313/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0560 - auc: 0.9966 - accuracy: 0.9833 - cost: 2.1470 - val_loss: 0.1273 - val_auc: 0.9886 - val_accuracy: 0.9708 - val_cost: 3.6640\n",
            "Epoch 314/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0570 - auc: 0.9964 - accuracy: 0.9830 - cost: 2.1910 - val_loss: 0.1263 - val_auc: 0.9891 - val_accuracy: 0.9709 - val_cost: 3.5979\n",
            "Epoch 315/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0560 - auc: 0.9966 - accuracy: 0.9833 - cost: 2.1478 - val_loss: 0.1261 - val_auc: 0.9890 - val_accuracy: 0.9714 - val_cost: 3.5483\n",
            "Epoch 316/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0567 - auc: 0.9965 - accuracy: 0.9833 - cost: 2.1508 - val_loss: 0.1254 - val_auc: 0.9888 - val_accuracy: 0.9710 - val_cost: 3.6772\n",
            "Epoch 317/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0558 - auc: 0.9965 - accuracy: 0.9835 - cost: 2.1188 - val_loss: 0.1268 - val_auc: 0.9887 - val_accuracy: 0.9706 - val_cost: 3.7037\n",
            "Epoch 318/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0565 - auc: 0.9965 - accuracy: 0.9832 - cost: 2.1659 - val_loss: 0.1246 - val_auc: 0.9884 - val_accuracy: 0.9708 - val_cost: 3.6806\n",
            "Epoch 319/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0558 - auc: 0.9967 - accuracy: 0.9833 - cost: 2.1547 - val_loss: 0.1289 - val_auc: 0.9885 - val_accuracy: 0.9704 - val_cost: 3.6640\n",
            "Epoch 320/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0564 - auc: 0.9966 - accuracy: 0.9833 - cost: 2.1532 - val_loss: 0.1262 - val_auc: 0.9888 - val_accuracy: 0.9705 - val_cost: 3.6376\n",
            "Epoch 321/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0568 - auc: 0.9965 - accuracy: 0.9832 - cost: 2.1647 - val_loss: 0.1259 - val_auc: 0.9890 - val_accuracy: 0.9706 - val_cost: 3.7269\n",
            "Epoch 322/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0557 - auc: 0.9966 - accuracy: 0.9833 - cost: 2.1516 - val_loss: 0.1264 - val_auc: 0.9888 - val_accuracy: 0.9708 - val_cost: 3.6508\n",
            "Epoch 323/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0565 - auc: 0.9965 - accuracy: 0.9832 - cost: 2.1717 - val_loss: 0.1277 - val_auc: 0.9889 - val_accuracy: 0.9717 - val_cost: 3.5384\n",
            "Epoch 324/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0561 - auc: 0.9967 - accuracy: 0.9828 - cost: 2.2172 - val_loss: 0.1272 - val_auc: 0.9886 - val_accuracy: 0.9708 - val_cost: 3.6343\n",
            "Epoch 325/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0557 - auc: 0.9966 - accuracy: 0.9834 - cost: 2.1331 - val_loss: 0.1275 - val_auc: 0.9886 - val_accuracy: 0.9704 - val_cost: 3.6343\n",
            "Epoch 326/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0567 - auc: 0.9966 - accuracy: 0.9827 - cost: 2.2342 - val_loss: 0.1268 - val_auc: 0.9885 - val_accuracy: 0.9713 - val_cost: 3.5648\n",
            "Epoch 327/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0558 - auc: 0.9965 - accuracy: 0.9834 - cost: 2.1296 - val_loss: 0.1284 - val_auc: 0.9884 - val_accuracy: 0.9703 - val_cost: 3.7037\n",
            "Epoch 328/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0561 - auc: 0.9966 - accuracy: 0.9834 - cost: 2.1404 - val_loss: 0.1272 - val_auc: 0.9885 - val_accuracy: 0.9708 - val_cost: 3.7169\n",
            "Epoch 329/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0559 - auc: 0.9966 - accuracy: 0.9831 - cost: 2.1755 - val_loss: 0.1300 - val_auc: 0.9884 - val_accuracy: 0.9712 - val_cost: 3.4524\n",
            "Epoch 330/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0557 - auc: 0.9966 - accuracy: 0.9832 - cost: 2.1667 - val_loss: 0.1286 - val_auc: 0.9886 - val_accuracy: 0.9715 - val_cost: 3.5714\n",
            "Epoch 331/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0560 - auc: 0.9966 - accuracy: 0.9834 - cost: 2.1300 - val_loss: 0.1270 - val_auc: 0.9882 - val_accuracy: 0.9700 - val_cost: 3.8029\n",
            "Epoch 332/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0560 - auc: 0.9966 - accuracy: 0.9831 - cost: 2.1821 - val_loss: 0.1287 - val_auc: 0.9886 - val_accuracy: 0.9701 - val_cost: 3.7136\n",
            "Epoch 333/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0562 - auc: 0.9965 - accuracy: 0.9829 - cost: 2.2025 - val_loss: 0.1275 - val_auc: 0.9885 - val_accuracy: 0.9706 - val_cost: 3.6706\n",
            "Epoch 334/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0553 - auc: 0.9966 - accuracy: 0.9836 - cost: 2.1030 - val_loss: 0.1282 - val_auc: 0.9887 - val_accuracy: 0.9709 - val_cost: 3.5813\n",
            "Epoch 335/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0560 - auc: 0.9966 - accuracy: 0.9833 - cost: 2.1582 - val_loss: 0.1316 - val_auc: 0.9882 - val_accuracy: 0.9697 - val_cost: 3.6905\n",
            "Epoch 336/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0549 - auc: 0.9966 - accuracy: 0.9833 - cost: 2.1617 - val_loss: 0.1307 - val_auc: 0.9886 - val_accuracy: 0.9697 - val_cost: 3.7269\n",
            "Epoch 337/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0554 - auc: 0.9966 - accuracy: 0.9838 - cost: 2.0941 - val_loss: 0.1288 - val_auc: 0.9885 - val_accuracy: 0.9699 - val_cost: 3.7831\n",
            "Epoch 338/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0559 - auc: 0.9966 - accuracy: 0.9835 - cost: 2.1304 - val_loss: 0.1291 - val_auc: 0.9884 - val_accuracy: 0.9703 - val_cost: 3.6971\n",
            "Epoch 339/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0554 - auc: 0.9966 - accuracy: 0.9831 - cost: 2.1620 - val_loss: 0.1286 - val_auc: 0.9885 - val_accuracy: 0.9706 - val_cost: 3.7169\n",
            "Epoch 340/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0555 - auc: 0.9966 - accuracy: 0.9834 - cost: 2.1389 - val_loss: 0.1275 - val_auc: 0.9885 - val_accuracy: 0.9702 - val_cost: 3.7434\n",
            "Epoch 341/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0556 - auc: 0.9967 - accuracy: 0.9832 - cost: 2.1609 - val_loss: 0.1280 - val_auc: 0.9883 - val_accuracy: 0.9706 - val_cost: 3.7533\n",
            "Epoch 342/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0551 - auc: 0.9967 - accuracy: 0.9831 - cost: 2.1755 - val_loss: 0.1286 - val_auc: 0.9887 - val_accuracy: 0.9714 - val_cost: 3.5747\n",
            "Epoch 343/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0562 - auc: 0.9966 - accuracy: 0.9827 - cost: 2.2299 - val_loss: 0.1292 - val_auc: 0.9885 - val_accuracy: 0.9708 - val_cost: 3.6574\n",
            "Epoch 344/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0555 - auc: 0.9968 - accuracy: 0.9832 - cost: 2.1586 - val_loss: 0.1273 - val_auc: 0.9887 - val_accuracy: 0.9710 - val_cost: 3.6078\n",
            "Epoch 345/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0557 - auc: 0.9966 - accuracy: 0.9832 - cost: 2.1644 - val_loss: 0.1288 - val_auc: 0.9887 - val_accuracy: 0.9708 - val_cost: 3.5946\n",
            "Epoch 346/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0556 - auc: 0.9966 - accuracy: 0.9833 - cost: 2.1520 - val_loss: 0.1294 - val_auc: 0.9885 - val_accuracy: 0.9710 - val_cost: 3.5714\n",
            "Epoch 347/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0552 - auc: 0.9967 - accuracy: 0.9831 - cost: 2.1732 - val_loss: 0.1284 - val_auc: 0.9888 - val_accuracy: 0.9706 - val_cost: 3.7269\n",
            "Epoch 348/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0558 - auc: 0.9965 - accuracy: 0.9836 - cost: 2.1061 - val_loss: 0.1283 - val_auc: 0.9886 - val_accuracy: 0.9699 - val_cost: 3.7930\n",
            "Epoch 349/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0558 - auc: 0.9967 - accuracy: 0.9833 - cost: 2.1563 - val_loss: 0.1266 - val_auc: 0.9885 - val_accuracy: 0.9708 - val_cost: 3.6541\n",
            "Epoch 350/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0550 - auc: 0.9967 - accuracy: 0.9834 - cost: 2.1327 - val_loss: 0.1305 - val_auc: 0.9885 - val_accuracy: 0.9693 - val_cost: 3.7798\n",
            "Epoch 351/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0556 - auc: 0.9967 - accuracy: 0.9831 - cost: 2.1709 - val_loss: 0.1308 - val_auc: 0.9882 - val_accuracy: 0.9701 - val_cost: 3.8095\n",
            "Epoch 352/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0554 - auc: 0.9966 - accuracy: 0.9833 - cost: 2.1454 - val_loss: 0.1324 - val_auc: 0.9879 - val_accuracy: 0.9694 - val_cost: 3.7632\n",
            "Epoch 353/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0559 - auc: 0.9965 - accuracy: 0.9835 - cost: 2.1154 - val_loss: 0.1296 - val_auc: 0.9887 - val_accuracy: 0.9700 - val_cost: 3.7235\n",
            "Epoch 354/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0553 - auc: 0.9967 - accuracy: 0.9834 - cost: 2.1458 - val_loss: 0.1332 - val_auc: 0.9879 - val_accuracy: 0.9708 - val_cost: 3.5946\n",
            "Epoch 355/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0562 - auc: 0.9965 - accuracy: 0.9827 - cost: 2.2245 - val_loss: 0.1311 - val_auc: 0.9882 - val_accuracy: 0.9704 - val_cost: 3.7566\n",
            "Epoch 356/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0552 - auc: 0.9967 - accuracy: 0.9835 - cost: 2.1327 - val_loss: 0.1307 - val_auc: 0.9884 - val_accuracy: 0.9710 - val_cost: 3.7004\n",
            "Epoch 357/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0550 - auc: 0.9966 - accuracy: 0.9835 - cost: 2.1300 - val_loss: 0.1305 - val_auc: 0.9885 - val_accuracy: 0.9713 - val_cost: 3.5780\n",
            "Epoch 358/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0557 - auc: 0.9966 - accuracy: 0.9834 - cost: 2.1350 - val_loss: 0.1292 - val_auc: 0.9883 - val_accuracy: 0.9709 - val_cost: 3.6508\n",
            "Epoch 359/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0564 - auc: 0.9965 - accuracy: 0.9831 - cost: 2.1748 - val_loss: 0.1298 - val_auc: 0.9885 - val_accuracy: 0.9699 - val_cost: 3.8261\n",
            "Epoch 360/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0547 - auc: 0.9968 - accuracy: 0.9838 - cost: 2.0907 - val_loss: 0.1318 - val_auc: 0.9885 - val_accuracy: 0.9709 - val_cost: 3.6243\n",
            "Epoch 361/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0551 - auc: 0.9967 - accuracy: 0.9831 - cost: 2.1833 - val_loss: 0.1317 - val_auc: 0.9883 - val_accuracy: 0.9708 - val_cost: 3.6442\n",
            "Epoch 362/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0553 - auc: 0.9968 - accuracy: 0.9829 - cost: 2.1995 - val_loss: 0.1291 - val_auc: 0.9887 - val_accuracy: 0.9702 - val_cost: 3.8393\n",
            "Epoch 363/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0542 - auc: 0.9968 - accuracy: 0.9837 - cost: 2.0953 - val_loss: 0.1297 - val_auc: 0.9885 - val_accuracy: 0.9703 - val_cost: 3.6872\n",
            "Epoch 364/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0555 - auc: 0.9966 - accuracy: 0.9831 - cost: 2.1709 - val_loss: 0.1302 - val_auc: 0.9887 - val_accuracy: 0.9707 - val_cost: 3.6772\n",
            "Epoch 365/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0553 - auc: 0.9966 - accuracy: 0.9833 - cost: 2.1590 - val_loss: 0.1290 - val_auc: 0.9889 - val_accuracy: 0.9715 - val_cost: 3.5251\n",
            "Epoch 366/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0553 - auc: 0.9967 - accuracy: 0.9833 - cost: 2.1431 - val_loss: 0.1302 - val_auc: 0.9884 - val_accuracy: 0.9711 - val_cost: 3.6409\n",
            "Epoch 367/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0554 - auc: 0.9967 - accuracy: 0.9833 - cost: 2.1617 - val_loss: 0.1301 - val_auc: 0.9886 - val_accuracy: 0.9691 - val_cost: 3.8228\n",
            "Epoch 368/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0548 - auc: 0.9967 - accuracy: 0.9834 - cost: 2.1265 - val_loss: 0.1328 - val_auc: 0.9880 - val_accuracy: 0.9703 - val_cost: 3.7533\n",
            "Epoch 369/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0559 - auc: 0.9965 - accuracy: 0.9832 - cost: 2.1562 - val_loss: 0.1305 - val_auc: 0.9883 - val_accuracy: 0.9701 - val_cost: 3.8261\n",
            "Epoch 370/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0545 - auc: 0.9968 - accuracy: 0.9836 - cost: 2.1111 - val_loss: 0.1309 - val_auc: 0.9884 - val_accuracy: 0.9704 - val_cost: 3.6839\n",
            "Epoch 371/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0548 - auc: 0.9966 - accuracy: 0.9833 - cost: 2.1601 - val_loss: 0.1330 - val_auc: 0.9884 - val_accuracy: 0.9693 - val_cost: 3.8393\n",
            "Epoch 372/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0548 - auc: 0.9967 - accuracy: 0.9835 - cost: 2.1184 - val_loss: 0.1309 - val_auc: 0.9884 - val_accuracy: 0.9705 - val_cost: 3.7632\n",
            "Epoch 373/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0547 - auc: 0.9967 - accuracy: 0.9835 - cost: 2.1331 - val_loss: 0.1312 - val_auc: 0.9884 - val_accuracy: 0.9699 - val_cost: 3.7765\n",
            "Epoch 374/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0544 - auc: 0.9967 - accuracy: 0.9835 - cost: 2.1196 - val_loss: 0.1297 - val_auc: 0.9885 - val_accuracy: 0.9701 - val_cost: 3.7731\n",
            "Epoch 375/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0547 - auc: 0.9967 - accuracy: 0.9834 - cost: 2.1381 - val_loss: 0.1319 - val_auc: 0.9882 - val_accuracy: 0.9701 - val_cost: 3.7500\n",
            "Epoch 376/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0536 - auc: 0.9968 - accuracy: 0.9839 - cost: 2.0826 - val_loss: 0.1321 - val_auc: 0.9881 - val_accuracy: 0.9715 - val_cost: 3.5913\n",
            "Epoch 377/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0550 - auc: 0.9967 - accuracy: 0.9834 - cost: 2.1346 - val_loss: 0.1295 - val_auc: 0.9887 - val_accuracy: 0.9712 - val_cost: 3.5813\n",
            "Epoch 378/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0548 - auc: 0.9968 - accuracy: 0.9836 - cost: 2.1204 - val_loss: 0.1324 - val_auc: 0.9884 - val_accuracy: 0.9702 - val_cost: 3.6706\n",
            "Epoch 379/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0550 - auc: 0.9967 - accuracy: 0.9834 - cost: 2.1431 - val_loss: 0.1296 - val_auc: 0.9885 - val_accuracy: 0.9695 - val_cost: 3.8525\n",
            "Epoch 380/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0546 - auc: 0.9967 - accuracy: 0.9838 - cost: 2.0976 - val_loss: 0.1296 - val_auc: 0.9886 - val_accuracy: 0.9694 - val_cost: 3.8988\n",
            "Epoch 381/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0552 - auc: 0.9967 - accuracy: 0.9834 - cost: 2.1343 - val_loss: 0.1303 - val_auc: 0.9885 - val_accuracy: 0.9702 - val_cost: 3.6971\n",
            "Epoch 382/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0548 - auc: 0.9967 - accuracy: 0.9836 - cost: 2.1088 - val_loss: 0.1319 - val_auc: 0.9884 - val_accuracy: 0.9699 - val_cost: 3.7930\n",
            "Epoch 383/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0549 - auc: 0.9968 - accuracy: 0.9834 - cost: 2.1385 - val_loss: 0.1311 - val_auc: 0.9881 - val_accuracy: 0.9703 - val_cost: 3.7963\n",
            "Epoch 384/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0545 - auc: 0.9967 - accuracy: 0.9840 - cost: 2.0737 - val_loss: 0.1310 - val_auc: 0.9884 - val_accuracy: 0.9701 - val_cost: 3.6971\n",
            "Epoch 385/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0533 - auc: 0.9968 - accuracy: 0.9839 - cost: 2.0822 - val_loss: 0.1278 - val_auc: 0.9887 - val_accuracy: 0.9706 - val_cost: 3.6508\n",
            "Epoch 386/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0549 - auc: 0.9967 - accuracy: 0.9838 - cost: 2.0887 - val_loss: 0.1311 - val_auc: 0.9887 - val_accuracy: 0.9708 - val_cost: 3.6574\n",
            "Epoch 387/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0551 - auc: 0.9968 - accuracy: 0.9831 - cost: 2.1790 - val_loss: 0.1323 - val_auc: 0.9886 - val_accuracy: 0.9698 - val_cost: 3.6971\n",
            "Epoch 388/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0530 - auc: 0.9969 - accuracy: 0.9839 - cost: 2.0760 - val_loss: 0.1340 - val_auc: 0.9887 - val_accuracy: 0.9698 - val_cost: 3.6938\n",
            "Epoch 389/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0535 - auc: 0.9970 - accuracy: 0.9841 - cost: 2.0478 - val_loss: 0.1312 - val_auc: 0.9883 - val_accuracy: 0.9703 - val_cost: 3.6772\n",
            "Epoch 390/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0543 - auc: 0.9967 - accuracy: 0.9835 - cost: 2.1242 - val_loss: 0.1312 - val_auc: 0.9885 - val_accuracy: 0.9715 - val_cost: 3.4954\n",
            "Epoch 391/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0547 - auc: 0.9966 - accuracy: 0.9834 - cost: 2.1366 - val_loss: 0.1327 - val_auc: 0.9885 - val_accuracy: 0.9699 - val_cost: 3.7169\n",
            "Epoch 392/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0548 - auc: 0.9967 - accuracy: 0.9836 - cost: 2.1211 - val_loss: 0.1338 - val_auc: 0.9883 - val_accuracy: 0.9701 - val_cost: 3.7004\n",
            "Epoch 393/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0549 - auc: 0.9968 - accuracy: 0.9830 - cost: 2.1952 - val_loss: 0.1320 - val_auc: 0.9888 - val_accuracy: 0.9706 - val_cost: 3.6574\n",
            "Epoch 394/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0539 - auc: 0.9968 - accuracy: 0.9839 - cost: 2.0698 - val_loss: 0.1307 - val_auc: 0.9889 - val_accuracy: 0.9707 - val_cost: 3.6541\n",
            "Epoch 395/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0542 - auc: 0.9968 - accuracy: 0.9839 - cost: 2.0775 - val_loss: 0.1294 - val_auc: 0.9883 - val_accuracy: 0.9701 - val_cost: 3.9021\n",
            "Epoch 396/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0543 - auc: 0.9968 - accuracy: 0.9839 - cost: 2.0772 - val_loss: 0.1308 - val_auc: 0.9885 - val_accuracy: 0.9706 - val_cost: 3.6739\n",
            "Epoch 397/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0527 - auc: 0.9969 - accuracy: 0.9843 - cost: 2.0231 - val_loss: 0.1323 - val_auc: 0.9885 - val_accuracy: 0.9701 - val_cost: 3.7368\n",
            "Epoch 398/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0542 - auc: 0.9966 - accuracy: 0.9841 - cost: 2.0471 - val_loss: 0.1320 - val_auc: 0.9885 - val_accuracy: 0.9694 - val_cost: 3.8558\n",
            "Epoch 399/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0543 - auc: 0.9968 - accuracy: 0.9838 - cost: 2.0992 - val_loss: 0.1345 - val_auc: 0.9878 - val_accuracy: 0.9699 - val_cost: 3.8393\n",
            "Epoch 400/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0540 - auc: 0.9968 - accuracy: 0.9836 - cost: 2.1161 - val_loss: 0.1348 - val_auc: 0.9880 - val_accuracy: 0.9697 - val_cost: 3.7798\n",
            "Epoch 401/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0541 - auc: 0.9969 - accuracy: 0.9838 - cost: 2.0914 - val_loss: 0.1322 - val_auc: 0.9883 - val_accuracy: 0.9711 - val_cost: 3.5648\n",
            "Epoch 402/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0540 - auc: 0.9967 - accuracy: 0.9835 - cost: 2.1265 - val_loss: 0.1319 - val_auc: 0.9882 - val_accuracy: 0.9694 - val_cost: 3.7566\n",
            "Epoch 403/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0538 - auc: 0.9968 - accuracy: 0.9837 - cost: 2.0992 - val_loss: 0.1325 - val_auc: 0.9884 - val_accuracy: 0.9699 - val_cost: 3.8128\n",
            "Epoch 404/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0536 - auc: 0.9968 - accuracy: 0.9840 - cost: 2.0652 - val_loss: 0.1325 - val_auc: 0.9884 - val_accuracy: 0.9701 - val_cost: 3.7963\n",
            "Epoch 405/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0537 - auc: 0.9968 - accuracy: 0.9839 - cost: 2.0702 - val_loss: 0.1330 - val_auc: 0.9881 - val_accuracy: 0.9706 - val_cost: 3.6409\n",
            "Epoch 406/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0534 - auc: 0.9969 - accuracy: 0.9838 - cost: 2.0984 - val_loss: 0.1335 - val_auc: 0.9881 - val_accuracy: 0.9691 - val_cost: 3.8657\n",
            "Epoch 407/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0539 - auc: 0.9967 - accuracy: 0.9840 - cost: 2.0648 - val_loss: 0.1327 - val_auc: 0.9880 - val_accuracy: 0.9692 - val_cost: 3.9021\n",
            "Epoch 408/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0548 - auc: 0.9968 - accuracy: 0.9834 - cost: 2.1366 - val_loss: 0.1313 - val_auc: 0.9887 - val_accuracy: 0.9706 - val_cost: 3.7037\n",
            "Epoch 409/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0541 - auc: 0.9967 - accuracy: 0.9840 - cost: 2.0698 - val_loss: 0.1325 - val_auc: 0.9885 - val_accuracy: 0.9702 - val_cost: 3.6706\n",
            "Epoch 410/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0541 - auc: 0.9967 - accuracy: 0.9838 - cost: 2.1019 - val_loss: 0.1329 - val_auc: 0.9887 - val_accuracy: 0.9697 - val_cost: 3.7632\n",
            "Epoch 411/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0544 - auc: 0.9967 - accuracy: 0.9837 - cost: 2.0999 - val_loss: 0.1340 - val_auc: 0.9885 - val_accuracy: 0.9702 - val_cost: 3.6905\n",
            "Epoch 412/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0538 - auc: 0.9968 - accuracy: 0.9836 - cost: 2.1161 - val_loss: 0.1341 - val_auc: 0.9881 - val_accuracy: 0.9705 - val_cost: 3.6640\n",
            "Epoch 413/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0539 - auc: 0.9969 - accuracy: 0.9838 - cost: 2.0918 - val_loss: 0.1339 - val_auc: 0.9879 - val_accuracy: 0.9693 - val_cost: 3.8228\n",
            "Epoch 414/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0544 - auc: 0.9968 - accuracy: 0.9836 - cost: 2.1065 - val_loss: 0.1327 - val_auc: 0.9880 - val_accuracy: 0.9708 - val_cost: 3.6276\n",
            "Epoch 415/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0545 - auc: 0.9969 - accuracy: 0.9832 - cost: 2.1674 - val_loss: 0.1342 - val_auc: 0.9880 - val_accuracy: 0.9703 - val_cost: 3.6310\n",
            "Epoch 416/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0541 - auc: 0.9968 - accuracy: 0.9839 - cost: 2.0664 - val_loss: 0.1327 - val_auc: 0.9884 - val_accuracy: 0.9708 - val_cost: 3.5582\n",
            "Epoch 417/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0543 - auc: 0.9967 - accuracy: 0.9839 - cost: 2.0775 - val_loss: 0.1322 - val_auc: 0.9877 - val_accuracy: 0.9701 - val_cost: 3.7202\n",
            "Epoch 418/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0537 - auc: 0.9968 - accuracy: 0.9836 - cost: 2.1073 - val_loss: 0.1360 - val_auc: 0.9881 - val_accuracy: 0.9708 - val_cost: 3.5384\n",
            "Epoch 419/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0554 - auc: 0.9967 - accuracy: 0.9832 - cost: 2.1636 - val_loss: 0.1330 - val_auc: 0.9885 - val_accuracy: 0.9703 - val_cost: 3.6872\n",
            "Epoch 420/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0534 - auc: 0.9969 - accuracy: 0.9837 - cost: 2.1007 - val_loss: 0.1355 - val_auc: 0.9881 - val_accuracy: 0.9699 - val_cost: 3.7269\n",
            "Epoch 421/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0529 - auc: 0.9969 - accuracy: 0.9837 - cost: 2.0949 - val_loss: 0.1365 - val_auc: 0.9881 - val_accuracy: 0.9701 - val_cost: 3.7269\n",
            "Epoch 422/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0535 - auc: 0.9969 - accuracy: 0.9836 - cost: 2.1254 - val_loss: 0.1330 - val_auc: 0.9887 - val_accuracy: 0.9702 - val_cost: 3.7202\n",
            "Epoch 423/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0540 - auc: 0.9968 - accuracy: 0.9838 - cost: 2.0953 - val_loss: 0.1329 - val_auc: 0.9886 - val_accuracy: 0.9709 - val_cost: 3.6012\n",
            "Epoch 424/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0537 - auc: 0.9968 - accuracy: 0.9838 - cost: 2.0841 - val_loss: 0.1337 - val_auc: 0.9883 - val_accuracy: 0.9695 - val_cost: 3.8657\n",
            "Epoch 425/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0537 - auc: 0.9969 - accuracy: 0.9836 - cost: 2.1096 - val_loss: 0.1334 - val_auc: 0.9878 - val_accuracy: 0.9690 - val_cost: 3.9749\n",
            "Epoch 426/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0538 - auc: 0.9968 - accuracy: 0.9838 - cost: 2.0930 - val_loss: 0.1351 - val_auc: 0.9883 - val_accuracy: 0.9699 - val_cost: 3.6673\n",
            "Epoch 427/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0536 - auc: 0.9968 - accuracy: 0.9838 - cost: 2.0918 - val_loss: 0.1354 - val_auc: 0.9879 - val_accuracy: 0.9693 - val_cost: 3.9054\n",
            "Epoch 428/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0538 - auc: 0.9968 - accuracy: 0.9837 - cost: 2.1076 - val_loss: 0.1329 - val_auc: 0.9881 - val_accuracy: 0.9705 - val_cost: 3.7897\n",
            "Epoch 429/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0545 - auc: 0.9969 - accuracy: 0.9837 - cost: 2.1053 - val_loss: 0.1347 - val_auc: 0.9885 - val_accuracy: 0.9695 - val_cost: 3.7731\n",
            "Epoch 430/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0524 - auc: 0.9970 - accuracy: 0.9839 - cost: 2.0760 - val_loss: 0.1325 - val_auc: 0.9880 - val_accuracy: 0.9696 - val_cost: 3.8393\n",
            "Epoch 431/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0532 - auc: 0.9969 - accuracy: 0.9843 - cost: 2.0309 - val_loss: 0.1366 - val_auc: 0.9879 - val_accuracy: 0.9695 - val_cost: 3.8095\n",
            "Epoch 432/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0541 - auc: 0.9968 - accuracy: 0.9835 - cost: 2.1381 - val_loss: 0.1351 - val_auc: 0.9886 - val_accuracy: 0.9706 - val_cost: 3.6839\n",
            "Epoch 433/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0540 - auc: 0.9968 - accuracy: 0.9836 - cost: 2.1146 - val_loss: 0.1350 - val_auc: 0.9882 - val_accuracy: 0.9699 - val_cost: 3.7897\n",
            "Epoch 434/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0535 - auc: 0.9969 - accuracy: 0.9837 - cost: 2.0941 - val_loss: 0.1323 - val_auc: 0.9883 - val_accuracy: 0.9698 - val_cost: 3.7864\n",
            "Epoch 435/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0537 - auc: 0.9969 - accuracy: 0.9839 - cost: 2.0752 - val_loss: 0.1336 - val_auc: 0.9881 - val_accuracy: 0.9697 - val_cost: 3.8095\n",
            "Epoch 436/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0531 - auc: 0.9969 - accuracy: 0.9837 - cost: 2.0961 - val_loss: 0.1356 - val_auc: 0.9884 - val_accuracy: 0.9696 - val_cost: 3.7930\n",
            "Epoch 437/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0537 - auc: 0.9969 - accuracy: 0.9838 - cost: 2.0853 - val_loss: 0.1326 - val_auc: 0.9886 - val_accuracy: 0.9709 - val_cost: 3.6276\n",
            "Epoch 438/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0527 - auc: 0.9970 - accuracy: 0.9839 - cost: 2.0667 - val_loss: 0.1357 - val_auc: 0.9880 - val_accuracy: 0.9693 - val_cost: 3.8757\n",
            "Epoch 439/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0520 - auc: 0.9970 - accuracy: 0.9838 - cost: 2.0980 - val_loss: 0.1367 - val_auc: 0.9882 - val_accuracy: 0.9701 - val_cost: 3.7037\n",
            "Epoch 440/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0534 - auc: 0.9969 - accuracy: 0.9840 - cost: 2.0671 - val_loss: 0.1369 - val_auc: 0.9879 - val_accuracy: 0.9713 - val_cost: 3.5946\n",
            "Epoch 441/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0530 - auc: 0.9969 - accuracy: 0.9839 - cost: 2.0768 - val_loss: 0.1368 - val_auc: 0.9878 - val_accuracy: 0.9700 - val_cost: 3.7202\n",
            "Epoch 442/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0531 - auc: 0.9968 - accuracy: 0.9841 - cost: 2.0540 - val_loss: 0.1332 - val_auc: 0.9883 - val_accuracy: 0.9708 - val_cost: 3.6541\n",
            "Epoch 443/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0535 - auc: 0.9969 - accuracy: 0.9841 - cost: 2.0544 - val_loss: 0.1351 - val_auc: 0.9884 - val_accuracy: 0.9698 - val_cost: 3.7698\n",
            "Epoch 444/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0533 - auc: 0.9968 - accuracy: 0.9839 - cost: 2.0687 - val_loss: 0.1345 - val_auc: 0.9883 - val_accuracy: 0.9694 - val_cost: 3.8525\n",
            "Epoch 445/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0526 - auc: 0.9970 - accuracy: 0.9847 - cost: 1.9757 - val_loss: 0.1348 - val_auc: 0.9879 - val_accuracy: 0.9697 - val_cost: 3.7765\n",
            "Epoch 446/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0534 - auc: 0.9969 - accuracy: 0.9833 - cost: 2.1505 - val_loss: 0.1360 - val_auc: 0.9875 - val_accuracy: 0.9692 - val_cost: 3.8228\n",
            "Epoch 447/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0524 - auc: 0.9970 - accuracy: 0.9839 - cost: 2.0721 - val_loss: 0.1365 - val_auc: 0.9880 - val_accuracy: 0.9694 - val_cost: 3.8261\n",
            "Epoch 448/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0527 - auc: 0.9969 - accuracy: 0.9841 - cost: 2.0640 - val_loss: 0.1361 - val_auc: 0.9878 - val_accuracy: 0.9692 - val_cost: 3.8194\n",
            "Epoch 449/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0522 - auc: 0.9970 - accuracy: 0.9842 - cost: 2.0382 - val_loss: 0.1351 - val_auc: 0.9880 - val_accuracy: 0.9701 - val_cost: 3.7831\n",
            "Epoch 450/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0526 - auc: 0.9970 - accuracy: 0.9845 - cost: 2.0108 - val_loss: 0.1351 - val_auc: 0.9882 - val_accuracy: 0.9703 - val_cost: 3.6607\n",
            "Epoch 451/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0526 - auc: 0.9971 - accuracy: 0.9843 - cost: 2.0336 - val_loss: 0.1369 - val_auc: 0.9878 - val_accuracy: 0.9688 - val_cost: 3.8724\n",
            "Epoch 452/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0537 - auc: 0.9969 - accuracy: 0.9837 - cost: 2.0988 - val_loss: 0.1377 - val_auc: 0.9881 - val_accuracy: 0.9696 - val_cost: 3.7963\n",
            "Epoch 453/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0529 - auc: 0.9970 - accuracy: 0.9837 - cost: 2.0992 - val_loss: 0.1397 - val_auc: 0.9882 - val_accuracy: 0.9697 - val_cost: 3.7235\n",
            "Epoch 454/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0533 - auc: 0.9968 - accuracy: 0.9839 - cost: 2.0772 - val_loss: 0.1391 - val_auc: 0.9875 - val_accuracy: 0.9692 - val_cost: 3.8294\n",
            "Epoch 455/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0530 - auc: 0.9969 - accuracy: 0.9840 - cost: 2.0637 - val_loss: 0.1380 - val_auc: 0.9880 - val_accuracy: 0.9694 - val_cost: 3.8327\n",
            "Epoch 456/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0531 - auc: 0.9969 - accuracy: 0.9841 - cost: 2.0563 - val_loss: 0.1371 - val_auc: 0.9881 - val_accuracy: 0.9701 - val_cost: 3.7037\n",
            "Epoch 457/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0530 - auc: 0.9969 - accuracy: 0.9840 - cost: 2.0748 - val_loss: 0.1374 - val_auc: 0.9879 - val_accuracy: 0.9701 - val_cost: 3.6574\n",
            "Epoch 458/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0529 - auc: 0.9969 - accuracy: 0.9836 - cost: 2.1073 - val_loss: 0.1351 - val_auc: 0.9879 - val_accuracy: 0.9710 - val_cost: 3.5714\n",
            "Epoch 459/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0523 - auc: 0.9970 - accuracy: 0.9834 - cost: 2.1300 - val_loss: 0.1369 - val_auc: 0.9877 - val_accuracy: 0.9696 - val_cost: 3.7335\n",
            "Epoch 460/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0532 - auc: 0.9969 - accuracy: 0.9840 - cost: 2.0513 - val_loss: 0.1358 - val_auc: 0.9879 - val_accuracy: 0.9697 - val_cost: 3.6938\n",
            "Epoch 461/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0521 - auc: 0.9970 - accuracy: 0.9842 - cost: 2.0312 - val_loss: 0.1385 - val_auc: 0.9879 - val_accuracy: 0.9697 - val_cost: 3.7533\n",
            "Epoch 462/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0534 - auc: 0.9969 - accuracy: 0.9838 - cost: 2.1011 - val_loss: 0.1364 - val_auc: 0.9882 - val_accuracy: 0.9708 - val_cost: 3.6177\n",
            "Epoch 463/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0526 - auc: 0.9969 - accuracy: 0.9839 - cost: 2.0687 - val_loss: 0.1351 - val_auc: 0.9880 - val_accuracy: 0.9693 - val_cost: 3.8294\n",
            "Epoch 464/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0533 - auc: 0.9970 - accuracy: 0.9839 - cost: 2.0787 - val_loss: 0.1363 - val_auc: 0.9880 - val_accuracy: 0.9706 - val_cost: 3.7798\n",
            "Epoch 465/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0521 - auc: 0.9970 - accuracy: 0.9840 - cost: 2.0617 - val_loss: 0.1368 - val_auc: 0.9879 - val_accuracy: 0.9703 - val_cost: 3.6839\n",
            "Epoch 466/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0527 - auc: 0.9970 - accuracy: 0.9840 - cost: 2.0660 - val_loss: 0.1374 - val_auc: 0.9879 - val_accuracy: 0.9706 - val_cost: 3.7037\n",
            "Epoch 467/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0528 - auc: 0.9969 - accuracy: 0.9842 - cost: 2.0390 - val_loss: 0.1375 - val_auc: 0.9880 - val_accuracy: 0.9708 - val_cost: 3.6442\n",
            "Epoch 468/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0530 - auc: 0.9970 - accuracy: 0.9841 - cost: 2.0660 - val_loss: 0.1388 - val_auc: 0.9880 - val_accuracy: 0.9701 - val_cost: 3.6905\n",
            "Epoch 469/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0528 - auc: 0.9970 - accuracy: 0.9838 - cost: 2.0860 - val_loss: 0.1368 - val_auc: 0.9880 - val_accuracy: 0.9702 - val_cost: 3.6872\n",
            "Epoch 470/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0527 - auc: 0.9970 - accuracy: 0.9844 - cost: 2.0208 - val_loss: 0.1382 - val_auc: 0.9880 - val_accuracy: 0.9701 - val_cost: 3.7599\n",
            "Epoch 471/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0533 - auc: 0.9969 - accuracy: 0.9837 - cost: 2.0988 - val_loss: 0.1376 - val_auc: 0.9877 - val_accuracy: 0.9699 - val_cost: 3.7401\n",
            "Epoch 472/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0529 - auc: 0.9969 - accuracy: 0.9842 - cost: 2.0355 - val_loss: 0.1363 - val_auc: 0.9877 - val_accuracy: 0.9694 - val_cost: 3.8823\n",
            "Epoch 473/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0514 - auc: 0.9971 - accuracy: 0.9843 - cost: 2.0243 - val_loss: 0.1359 - val_auc: 0.9879 - val_accuracy: 0.9697 - val_cost: 3.7963\n",
            "Epoch 474/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0527 - auc: 0.9969 - accuracy: 0.9836 - cost: 2.1119 - val_loss: 0.1367 - val_auc: 0.9882 - val_accuracy: 0.9704 - val_cost: 3.7169\n",
            "Epoch 475/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0526 - auc: 0.9970 - accuracy: 0.9841 - cost: 2.0498 - val_loss: 0.1392 - val_auc: 0.9876 - val_accuracy: 0.9688 - val_cost: 3.8856\n",
            "Epoch 476/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0531 - auc: 0.9970 - accuracy: 0.9840 - cost: 2.0594 - val_loss: 0.1382 - val_auc: 0.9875 - val_accuracy: 0.9704 - val_cost: 3.7302\n",
            "Epoch 477/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0531 - auc: 0.9969 - accuracy: 0.9841 - cost: 2.0463 - val_loss: 0.1382 - val_auc: 0.9878 - val_accuracy: 0.9701 - val_cost: 3.7665\n",
            "Epoch 478/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0525 - auc: 0.9970 - accuracy: 0.9841 - cost: 2.0475 - val_loss: 0.1368 - val_auc: 0.9883 - val_accuracy: 0.9699 - val_cost: 3.7037\n",
            "Epoch 479/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0515 - auc: 0.9971 - accuracy: 0.9843 - cost: 2.0270 - val_loss: 0.1395 - val_auc: 0.9878 - val_accuracy: 0.9705 - val_cost: 3.7302\n",
            "Epoch 480/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0525 - auc: 0.9970 - accuracy: 0.9841 - cost: 2.0509 - val_loss: 0.1389 - val_auc: 0.9880 - val_accuracy: 0.9695 - val_cost: 3.7831\n",
            "Epoch 481/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0517 - auc: 0.9970 - accuracy: 0.9843 - cost: 2.0104 - val_loss: 0.1374 - val_auc: 0.9879 - val_accuracy: 0.9687 - val_cost: 4.0013\n",
            "Epoch 482/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0526 - auc: 0.9971 - accuracy: 0.9842 - cost: 2.0444 - val_loss: 0.1374 - val_auc: 0.9879 - val_accuracy: 0.9690 - val_cost: 3.9187\n",
            "Epoch 483/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0509 - auc: 0.9971 - accuracy: 0.9848 - cost: 1.9718 - val_loss: 0.1392 - val_auc: 0.9878 - val_accuracy: 0.9694 - val_cost: 3.8327\n",
            "Epoch 484/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0529 - auc: 0.9969 - accuracy: 0.9840 - cost: 2.0640 - val_loss: 0.1390 - val_auc: 0.9877 - val_accuracy: 0.9699 - val_cost: 3.6971\n",
            "Epoch 485/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0516 - auc: 0.9971 - accuracy: 0.9843 - cost: 2.0297 - val_loss: 0.1386 - val_auc: 0.9877 - val_accuracy: 0.9699 - val_cost: 3.7202\n",
            "Epoch 486/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0515 - auc: 0.9971 - accuracy: 0.9843 - cost: 2.0313 - val_loss: 0.1429 - val_auc: 0.9878 - val_accuracy: 0.9693 - val_cost: 3.6938\n",
            "Epoch 487/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0521 - auc: 0.9970 - accuracy: 0.9840 - cost: 2.0683 - val_loss: 0.1411 - val_auc: 0.9874 - val_accuracy: 0.9695 - val_cost: 3.7434\n",
            "Epoch 488/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0529 - auc: 0.9970 - accuracy: 0.9839 - cost: 2.0829 - val_loss: 0.1385 - val_auc: 0.9877 - val_accuracy: 0.9697 - val_cost: 3.7731\n",
            "Epoch 489/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0516 - auc: 0.9971 - accuracy: 0.9846 - cost: 1.9823 - val_loss: 0.1391 - val_auc: 0.9873 - val_accuracy: 0.9691 - val_cost: 3.8724\n",
            "Epoch 490/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0533 - auc: 0.9969 - accuracy: 0.9839 - cost: 2.0853 - val_loss: 0.1397 - val_auc: 0.9880 - val_accuracy: 0.9699 - val_cost: 3.7533\n",
            "Epoch 491/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0524 - auc: 0.9970 - accuracy: 0.9840 - cost: 2.0644 - val_loss: 0.1404 - val_auc: 0.9877 - val_accuracy: 0.9692 - val_cost: 3.8790\n",
            "Epoch 492/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0517 - auc: 0.9971 - accuracy: 0.9841 - cost: 2.0571 - val_loss: 0.1433 - val_auc: 0.9877 - val_accuracy: 0.9694 - val_cost: 3.7335\n",
            "Epoch 493/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0528 - auc: 0.9970 - accuracy: 0.9839 - cost: 2.0849 - val_loss: 0.1409 - val_auc: 0.9879 - val_accuracy: 0.9695 - val_cost: 3.7930\n",
            "Epoch 494/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0515 - auc: 0.9970 - accuracy: 0.9846 - cost: 1.9815 - val_loss: 0.1398 - val_auc: 0.9878 - val_accuracy: 0.9708 - val_cost: 3.5813\n",
            "Epoch 495/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0515 - auc: 0.9971 - accuracy: 0.9844 - cost: 2.0104 - val_loss: 0.1414 - val_auc: 0.9878 - val_accuracy: 0.9690 - val_cost: 3.7235\n",
            "Epoch 496/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0525 - auc: 0.9970 - accuracy: 0.9841 - cost: 2.0509 - val_loss: 0.1392 - val_auc: 0.9875 - val_accuracy: 0.9692 - val_cost: 3.8393\n",
            "Epoch 497/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0533 - auc: 0.9969 - accuracy: 0.9836 - cost: 2.1084 - val_loss: 0.1378 - val_auc: 0.9877 - val_accuracy: 0.9699 - val_cost: 3.7632\n",
            "Epoch 498/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0517 - auc: 0.9970 - accuracy: 0.9843 - cost: 2.0370 - val_loss: 0.1408 - val_auc: 0.9875 - val_accuracy: 0.9699 - val_cost: 3.7731\n",
            "Epoch 499/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0513 - auc: 0.9971 - accuracy: 0.9843 - cost: 2.0239 - val_loss: 0.1379 - val_auc: 0.9874 - val_accuracy: 0.9701 - val_cost: 3.8095\n",
            "Epoch 500/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0524 - auc: 0.9970 - accuracy: 0.9841 - cost: 2.0482 - val_loss: 0.1428 - val_auc: 0.9874 - val_accuracy: 0.9691 - val_cost: 3.8029\n",
            "Epoch 501/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0511 - auc: 0.9972 - accuracy: 0.9844 - cost: 2.0181 - val_loss: 0.1420 - val_auc: 0.9872 - val_accuracy: 0.9692 - val_cost: 3.8393\n",
            "Epoch 502/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0522 - auc: 0.9970 - accuracy: 0.9841 - cost: 2.0544 - val_loss: 0.1411 - val_auc: 0.9876 - val_accuracy: 0.9697 - val_cost: 3.7070\n",
            "Epoch 503/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0520 - auc: 0.9971 - accuracy: 0.9842 - cost: 2.0386 - val_loss: 0.1417 - val_auc: 0.9875 - val_accuracy: 0.9703 - val_cost: 3.6343\n",
            "Epoch 504/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0517 - auc: 0.9972 - accuracy: 0.9842 - cost: 2.0336 - val_loss: 0.1435 - val_auc: 0.9875 - val_accuracy: 0.9698 - val_cost: 3.6739\n",
            "Epoch 505/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0521 - auc: 0.9971 - accuracy: 0.9841 - cost: 2.0482 - val_loss: 0.1400 - val_auc: 0.9872 - val_accuracy: 0.9692 - val_cost: 3.8922\n",
            "Epoch 506/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0525 - auc: 0.9970 - accuracy: 0.9840 - cost: 2.0606 - val_loss: 0.1418 - val_auc: 0.9876 - val_accuracy: 0.9696 - val_cost: 3.8161\n",
            "Epoch 507/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0515 - auc: 0.9970 - accuracy: 0.9844 - cost: 2.0154 - val_loss: 0.1433 - val_auc: 0.9872 - val_accuracy: 0.9678 - val_cost: 3.9947\n",
            "Epoch 508/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0509 - auc: 0.9971 - accuracy: 0.9845 - cost: 1.9954 - val_loss: 0.1413 - val_auc: 0.9878 - val_accuracy: 0.9698 - val_cost: 3.7368\n",
            "Epoch 509/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0522 - auc: 0.9969 - accuracy: 0.9843 - cost: 2.0320 - val_loss: 0.1403 - val_auc: 0.9876 - val_accuracy: 0.9701 - val_cost: 3.7897\n",
            "Epoch 510/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0520 - auc: 0.9970 - accuracy: 0.9841 - cost: 2.0517 - val_loss: 0.1434 - val_auc: 0.9874 - val_accuracy: 0.9687 - val_cost: 3.8525\n",
            "Epoch 511/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0516 - auc: 0.9972 - accuracy: 0.9843 - cost: 2.0247 - val_loss: 0.1398 - val_auc: 0.9876 - val_accuracy: 0.9694 - val_cost: 3.8327\n",
            "Epoch 512/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0517 - auc: 0.9971 - accuracy: 0.9843 - cost: 2.0239 - val_loss: 0.1418 - val_auc: 0.9875 - val_accuracy: 0.9685 - val_cost: 3.9253\n",
            "Epoch 513/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0514 - auc: 0.9972 - accuracy: 0.9846 - cost: 1.9842 - val_loss: 0.1394 - val_auc: 0.9877 - val_accuracy: 0.9688 - val_cost: 3.8757\n",
            "Epoch 514/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0515 - auc: 0.9971 - accuracy: 0.9847 - cost: 1.9819 - val_loss: 0.1424 - val_auc: 0.9875 - val_accuracy: 0.9697 - val_cost: 3.7136\n",
            "Epoch 515/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0510 - auc: 0.9972 - accuracy: 0.9844 - cost: 2.0150 - val_loss: 0.1426 - val_auc: 0.9875 - val_accuracy: 0.9695 - val_cost: 3.9153\n",
            "Epoch 516/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0510 - auc: 0.9971 - accuracy: 0.9846 - cost: 1.9850 - val_loss: 0.1471 - val_auc: 0.9873 - val_accuracy: 0.9690 - val_cost: 3.8922\n",
            "Epoch 517/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0519 - auc: 0.9971 - accuracy: 0.9839 - cost: 2.0756 - val_loss: 0.1449 - val_auc: 0.9876 - val_accuracy: 0.9697 - val_cost: 3.7798\n",
            "Epoch 518/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0525 - auc: 0.9969 - accuracy: 0.9841 - cost: 2.0536 - val_loss: 0.1417 - val_auc: 0.9880 - val_accuracy: 0.9694 - val_cost: 3.8128\n",
            "Epoch 519/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0508 - auc: 0.9972 - accuracy: 0.9845 - cost: 1.9996 - val_loss: 0.1419 - val_auc: 0.9873 - val_accuracy: 0.9690 - val_cost: 3.9782\n",
            "Epoch 520/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0521 - auc: 0.9971 - accuracy: 0.9844 - cost: 2.0143 - val_loss: 0.1393 - val_auc: 0.9879 - val_accuracy: 0.9690 - val_cost: 3.8393\n",
            "Epoch 521/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0514 - auc: 0.9970 - accuracy: 0.9841 - cost: 2.0583 - val_loss: 0.1424 - val_auc: 0.9876 - val_accuracy: 0.9697 - val_cost: 3.7930\n",
            "Epoch 522/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0512 - auc: 0.9971 - accuracy: 0.9843 - cost: 2.0247 - val_loss: 0.1402 - val_auc: 0.9879 - val_accuracy: 0.9683 - val_cost: 3.9187\n",
            "Epoch 523/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0527 - auc: 0.9970 - accuracy: 0.9840 - cost: 2.0702 - val_loss: 0.1411 - val_auc: 0.9878 - val_accuracy: 0.9695 - val_cost: 3.7831\n",
            "Epoch 524/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0525 - auc: 0.9971 - accuracy: 0.9838 - cost: 2.0826 - val_loss: 0.1428 - val_auc: 0.9876 - val_accuracy: 0.9698 - val_cost: 3.6938\n",
            "Epoch 525/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0512 - auc: 0.9972 - accuracy: 0.9843 - cost: 2.0204 - val_loss: 0.1415 - val_auc: 0.9878 - val_accuracy: 0.9697 - val_cost: 3.7202\n",
            "Epoch 526/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0521 - auc: 0.9971 - accuracy: 0.9841 - cost: 2.0552 - val_loss: 0.1408 - val_auc: 0.9877 - val_accuracy: 0.9707 - val_cost: 3.6739\n",
            "Epoch 527/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0512 - auc: 0.9971 - accuracy: 0.9847 - cost: 1.9880 - val_loss: 0.1440 - val_auc: 0.9875 - val_accuracy: 0.9691 - val_cost: 3.8624\n",
            "Epoch 528/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0515 - auc: 0.9971 - accuracy: 0.9842 - cost: 2.0340 - val_loss: 0.1455 - val_auc: 0.9873 - val_accuracy: 0.9685 - val_cost: 3.9352\n",
            "Epoch 529/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0519 - auc: 0.9970 - accuracy: 0.9845 - cost: 1.9946 - val_loss: 0.1414 - val_auc: 0.9874 - val_accuracy: 0.9699 - val_cost: 3.7302\n",
            "Epoch 530/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0513 - auc: 0.9970 - accuracy: 0.9844 - cost: 2.0081 - val_loss: 0.1398 - val_auc: 0.9874 - val_accuracy: 0.9694 - val_cost: 3.8823\n",
            "Epoch 531/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0523 - auc: 0.9970 - accuracy: 0.9842 - cost: 2.0367 - val_loss: 0.1402 - val_auc: 0.9876 - val_accuracy: 0.9689 - val_cost: 3.9583\n",
            "Epoch 532/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0518 - auc: 0.9971 - accuracy: 0.9842 - cost: 2.0529 - val_loss: 0.1428 - val_auc: 0.9878 - val_accuracy: 0.9695 - val_cost: 3.7500\n",
            "Epoch 533/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0516 - auc: 0.9971 - accuracy: 0.9842 - cost: 2.0455 - val_loss: 0.1463 - val_auc: 0.9876 - val_accuracy: 0.9692 - val_cost: 3.7864\n",
            "Epoch 534/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0513 - auc: 0.9972 - accuracy: 0.9844 - cost: 2.0135 - val_loss: 0.1406 - val_auc: 0.9879 - val_accuracy: 0.9700 - val_cost: 3.8029\n",
            "Epoch 535/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0510 - auc: 0.9971 - accuracy: 0.9848 - cost: 1.9687 - val_loss: 0.1441 - val_auc: 0.9874 - val_accuracy: 0.9688 - val_cost: 3.9418\n",
            "Epoch 536/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0509 - auc: 0.9972 - accuracy: 0.9848 - cost: 1.9491 - val_loss: 0.1429 - val_auc: 0.9877 - val_accuracy: 0.9698 - val_cost: 3.7599\n",
            "Epoch 537/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0513 - auc: 0.9971 - accuracy: 0.9843 - cost: 2.0313 - val_loss: 0.1434 - val_auc: 0.9876 - val_accuracy: 0.9693 - val_cost: 3.8095\n",
            "Epoch 538/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0503 - auc: 0.9972 - accuracy: 0.9847 - cost: 1.9668 - val_loss: 0.1443 - val_auc: 0.9877 - val_accuracy: 0.9699 - val_cost: 3.7566\n",
            "Epoch 539/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0512 - auc: 0.9971 - accuracy: 0.9843 - cost: 2.0347 - val_loss: 0.1440 - val_auc: 0.9875 - val_accuracy: 0.9699 - val_cost: 3.7831\n",
            "Epoch 540/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0509 - auc: 0.9972 - accuracy: 0.9847 - cost: 1.9718 - val_loss: 0.1451 - val_auc: 0.9871 - val_accuracy: 0.9688 - val_cost: 3.8988\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.1272 - auc: 0.9892 - accuracy: 0.9701 - cost: 3.7344\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:04:12.278134\n",
            "fold accuracy: 0.9700624942779541 - fold cost: 3.734375\n",
            "total train/predict time: 0:42:25.490417\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m5_results = fold_results"
      ],
      "metadata": {
        "id": "h8ySkCi9mPHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds_m5 = np.zeros(len(y))\n",
        "for i in fold_results.keys():\n",
        "  for j in range(len(fold_results.get(i).get('predictions'))):\n",
        "    idx = fold_results.get(i).get('index')[j]\n",
        "    preds_m5[idx] = np.round(fold_results.get(i).get('predictions')[j],0)\n",
        "\n",
        "m5_cost = cost_func(y,preds_m5)\n",
        "m5_cost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkrG6or3mRV4",
        "outputId": "1a3ea345-7af8-4667-bfc3-92732fcb9e84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "591550"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds_new = np.zeros(len(y))\n",
        "for i in fold_results.keys():\n",
        "  for j in range(len(fold_results.get(i).get('predictions'))):\n",
        "    idx = fold_results.get(i).get('index')[j]\n",
        "    if fold_results.get(i).get('predictions')[j] > 0.6:\n",
        "      preds_new[idx] = 1\n",
        "    else:\n",
        "      preds_new[idx] = 0\n",
        "\n",
        "m5_cost_t = cost_func(y,preds_new)\n",
        "m5_cost_t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YGSE-MSmS5Q",
        "outputId": "af275b5f-6cc4-488a-80b2-71ff28c0edc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "581400"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model5.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xhEJqvbmWkK",
        "outputId": "e6fd3554-e3db-45b1-f1af-03d5e2bee029"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Relu1 (Dense)               (None, 64)                4352      \n",
            "                                                                 \n",
            " Relu2 (Dense)               (None, 64)                4160      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " Activation (Dense)          (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,577\n",
            "Trainable params: 8,577\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model5.save('model5.keras')"
      ],
      "metadata": {
        "id": "bmq9o4ehJjIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### XGBoost"
      ],
      "metadata": {
        "id": "kf48YNxF5eEk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#setting up a hyperparameter dataframe\n",
        "\n",
        "learning_rates = [0.1, 0.25, 0.35]\n",
        "max_depths = [3, 5, 10, 20]\n",
        "gamma = [0,1,3]\n",
        "lambda_ls = [1,2,3]\n",
        "alpha = [0,0.1,1]\n",
        "\n",
        "xgb_param = pd.DataFrame(list(product(learning_rates, max_depths, gamma, lambda_ls, alpha)), columns=['learning_rate', 'max_depth', 'gamma', 'lambda', 'alpha'])\n",
        "\n",
        "#randomizing the dataframe order\n",
        "xgb_param = shuffle(xgb_param)\n",
        "xgb_param = xgb_param.reset_index()\n",
        "xgb_param=xgb_param.drop(['index'], axis=1)\n",
        "xgb_param"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "crFxa8d68wBQ",
        "outputId": "b15aaf95-050b-41cc-d058-d3734fb23abc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     learning_rate  max_depth  gamma  lambda  alpha\n",
              "0             0.10         20      3       1    0.0\n",
              "1             0.25         20      1       3    0.0\n",
              "2             0.35         20      1       3    0.0\n",
              "3             0.35          3      0       2    0.0\n",
              "4             0.25          5      3       1    0.1\n",
              "..             ...        ...    ...     ...    ...\n",
              "319           0.25         20      0       3    0.1\n",
              "320           0.10          3      1       2    1.0\n",
              "321           0.25         10      3       2    1.0\n",
              "322           0.25          5      1       1    0.0\n",
              "323           0.25          3      0       3    0.1\n",
              "\n",
              "[324 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-c3d091ef-80fa-4745-8f71-54c43ba7eb27\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>learning_rate</th>\n",
              "      <th>max_depth</th>\n",
              "      <th>gamma</th>\n",
              "      <th>lambda</th>\n",
              "      <th>alpha</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.10</td>\n",
              "      <td>20</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.25</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.35</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.35</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.25</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>319</th>\n",
              "      <td>0.25</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>320</th>\n",
              "      <td>0.10</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>321</th>\n",
              "      <td>0.25</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>322</th>\n",
              "      <td>0.25</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>323</th>\n",
              "      <td>0.25</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>324 rows  5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c3d091ef-80fa-4745-8f71-54c43ba7eb27')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-b1b1a599-f754-46e9-a83e-11693c67c937\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b1b1a599-f754-46e9-a83e-11693c67c937')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-b1b1a599-f754-46e9-a83e-11693c67c937 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c3d091ef-80fa-4745-8f71-54c43ba7eb27 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c3d091ef-80fa-4745-8f71-54c43ba7eb27');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#setting up a hyperparameter dataframe\n",
        "\n",
        "learning_rates = [0.1, 0.25]\n",
        "max_depths = [3, 5, 10, 20]\n",
        "gamma = [0,1,3]\n",
        "lambda_ls = [1,2,3]\n",
        "alpha = [0,0.1,1]\n",
        "\n",
        "xgb_param = pd.DataFrame(list(product(learning_rates, max_depths, gamma, lambda_ls, alpha)), columns=['learning_rate', 'max_depth', 'gamma', 'lambda', 'alpha'])\n",
        "\n",
        "#randomizing the dataframe order\n",
        "xgb_param = shuffle(xgb_param)\n",
        "xgb_param = xgb_param.reset_index()\n",
        "xgb_param=xgb_param.drop(['index'], axis=1)\n",
        "xgb_param"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "Kn5Hv4-4YeKH",
        "outputId": "b3551b6c-f15f-46bb-a453-1a26b490587d"
      },
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-67ab67fa-04b3-4f3f-a50a-570001f40e53\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>learning_rate</th>\n",
              "      <th>max_depth</th>\n",
              "      <th>gamma</th>\n",
              "      <th>lambda</th>\n",
              "      <th>alpha</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.25</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.25</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.10</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.10</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.10</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>211</th>\n",
              "      <td>0.10</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>212</th>\n",
              "      <td>0.25</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>213</th>\n",
              "      <td>0.25</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>214</th>\n",
              "      <td>0.25</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>215</th>\n",
              "      <td>0.25</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>216 rows  5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-67ab67fa-04b3-4f3f-a50a-570001f40e53')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-a47afd49-f8e2-4262-9bbf-415f9bb0069e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a47afd49-f8e2-4262-9bbf-415f9bb0069e')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-a47afd49-f8e2-4262-9bbf-415f9bb0069e button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-67ab67fa-04b3-4f3f-a50a-570001f40e53 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-67ab67fa-04b3-4f3f-a50a-570001f40e53');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "     learning_rate  max_depth  gamma  lambda  alpha\n",
              "0             0.25          3      0       2    0.1\n",
              "1             0.25          5      0       3    1.0\n",
              "2             0.10         10      3       1    0.0\n",
              "3             0.10          3      0       3    0.0\n",
              "4             0.10         20      0       3    1.0\n",
              "..             ...        ...    ...     ...    ...\n",
              "211           0.10         10      1       1    0.1\n",
              "212           0.25         20      0       1    0.0\n",
              "213           0.25          5      3       1    0.0\n",
              "214           0.25         10      0       1    1.0\n",
              "215           0.25          5      1       2    1.0\n",
              "\n",
              "[216 rows x 5 columns]"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dtrain = xgb.DMatrix(X[train_index], label=y[train_index])\n",
        "dtest = xgb.DMatrix(X[test_index], label=y[test_index])\n",
        "\n",
        "trials = 30\n",
        "best_params = {}\n",
        "i=0\n",
        "\n",
        "for i in range(trials):\n",
        "  #random sampling from paramdf\n",
        "  hyperparams = {'objective': 'binary:logistic',\n",
        "                 'eta': xgb_param['learning_rate'][i],\n",
        "                 'max_depth': xgb_param['max_depth'][i],\n",
        "                 'gamma': xgb_param['gamma'][i],\n",
        "                 'lambda': xgb_param['lambda'][i],\n",
        "                 'alpha': xgb_param['alpha'][i],\n",
        "                 'eval_metric': 'aucpr'\n",
        "                 }\n",
        "\n",
        "  print(hyperparams)\n",
        "  out=xgb.cv(params=hyperparams,\n",
        "             num_boost_round=20,\n",
        "             dtrain=dtrain,\n",
        "             nfold=5,\n",
        "             stratified=True,\n",
        "             early_stopping_rounds=3,\n",
        "             verbose_eval=1\n",
        "             )\n",
        "\n",
        "  index=out.shape[0]-1\n",
        "  result=out.iloc[index,2]\n",
        "  if i< 1.1:\n",
        "    best_result = result\n",
        "    best_params = hyperparams\n",
        "\n",
        "  if result> best_result:\n",
        "      best_result = result\n",
        "      best_params = hyperparams\n",
        "      print('result: ' ,result)\n",
        "      print('best result: ' ,best_result)\n",
        "      print('hyperparameters: ' ,hyperparams)\n",
        "      print('best hyperparameters: ' ,best_params)\n",
        "      i+=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejnx8bTi5lsU",
        "outputId": "35897351-2785-4c1d-d03a-faa23ff501af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 3, 'gamma': 0, 'lambda': 2, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.64563+0.00181\ttest-aucpr:0.64315+0.00505\n",
            "[1]\ttrain-aucpr:0.69980+0.00174\ttest-aucpr:0.69633+0.00534\n",
            "[2]\ttrain-aucpr:0.72409+0.00755\ttest-aucpr:0.71974+0.01007\n",
            "[3]\ttrain-aucpr:0.73761+0.00208\ttest-aucpr:0.73401+0.00555\n",
            "[4]\ttrain-aucpr:0.74850+0.00132\ttest-aucpr:0.74449+0.00515\n",
            "[5]\ttrain-aucpr:0.75308+0.00284\ttest-aucpr:0.74841+0.00202\n",
            "[6]\ttrain-aucpr:0.76401+0.00358\ttest-aucpr:0.75897+0.00562\n",
            "[7]\ttrain-aucpr:0.77443+0.00387\ttest-aucpr:0.76929+0.00501\n",
            "[8]\ttrain-aucpr:0.78353+0.00227\ttest-aucpr:0.77830+0.00214\n",
            "[9]\ttrain-aucpr:0.79100+0.00270\ttest-aucpr:0.78574+0.00044\n",
            "[10]\ttrain-aucpr:0.79796+0.00160\ttest-aucpr:0.79272+0.00191\n",
            "[11]\ttrain-aucpr:0.80414+0.00166\ttest-aucpr:0.79894+0.00328\n",
            "[12]\ttrain-aucpr:0.80805+0.00231\ttest-aucpr:0.80253+0.00271\n",
            "[13]\ttrain-aucpr:0.81465+0.00377\ttest-aucpr:0.80908+0.00378\n",
            "[14]\ttrain-aucpr:0.81993+0.00351\ttest-aucpr:0.81426+0.00372\n",
            "[15]\ttrain-aucpr:0.82332+0.00361\ttest-aucpr:0.81784+0.00370\n",
            "[16]\ttrain-aucpr:0.82662+0.00381\ttest-aucpr:0.82082+0.00337\n",
            "[17]\ttrain-aucpr:0.83062+0.00327\ttest-aucpr:0.82481+0.00400\n",
            "[18]\ttrain-aucpr:0.83598+0.00418\ttest-aucpr:0.83030+0.00522\n",
            "[19]\ttrain-aucpr:0.83916+0.00467\ttest-aucpr:0.83345+0.00572\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 5, 'gamma': 0, 'lambda': 3, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76550+0.00235\ttest-aucpr:0.75927+0.00435\n",
            "[1]\ttrain-aucpr:0.81318+0.00225\ttest-aucpr:0.80539+0.00334\n",
            "[2]\ttrain-aucpr:0.83318+0.00295\ttest-aucpr:0.82591+0.00336\n",
            "[3]\ttrain-aucpr:0.84939+0.00145\ttest-aucpr:0.84225+0.00267\n",
            "[4]\ttrain-aucpr:0.85931+0.00101\ttest-aucpr:0.85189+0.00276\n",
            "[5]\ttrain-aucpr:0.86673+0.00230\ttest-aucpr:0.85947+0.00362\n",
            "[6]\ttrain-aucpr:0.87432+0.00233\ttest-aucpr:0.86671+0.00337\n",
            "[7]\ttrain-aucpr:0.88360+0.00369\ttest-aucpr:0.87603+0.00496\n",
            "[8]\ttrain-aucpr:0.89029+0.00271\ttest-aucpr:0.88296+0.00332\n",
            "[9]\ttrain-aucpr:0.89450+0.00311\ttest-aucpr:0.88709+0.00372\n",
            "[10]\ttrain-aucpr:0.89871+0.00108\ttest-aucpr:0.89103+0.00216\n",
            "[11]\ttrain-aucpr:0.90387+0.00182\ttest-aucpr:0.89611+0.00226\n",
            "[12]\ttrain-aucpr:0.90796+0.00308\ttest-aucpr:0.90005+0.00332\n",
            "[13]\ttrain-aucpr:0.91089+0.00251\ttest-aucpr:0.90283+0.00223\n",
            "[14]\ttrain-aucpr:0.91468+0.00190\ttest-aucpr:0.90639+0.00206\n",
            "[15]\ttrain-aucpr:0.91783+0.00235\ttest-aucpr:0.90934+0.00278\n",
            "[16]\ttrain-aucpr:0.91965+0.00216\ttest-aucpr:0.91114+0.00209\n",
            "[17]\ttrain-aucpr:0.92165+0.00265\ttest-aucpr:0.91322+0.00278\n",
            "[18]\ttrain-aucpr:0.92351+0.00273\ttest-aucpr:0.91509+0.00272\n",
            "[19]\ttrain-aucpr:0.92562+0.00328\ttest-aucpr:0.91723+0.00321\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 10, 'gamma': 3, 'lambda': 1, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.90560+0.00136\ttest-aucpr:0.87281+0.00246\n",
            "[1]\ttrain-aucpr:0.93138+0.00371\ttest-aucpr:0.90324+0.00377\n",
            "[2]\ttrain-aucpr:0.94181+0.00295\ttest-aucpr:0.91546+0.00261\n",
            "[3]\ttrain-aucpr:0.94852+0.00280\ttest-aucpr:0.92354+0.00318\n",
            "[4]\ttrain-aucpr:0.95339+0.00224\ttest-aucpr:0.92893+0.00228\n",
            "[5]\ttrain-aucpr:0.95770+0.00096\ttest-aucpr:0.93427+0.00122\n",
            "[6]\ttrain-aucpr:0.96061+0.00112\ttest-aucpr:0.93722+0.00081\n",
            "[7]\ttrain-aucpr:0.96275+0.00110\ttest-aucpr:0.93929+0.00083\n",
            "[8]\ttrain-aucpr:0.96501+0.00076\ttest-aucpr:0.94173+0.00098\n",
            "[9]\ttrain-aucpr:0.96701+0.00047\ttest-aucpr:0.94391+0.00050\n",
            "[10]\ttrain-aucpr:0.96869+0.00022\ttest-aucpr:0.94571+0.00087\n",
            "[11]\ttrain-aucpr:0.97022+0.00020\ttest-aucpr:0.94726+0.00064\n",
            "[12]\ttrain-aucpr:0.97141+0.00024\ttest-aucpr:0.94847+0.00048\n",
            "[13]\ttrain-aucpr:0.97253+0.00035\ttest-aucpr:0.94970+0.00024\n",
            "[14]\ttrain-aucpr:0.97353+0.00022\ttest-aucpr:0.95084+0.00033\n",
            "[15]\ttrain-aucpr:0.97467+0.00022\ttest-aucpr:0.95221+0.00034\n",
            "[16]\ttrain-aucpr:0.97580+0.00040\ttest-aucpr:0.95340+0.00038\n",
            "[17]\ttrain-aucpr:0.97659+0.00038\ttest-aucpr:0.95420+0.00039\n",
            "[18]\ttrain-aucpr:0.97736+0.00026\ttest-aucpr:0.95502+0.00038\n",
            "[19]\ttrain-aucpr:0.97818+0.00021\ttest-aucpr:0.95586+0.00038\n",
            "result:  0.9558574813295282\n",
            "best result:  0.9558574813295282\n",
            "hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 10, 'gamma': 3, 'lambda': 1, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "best hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 10, 'gamma': 3, 'lambda': 1, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 3, 'gamma': 0, 'lambda': 3, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.64563+0.00181\ttest-aucpr:0.64315+0.00505\n",
            "[1]\ttrain-aucpr:0.68916+0.00516\ttest-aucpr:0.68605+0.00458\n",
            "[2]\ttrain-aucpr:0.70762+0.00244\ttest-aucpr:0.70463+0.00583\n",
            "[3]\ttrain-aucpr:0.71815+0.00233\ttest-aucpr:0.71444+0.00571\n",
            "[4]\ttrain-aucpr:0.72935+0.00507\ttest-aucpr:0.72481+0.00983\n",
            "[5]\ttrain-aucpr:0.73475+0.00403\ttest-aucpr:0.73041+0.00907\n",
            "[6]\ttrain-aucpr:0.74144+0.00197\ttest-aucpr:0.73730+0.00612\n",
            "[7]\ttrain-aucpr:0.74512+0.00232\ttest-aucpr:0.74078+0.00549\n",
            "[8]\ttrain-aucpr:0.74908+0.00173\ttest-aucpr:0.74434+0.00441\n",
            "[9]\ttrain-aucpr:0.75073+0.00079\ttest-aucpr:0.74618+0.00414\n",
            "[10]\ttrain-aucpr:0.75240+0.00215\ttest-aucpr:0.74759+0.00479\n",
            "[11]\ttrain-aucpr:0.75616+0.00265\ttest-aucpr:0.75156+0.00445\n",
            "[12]\ttrain-aucpr:0.75850+0.00161\ttest-aucpr:0.75370+0.00417\n",
            "[13]\ttrain-aucpr:0.76290+0.00245\ttest-aucpr:0.75780+0.00201\n",
            "[14]\ttrain-aucpr:0.76493+0.00215\ttest-aucpr:0.76010+0.00309\n",
            "[15]\ttrain-aucpr:0.76779+0.00324\ttest-aucpr:0.76279+0.00328\n",
            "[16]\ttrain-aucpr:0.77002+0.00213\ttest-aucpr:0.76497+0.00301\n",
            "[17]\ttrain-aucpr:0.77335+0.00251\ttest-aucpr:0.76821+0.00227\n",
            "[18]\ttrain-aucpr:0.77641+0.00283\ttest-aucpr:0.77114+0.00366\n",
            "[19]\ttrain-aucpr:0.78056+0.00281\ttest-aucpr:0.77480+0.00361\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 20, 'gamma': 0, 'lambda': 3, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.94669+0.00203\ttest-aucpr:0.88450+0.00314\n",
            "[1]\ttrain-aucpr:0.96495+0.00291\ttest-aucpr:0.90774+0.00501\n",
            "[2]\ttrain-aucpr:0.97536+0.00234\ttest-aucpr:0.92202+0.00414\n",
            "[3]\ttrain-aucpr:0.98032+0.00163\ttest-aucpr:0.93012+0.00276\n",
            "[4]\ttrain-aucpr:0.98418+0.00137\ttest-aucpr:0.93630+0.00233\n",
            "[5]\ttrain-aucpr:0.98717+0.00084\ttest-aucpr:0.94131+0.00210\n",
            "[6]\ttrain-aucpr:0.98915+0.00069\ttest-aucpr:0.94423+0.00167\n",
            "[7]\ttrain-aucpr:0.99068+0.00046\ttest-aucpr:0.94685+0.00141\n",
            "[8]\ttrain-aucpr:0.99197+0.00040\ttest-aucpr:0.94973+0.00114\n",
            "[9]\ttrain-aucpr:0.99287+0.00039\ttest-aucpr:0.95147+0.00103\n",
            "[10]\ttrain-aucpr:0.99371+0.00029\ttest-aucpr:0.95323+0.00086\n",
            "[11]\ttrain-aucpr:0.99441+0.00025\ttest-aucpr:0.95485+0.00099\n",
            "[12]\ttrain-aucpr:0.99495+0.00024\ttest-aucpr:0.95595+0.00082\n",
            "[13]\ttrain-aucpr:0.99545+0.00025\ttest-aucpr:0.95708+0.00062\n",
            "[14]\ttrain-aucpr:0.99591+0.00014\ttest-aucpr:0.95810+0.00051\n",
            "[15]\ttrain-aucpr:0.99630+0.00016\ttest-aucpr:0.95899+0.00044\n",
            "[16]\ttrain-aucpr:0.99667+0.00015\ttest-aucpr:0.96003+0.00033\n",
            "[17]\ttrain-aucpr:0.99693+0.00014\ttest-aucpr:0.96072+0.00034\n",
            "[18]\ttrain-aucpr:0.99719+0.00012\ttest-aucpr:0.96160+0.00054\n",
            "[19]\ttrain-aucpr:0.99744+0.00010\ttest-aucpr:0.96219+0.00056\n",
            "result:  0.9621872731832992\n",
            "best result:  0.9621872731832992\n",
            "hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 20, 'gamma': 0, 'lambda': 3, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "best hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 20, 'gamma': 0, 'lambda': 3, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 20, 'gamma': 1, 'lambda': 1, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.95555+0.00089\ttest-aucpr:0.88733+0.00278\n",
            "[1]\ttrain-aucpr:0.97987+0.00160\ttest-aucpr:0.91923+0.00264\n",
            "[2]\ttrain-aucpr:0.98830+0.00110\ttest-aucpr:0.93501+0.00291\n",
            "[3]\ttrain-aucpr:0.99182+0.00061\ttest-aucpr:0.94304+0.00234\n",
            "[4]\ttrain-aucpr:0.99392+0.00043\ttest-aucpr:0.94862+0.00150\n",
            "[5]\ttrain-aucpr:0.99538+0.00020\ttest-aucpr:0.95260+0.00105\n",
            "[6]\ttrain-aucpr:0.99631+0.00019\ttest-aucpr:0.95589+0.00121\n",
            "[7]\ttrain-aucpr:0.99709+0.00013\ttest-aucpr:0.95838+0.00098\n",
            "[8]\ttrain-aucpr:0.99762+0.00009\ttest-aucpr:0.96050+0.00092\n",
            "[9]\ttrain-aucpr:0.99804+0.00010\ttest-aucpr:0.96232+0.00086\n",
            "[10]\ttrain-aucpr:0.99837+0.00010\ttest-aucpr:0.96367+0.00061\n",
            "[11]\ttrain-aucpr:0.99866+0.00007\ttest-aucpr:0.96515+0.00070\n",
            "[12]\ttrain-aucpr:0.99888+0.00006\ttest-aucpr:0.96616+0.00060\n",
            "[13]\ttrain-aucpr:0.99906+0.00005\ttest-aucpr:0.96717+0.00058\n",
            "[14]\ttrain-aucpr:0.99920+0.00004\ttest-aucpr:0.96818+0.00077\n",
            "[15]\ttrain-aucpr:0.99932+0.00004\ttest-aucpr:0.96891+0.00079\n",
            "[16]\ttrain-aucpr:0.99941+0.00004\ttest-aucpr:0.96963+0.00084\n",
            "[17]\ttrain-aucpr:0.99949+0.00003\ttest-aucpr:0.97036+0.00089\n",
            "[18]\ttrain-aucpr:0.99957+0.00003\ttest-aucpr:0.97084+0.00094\n",
            "[19]\ttrain-aucpr:0.99962+0.00002\ttest-aucpr:0.97134+0.00099\n",
            "result:  0.9713368907046164\n",
            "best result:  0.9713368907046164\n",
            "hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 20, 'gamma': 1, 'lambda': 1, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "best hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 20, 'gamma': 1, 'lambda': 1, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 3, 'gamma': 0, 'lambda': 3, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.64563+0.00181\ttest-aucpr:0.64315+0.00505\n",
            "[1]\ttrain-aucpr:0.69979+0.00174\ttest-aucpr:0.69633+0.00534\n",
            "[2]\ttrain-aucpr:0.72408+0.00754\ttest-aucpr:0.71973+0.01007\n",
            "[3]\ttrain-aucpr:0.73763+0.00209\ttest-aucpr:0.73403+0.00556\n",
            "[4]\ttrain-aucpr:0.74849+0.00131\ttest-aucpr:0.74449+0.00515\n",
            "[5]\ttrain-aucpr:0.75306+0.00284\ttest-aucpr:0.74839+0.00202\n",
            "[6]\ttrain-aucpr:0.76399+0.00358\ttest-aucpr:0.75896+0.00563\n",
            "[7]\ttrain-aucpr:0.77440+0.00388\ttest-aucpr:0.76927+0.00502\n",
            "[8]\ttrain-aucpr:0.78349+0.00228\ttest-aucpr:0.77828+0.00214\n",
            "[9]\ttrain-aucpr:0.79097+0.00270\ttest-aucpr:0.78570+0.00044\n",
            "[10]\ttrain-aucpr:0.79791+0.00161\ttest-aucpr:0.79267+0.00191\n",
            "[11]\ttrain-aucpr:0.80409+0.00166\ttest-aucpr:0.79890+0.00328\n",
            "[12]\ttrain-aucpr:0.80800+0.00232\ttest-aucpr:0.80247+0.00270\n",
            "[13]\ttrain-aucpr:0.81439+0.00355\ttest-aucpr:0.80880+0.00373\n",
            "[14]\ttrain-aucpr:0.81976+0.00349\ttest-aucpr:0.81392+0.00393\n",
            "[15]\ttrain-aucpr:0.82372+0.00387\ttest-aucpr:0.81764+0.00323\n",
            "[16]\ttrain-aucpr:0.82728+0.00452\ttest-aucpr:0.82121+0.00374\n",
            "[17]\ttrain-aucpr:0.83238+0.00400\ttest-aucpr:0.82622+0.00430\n",
            "[18]\ttrain-aucpr:0.83627+0.00462\ttest-aucpr:0.83022+0.00562\n",
            "[19]\ttrain-aucpr:0.83893+0.00416\ttest-aucpr:0.83280+0.00508\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 20, 'gamma': 1, 'lambda': 2, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.95752+0.00066\ttest-aucpr:0.88951+0.00308\n",
            "[1]\ttrain-aucpr:0.98161+0.00142\ttest-aucpr:0.91862+0.00349\n",
            "[2]\ttrain-aucpr:0.98959+0.00056\ttest-aucpr:0.93323+0.00072\n",
            "[3]\ttrain-aucpr:0.99333+0.00038\ttest-aucpr:0.94294+0.00132\n",
            "[4]\ttrain-aucpr:0.99539+0.00007\ttest-aucpr:0.94884+0.00132\n",
            "[5]\ttrain-aucpr:0.99661+0.00009\ttest-aucpr:0.95324+0.00085\n",
            "[6]\ttrain-aucpr:0.99741+0.00007\ttest-aucpr:0.95635+0.00081\n",
            "[7]\ttrain-aucpr:0.99804+0.00008\ttest-aucpr:0.95861+0.00074\n",
            "[8]\ttrain-aucpr:0.99847+0.00005\ttest-aucpr:0.96095+0.00071\n",
            "[9]\ttrain-aucpr:0.99878+0.00003\ttest-aucpr:0.96255+0.00080\n",
            "[10]\ttrain-aucpr:0.99904+0.00005\ttest-aucpr:0.96405+0.00047\n",
            "[11]\ttrain-aucpr:0.99925+0.00001\ttest-aucpr:0.96533+0.00057\n",
            "[12]\ttrain-aucpr:0.99941+0.00001\ttest-aucpr:0.96634+0.00042\n",
            "[13]\ttrain-aucpr:0.99953+0.00002\ttest-aucpr:0.96736+0.00042\n",
            "[14]\ttrain-aucpr:0.99963+0.00002\ttest-aucpr:0.96824+0.00051\n",
            "[15]\ttrain-aucpr:0.99970+0.00002\ttest-aucpr:0.96896+0.00047\n",
            "[16]\ttrain-aucpr:0.99975+0.00002\ttest-aucpr:0.96960+0.00051\n",
            "[17]\ttrain-aucpr:0.99980+0.00001\ttest-aucpr:0.97020+0.00048\n",
            "[18]\ttrain-aucpr:0.99984+0.00001\ttest-aucpr:0.97081+0.00037\n",
            "[19]\ttrain-aucpr:0.99987+0.00001\ttest-aucpr:0.97130+0.00041\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 5, 'gamma': 0, 'lambda': 3, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76550+0.00231\ttest-aucpr:0.75917+0.00435\n",
            "[1]\ttrain-aucpr:0.79807+0.00432\ttest-aucpr:0.79129+0.00387\n",
            "[2]\ttrain-aucpr:0.81769+0.00272\ttest-aucpr:0.81111+0.00389\n",
            "[3]\ttrain-aucpr:0.82860+0.00115\ttest-aucpr:0.82209+0.00434\n",
            "[4]\ttrain-aucpr:0.83620+0.00319\ttest-aucpr:0.82952+0.00443\n",
            "[5]\ttrain-aucpr:0.84293+0.00181\ttest-aucpr:0.83648+0.00364\n",
            "[6]\ttrain-aucpr:0.84708+0.00196\ttest-aucpr:0.84017+0.00392\n",
            "[7]\ttrain-aucpr:0.85182+0.00140\ttest-aucpr:0.84437+0.00225\n",
            "[8]\ttrain-aucpr:0.85580+0.00098\ttest-aucpr:0.84853+0.00285\n",
            "[9]\ttrain-aucpr:0.85999+0.00095\ttest-aucpr:0.85280+0.00295\n",
            "[10]\ttrain-aucpr:0.86374+0.00037\ttest-aucpr:0.85669+0.00256\n",
            "[11]\ttrain-aucpr:0.86764+0.00160\ttest-aucpr:0.86035+0.00308\n",
            "[12]\ttrain-aucpr:0.87089+0.00103\ttest-aucpr:0.86341+0.00286\n",
            "[13]\ttrain-aucpr:0.87371+0.00092\ttest-aucpr:0.86620+0.00279\n",
            "[14]\ttrain-aucpr:0.87702+0.00092\ttest-aucpr:0.86956+0.00251\n",
            "[15]\ttrain-aucpr:0.87958+0.00084\ttest-aucpr:0.87198+0.00259\n",
            "[16]\ttrain-aucpr:0.88188+0.00096\ttest-aucpr:0.87414+0.00281\n",
            "[17]\ttrain-aucpr:0.88406+0.00114\ttest-aucpr:0.87609+0.00280\n",
            "[18]\ttrain-aucpr:0.88744+0.00130\ttest-aucpr:0.87926+0.00249\n",
            "[19]\ttrain-aucpr:0.88949+0.00149\ttest-aucpr:0.88124+0.00284\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 3, 'gamma': 0, 'lambda': 1, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.64571+0.00171\ttest-aucpr:0.64300+0.00505\n",
            "[1]\ttrain-aucpr:0.68945+0.00533\ttest-aucpr:0.68631+0.00481\n",
            "[2]\ttrain-aucpr:0.70779+0.00228\ttest-aucpr:0.70469+0.00584\n",
            "[3]\ttrain-aucpr:0.71829+0.00226\ttest-aucpr:0.71451+0.00574\n",
            "[4]\ttrain-aucpr:0.72944+0.00515\ttest-aucpr:0.72491+0.00992\n",
            "[5]\ttrain-aucpr:0.73478+0.00406\ttest-aucpr:0.73042+0.00908\n",
            "[6]\ttrain-aucpr:0.74147+0.00198\ttest-aucpr:0.73732+0.00612\n",
            "[7]\ttrain-aucpr:0.74517+0.00230\ttest-aucpr:0.74083+0.00550\n",
            "[8]\ttrain-aucpr:0.74914+0.00175\ttest-aucpr:0.74438+0.00441\n",
            "[9]\ttrain-aucpr:0.75080+0.00085\ttest-aucpr:0.74623+0.00417\n",
            "[10]\ttrain-aucpr:0.75245+0.00215\ttest-aucpr:0.74762+0.00479\n",
            "[11]\ttrain-aucpr:0.75622+0.00268\ttest-aucpr:0.75159+0.00444\n",
            "[12]\ttrain-aucpr:0.75858+0.00165\ttest-aucpr:0.75371+0.00411\n",
            "[13]\ttrain-aucpr:0.76305+0.00231\ttest-aucpr:0.75788+0.00194\n",
            "[14]\ttrain-aucpr:0.76508+0.00199\ttest-aucpr:0.76020+0.00303\n",
            "[15]\ttrain-aucpr:0.76758+0.00364\ttest-aucpr:0.76262+0.00341\n",
            "[16]\ttrain-aucpr:0.76989+0.00242\ttest-aucpr:0.76480+0.00301\n",
            "[17]\ttrain-aucpr:0.77372+0.00206\ttest-aucpr:0.76851+0.00204\n",
            "[18]\ttrain-aucpr:0.77671+0.00247\ttest-aucpr:0.77134+0.00347\n",
            "[19]\ttrain-aucpr:0.78047+0.00316\ttest-aucpr:0.77465+0.00370\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 5, 'gamma': 3, 'lambda': 1, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76569+0.00223\ttest-aucpr:0.75902+0.00403\n",
            "[1]\ttrain-aucpr:0.81349+0.00249\ttest-aucpr:0.80541+0.00348\n",
            "[2]\ttrain-aucpr:0.83384+0.00283\ttest-aucpr:0.82622+0.00343\n",
            "[3]\ttrain-aucpr:0.84957+0.00175\ttest-aucpr:0.84230+0.00258\n",
            "[4]\ttrain-aucpr:0.85957+0.00124\ttest-aucpr:0.85205+0.00262\n",
            "[5]\ttrain-aucpr:0.86772+0.00294\ttest-aucpr:0.86016+0.00411\n",
            "[6]\ttrain-aucpr:0.87563+0.00216\ttest-aucpr:0.86792+0.00401\n",
            "[7]\ttrain-aucpr:0.88307+0.00263\ttest-aucpr:0.87529+0.00418\n",
            "[8]\ttrain-aucpr:0.88884+0.00110\ttest-aucpr:0.88119+0.00137\n",
            "[9]\ttrain-aucpr:0.89481+0.00136\ttest-aucpr:0.88704+0.00242\n",
            "[10]\ttrain-aucpr:0.89810+0.00080\ttest-aucpr:0.89005+0.00161\n",
            "[11]\ttrain-aucpr:0.90183+0.00033\ttest-aucpr:0.89373+0.00146\n",
            "[12]\ttrain-aucpr:0.90700+0.00128\ttest-aucpr:0.89889+0.00060\n",
            "[13]\ttrain-aucpr:0.91026+0.00239\ttest-aucpr:0.90216+0.00215\n",
            "[14]\ttrain-aucpr:0.91400+0.00227\ttest-aucpr:0.90591+0.00184\n",
            "[15]\ttrain-aucpr:0.91630+0.00253\ttest-aucpr:0.90810+0.00227\n",
            "[16]\ttrain-aucpr:0.91886+0.00255\ttest-aucpr:0.91071+0.00266\n",
            "[17]\ttrain-aucpr:0.92122+0.00209\ttest-aucpr:0.91296+0.00211\n",
            "[18]\ttrain-aucpr:0.92320+0.00226\ttest-aucpr:0.91482+0.00221\n",
            "[19]\ttrain-aucpr:0.92519+0.00272\ttest-aucpr:0.91667+0.00267\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 3, 'gamma': 3, 'lambda': 1, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.64563+0.00181\ttest-aucpr:0.64315+0.00505\n",
            "[1]\ttrain-aucpr:0.68919+0.00517\ttest-aucpr:0.68607+0.00460\n",
            "[2]\ttrain-aucpr:0.70762+0.00244\ttest-aucpr:0.70463+0.00583\n",
            "[3]\ttrain-aucpr:0.71817+0.00233\ttest-aucpr:0.71445+0.00572\n",
            "[4]\ttrain-aucpr:0.72933+0.00507\ttest-aucpr:0.72479+0.00983\n",
            "[5]\ttrain-aucpr:0.73475+0.00404\ttest-aucpr:0.73041+0.00907\n",
            "[6]\ttrain-aucpr:0.74145+0.00197\ttest-aucpr:0.73730+0.00612\n",
            "[7]\ttrain-aucpr:0.74513+0.00231\ttest-aucpr:0.74078+0.00549\n",
            "[8]\ttrain-aucpr:0.74910+0.00172\ttest-aucpr:0.74436+0.00439\n",
            "[9]\ttrain-aucpr:0.75074+0.00078\ttest-aucpr:0.74619+0.00414\n",
            "[10]\ttrain-aucpr:0.75242+0.00215\ttest-aucpr:0.74761+0.00479\n",
            "[11]\ttrain-aucpr:0.75617+0.00265\ttest-aucpr:0.75156+0.00443\n",
            "[12]\ttrain-aucpr:0.75852+0.00161\ttest-aucpr:0.75368+0.00411\n",
            "[13]\ttrain-aucpr:0.76302+0.00235\ttest-aucpr:0.75786+0.00194\n",
            "[14]\ttrain-aucpr:0.76505+0.00199\ttest-aucpr:0.76018+0.00302\n",
            "[15]\ttrain-aucpr:0.76754+0.00363\ttest-aucpr:0.76257+0.00343\n",
            "[16]\ttrain-aucpr:0.76984+0.00241\ttest-aucpr:0.76475+0.00305\n",
            "[17]\ttrain-aucpr:0.77368+0.00206\ttest-aucpr:0.76847+0.00208\n",
            "[18]\ttrain-aucpr:0.77667+0.00245\ttest-aucpr:0.77129+0.00352\n",
            "[19]\ttrain-aucpr:0.78042+0.00315\ttest-aucpr:0.77460+0.00373\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 3, 'gamma': 3, 'lambda': 1, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.64571+0.00171\ttest-aucpr:0.64300+0.00505\n",
            "[1]\ttrain-aucpr:0.69996+0.00178\ttest-aucpr:0.69634+0.00534\n",
            "[2]\ttrain-aucpr:0.72428+0.00732\ttest-aucpr:0.71979+0.01005\n",
            "[3]\ttrain-aucpr:0.73812+0.00237\ttest-aucpr:0.73389+0.00550\n",
            "[4]\ttrain-aucpr:0.74914+0.00187\ttest-aucpr:0.74508+0.00522\n",
            "[5]\ttrain-aucpr:0.75370+0.00235\ttest-aucpr:0.74899+0.00137\n",
            "[6]\ttrain-aucpr:0.76480+0.00353\ttest-aucpr:0.75970+0.00542\n",
            "[7]\ttrain-aucpr:0.77330+0.00225\ttest-aucpr:0.76828+0.00398\n",
            "[8]\ttrain-aucpr:0.78143+0.00403\ttest-aucpr:0.77629+0.00409\n",
            "[9]\ttrain-aucpr:0.78920+0.00341\ttest-aucpr:0.78401+0.00238\n",
            "[10]\ttrain-aucpr:0.79564+0.00400\ttest-aucpr:0.79041+0.00363\n",
            "[11]\ttrain-aucpr:0.80268+0.00379\ttest-aucpr:0.79778+0.00413\n",
            "[12]\ttrain-aucpr:0.80901+0.00186\ttest-aucpr:0.80386+0.00164\n",
            "[13]\ttrain-aucpr:0.81633+0.00264\ttest-aucpr:0.81099+0.00205\n",
            "[14]\ttrain-aucpr:0.82101+0.00283\ttest-aucpr:0.81542+0.00336\n",
            "[15]\ttrain-aucpr:0.82425+0.00309\ttest-aucpr:0.81874+0.00328\n",
            "[16]\ttrain-aucpr:0.82800+0.00388\ttest-aucpr:0.82251+0.00443\n",
            "[17]\ttrain-aucpr:0.83153+0.00326\ttest-aucpr:0.82601+0.00497\n",
            "[18]\ttrain-aucpr:0.83714+0.00166\ttest-aucpr:0.83188+0.00329\n",
            "[19]\ttrain-aucpr:0.83971+0.00204\ttest-aucpr:0.83441+0.00379\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 3, 'gamma': 3, 'lambda': 1, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.64563+0.00181\ttest-aucpr:0.64315+0.00505\n",
            "[1]\ttrain-aucpr:0.69980+0.00174\ttest-aucpr:0.69634+0.00534\n",
            "[2]\ttrain-aucpr:0.72409+0.00755\ttest-aucpr:0.71974+0.01007\n",
            "[3]\ttrain-aucpr:0.73762+0.00207\ttest-aucpr:0.73401+0.00555\n",
            "[4]\ttrain-aucpr:0.74851+0.00130\ttest-aucpr:0.74450+0.00514\n",
            "[5]\ttrain-aucpr:0.75307+0.00283\ttest-aucpr:0.74840+0.00201\n",
            "[6]\ttrain-aucpr:0.76401+0.00358\ttest-aucpr:0.75897+0.00562\n",
            "[7]\ttrain-aucpr:0.77443+0.00387\ttest-aucpr:0.76929+0.00502\n",
            "[8]\ttrain-aucpr:0.78353+0.00228\ttest-aucpr:0.77830+0.00214\n",
            "[9]\ttrain-aucpr:0.79100+0.00270\ttest-aucpr:0.78574+0.00044\n",
            "[10]\ttrain-aucpr:0.79796+0.00161\ttest-aucpr:0.79272+0.00191\n",
            "[11]\ttrain-aucpr:0.80414+0.00167\ttest-aucpr:0.79894+0.00328\n",
            "[12]\ttrain-aucpr:0.80805+0.00231\ttest-aucpr:0.80253+0.00271\n",
            "[13]\ttrain-aucpr:0.81445+0.00354\ttest-aucpr:0.80886+0.00372\n",
            "[14]\ttrain-aucpr:0.81982+0.00349\ttest-aucpr:0.81398+0.00393\n",
            "[15]\ttrain-aucpr:0.82378+0.00386\ttest-aucpr:0.81770+0.00322\n",
            "[16]\ttrain-aucpr:0.82735+0.00451\ttest-aucpr:0.82128+0.00374\n",
            "[17]\ttrain-aucpr:0.83244+0.00400\ttest-aucpr:0.82628+0.00430\n",
            "[18]\ttrain-aucpr:0.83634+0.00463\ttest-aucpr:0.83028+0.00562\n",
            "[19]\ttrain-aucpr:0.83899+0.00417\ttest-aucpr:0.83285+0.00509\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 10, 'gamma': 3, 'lambda': 1, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.90143+0.00174\ttest-aucpr:0.87209+0.00410\n",
            "[1]\ttrain-aucpr:0.93481+0.00131\ttest-aucpr:0.90821+0.00184\n",
            "[2]\ttrain-aucpr:0.94936+0.00095\ttest-aucpr:0.92508+0.00082\n",
            "[3]\ttrain-aucpr:0.95746+0.00102\ttest-aucpr:0.93383+0.00131\n",
            "[4]\ttrain-aucpr:0.96245+0.00090\ttest-aucpr:0.93935+0.00062\n",
            "[5]\ttrain-aucpr:0.96621+0.00108\ttest-aucpr:0.94336+0.00079\n",
            "[6]\ttrain-aucpr:0.96954+0.00123\ttest-aucpr:0.94693+0.00100\n",
            "[7]\ttrain-aucpr:0.97212+0.00130\ttest-aucpr:0.94966+0.00105\n",
            "[8]\ttrain-aucpr:0.97436+0.00095\ttest-aucpr:0.95238+0.00065\n",
            "[9]\ttrain-aucpr:0.97658+0.00079\ttest-aucpr:0.95482+0.00055\n",
            "[10]\ttrain-aucpr:0.97821+0.00052\ttest-aucpr:0.95685+0.00037\n",
            "[11]\ttrain-aucpr:0.97939+0.00044\ttest-aucpr:0.95822+0.00038\n",
            "[12]\ttrain-aucpr:0.98029+0.00047\ttest-aucpr:0.95936+0.00071\n",
            "[13]\ttrain-aucpr:0.98130+0.00051\ttest-aucpr:0.96064+0.00049\n",
            "[14]\ttrain-aucpr:0.98255+0.00043\ttest-aucpr:0.96222+0.00027\n",
            "[15]\ttrain-aucpr:0.98318+0.00046\ttest-aucpr:0.96309+0.00020\n",
            "[16]\ttrain-aucpr:0.98392+0.00052\ttest-aucpr:0.96400+0.00053\n",
            "[17]\ttrain-aucpr:0.98439+0.00054\ttest-aucpr:0.96476+0.00050\n",
            "[18]\ttrain-aucpr:0.98489+0.00075\ttest-aucpr:0.96538+0.00043\n",
            "[19]\ttrain-aucpr:0.98532+0.00061\ttest-aucpr:0.96596+0.00042\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 10, 'gamma': 3, 'lambda': 2, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.90107+0.00181\ttest-aucpr:0.87201+0.00406\n",
            "[1]\ttrain-aucpr:0.92761+0.00399\ttest-aucpr:0.90065+0.00401\n",
            "[2]\ttrain-aucpr:0.93951+0.00295\ttest-aucpr:0.91439+0.00244\n",
            "[3]\ttrain-aucpr:0.94586+0.00238\ttest-aucpr:0.92160+0.00217\n",
            "[4]\ttrain-aucpr:0.95245+0.00125\ttest-aucpr:0.92944+0.00152\n",
            "[5]\ttrain-aucpr:0.95588+0.00136\ttest-aucpr:0.93315+0.00114\n",
            "[6]\ttrain-aucpr:0.95862+0.00086\ttest-aucpr:0.93630+0.00085\n",
            "[7]\ttrain-aucpr:0.96064+0.00092\ttest-aucpr:0.93849+0.00088\n",
            "[8]\ttrain-aucpr:0.96290+0.00077\ttest-aucpr:0.94087+0.00073\n",
            "[9]\ttrain-aucpr:0.96449+0.00072\ttest-aucpr:0.94249+0.00027\n",
            "[10]\ttrain-aucpr:0.96624+0.00031\ttest-aucpr:0.94429+0.00045\n",
            "[11]\ttrain-aucpr:0.96761+0.00043\ttest-aucpr:0.94576+0.00045\n",
            "[12]\ttrain-aucpr:0.96890+0.00046\ttest-aucpr:0.94701+0.00049\n",
            "[13]\ttrain-aucpr:0.97039+0.00061\ttest-aucpr:0.94880+0.00062\n",
            "[14]\ttrain-aucpr:0.97154+0.00062\ttest-aucpr:0.95004+0.00067\n",
            "[15]\ttrain-aucpr:0.97263+0.00084\ttest-aucpr:0.95115+0.00068\n",
            "[16]\ttrain-aucpr:0.97373+0.00100\ttest-aucpr:0.95239+0.00095\n",
            "[17]\ttrain-aucpr:0.97459+0.00088\ttest-aucpr:0.95338+0.00108\n",
            "[18]\ttrain-aucpr:0.97543+0.00085\ttest-aucpr:0.95435+0.00087\n",
            "[19]\ttrain-aucpr:0.97630+0.00102\ttest-aucpr:0.95526+0.00108\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 3, 'gamma': 0, 'lambda': 2, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.64563+0.00181\ttest-aucpr:0.64315+0.00505\n",
            "[1]\ttrain-aucpr:0.69979+0.00174\ttest-aucpr:0.69633+0.00534\n",
            "[2]\ttrain-aucpr:0.72408+0.00755\ttest-aucpr:0.71973+0.01008\n",
            "[3]\ttrain-aucpr:0.73762+0.00208\ttest-aucpr:0.73402+0.00557\n",
            "[4]\ttrain-aucpr:0.74849+0.00131\ttest-aucpr:0.74448+0.00515\n",
            "[5]\ttrain-aucpr:0.75305+0.00284\ttest-aucpr:0.74838+0.00202\n",
            "[6]\ttrain-aucpr:0.76399+0.00358\ttest-aucpr:0.75895+0.00563\n",
            "[7]\ttrain-aucpr:0.77439+0.00388\ttest-aucpr:0.76926+0.00502\n",
            "[8]\ttrain-aucpr:0.78349+0.00228\ttest-aucpr:0.77827+0.00214\n",
            "[9]\ttrain-aucpr:0.79096+0.00271\ttest-aucpr:0.78570+0.00045\n",
            "[10]\ttrain-aucpr:0.79791+0.00161\ttest-aucpr:0.79267+0.00191\n",
            "[11]\ttrain-aucpr:0.80409+0.00166\ttest-aucpr:0.79889+0.00328\n",
            "[12]\ttrain-aucpr:0.80800+0.00232\ttest-aucpr:0.80247+0.00270\n",
            "[13]\ttrain-aucpr:0.81439+0.00355\ttest-aucpr:0.80880+0.00372\n",
            "[14]\ttrain-aucpr:0.81976+0.00349\ttest-aucpr:0.81392+0.00392\n",
            "[15]\ttrain-aucpr:0.82411+0.00447\ttest-aucpr:0.81813+0.00418\n",
            "[16]\ttrain-aucpr:0.82775+0.00520\ttest-aucpr:0.82170+0.00470\n",
            "[17]\ttrain-aucpr:0.83303+0.00484\ttest-aucpr:0.82689+0.00525\n",
            "[18]\ttrain-aucpr:0.83699+0.00510\ttest-aucpr:0.83099+0.00622\n",
            "[19]\ttrain-aucpr:0.83933+0.00456\ttest-aucpr:0.83319+0.00548\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 20, 'gamma': 1, 'lambda': 1, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.96995+0.00060\ttest-aucpr:0.89124+0.00327\n",
            "[1]\ttrain-aucpr:0.98800+0.00114\ttest-aucpr:0.91813+0.00197\n",
            "[2]\ttrain-aucpr:0.99404+0.00072\ttest-aucpr:0.93402+0.00240\n",
            "[3]\ttrain-aucpr:0.99648+0.00043\ttest-aucpr:0.94225+0.00277\n",
            "[4]\ttrain-aucpr:0.99777+0.00018\ttest-aucpr:0.94829+0.00208\n",
            "[5]\ttrain-aucpr:0.99853+0.00011\ttest-aucpr:0.95284+0.00202\n",
            "[6]\ttrain-aucpr:0.99897+0.00009\ttest-aucpr:0.95597+0.00165\n",
            "[7]\ttrain-aucpr:0.99924+0.00008\ttest-aucpr:0.95835+0.00148\n",
            "[8]\ttrain-aucpr:0.99945+0.00005\ttest-aucpr:0.96022+0.00134\n",
            "[9]\ttrain-aucpr:0.99961+0.00006\ttest-aucpr:0.96192+0.00110\n",
            "[10]\ttrain-aucpr:0.99970+0.00005\ttest-aucpr:0.96339+0.00106\n",
            "[11]\ttrain-aucpr:0.99979+0.00003\ttest-aucpr:0.96457+0.00105\n",
            "[12]\ttrain-aucpr:0.99985+0.00002\ttest-aucpr:0.96563+0.00095\n",
            "[13]\ttrain-aucpr:0.99989+0.00001\ttest-aucpr:0.96666+0.00111\n",
            "[14]\ttrain-aucpr:0.99992+0.00001\ttest-aucpr:0.96772+0.00087\n",
            "[15]\ttrain-aucpr:0.99994+0.00001\ttest-aucpr:0.96842+0.00079\n",
            "[16]\ttrain-aucpr:0.99996+0.00001\ttest-aucpr:0.96922+0.00078\n",
            "[17]\ttrain-aucpr:0.99997+0.00001\ttest-aucpr:0.96981+0.00091\n",
            "[18]\ttrain-aucpr:0.99998+0.00000\ttest-aucpr:0.97035+0.00095\n",
            "[19]\ttrain-aucpr:0.99998+0.00000\ttest-aucpr:0.97082+0.00099\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 5, 'gamma': 3, 'lambda': 1, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76569+0.00223\ttest-aucpr:0.75902+0.00402\n",
            "[1]\ttrain-aucpr:0.79887+0.00361\ttest-aucpr:0.79184+0.00372\n",
            "[2]\ttrain-aucpr:0.81831+0.00312\ttest-aucpr:0.81134+0.00402\n",
            "[3]\ttrain-aucpr:0.82970+0.00179\ttest-aucpr:0.82294+0.00487\n",
            "[4]\ttrain-aucpr:0.83700+0.00306\ttest-aucpr:0.83006+0.00456\n",
            "[5]\ttrain-aucpr:0.84354+0.00213\ttest-aucpr:0.83694+0.00378\n",
            "[6]\ttrain-aucpr:0.84714+0.00189\ttest-aucpr:0.84010+0.00377\n",
            "[7]\ttrain-aucpr:0.85265+0.00180\ttest-aucpr:0.84523+0.00248\n",
            "[8]\ttrain-aucpr:0.85632+0.00130\ttest-aucpr:0.84904+0.00272\n",
            "[9]\ttrain-aucpr:0.86071+0.00142\ttest-aucpr:0.85347+0.00328\n",
            "[10]\ttrain-aucpr:0.86405+0.00092\ttest-aucpr:0.85671+0.00278\n",
            "[11]\ttrain-aucpr:0.86777+0.00084\ttest-aucpr:0.86032+0.00215\n",
            "[12]\ttrain-aucpr:0.87107+0.00076\ttest-aucpr:0.86358+0.00222\n",
            "[13]\ttrain-aucpr:0.87356+0.00068\ttest-aucpr:0.86599+0.00242\n",
            "[14]\ttrain-aucpr:0.87669+0.00070\ttest-aucpr:0.86923+0.00258\n",
            "[15]\ttrain-aucpr:0.87924+0.00058\ttest-aucpr:0.87175+0.00216\n",
            "[16]\ttrain-aucpr:0.88214+0.00103\ttest-aucpr:0.87452+0.00221\n",
            "[17]\ttrain-aucpr:0.88479+0.00100\ttest-aucpr:0.87706+0.00226\n",
            "[18]\ttrain-aucpr:0.88692+0.00113\ttest-aucpr:0.87919+0.00265\n",
            "[19]\ttrain-aucpr:0.89032+0.00092\ttest-aucpr:0.88262+0.00212\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 10, 'gamma': 1, 'lambda': 1, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.90648+0.00131\ttest-aucpr:0.87250+0.00255\n",
            "[1]\ttrain-aucpr:0.93227+0.00376\ttest-aucpr:0.90315+0.00362\n",
            "[2]\ttrain-aucpr:0.94224+0.00211\ttest-aucpr:0.91512+0.00145\n",
            "[3]\ttrain-aucpr:0.94845+0.00199\ttest-aucpr:0.92203+0.00166\n",
            "[4]\ttrain-aucpr:0.95365+0.00173\ttest-aucpr:0.92839+0.00185\n",
            "[5]\ttrain-aucpr:0.95819+0.00062\ttest-aucpr:0.93349+0.00071\n",
            "[6]\ttrain-aucpr:0.96129+0.00099\ttest-aucpr:0.93693+0.00075\n",
            "[7]\ttrain-aucpr:0.96351+0.00087\ttest-aucpr:0.93913+0.00053\n",
            "[8]\ttrain-aucpr:0.96553+0.00085\ttest-aucpr:0.94118+0.00069\n",
            "[9]\ttrain-aucpr:0.96761+0.00101\ttest-aucpr:0.94329+0.00088\n",
            "[10]\ttrain-aucpr:0.96913+0.00080\ttest-aucpr:0.94480+0.00058\n",
            "[11]\ttrain-aucpr:0.97052+0.00081\ttest-aucpr:0.94627+0.00069\n",
            "[12]\ttrain-aucpr:0.97201+0.00057\ttest-aucpr:0.94783+0.00054\n",
            "[13]\ttrain-aucpr:0.97308+0.00060\ttest-aucpr:0.94886+0.00061\n",
            "[14]\ttrain-aucpr:0.97422+0.00055\ttest-aucpr:0.95007+0.00057\n",
            "[15]\ttrain-aucpr:0.97536+0.00053\ttest-aucpr:0.95115+0.00067\n",
            "[16]\ttrain-aucpr:0.97624+0.00042\ttest-aucpr:0.95221+0.00063\n",
            "[17]\ttrain-aucpr:0.97729+0.00049\ttest-aucpr:0.95323+0.00072\n",
            "[18]\ttrain-aucpr:0.97820+0.00044\ttest-aucpr:0.95427+0.00081\n",
            "[19]\ttrain-aucpr:0.97899+0.00050\ttest-aucpr:0.95510+0.00080\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 5, 'gamma': 3, 'lambda': 2, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76562+0.00227\ttest-aucpr:0.75887+0.00420\n",
            "[1]\ttrain-aucpr:0.81337+0.00230\ttest-aucpr:0.80537+0.00343\n",
            "[2]\ttrain-aucpr:0.83328+0.00309\ttest-aucpr:0.82599+0.00338\n",
            "[3]\ttrain-aucpr:0.84947+0.00147\ttest-aucpr:0.84236+0.00255\n",
            "[4]\ttrain-aucpr:0.85936+0.00094\ttest-aucpr:0.85202+0.00250\n",
            "[5]\ttrain-aucpr:0.86762+0.00275\ttest-aucpr:0.86011+0.00398\n",
            "[6]\ttrain-aucpr:0.87499+0.00138\ttest-aucpr:0.86730+0.00306\n",
            "[7]\ttrain-aucpr:0.88209+0.00234\ttest-aucpr:0.87446+0.00337\n",
            "[8]\ttrain-aucpr:0.88837+0.00227\ttest-aucpr:0.88052+0.00217\n",
            "[9]\ttrain-aucpr:0.89361+0.00226\ttest-aucpr:0.88577+0.00276\n",
            "[10]\ttrain-aucpr:0.89709+0.00179\ttest-aucpr:0.88897+0.00235\n",
            "[11]\ttrain-aucpr:0.90149+0.00180\ttest-aucpr:0.89335+0.00287\n",
            "[12]\ttrain-aucpr:0.90548+0.00101\ttest-aucpr:0.89725+0.00195\n",
            "[13]\ttrain-aucpr:0.90933+0.00136\ttest-aucpr:0.90113+0.00241\n",
            "[14]\ttrain-aucpr:0.91240+0.00122\ttest-aucpr:0.90415+0.00211\n",
            "[15]\ttrain-aucpr:0.91515+0.00106\ttest-aucpr:0.90709+0.00146\n",
            "[16]\ttrain-aucpr:0.91742+0.00093\ttest-aucpr:0.90934+0.00074\n",
            "[17]\ttrain-aucpr:0.91991+0.00190\ttest-aucpr:0.91169+0.00258\n",
            "[18]\ttrain-aucpr:0.92227+0.00253\ttest-aucpr:0.91407+0.00346\n",
            "[19]\ttrain-aucpr:0.92493+0.00176\ttest-aucpr:0.91673+0.00257\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 3, 'gamma': 0, 'lambda': 1, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.64563+0.00181\ttest-aucpr:0.64315+0.00505\n",
            "[1]\ttrain-aucpr:0.68919+0.00517\ttest-aucpr:0.68607+0.00460\n",
            "[2]\ttrain-aucpr:0.70762+0.00244\ttest-aucpr:0.70463+0.00583\n",
            "[3]\ttrain-aucpr:0.71817+0.00233\ttest-aucpr:0.71445+0.00572\n",
            "[4]\ttrain-aucpr:0.72933+0.00507\ttest-aucpr:0.72479+0.00983\n",
            "[5]\ttrain-aucpr:0.73475+0.00404\ttest-aucpr:0.73041+0.00907\n",
            "[6]\ttrain-aucpr:0.74145+0.00197\ttest-aucpr:0.73730+0.00612\n",
            "[7]\ttrain-aucpr:0.74513+0.00231\ttest-aucpr:0.74078+0.00549\n",
            "[8]\ttrain-aucpr:0.74910+0.00172\ttest-aucpr:0.74436+0.00439\n",
            "[9]\ttrain-aucpr:0.75074+0.00078\ttest-aucpr:0.74619+0.00414\n",
            "[10]\ttrain-aucpr:0.75242+0.00215\ttest-aucpr:0.74761+0.00479\n",
            "[11]\ttrain-aucpr:0.75617+0.00265\ttest-aucpr:0.75156+0.00443\n",
            "[12]\ttrain-aucpr:0.75852+0.00161\ttest-aucpr:0.75368+0.00411\n",
            "[13]\ttrain-aucpr:0.76302+0.00235\ttest-aucpr:0.75786+0.00194\n",
            "[14]\ttrain-aucpr:0.76505+0.00199\ttest-aucpr:0.76018+0.00302\n",
            "[15]\ttrain-aucpr:0.76754+0.00363\ttest-aucpr:0.76257+0.00343\n",
            "[16]\ttrain-aucpr:0.76984+0.00241\ttest-aucpr:0.76475+0.00305\n",
            "[17]\ttrain-aucpr:0.77368+0.00206\ttest-aucpr:0.76847+0.00208\n",
            "[18]\ttrain-aucpr:0.77667+0.00245\ttest-aucpr:0.77129+0.00352\n",
            "[19]\ttrain-aucpr:0.78042+0.00315\ttest-aucpr:0.77460+0.00373\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 5, 'gamma': 1, 'lambda': 3, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76550+0.00231\ttest-aucpr:0.75917+0.00435\n",
            "[1]\ttrain-aucpr:0.81329+0.00228\ttest-aucpr:0.80537+0.00332\n",
            "[2]\ttrain-aucpr:0.83322+0.00300\ttest-aucpr:0.82593+0.00336\n",
            "[3]\ttrain-aucpr:0.84949+0.00146\ttest-aucpr:0.84230+0.00261\n",
            "[4]\ttrain-aucpr:0.85945+0.00091\ttest-aucpr:0.85195+0.00265\n",
            "[5]\ttrain-aucpr:0.86692+0.00230\ttest-aucpr:0.85960+0.00352\n",
            "[6]\ttrain-aucpr:0.87440+0.00160\ttest-aucpr:0.86668+0.00273\n",
            "[7]\ttrain-aucpr:0.88236+0.00259\ttest-aucpr:0.87460+0.00358\n",
            "[8]\ttrain-aucpr:0.88904+0.00102\ttest-aucpr:0.88132+0.00140\n",
            "[9]\ttrain-aucpr:0.89339+0.00155\ttest-aucpr:0.88553+0.00096\n",
            "[10]\ttrain-aucpr:0.89747+0.00144\ttest-aucpr:0.88909+0.00035\n",
            "[11]\ttrain-aucpr:0.90172+0.00147\ttest-aucpr:0.89324+0.00101\n",
            "[12]\ttrain-aucpr:0.90622+0.00147\ttest-aucpr:0.89768+0.00166\n",
            "[13]\ttrain-aucpr:0.90929+0.00095\ttest-aucpr:0.90087+0.00141\n",
            "[14]\ttrain-aucpr:0.91321+0.00120\ttest-aucpr:0.90473+0.00176\n",
            "[15]\ttrain-aucpr:0.91442+0.00125\ttest-aucpr:0.90591+0.00146\n",
            "[16]\ttrain-aucpr:0.91721+0.00164\ttest-aucpr:0.90866+0.00221\n",
            "[17]\ttrain-aucpr:0.91923+0.00122\ttest-aucpr:0.91073+0.00159\n",
            "[18]\ttrain-aucpr:0.92139+0.00105\ttest-aucpr:0.91275+0.00176\n",
            "[19]\ttrain-aucpr:0.92425+0.00164\ttest-aucpr:0.91547+0.00245\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 10, 'gamma': 1, 'lambda': 3, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.89849+0.00177\ttest-aucpr:0.87056+0.00377\n",
            "[1]\ttrain-aucpr:0.93193+0.00123\ttest-aucpr:0.90645+0.00169\n",
            "[2]\ttrain-aucpr:0.94755+0.00104\ttest-aucpr:0.92373+0.00150\n",
            "[3]\ttrain-aucpr:0.95520+0.00059\ttest-aucpr:0.93160+0.00064\n",
            "[4]\ttrain-aucpr:0.96071+0.00090\ttest-aucpr:0.93729+0.00133\n",
            "[5]\ttrain-aucpr:0.96499+0.00070\ttest-aucpr:0.94206+0.00123\n",
            "[6]\ttrain-aucpr:0.96854+0.00088\ttest-aucpr:0.94574+0.00152\n",
            "[7]\ttrain-aucpr:0.97151+0.00058\ttest-aucpr:0.94880+0.00119\n",
            "[8]\ttrain-aucpr:0.97394+0.00070\ttest-aucpr:0.95135+0.00139\n",
            "[9]\ttrain-aucpr:0.97615+0.00045\ttest-aucpr:0.95399+0.00116\n",
            "[10]\ttrain-aucpr:0.97832+0.00037\ttest-aucpr:0.95645+0.00075\n",
            "[11]\ttrain-aucpr:0.97989+0.00039\ttest-aucpr:0.95818+0.00089\n",
            "[12]\ttrain-aucpr:0.98078+0.00026\ttest-aucpr:0.95929+0.00091\n",
            "[13]\ttrain-aucpr:0.98195+0.00048\ttest-aucpr:0.96090+0.00116\n",
            "[14]\ttrain-aucpr:0.98258+0.00058\ttest-aucpr:0.96176+0.00131\n",
            "[15]\ttrain-aucpr:0.98339+0.00061\ttest-aucpr:0.96265+0.00120\n",
            "[16]\ttrain-aucpr:0.98418+0.00073\ttest-aucpr:0.96355+0.00134\n",
            "[17]\ttrain-aucpr:0.98478+0.00075\ttest-aucpr:0.96423+0.00111\n",
            "[18]\ttrain-aucpr:0.98530+0.00067\ttest-aucpr:0.96492+0.00109\n",
            "[19]\ttrain-aucpr:0.98581+0.00087\ttest-aucpr:0.96544+0.00112\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 10, 'gamma': 0, 'lambda': 2, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.90305+0.00167\ttest-aucpr:0.87212+0.00414\n",
            "[1]\ttrain-aucpr:0.93640+0.00176\ttest-aucpr:0.90820+0.00217\n",
            "[2]\ttrain-aucpr:0.95121+0.00103\ttest-aucpr:0.92526+0.00195\n",
            "[3]\ttrain-aucpr:0.95965+0.00132\ttest-aucpr:0.93387+0.00168\n",
            "[4]\ttrain-aucpr:0.96405+0.00153\ttest-aucpr:0.93858+0.00170\n",
            "[5]\ttrain-aucpr:0.96849+0.00128\ttest-aucpr:0.94290+0.00118\n",
            "[6]\ttrain-aucpr:0.97222+0.00117\ttest-aucpr:0.94680+0.00126\n",
            "[7]\ttrain-aucpr:0.97505+0.00130\ttest-aucpr:0.94980+0.00143\n",
            "[8]\ttrain-aucpr:0.97770+0.00099\ttest-aucpr:0.95274+0.00096\n",
            "[9]\ttrain-aucpr:0.97967+0.00112\ttest-aucpr:0.95493+0.00126\n",
            "[10]\ttrain-aucpr:0.98132+0.00109\ttest-aucpr:0.95688+0.00152\n",
            "[11]\ttrain-aucpr:0.98311+0.00078\ttest-aucpr:0.95913+0.00084\n",
            "[12]\ttrain-aucpr:0.98395+0.00060\ttest-aucpr:0.96028+0.00083\n",
            "[13]\ttrain-aucpr:0.98502+0.00041\ttest-aucpr:0.96144+0.00070\n",
            "[14]\ttrain-aucpr:0.98573+0.00061\ttest-aucpr:0.96227+0.00103\n",
            "[15]\ttrain-aucpr:0.98654+0.00060\ttest-aucpr:0.96336+0.00119\n",
            "[16]\ttrain-aucpr:0.98711+0.00074\ttest-aucpr:0.96418+0.00105\n",
            "[17]\ttrain-aucpr:0.98769+0.00039\ttest-aucpr:0.96486+0.00093\n",
            "[18]\ttrain-aucpr:0.98833+0.00033\ttest-aucpr:0.96551+0.00101\n",
            "[19]\ttrain-aucpr:0.98875+0.00046\ttest-aucpr:0.96602+0.00107\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 5, 'gamma': 3, 'lambda': 3, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76550+0.00231\ttest-aucpr:0.75917+0.00435\n",
            "[1]\ttrain-aucpr:0.79807+0.00432\ttest-aucpr:0.79129+0.00387\n",
            "[2]\ttrain-aucpr:0.81769+0.00272\ttest-aucpr:0.81111+0.00389\n",
            "[3]\ttrain-aucpr:0.82860+0.00115\ttest-aucpr:0.82209+0.00434\n",
            "[4]\ttrain-aucpr:0.83620+0.00319\ttest-aucpr:0.82952+0.00443\n",
            "[5]\ttrain-aucpr:0.84293+0.00181\ttest-aucpr:0.83648+0.00364\n",
            "[6]\ttrain-aucpr:0.84708+0.00196\ttest-aucpr:0.84017+0.00392\n",
            "[7]\ttrain-aucpr:0.85182+0.00140\ttest-aucpr:0.84437+0.00225\n",
            "[8]\ttrain-aucpr:0.85580+0.00098\ttest-aucpr:0.84853+0.00285\n",
            "[9]\ttrain-aucpr:0.85999+0.00095\ttest-aucpr:0.85280+0.00295\n",
            "[10]\ttrain-aucpr:0.86374+0.00037\ttest-aucpr:0.85669+0.00256\n",
            "[11]\ttrain-aucpr:0.86764+0.00160\ttest-aucpr:0.86035+0.00308\n",
            "[12]\ttrain-aucpr:0.87089+0.00103\ttest-aucpr:0.86341+0.00286\n",
            "[13]\ttrain-aucpr:0.87371+0.00092\ttest-aucpr:0.86620+0.00279\n",
            "[14]\ttrain-aucpr:0.87702+0.00092\ttest-aucpr:0.86956+0.00251\n",
            "[15]\ttrain-aucpr:0.87958+0.00084\ttest-aucpr:0.87198+0.00259\n",
            "[16]\ttrain-aucpr:0.88188+0.00096\ttest-aucpr:0.87414+0.00281\n",
            "[17]\ttrain-aucpr:0.88406+0.00114\ttest-aucpr:0.87609+0.00280\n",
            "[18]\ttrain-aucpr:0.88744+0.00130\ttest-aucpr:0.87926+0.00249\n",
            "[19]\ttrain-aucpr:0.88949+0.00149\ttest-aucpr:0.88124+0.00284\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 3, 'gamma': 0, 'lambda': 2, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.64563+0.00181\ttest-aucpr:0.64315+0.00505\n",
            "[1]\ttrain-aucpr:0.68919+0.00517\ttest-aucpr:0.68607+0.00460\n",
            "[2]\ttrain-aucpr:0.70763+0.00244\ttest-aucpr:0.70463+0.00584\n",
            "[3]\ttrain-aucpr:0.71817+0.00233\ttest-aucpr:0.71445+0.00571\n",
            "[4]\ttrain-aucpr:0.72935+0.00507\ttest-aucpr:0.72481+0.00983\n",
            "[5]\ttrain-aucpr:0.73475+0.00403\ttest-aucpr:0.73041+0.00907\n",
            "[6]\ttrain-aucpr:0.74145+0.00197\ttest-aucpr:0.73731+0.00612\n",
            "[7]\ttrain-aucpr:0.74513+0.00231\ttest-aucpr:0.74079+0.00549\n",
            "[8]\ttrain-aucpr:0.74910+0.00173\ttest-aucpr:0.74436+0.00439\n",
            "[9]\ttrain-aucpr:0.75075+0.00079\ttest-aucpr:0.74620+0.00414\n",
            "[10]\ttrain-aucpr:0.75242+0.00215\ttest-aucpr:0.74760+0.00479\n",
            "[11]\ttrain-aucpr:0.75618+0.00265\ttest-aucpr:0.75157+0.00444\n",
            "[12]\ttrain-aucpr:0.75853+0.00161\ttest-aucpr:0.75369+0.00411\n",
            "[13]\ttrain-aucpr:0.76292+0.00245\ttest-aucpr:0.75780+0.00197\n",
            "[14]\ttrain-aucpr:0.76496+0.00215\ttest-aucpr:0.76011+0.00306\n",
            "[15]\ttrain-aucpr:0.76782+0.00325\ttest-aucpr:0.76280+0.00325\n",
            "[16]\ttrain-aucpr:0.77006+0.00213\ttest-aucpr:0.76498+0.00299\n",
            "[17]\ttrain-aucpr:0.77340+0.00251\ttest-aucpr:0.76823+0.00224\n",
            "[18]\ttrain-aucpr:0.77646+0.00284\ttest-aucpr:0.77114+0.00363\n",
            "[19]\ttrain-aucpr:0.78061+0.00282\ttest-aucpr:0.77482+0.00358\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 10, 'gamma': 0, 'lambda': 3, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.89869+0.00174\ttest-aucpr:0.87054+0.00378\n",
            "[1]\ttrain-aucpr:0.93221+0.00151\ttest-aucpr:0.90655+0.00175\n",
            "[2]\ttrain-aucpr:0.94847+0.00128\ttest-aucpr:0.92439+0.00122\n",
            "[3]\ttrain-aucpr:0.95545+0.00099\ttest-aucpr:0.93159+0.00098\n",
            "[4]\ttrain-aucpr:0.96087+0.00136\ttest-aucpr:0.93693+0.00165\n",
            "[5]\ttrain-aucpr:0.96482+0.00103\ttest-aucpr:0.94152+0.00102\n",
            "[6]\ttrain-aucpr:0.96890+0.00035\ttest-aucpr:0.94608+0.00079\n",
            "[7]\ttrain-aucpr:0.97211+0.00055\ttest-aucpr:0.94953+0.00104\n",
            "[8]\ttrain-aucpr:0.97421+0.00047\ttest-aucpr:0.95171+0.00110\n",
            "[9]\ttrain-aucpr:0.97655+0.00073\ttest-aucpr:0.95413+0.00107\n",
            "[10]\ttrain-aucpr:0.97834+0.00080\ttest-aucpr:0.95619+0.00091\n",
            "[11]\ttrain-aucpr:0.97995+0.00083\ttest-aucpr:0.95788+0.00092\n",
            "[12]\ttrain-aucpr:0.98132+0.00041\ttest-aucpr:0.95939+0.00059\n",
            "[13]\ttrain-aucpr:0.98210+0.00050\ttest-aucpr:0.96042+0.00041\n",
            "[14]\ttrain-aucpr:0.98291+0.00029\ttest-aucpr:0.96147+0.00041\n",
            "[15]\ttrain-aucpr:0.98385+0.00040\ttest-aucpr:0.96264+0.00058\n",
            "[16]\ttrain-aucpr:0.98435+0.00029\ttest-aucpr:0.96326+0.00061\n",
            "[17]\ttrain-aucpr:0.98538+0.00039\ttest-aucpr:0.96453+0.00039\n",
            "[18]\ttrain-aucpr:0.98589+0.00026\ttest-aucpr:0.96519+0.00044\n",
            "[19]\ttrain-aucpr:0.98640+0.00040\ttest-aucpr:0.96565+0.00039\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 5, 'gamma': 3, 'lambda': 2, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76562+0.00227\ttest-aucpr:0.75886+0.00421\n",
            "[1]\ttrain-aucpr:0.79813+0.00424\ttest-aucpr:0.79127+0.00391\n",
            "[2]\ttrain-aucpr:0.81796+0.00286\ttest-aucpr:0.81121+0.00397\n",
            "[3]\ttrain-aucpr:0.82899+0.00115\ttest-aucpr:0.82236+0.00436\n",
            "[4]\ttrain-aucpr:0.83654+0.00304\ttest-aucpr:0.82981+0.00439\n",
            "[5]\ttrain-aucpr:0.84330+0.00201\ttest-aucpr:0.83689+0.00376\n",
            "[6]\ttrain-aucpr:0.84729+0.00198\ttest-aucpr:0.84033+0.00403\n",
            "[7]\ttrain-aucpr:0.85277+0.00198\ttest-aucpr:0.84548+0.00243\n",
            "[8]\ttrain-aucpr:0.85683+0.00174\ttest-aucpr:0.84967+0.00322\n",
            "[9]\ttrain-aucpr:0.86067+0.00139\ttest-aucpr:0.85345+0.00318\n",
            "[10]\ttrain-aucpr:0.86454+0.00093\ttest-aucpr:0.85746+0.00260\n",
            "[11]\ttrain-aucpr:0.86742+0.00127\ttest-aucpr:0.86016+0.00288\n",
            "[12]\ttrain-aucpr:0.87021+0.00102\ttest-aucpr:0.86290+0.00295\n",
            "[13]\ttrain-aucpr:0.87331+0.00072\ttest-aucpr:0.86599+0.00267\n",
            "[14]\ttrain-aucpr:0.87622+0.00084\ttest-aucpr:0.86906+0.00260\n",
            "[15]\ttrain-aucpr:0.87910+0.00068\ttest-aucpr:0.87181+0.00249\n",
            "[16]\ttrain-aucpr:0.88170+0.00080\ttest-aucpr:0.87431+0.00248\n",
            "[17]\ttrain-aucpr:0.88430+0.00055\ttest-aucpr:0.87661+0.00221\n",
            "[18]\ttrain-aucpr:0.88698+0.00147\ttest-aucpr:0.87933+0.00311\n",
            "[19]\ttrain-aucpr:0.88954+0.00129\ttest-aucpr:0.88184+0.00317\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 10, 'gamma': 1, 'lambda': 1, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.90627+0.00135\ttest-aucpr:0.87263+0.00253\n",
            "[1]\ttrain-aucpr:0.93801+0.00154\ttest-aucpr:0.90831+0.00187\n",
            "[2]\ttrain-aucpr:0.95256+0.00107\ttest-aucpr:0.92557+0.00231\n",
            "[3]\ttrain-aucpr:0.95948+0.00160\ttest-aucpr:0.93293+0.00203\n",
            "[4]\ttrain-aucpr:0.96529+0.00061\ttest-aucpr:0.93917+0.00055\n",
            "[5]\ttrain-aucpr:0.96986+0.00122\ttest-aucpr:0.94438+0.00087\n",
            "[6]\ttrain-aucpr:0.97279+0.00092\ttest-aucpr:0.94755+0.00095\n",
            "[7]\ttrain-aucpr:0.97572+0.00101\ttest-aucpr:0.95070+0.00101\n",
            "[8]\ttrain-aucpr:0.97791+0.00105\ttest-aucpr:0.95308+0.00078\n",
            "[9]\ttrain-aucpr:0.98033+0.00082\ttest-aucpr:0.95589+0.00064\n",
            "[10]\ttrain-aucpr:0.98231+0.00070\ttest-aucpr:0.95785+0.00077\n",
            "[11]\ttrain-aucpr:0.98357+0.00065\ttest-aucpr:0.95941+0.00082\n",
            "[12]\ttrain-aucpr:0.98467+0.00040\ttest-aucpr:0.96085+0.00075\n",
            "[13]\ttrain-aucpr:0.98563+0.00033\ttest-aucpr:0.96189+0.00089\n",
            "[14]\ttrain-aucpr:0.98628+0.00032\ttest-aucpr:0.96274+0.00083\n",
            "[15]\ttrain-aucpr:0.98689+0.00035\ttest-aucpr:0.96344+0.00072\n",
            "[16]\ttrain-aucpr:0.98750+0.00048\ttest-aucpr:0.96415+0.00064\n",
            "[17]\ttrain-aucpr:0.98818+0.00063\ttest-aucpr:0.96501+0.00067\n",
            "[18]\ttrain-aucpr:0.98885+0.00057\ttest-aucpr:0.96576+0.00079\n",
            "[19]\ttrain-aucpr:0.98941+0.00084\ttest-aucpr:0.96626+0.00092\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_params"
      ],
      "metadata": {
        "id": "xXJEj4W_8T-H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69863b78-b66d-45ff-bb28-49504e4cb18d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'objective': 'binary:logistic',\n",
              " 'eta': 0.25,\n",
              " 'max_depth': 20,\n",
              " 'gamma': 1,\n",
              " 'lambda': 1,\n",
              " 'alpha': 1.0,\n",
              " 'eval_metric': 'aucpr'}"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aucpr_params = {'objective': 'binary:logistic',\n",
        "         'eta': 0.25,\n",
        "         'max_depth': 20,\n",
        "         'gamma': 1,\n",
        "         'lambda': 1,\n",
        "         'alpha': 1.0,\n",
        "         'eval_metric': 'aucpr'}"
      ],
      "metadata": {
        "id": "_RjSFnb1SXl7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fold_results = {}\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(skf.split(X,y)):\n",
        "    dtrain = xgb.DMatrix(X[train_index], label=y[train_index])\n",
        "    dtest = xgb.DMatrix(X[test_index], label=y[test_index])\n",
        "    evallist = [(dtrain, 'train'), (dtest, 'eval')]\n",
        "\n",
        "    tr=xgb.train(params=aucpr_params,\n",
        "                 num_boost_round=222,\n",
        "                 dtrain=dtrain,\n",
        "                 verbose_eval=1,\n",
        "                 evals=evallist,\n",
        "                 early_stopping_rounds = 3\n",
        "             )\n",
        "\n",
        "    preds_XGB = np.round(tr.predict(dtest), 0)\n",
        "\n",
        "    classification_report(y[test_index],np.round(preds_XGB, 0),output_dict=True)\n",
        "    fold_results.update({i:{'predictions':preds_XGB,'index':test_index,'y_true':y[test_index]}})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eY58xAj3XqoL",
        "outputId": "cd600deb-5928-4083-d466-473595f8e229"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\ttrain-aucpr:0.95637\teval-aucpr:0.88765\n",
            "[1]\ttrain-aucpr:0.98006\teval-aucpr:0.92214\n",
            "[2]\ttrain-aucpr:0.98894\teval-aucpr:0.93891\n",
            "[3]\ttrain-aucpr:0.99180\teval-aucpr:0.94592\n",
            "[4]\ttrain-aucpr:0.99410\teval-aucpr:0.95182\n",
            "[5]\ttrain-aucpr:0.99541\teval-aucpr:0.95523\n",
            "[6]\ttrain-aucpr:0.99629\teval-aucpr:0.95760\n",
            "[7]\ttrain-aucpr:0.99683\teval-aucpr:0.95925\n",
            "[8]\ttrain-aucpr:0.99741\teval-aucpr:0.96116\n",
            "[9]\ttrain-aucpr:0.99792\teval-aucpr:0.96266\n",
            "[10]\ttrain-aucpr:0.99828\teval-aucpr:0.96439\n",
            "[11]\ttrain-aucpr:0.99858\teval-aucpr:0.96591\n",
            "[12]\ttrain-aucpr:0.99881\teval-aucpr:0.96730\n",
            "[13]\ttrain-aucpr:0.99902\teval-aucpr:0.96824\n",
            "[14]\ttrain-aucpr:0.99916\teval-aucpr:0.96904\n",
            "[15]\ttrain-aucpr:0.99928\teval-aucpr:0.96988\n",
            "[16]\ttrain-aucpr:0.99937\teval-aucpr:0.97065\n",
            "[17]\ttrain-aucpr:0.99945\teval-aucpr:0.97132\n",
            "[18]\ttrain-aucpr:0.99952\teval-aucpr:0.97186\n",
            "[19]\ttrain-aucpr:0.99957\teval-aucpr:0.97254\n",
            "[20]\ttrain-aucpr:0.99960\teval-aucpr:0.97293\n",
            "[21]\ttrain-aucpr:0.99966\teval-aucpr:0.97307\n",
            "[22]\ttrain-aucpr:0.99970\teval-aucpr:0.97341\n",
            "[23]\ttrain-aucpr:0.99975\teval-aucpr:0.97361\n",
            "[24]\ttrain-aucpr:0.99979\teval-aucpr:0.97368\n",
            "[25]\ttrain-aucpr:0.99981\teval-aucpr:0.97377\n",
            "[26]\ttrain-aucpr:0.99984\teval-aucpr:0.97416\n",
            "[27]\ttrain-aucpr:0.99986\teval-aucpr:0.97417\n",
            "[28]\ttrain-aucpr:0.99988\teval-aucpr:0.97444\n",
            "[29]\ttrain-aucpr:0.99989\teval-aucpr:0.97455\n",
            "[30]\ttrain-aucpr:0.99990\teval-aucpr:0.97467\n",
            "[31]\ttrain-aucpr:0.99992\teval-aucpr:0.97456\n",
            "[32]\ttrain-aucpr:0.99992\teval-aucpr:0.97460\n",
            "[0]\ttrain-aucpr:0.95389\teval-aucpr:0.89182\n",
            "[1]\ttrain-aucpr:0.97926\teval-aucpr:0.92293\n",
            "[2]\ttrain-aucpr:0.98804\teval-aucpr:0.94113\n",
            "[3]\ttrain-aucpr:0.99160\teval-aucpr:0.94954\n",
            "[4]\ttrain-aucpr:0.99359\teval-aucpr:0.95398\n",
            "[5]\ttrain-aucpr:0.99518\teval-aucpr:0.95768\n",
            "[6]\ttrain-aucpr:0.99611\teval-aucpr:0.95992\n",
            "[7]\ttrain-aucpr:0.99687\teval-aucpr:0.96207\n",
            "[8]\ttrain-aucpr:0.99743\teval-aucpr:0.96387\n",
            "[9]\ttrain-aucpr:0.99787\teval-aucpr:0.96550\n",
            "[10]\ttrain-aucpr:0.99821\teval-aucpr:0.96689\n",
            "[11]\ttrain-aucpr:0.99849\teval-aucpr:0.96811\n",
            "[12]\ttrain-aucpr:0.99871\teval-aucpr:0.96917\n",
            "[13]\ttrain-aucpr:0.99892\teval-aucpr:0.96982\n",
            "[14]\ttrain-aucpr:0.99910\teval-aucpr:0.97061\n",
            "[15]\ttrain-aucpr:0.99922\teval-aucpr:0.97151\n",
            "[16]\ttrain-aucpr:0.99934\teval-aucpr:0.97218\n",
            "[17]\ttrain-aucpr:0.99942\teval-aucpr:0.97272\n",
            "[18]\ttrain-aucpr:0.99950\teval-aucpr:0.97318\n",
            "[19]\ttrain-aucpr:0.99955\teval-aucpr:0.97359\n",
            "[20]\ttrain-aucpr:0.99960\teval-aucpr:0.97393\n",
            "[21]\ttrain-aucpr:0.99965\teval-aucpr:0.97421\n",
            "[22]\ttrain-aucpr:0.99971\teval-aucpr:0.97466\n",
            "[23]\ttrain-aucpr:0.99976\teval-aucpr:0.97477\n",
            "[24]\ttrain-aucpr:0.99979\teval-aucpr:0.97494\n",
            "[25]\ttrain-aucpr:0.99982\teval-aucpr:0.97510\n",
            "[26]\ttrain-aucpr:0.99985\teval-aucpr:0.97519\n",
            "[27]\ttrain-aucpr:0.99987\teval-aucpr:0.97508\n",
            "[28]\ttrain-aucpr:0.99989\teval-aucpr:0.97510\n",
            "[29]\ttrain-aucpr:0.99990\teval-aucpr:0.97524\n",
            "[30]\ttrain-aucpr:0.99992\teval-aucpr:0.97532\n",
            "[31]\ttrain-aucpr:0.99992\teval-aucpr:0.97540\n",
            "[32]\ttrain-aucpr:0.99994\teval-aucpr:0.97543\n",
            "[33]\ttrain-aucpr:0.99995\teval-aucpr:0.97546\n",
            "[34]\ttrain-aucpr:0.99996\teval-aucpr:0.97538\n",
            "[35]\ttrain-aucpr:0.99996\teval-aucpr:0.97542\n",
            "[36]\ttrain-aucpr:0.99997\teval-aucpr:0.97559\n",
            "[37]\ttrain-aucpr:0.99997\teval-aucpr:0.97573\n",
            "[38]\ttrain-aucpr:0.99997\teval-aucpr:0.97585\n",
            "[39]\ttrain-aucpr:0.99998\teval-aucpr:0.97588\n",
            "[40]\ttrain-aucpr:0.99998\teval-aucpr:0.97606\n",
            "[41]\ttrain-aucpr:0.99998\teval-aucpr:0.97605\n",
            "[42]\ttrain-aucpr:0.99998\teval-aucpr:0.97608\n",
            "[43]\ttrain-aucpr:0.99999\teval-aucpr:0.97617\n",
            "[44]\ttrain-aucpr:0.99999\teval-aucpr:0.97615\n",
            "[45]\ttrain-aucpr:0.99999\teval-aucpr:0.97626\n",
            "[46]\ttrain-aucpr:0.99999\teval-aucpr:0.97627\n",
            "[47]\ttrain-aucpr:0.99999\teval-aucpr:0.97628\n",
            "[48]\ttrain-aucpr:0.99999\teval-aucpr:0.97625\n",
            "[49]\ttrain-aucpr:0.99999\teval-aucpr:0.97625\n",
            "[0]\ttrain-aucpr:0.95668\teval-aucpr:0.89415\n",
            "[1]\ttrain-aucpr:0.98030\teval-aucpr:0.92624\n",
            "[2]\ttrain-aucpr:0.98831\teval-aucpr:0.94263\n",
            "[3]\ttrain-aucpr:0.99196\teval-aucpr:0.94928\n",
            "[4]\ttrain-aucpr:0.99399\teval-aucpr:0.95456\n",
            "[5]\ttrain-aucpr:0.99531\teval-aucpr:0.95837\n",
            "[6]\ttrain-aucpr:0.99618\teval-aucpr:0.96045\n",
            "[7]\ttrain-aucpr:0.99676\teval-aucpr:0.96272\n",
            "[8]\ttrain-aucpr:0.99727\teval-aucpr:0.96439\n",
            "[9]\ttrain-aucpr:0.99772\teval-aucpr:0.96607\n",
            "[10]\ttrain-aucpr:0.99814\teval-aucpr:0.96754\n",
            "[11]\ttrain-aucpr:0.99844\teval-aucpr:0.96860\n",
            "[12]\ttrain-aucpr:0.99872\teval-aucpr:0.96976\n",
            "[13]\ttrain-aucpr:0.99892\teval-aucpr:0.97070\n",
            "[14]\ttrain-aucpr:0.99908\teval-aucpr:0.97156\n",
            "[15]\ttrain-aucpr:0.99920\teval-aucpr:0.97240\n",
            "[16]\ttrain-aucpr:0.99931\teval-aucpr:0.97307\n",
            "[17]\ttrain-aucpr:0.99939\teval-aucpr:0.97372\n",
            "[18]\ttrain-aucpr:0.99947\teval-aucpr:0.97418\n",
            "[19]\ttrain-aucpr:0.99954\teval-aucpr:0.97455\n",
            "[20]\ttrain-aucpr:0.99961\teval-aucpr:0.97491\n",
            "[21]\ttrain-aucpr:0.99966\teval-aucpr:0.97538\n",
            "[22]\ttrain-aucpr:0.99971\teval-aucpr:0.97567\n",
            "[23]\ttrain-aucpr:0.99975\teval-aucpr:0.97590\n",
            "[24]\ttrain-aucpr:0.99979\teval-aucpr:0.97590\n",
            "[25]\ttrain-aucpr:0.99981\teval-aucpr:0.97627\n",
            "[26]\ttrain-aucpr:0.99984\teval-aucpr:0.97651\n",
            "[27]\ttrain-aucpr:0.99986\teval-aucpr:0.97662\n",
            "[28]\ttrain-aucpr:0.99988\teval-aucpr:0.97660\n",
            "[29]\ttrain-aucpr:0.99989\teval-aucpr:0.97669\n",
            "[30]\ttrain-aucpr:0.99991\teval-aucpr:0.97669\n",
            "[31]\ttrain-aucpr:0.99992\teval-aucpr:0.97689\n",
            "[32]\ttrain-aucpr:0.99993\teval-aucpr:0.97691\n",
            "[33]\ttrain-aucpr:0.99994\teval-aucpr:0.97693\n",
            "[34]\ttrain-aucpr:0.99995\teval-aucpr:0.97701\n",
            "[35]\ttrain-aucpr:0.99996\teval-aucpr:0.97704\n",
            "[36]\ttrain-aucpr:0.99996\teval-aucpr:0.97710\n",
            "[37]\ttrain-aucpr:0.99997\teval-aucpr:0.97718\n",
            "[38]\ttrain-aucpr:0.99997\teval-aucpr:0.97715\n",
            "[39]\ttrain-aucpr:0.99997\teval-aucpr:0.97725\n",
            "[40]\ttrain-aucpr:0.99998\teval-aucpr:0.97723\n",
            "[41]\ttrain-aucpr:0.99998\teval-aucpr:0.97723\n",
            "[0]\ttrain-aucpr:0.96050\teval-aucpr:0.90412\n",
            "[1]\ttrain-aucpr:0.98301\teval-aucpr:0.93362\n",
            "[2]\ttrain-aucpr:0.98861\teval-aucpr:0.94422\n",
            "[3]\ttrain-aucpr:0.99201\teval-aucpr:0.95020\n",
            "[4]\ttrain-aucpr:0.99432\teval-aucpr:0.95433\n",
            "[5]\ttrain-aucpr:0.99537\teval-aucpr:0.95783\n",
            "[6]\ttrain-aucpr:0.99637\teval-aucpr:0.96039\n",
            "[7]\ttrain-aucpr:0.99708\teval-aucpr:0.96250\n",
            "[8]\ttrain-aucpr:0.99760\teval-aucpr:0.96421\n",
            "[9]\ttrain-aucpr:0.99804\teval-aucpr:0.96558\n",
            "[10]\ttrain-aucpr:0.99836\teval-aucpr:0.96678\n",
            "[11]\ttrain-aucpr:0.99866\teval-aucpr:0.96805\n",
            "[12]\ttrain-aucpr:0.99888\teval-aucpr:0.96879\n",
            "[13]\ttrain-aucpr:0.99903\teval-aucpr:0.96957\n",
            "[14]\ttrain-aucpr:0.99916\teval-aucpr:0.97067\n",
            "[15]\ttrain-aucpr:0.99926\teval-aucpr:0.97144\n",
            "[16]\ttrain-aucpr:0.99937\teval-aucpr:0.97214\n",
            "[17]\ttrain-aucpr:0.99947\teval-aucpr:0.97274\n",
            "[18]\ttrain-aucpr:0.99954\teval-aucpr:0.97309\n",
            "[19]\ttrain-aucpr:0.99960\teval-aucpr:0.97352\n",
            "[20]\ttrain-aucpr:0.99965\teval-aucpr:0.97406\n",
            "[21]\ttrain-aucpr:0.99968\teval-aucpr:0.97437\n",
            "[22]\ttrain-aucpr:0.99972\teval-aucpr:0.97473\n",
            "[23]\ttrain-aucpr:0.99976\teval-aucpr:0.97504\n",
            "[24]\ttrain-aucpr:0.99978\teval-aucpr:0.97514\n",
            "[25]\ttrain-aucpr:0.99981\teval-aucpr:0.97537\n",
            "[26]\ttrain-aucpr:0.99984\teval-aucpr:0.97548\n",
            "[27]\ttrain-aucpr:0.99987\teval-aucpr:0.97540\n",
            "[28]\ttrain-aucpr:0.99989\teval-aucpr:0.97537\n",
            "[29]\ttrain-aucpr:0.99991\teval-aucpr:0.97552\n",
            "[30]\ttrain-aucpr:0.99992\teval-aucpr:0.97552\n",
            "[31]\ttrain-aucpr:0.99993\teval-aucpr:0.97582\n",
            "[32]\ttrain-aucpr:0.99994\teval-aucpr:0.97592\n",
            "[33]\ttrain-aucpr:0.99995\teval-aucpr:0.97597\n",
            "[34]\ttrain-aucpr:0.99995\teval-aucpr:0.97606\n",
            "[35]\ttrain-aucpr:0.99996\teval-aucpr:0.97620\n",
            "[36]\ttrain-aucpr:0.99997\teval-aucpr:0.97616\n",
            "[37]\ttrain-aucpr:0.99997\teval-aucpr:0.97637\n",
            "[38]\ttrain-aucpr:0.99997\teval-aucpr:0.97643\n",
            "[39]\ttrain-aucpr:0.99998\teval-aucpr:0.97648\n",
            "[40]\ttrain-aucpr:0.99998\teval-aucpr:0.97656\n",
            "[41]\ttrain-aucpr:0.99998\teval-aucpr:0.97653\n",
            "[42]\ttrain-aucpr:0.99999\teval-aucpr:0.97656\n",
            "[43]\ttrain-aucpr:0.99999\teval-aucpr:0.97672\n",
            "[44]\ttrain-aucpr:0.99999\teval-aucpr:0.97683\n",
            "[45]\ttrain-aucpr:0.99999\teval-aucpr:0.97683\n",
            "[46]\ttrain-aucpr:0.99999\teval-aucpr:0.97674\n",
            "[47]\ttrain-aucpr:0.99999\teval-aucpr:0.97680\n",
            "[48]\ttrain-aucpr:0.99999\teval-aucpr:0.97686\n",
            "[49]\ttrain-aucpr:0.99999\teval-aucpr:0.97690\n",
            "[50]\ttrain-aucpr:1.00000\teval-aucpr:0.97692\n",
            "[51]\ttrain-aucpr:1.00000\teval-aucpr:0.97692\n",
            "[52]\ttrain-aucpr:1.00000\teval-aucpr:0.97694\n",
            "[53]\ttrain-aucpr:1.00000\teval-aucpr:0.97696\n",
            "[54]\ttrain-aucpr:1.00000\teval-aucpr:0.97695\n",
            "[55]\ttrain-aucpr:1.00000\teval-aucpr:0.97700\n",
            "[56]\ttrain-aucpr:1.00000\teval-aucpr:0.97708\n",
            "[57]\ttrain-aucpr:1.00000\teval-aucpr:0.97707\n",
            "[58]\ttrain-aucpr:1.00000\teval-aucpr:0.97707\n",
            "[0]\ttrain-aucpr:0.95526\teval-aucpr:0.89207\n",
            "[1]\ttrain-aucpr:0.98053\teval-aucpr:0.92346\n",
            "[2]\ttrain-aucpr:0.98756\teval-aucpr:0.93581\n",
            "[3]\ttrain-aucpr:0.99154\teval-aucpr:0.94481\n",
            "[4]\ttrain-aucpr:0.99347\teval-aucpr:0.95028\n",
            "[5]\ttrain-aucpr:0.99505\teval-aucpr:0.95517\n",
            "[6]\ttrain-aucpr:0.99602\teval-aucpr:0.95844\n",
            "[7]\ttrain-aucpr:0.99678\teval-aucpr:0.96033\n",
            "[8]\ttrain-aucpr:0.99731\teval-aucpr:0.96246\n",
            "[9]\ttrain-aucpr:0.99775\teval-aucpr:0.96381\n",
            "[10]\ttrain-aucpr:0.99818\teval-aucpr:0.96490\n",
            "[11]\ttrain-aucpr:0.99852\teval-aucpr:0.96617\n",
            "[12]\ttrain-aucpr:0.99875\teval-aucpr:0.96750\n",
            "[13]\ttrain-aucpr:0.99893\teval-aucpr:0.96857\n",
            "[14]\ttrain-aucpr:0.99911\teval-aucpr:0.96964\n",
            "[15]\ttrain-aucpr:0.99923\teval-aucpr:0.97056\n",
            "[16]\ttrain-aucpr:0.99935\teval-aucpr:0.97086\n",
            "[17]\ttrain-aucpr:0.99941\teval-aucpr:0.97151\n",
            "[18]\ttrain-aucpr:0.99949\teval-aucpr:0.97189\n",
            "[19]\ttrain-aucpr:0.99956\teval-aucpr:0.97235\n",
            "[20]\ttrain-aucpr:0.99962\teval-aucpr:0.97270\n",
            "[21]\ttrain-aucpr:0.99967\teval-aucpr:0.97309\n",
            "[22]\ttrain-aucpr:0.99971\teval-aucpr:0.97311\n",
            "[23]\ttrain-aucpr:0.99975\teval-aucpr:0.97344\n",
            "[24]\ttrain-aucpr:0.99979\teval-aucpr:0.97376\n",
            "[25]\ttrain-aucpr:0.99983\teval-aucpr:0.97370\n",
            "[26]\ttrain-aucpr:0.99985\teval-aucpr:0.97380\n",
            "[27]\ttrain-aucpr:0.99987\teval-aucpr:0.97411\n",
            "[28]\ttrain-aucpr:0.99989\teval-aucpr:0.97420\n",
            "[29]\ttrain-aucpr:0.99990\teval-aucpr:0.97440\n",
            "[30]\ttrain-aucpr:0.99992\teval-aucpr:0.97464\n",
            "[31]\ttrain-aucpr:0.99993\teval-aucpr:0.97469\n",
            "[32]\ttrain-aucpr:0.99994\teval-aucpr:0.97480\n",
            "[33]\ttrain-aucpr:0.99995\teval-aucpr:0.97476\n",
            "[34]\ttrain-aucpr:0.99995\teval-aucpr:0.97488\n",
            "[35]\ttrain-aucpr:0.99996\teval-aucpr:0.97492\n",
            "[36]\ttrain-aucpr:0.99997\teval-aucpr:0.97516\n",
            "[37]\ttrain-aucpr:0.99997\teval-aucpr:0.97531\n",
            "[38]\ttrain-aucpr:0.99998\teval-aucpr:0.97536\n",
            "[39]\ttrain-aucpr:0.99998\teval-aucpr:0.97541\n",
            "[40]\ttrain-aucpr:0.99998\teval-aucpr:0.97534\n",
            "[41]\ttrain-aucpr:0.99998\teval-aucpr:0.97539\n",
            "[42]\ttrain-aucpr:0.99998\teval-aucpr:0.97534\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds_m6 = np.zeros(len(y))\n",
        "for i in fold_results.keys():\n",
        "  for j in range(len(fold_results.get(i).get('predictions'))):\n",
        "    idx = fold_results.get(i).get('index')[j]\n",
        "    preds_m6[idx] = np.round(fold_results.get(i).get('predictions')[j], 0)"
      ],
      "metadata": {
        "id": "7hSFBjJSXmnc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m6_cost = cost_func(preds_m6,y)\n",
        "m6_cost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSw-zr1_YDa6",
        "outputId": "d0959827-067b-4cc8-c6ee-1d592f14cf65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1203450"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Results"
      ],
      "metadata": {
        "id": "OGDgxEMEAh0D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cm2df(cm, labels):\n",
        "    df = pd.DataFrame()\n",
        "    # rows\n",
        "    for i, row_label in enumerate(labels):\n",
        "        rowdata={}\n",
        "        # columns\n",
        "        for j, col_label in enumerate(labels):\n",
        "            rowdata[col_label]=cm[i,j]\n",
        "        df = df.append(pd.DataFrame.from_dict({row_label:rowdata}, orient='index'))\n",
        "    return df[labels]"
      ],
      "metadata": {
        "id": "OEGpLW4wYtS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm_preds_m1 = confusion_matrix(y,preds_m1)\n",
        "cm_preds_m2 = confusion_matrix(y,preds_m2)\n",
        "cm_preds_m4 = confusion_matrix(y,preds_m4)\n",
        "cm_preds_m5 = confusion_matrix(y,preds_m5)\n",
        "cm_preds_m6 = confusion_matrix(y,preds_m6)\n",
        "\n",
        "\n",
        "cm_preds_m1 = cm_preds_m1 / cm_preds_m1.astype(np.float).sum(axis=1)\n",
        "cm_preds_m2 = cm_preds_m2 / cm_preds_m2.astype(np.float).sum(axis=1)\n",
        "cm_preds_m4 = cm_preds_m4 / cm_preds_m4.astype(np.float).sum(axis=1)\n",
        "cm_preds_m5 = cm_preds_m5 / cm_preds_m5.astype(np.float).sum(axis=1)\n",
        "cm_preds_m6 = cm_preds_m6 / cm_preds_m6.astype(np.float).sum(axis=1)"
      ],
      "metadata": {
        "id": "obpbAgIWm1En"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Pos = pd.DataFrame(cm_preds_m1[:1], columns=['True Positive', 'False Positive'])\n",
        "Neg = pd.DataFrame(cm_preds_m1[1:], columns=['False Negative', 'True Negative'])\n",
        "Model = pd.DataFrame(['Logistic Regression'], columns=['Model'])\n",
        "Summary = pd.concat([Model, Pos, Neg], axis=1)\n",
        "\n",
        "Pos = pd.DataFrame(cm_preds_m2[:1], columns=['True Positive', 'False Positive'])\n",
        "Neg = pd.DataFrame(cm_preds_m2[1:], columns=['False Negative', 'True Negative'])\n",
        "Model = pd.DataFrame(['Random Forest'], columns=['Model'])\n",
        "Summary1 = (pd.concat([Model, Pos, Neg], axis=1))\n",
        "\n",
        "Summary = pd.concat([Summary, Summary1])\n",
        "\n",
        "Pos = pd.DataFrame(cm_preds_m4[:1], columns=['True Positive', 'False Positive'])\n",
        "Neg = pd.DataFrame(cm_preds_m4[1:], columns=['False Negative', 'True Negative'])\n",
        "Model = pd.DataFrame(['Neural Network'], columns=['Model'])\n",
        "Summary1 = (pd.concat([Model, Pos, Neg], axis=1))\n",
        "\n",
        "Summary = pd.concat([Summary, Summary1])\n",
        "\n",
        "Pos = pd.DataFrame(cm_preds_m5[:1], columns=['True Positive', 'False Positive'])\n",
        "Neg = pd.DataFrame(cm_preds_m5[1:], columns=['False Negative', 'True Negative'])\n",
        "Model = pd.DataFrame(['Neural Network 2'], columns=['Model'])\n",
        "Summary1 = (pd.concat([Model, Pos, Neg], axis=1))\n",
        "\n",
        "Summary = pd.concat([Summary, Summary1])\n",
        "\n",
        "Pos = pd.DataFrame(cm_preds_m6[:1], columns=['True Positive', 'False Positive'])\n",
        "Neg = pd.DataFrame(cm_preds_m6[1:], columns=['False Negative', 'True Negative'])\n",
        "Model = pd.DataFrame(['XGBoost'], columns=['Model'])\n",
        "Summary1 = (pd.concat([Model, Pos, Neg], axis=1))\n",
        "\n",
        "Summary = pd.concat([Summary, Summary1])\n",
        "Summary = Summary.reset_index()\n",
        "Summary = Summary.drop(columns=['index'])\n",
        "Summary = Summary.set_index('Model')\n",
        "\n",
        "Summary = Summary[['True Positive', 'True Negative', 'False Positive', 'False Negative']]\n",
        "\n",
        "\n",
        "Summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "vlrp5F7J_LqM",
        "outputId": "2944722d-96ea-4e36-8eac-81591faefed7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     True Positive  True Negative  False Positive  \\\n",
              "Model                                                               \n",
              "Logistic Regression            50%            85%             51%   \n",
              "Random Forest                  94%            91%              6%   \n",
              "Neural Network                 96%            97%              4%   \n",
              "Neural Network 2               96%            97%              4%   \n",
              "XGBoost                        94%            94%              6%   \n",
              "\n",
              "                     False Negative  \n",
              "Model                                \n",
              "Logistic Regression             15%  \n",
              "Random Forest                    9%  \n",
              "Neural Network                   3%  \n",
              "Neural Network 2                 3%  \n",
              "XGBoost                          5%  "
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-fc6ac2b6-4ed9-48c5-bcd3-ddd3a72365d9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>True Positive</th>\n",
              "      <th>True Negative</th>\n",
              "      <th>False Positive</th>\n",
              "      <th>False Negative</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Model</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Logistic Regression</th>\n",
              "      <td>50%</td>\n",
              "      <td>85%</td>\n",
              "      <td>51%</td>\n",
              "      <td>15%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Random Forest</th>\n",
              "      <td>94%</td>\n",
              "      <td>91%</td>\n",
              "      <td>6%</td>\n",
              "      <td>9%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Neural Network</th>\n",
              "      <td>96%</td>\n",
              "      <td>97%</td>\n",
              "      <td>4%</td>\n",
              "      <td>3%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Neural Network 2</th>\n",
              "      <td>96%</td>\n",
              "      <td>97%</td>\n",
              "      <td>4%</td>\n",
              "      <td>3%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XGBoost</th>\n",
              "      <td>94%</td>\n",
              "      <td>94%</td>\n",
              "      <td>6%</td>\n",
              "      <td>5%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fc6ac2b6-4ed9-48c5-bcd3-ddd3a72365d9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-2c10bb2f-608b-40e1-bb03-1064604a59be\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2c10bb2f-608b-40e1-bb03-1064604a59be')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-2c10bb2f-608b-40e1-bb03-1064604a59be button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fc6ac2b6-4ed9-48c5-bcd3-ddd3a72365d9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fc6ac2b6-4ed9-48c5-bcd3-ddd3a72365d9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 287
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap\n",
        "def wrap_labels(ax, width, break_long_words=False):\n",
        "    labels = []\n",
        "    for label in ax.get_xticklabels():\n",
        "        text = label.get_text()\n",
        "        labels.append(textwrap.fill(text, width=width,\n",
        "                      break_long_words=break_long_words))\n",
        "    ax.set_xticklabels(labels, rotation=0)\n",
        "\n",
        "ax = sns.heatmap(Summary, cmap='Blues', linewidths=0.50, annot=True)\n",
        "wrap_labels(ax, 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "id": "98yCyr-KCZjF",
        "outputId": "86130f0a-514f-4c5a-b4a9-e898f2dc4a74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 550x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Confusion Matrix of Results\n",
        "\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "cm_preds_m1 = confusion_matrix(y,preds_m1)\n",
        "cm_preds_m2 = confusion_matrix(y,preds_m2)\n",
        "cm_preds_m4 = confusion_matrix(y,preds_m4)\n",
        "cm_preds_m5 = confusion_matrix(y,preds_m5)\n",
        "cm_preds_m6 = confusion_matrix(y,preds_m6)\n",
        "\n",
        "fig, ax = plt.subplots(1,5,figsize= (20,4))\n",
        "\n",
        "disp1 = ConfusionMatrixDisplay(cm_preds_m1).plot(ax = ax[0],cmap = 'Blues', colorbar=False)\n",
        "ax[0].set_title('Logistic Regression'+ '\\n\\n' + ' Cost: '+ '$'+ str(f'{cost_m1:,}'), fontsize = 12)\n",
        "ax[0].grid(False)\n",
        "\n",
        "disp2 = ConfusionMatrixDisplay(cm_preds_m2).plot(ax= ax[1],cmap='Blues', colorbar=False)\n",
        "ax[1].set_title('Random Forest'+ '\\n\\n' + ' Cost: '+ '$'+ str(f'{cost_m2:,}'), fontsize = 12)\n",
        "ax[1].grid(False)\n",
        "\n",
        "\n",
        "disp3 = ConfusionMatrixDisplay(cm_preds_m4).plot(ax= ax[2],cmap='Blues', colorbar=False)\n",
        "ax[2].set_title('Neural Network'+ '\\n\\n' + ' Cost: '+ '$'+ str(f'{m4_cost:,}'), fontsize = 12)\n",
        "ax[2].grid(False)\n",
        "\n",
        "disp4 = ConfusionMatrixDisplay(cm_preds_m5).plot(ax= ax[3],cmap='Blues', colorbar=False)\n",
        "ax[3].set_title('Neural Network 2'+ '\\n\\n' + ' Cost: '+ '$'+ str(f'{m5_cost:,}'), fontsize = 12)\n",
        "ax[3].grid(False)\n",
        "\n",
        "disp5 = ConfusionMatrixDisplay(cm_preds_m6).plot(ax= ax[4],cmap='Blues', colorbar=False)\n",
        "ax[4].set_title('XGBoost'+ '\\n\\n' + ' Cost: '+ '$'+ str(f'{m6_cost:,}'), fontsize = 12)\n",
        "ax[4].grid(False)\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "hYPzNzlQ36Ct",
        "outputId": "e3c7e8de-09d3-4b0f-fb61-b7b673352f8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x400 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ensembling"
      ],
      "metadata": {
        "id": "lV6Za3-7SvNI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Combination of Neural Networks\n",
        "preds_nn = (preds_m4+ preds_m5)/2\n",
        "cost_nn= cost_func(np.round(preds_nn, 0), y)\n",
        "cm_preds_nn = confusion_matrix(y,np.round(preds_nn, 0))\n",
        "\n",
        "#Combination of Neural Networks and XGBoost\n",
        "preds_ens = (preds_m4+ preds_m5+preds_m6)/3\n",
        "cost_ens = cost_func(np.round(preds_ens, 0), y)\n",
        "cm_preds_ens = confusion_matrix(y,np.round(preds_ens, 0))\n",
        "\n",
        "#Combination of Neural Networks, XGBoost, and RF\n",
        "preds_ens2 = (preds_m2 + preds_m4+ preds_m5+preds_m6)/4\n",
        "cost_ens2 = cost_func(np.round(preds_ens2, 0), y)\n",
        "cm_preds_ens2= confusion_matrix(y,np.round(preds_ens2, 0))"
      ],
      "metadata": {
        "id": "2oJ4cy59VAFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1,3,figsize= (20,4))\n",
        "\n",
        "disp1 = ConfusionMatrixDisplay(cm_preds_nn).plot(ax = ax[0],cmap = 'Blues', colorbar=False)\n",
        "ax[0].set_title('Combined Neural Networks'+ '\\n\\n' + ' Cost: '+ '$'+ str(f'{cost_nn:,}'), fontsize = 12)\n",
        "ax[0].grid(False)\n",
        "\n",
        "disp1 = ConfusionMatrixDisplay(cm_preds_ens).plot(ax = ax[1],cmap = 'Blues', colorbar=False)\n",
        "ax[1].set_title('Neural Networks and XGBoost'+ '\\n\\n' + ' Cost: '+ '$'+ str(f'{cost_ens:,}'), fontsize = 12)\n",
        "ax[1].grid(False)\n",
        "\n",
        "disp1 = ConfusionMatrixDisplay(cm_preds_ens2).plot(ax = ax[2],cmap = 'Blues', colorbar=False)\n",
        "ax[2].set_title('Neural Networks, XGBoost, and Random Forest'+ '\\n\\n' + ' Cost: '+ '$'+ str(f'{cost_ens2:,}'), fontsize = 12)\n",
        "ax[2].grid(False)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "J71VGqBYU7hF",
        "outputId": "47aba4f4-48a9-493e-a051-c4113650e4f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x400 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Combination of Neural Networks\n",
        "preds_nn = np.minimum(preds_m4,preds_m5)\n",
        "cost_nn= cost_func(np.round(preds_nn, 0), y)\n",
        "cm_preds_nn = confusion_matrix(y,np.round(preds_nn, 0))\n",
        "\n",
        "#Combination of Neural Networks and XGBoost\n",
        "preds_ens = np.minimum(preds_m5,preds_m6)\n",
        "cost_ens = cost_func(np.round(preds_ens, 0), y)\n",
        "cm_preds_ens = confusion_matrix(y,np.round(preds_ens, 0))\n",
        "\n",
        "#Combination of Neural Networks, XGBoost, and RF\n",
        "preds_ens2 = np.minimum(preds_m2,preds_ens)\n",
        "cost_ens2 = cost_func(np.round(preds_ens2, 0), y)\n",
        "cm_preds_ens2= confusion_matrix(y,np.round(preds_ens2, 0))"
      ],
      "metadata": {
        "id": "lAQC40zKZieU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}